{
  "experiment_name": "E28-G4OMFT-ELFT-P",
  "start_time": "2025-03-26 05:44:21",
  "notes": "Experiment 28: Evaluate combined impact of fine-tuning and prompt collaboration between GPT-4o-mini and Electra Large fine-tuned model",
  "instance": "electra_large_gpt_sentiment",
  "dataset_shape": [
    6530,
    4
  ],
  "examples_length": 6530,
  "results_shape": [
    6530,
    7
  ],
  "save_directory": "results_round2_take2",
  "temperature": 0.1,
  "random_seed": 123,
  "merged_local": {
    "negative": {
      "precision": 0.8752151462994836,
      "recall": 0.8647959183673469,
      "f1-score": 0.8699743370402053,
      "support": 2352.0
    },
    "neutral": {
      "precision": 0.7593092282784674,
      "recall": 0.7692728266812466,
      "f1-score": 0.7642585551330798,
      "support": 1829.0
    },
    "positive": {
      "precision": 0.8810029749256268,
      "recall": 0.8825031928480205,
      "f1-score": 0.8817524457677584,
      "support": 2349.0
    },
    "accuracy": 0.8444104134762634,
    "macro avg": {
      "precision": 0.8385091165011925,
      "recall": 0.8388573126322046,
      "f1-score": 0.8386617793136812,
      "support": 6530.0
    },
    "weighted avg": {
      "precision": 0.8448328622845329,
      "recall": 0.8444104134762634,
      "f1-score": 0.8446010770544304,
      "support": 6530.0
    }
  },
  "dynasent_r1": {
    "negative": {
      "precision": 0.9281818181818182,
      "recall": 0.8508333333333333,
      "f1-score": 0.8878260869565218,
      "support": 1200.0
    },
    "neutral": {
      "precision": 0.7985611510791367,
      "recall": 0.925,
      "f1-score": 0.8571428571428571,
      "support": 1200.0
    },
    "positive": {
      "precision": 0.9153153153153153,
      "recall": 0.8466666666666667,
      "f1-score": 0.8796536796536797,
      "support": 1200.0
    },
    "accuracy": 0.8741666666666666,
    "macro avg": {
      "precision": 0.8806860948587567,
      "recall": 0.8741666666666666,
      "f1-score": 0.8748742079176862,
      "support": 3600.0
    },
    "weighted avg": {
      "precision": 0.8806860948587567,
      "recall": 0.8741666666666666,
      "f1-score": 0.8748742079176861,
      "support": 3600.0
    }
  },
  "dynasent_r2": {
    "negative": {
      "precision": 0.7984790874524715,
      "recall": 0.875,
      "f1-score": 0.8349900596421471,
      "support": 240.0
    },
    "neutral": {
      "precision": 0.8412698412698413,
      "recall": 0.6625,
      "f1-score": 0.7412587412587412,
      "support": 240.0
    },
    "positive": {
      "precision": 0.7798507462686567,
      "recall": 0.8708333333333333,
      "f1-score": 0.8228346456692913,
      "support": 240.0
    },
    "accuracy": 0.8027777777777778,
    "macro avg": {
      "precision": 0.8065332249969899,
      "recall": 0.8027777777777777,
      "f1-score": 0.7996944821900599,
      "support": 720.0
    },
    "weighted avg": {
      "precision": 0.8065332249969899,
      "recall": 0.8027777777777778,
      "f1-score": 0.7996944821900598,
      "support": 720.0
    }
  },
  "sst_local": {
    "negative": {
      "precision": 0.8355879292403746,
      "recall": 0.8804824561403509,
      "f1-score": 0.8574479444741057,
      "support": 912.0
    },
    "neutral": {
      "precision": 0.5036496350364964,
      "recall": 0.35475578406169667,
      "f1-score": 0.416289592760181,
      "support": 389.0
    },
    "positive": {
      "precision": 0.8697435897435898,
      "recall": 0.9328932893289329,
      "f1-score": 0.9002123142250531,
      "support": 909.0
    },
    "accuracy": 0.8095022624434389,
    "macro avg": {
      "precision": 0.7363270513401536,
      "recall": 0.7227105098436603,
      "f1-score": 0.7246499504864466,
      "support": 2210.0
    },
    "weighted avg": {
      "precision": 0.7912094219788878,
      "recall": 0.8095022624434389,
      "f1-score": 0.7973855975450986,
      "support": 2210.0
    }
  }
}