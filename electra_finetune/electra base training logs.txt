Last login: Fri Oct 18 21:33:27 on ttys008

The default interactive shell is now zsh.
To update your account to use zsh, please run `chsh -s /bin/zsh`.
For more details, please visit https://support.apple.com/kb/HT208050.
(base) Jims-MBP:~ jim$ ssh ubuntu@104.171.203.160
The authenticity of host '104.171.203.160 (104.171.203.160)' can't be established.
ED25519 key fingerprint is SHA256:0fMGWInJ62cf+UehvonR7xJQH7F1rMSMwUMR7akYwbQ.
This key is not known by any other names
Are you sure you want to continue connecting (yes/no/[fingerprint])? yes
Warning: Permanently added '104.171.203.160' (ED25519) to the list of known hosts.
Enter passphrase for key '/Users/jim/.ssh/id_rsa': 
Welcome to Ubuntu 22.04.3 LTS (GNU/Linux 6.2.0-37-generic x86_64)
 .============.
 ||   __      ||    _                    _         _
 ||   \_\     ||   | |    __ _ _ __ ___ | |__   __| | __ _
 ||    \_\    ||   | |   / _` | '_ ` _ \| '_ \ / _` |/ _` |
 ||   /_Î»_\   ||   | |__| (_| | | | | | | |_) | (_| | (_| |
 ||  /_/ \_\  ||   |_____\__,_|_| |_| |_|_.__/ \__,_|\__,_|
  .============.                                  GPU CLOUD

 * Documentation:  https://help.ubuntu.com
 * Management:     https://landscape.canonical.com
 * Support:        https://ubuntu.com/advantage

  System information as of Sun Oct 20 01:54:08 UTC 2024

  System load:  0.0908203125     Processes:                901
  Usage of /:   0.4% of 5.68TB   Users logged in:          0
  Memory usage: 0%               IPv4 address for docker0: 172.17.0.1
  Swap usage:   0%               IPv4 address for eno1:    104.171.203.160


Expanded Security Maintenance for Applications is not enabled.

4 updates can be applied immediately.
4 of these updates are standard security updates.
To see these additional updates run: apt list --upgradable

17 additional security updates can be applied with ESM Apps.
Learn more about enabling ESM Apps service at https://ubuntu.com/esm


The list of available updates is more than a week old.
To check for new updates run: sudo apt update

ubuntu@104-171-203-160:~$ cd nlp-test/sentiment/
ubuntu@104-171-203-160:~/nlp-test/sentiment$ source nlp/bin/activate
(nlp) ubuntu@104-171-203-160:~/nlp-test/sentiment$ wandb login
wandb: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)
wandb: You can find your API key in your browser here: https://wandb.ai/authorize
wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit: 
wandb: Appending key for api.wandb.ai to your netrc file: /home/ubuntu/.netrc
(nlp) ubuntu@104-171-203-160:~/nlp-test/sentiment$ python ./ddp_sentiment_finetune.py --dataset 'merged_local' --weights_name 'google/electra-base-discriminator' --save_data --save_model --save_pickle --save_preds --lr 0.00002 --epochs 100 --pooling 'mean' --dropout_rate 0.3 --num_layers 2 --hidden_dim 1024 --hidden_activation 'swishglu' --batch_size 16 --accumulation_steps 2 --finetune_bert --finetune_layers 12 --l2_strength 0.01 --checkpoint_interval 5 --use_zero --optimizer 'adamw' --scheduler 'cosine_warmup' --scheduler_kwargs '{"T_0":5, "T_mult":1, "eta_min":1e-7}' --show_progress --wandb --wandb_project 'Electra Multi-class' --wandb_run 'multi_run_1'

Starting DDP PyTorch Training...
Device: cuda, Number of GPUs: 8
Spawning 8 processes...
Rank 7 - Device: cuda:7
Rank 4 - Device: cuda:4
Rank 2 - Device: cuda:2
Rank 5 - Device: cuda:5
Rank 6 - Device: cuda:6
Rank 1 - Device: cuda:1
Rank 3 - Device: cuda:3
Rank 0 - Device: cuda:0
8 process groups initialized with 'nccl' backend on localhost:12355
NCCL Timeout: 1 hr 0 min. NCCL Blocking Wait: Enabled
wandb: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.
tokenizer_config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48.0/48.0 [00:00<00:00, 114kB/s]
config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 666/666 [00:00<00:00, 2.39MB/s]
An error occurred during training: [Errno 2] No such file or directory: '/home/ubuntu/.cache/huggingface/hub/models--google--electra-base-discriminator/snapshots/1ae76a97c7e84a4e640876a07453fccd636f0667/config.json'
Traceback (most recent call last):
  File "/home/ubuntu/nlp-test/sentiment/ddp_sentiment_finetune.py", line 1044, in main
    tokenizer, transformer_model = initialize_transformer_model(weights_name, device, rank, debug)
  File "/home/ubuntu/nlp-test/sentiment/ddp_sentiment_finetune.py", line 189, in initialize_transformer_model
    tokenizer = AutoTokenizer.from_pretrained(weights_name)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py", line 773, in from_pretrained
    config = AutoConfig.from_pretrained(
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py", line 1100, in from_pretrained
    config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/transformers/configuration_utils.py", line 634, in get_config_dict
    config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/transformers/configuration_utils.py", line 719, in _get_config_dict
    config_dict = cls._dict_from_json_file(resolved_config_file)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/transformers/configuration_utils.py", line 816, in _dict_from_json_file
    with open(json_file, "r", encoding="utf-8") as reader:
FileNotFoundError: [Errno 2] No such file or directory: '/home/ubuntu/.cache/huggingface/hub/models--google--electra-base-discriminator/snapshots/1ae76a97c7e84a4e640876a07453fccd636f0667/config.json'
vocab.txt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 232k/232k [00:00<00:00, 3.98MB/s]
tokenizer.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 466k/466k [00:00<00:00, 4.95MB/s]
wandb: Currently logged in as: jbeno (jimbeno). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.3
wandb: Run data is saved locally in /home/ubuntu/nlp-test/sentiment/wandb/run-20241020_015742-wqy5eftb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run multi_run_1
wandb: â­ï¸ View project at https://wandb.ai/jimbeno/Electra%20Multi-class
wandb: ðŸš€ View run at https://wandb.ai/jimbeno/Electra%20Multi-class/runs/wqy5eftb
Wand run initialized.

Initializing 'google/electra-base-discriminator' tokenizer and model...
pytorch_model.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 440M/440M [00:02<00:00, 194MB/s]
^C
Ctrl+C received. Terminating all processes...
Rank 0 - Current process: MainProcess cleaning up...
Terminating all child processes of MainProcess...
Terminated child process: SpawnProcess-7
Terminated child process: SpawnProcess-3
Terminated child process: SpawnProcess-6
Terminated child process: SpawnProcess-2
Terminated child process: SpawnProcess-5
Terminated child process: SpawnProcess-1
Terminated child process: SpawnProcess-4
Terminated child process: SpawnProcess-8
Rank 0 - Exiting program...
/usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 3 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
(nlp) ubuntu@104-171-203-160:~/nlp-test/sentiment$ python ./ddp_sentiment_finetune.py --dataset 'merged_local' --weights_name 'google/electra-base-discriminator' --save_data --save_model --save_pickle --save_preds --lr 0.00002 --epochs 100 --pooling 'mean' --dropout_rate 0.3 --num_layers 2 --hidden_dim 1024 --hidden_activation 'swishglu' --batch_size 16 --accumulation_steps 2 --finetune_bert --finetune_layers 12 --l2_strength 0.01 --checkpoint_interval 5 --use_zero --optimizer 'adamw' --scheduler 'cosine_warmup' --scheduler_kwargs '{"T_0":5, "T_mult":1, "eta_min":1e-7}' --show_progress --wandb --wandb_project 'Electra Multi-class' --wandb_run 'multi_run_1'

Starting DDP PyTorch Training...
Device: cuda, Number of GPUs: 8
Spawning 8 processes...
Rank 7 - Device: cuda:7
Rank 6 - Device: cuda:6
Rank 3 - Device: cuda:3
Rank 1 - Device: cuda:1
Rank 4 - Device: cuda:4
Rank 2 - Device: cuda:2
Rank 5 - Device: cuda:5
Rank 0 - Device: cuda:0
8 process groups initialized with 'nccl' backend on localhost:12355
NCCL Timeout: 1 hr 0 min. NCCL Blocking Wait: Enabled
wandb: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: jbeno (jimbeno). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.3
wandb: Run data is saved locally in /home/ubuntu/nlp-test/sentiment/wandb/run-20241020_015857-6jw12a9u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run multi_run_1
wandb: â­ï¸ View project at https://wandb.ai/jimbeno/Electra%20Multi-class
wandb: ðŸš€ View run at https://wandb.ai/jimbeno/Electra%20Multi-class/runs/6jw12a9u
Wand run initialized.

Initializing 'google/electra-base-discriminator' tokenizer and model...
Tokenizer and model initialized (1s)

Loading data...
Using the same dataset for training and evaluation
Train Data: Merged DynaSent Round 1, Round 2 and SST from Local: 'data/merged'
Dev Data: Merged DynaSent Round 1, Round 2 and SST from Local: 'data/merged'
Train size: 102097, Dev size: 5421
Train label distribution:
	      Negative: 21910
	       Neutral: 49148
	      Positive: 31039
Dev label distribution:
	      Negative: 1868
	       Neutral: 1669
	      Positive: 1884
Data loaded (365ms)

Processing data...
(Batch size: 16, Pooling: Mean, Fine Tune BERT: True, Chunk size: None)...
Extracting sentences and labels...

Data saved to: saves/data_8_gpu_20241020-015900.npz
X Train shape: [102097], X Dev shape: [5421]
y Train shape: [102097], y Dev shape: [5421]
Data processed (698ms)

Initializing DDP Neural Classifier...
Layers: 2, Hidden Dim: 1024, Hidden Act: SwishGLU, Dropout: 0.3, Optimizer: AdamW, L2 Strength: 0.01, Pooling: MEAN, Accumulation Steps: 2, Max Grad Norm: None
Batch Size: 16, Max Epochs: 100, LR: 2e-05, Early Stop: None, Fine-tune BERT: True, Fine-tune Layers: 12, Freeze BERT: False, Target Score: None, Interactive: False
Classifier initialized (14ms)

Fitting DDP Neural Classifier on training data...
Num Workers: 0, Prefetch: None
Building dataset and dataloader...
Training without early stopping. No validation set required, all data used for training.
Training will stop after 100 iterations.
Initializing model, graph, optimizer...
BERT's original pooler removed. Using custom pooling type: mean
BERT has 108,891,648 trainable parameters and 0 non-trainable parameters
Number of BERT layers requiring gradients: 12 out of 12
Fine-tuning the last 12 out of 12 BERT layers

Model Architecture Summary:
BERTClassifier(
  (bert): ElectraModel(
    (embeddings): ElectraEmbeddings(
      (word_embeddings): Embedding(30522, 768, padding_idx=0)
      (position_embeddings): Embedding(512, 768)
      (token_type_embeddings): Embedding(2, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): ElectraEncoder(
      (layer): ModuleList(
        (0-11): 12 x ElectraLayer(
          (attention): ElectraAttention(
            (self): ElectraSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): ElectraSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): ElectraIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): ElectraOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
  (custom_pooling): PoolingLayer()
  (classifier): Classifier(
    (layers): Sequential(
      (0): Linear(in_features=768, out_features=1024, bias=True)
      (1): SwishGLU(
        (projection): Linear(in_features=1024, out_features=2048, bias=True)
        (activation): SiLU()
      )
      (2): Dropout(p=0.3, inplace=False)
      (3): Linear(in_features=1024, out_features=1024, bias=True)
      (4): SwishGLU(
        (projection): Linear(in_features=1024, out_features=2048, bias=True)
        (activation): SiLU()
      )
      (5): Dropout(p=0.3, inplace=False)
      (6): Linear(in_features=1024, out_features=3, bias=True)
    )
  )
)

Model Parameters:
  bert.embeddings.word_embeddings: 23,440,896 (trainable)
  bert.embeddings.position_embeddings: 393,216 (trainable)
  bert.embeddings.token_type_embeddings: 1,536 (trainable)
  bert.embeddings.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.0.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.0.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.0.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.0.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.0.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.0.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.0.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.0.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.1.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.1.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.1.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.1.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.1.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.1.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.1.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.1.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.2.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.2.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.2.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.2.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.2.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.2.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.2.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.2.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.3.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.3.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.3.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.3.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.3.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.3.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.3.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.3.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.4.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.4.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.4.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.4.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.4.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.4.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.4.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.4.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.5.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.5.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.5.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.5.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.5.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.5.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.5.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.5.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.6.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.6.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.6.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.6.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.6.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.6.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.6.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.6.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.7.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.7.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.7.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.7.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.7.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.7.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.7.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.7.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.8.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.8.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.8.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.8.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.8.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.8.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.8.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.8.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.9.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.9.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.9.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.9.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.9.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.9.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.9.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.9.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.10.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.10.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.10.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.10.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.10.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.10.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.10.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.10.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.11.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.11.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.11.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.11.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.11.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.11.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.11.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.11.output.LayerNorm: 1,536 (trainable)
  classifier.layers.0: 787,456 (trainable)
  classifier.layers.1.projection: 2,099,200 (trainable)
  classifier.layers.3: 1,049,600 (trainable)
  classifier.layers.6: 3,075 (trainable)

Total layers: 104
Trainable layers: 104
Total parameters: 112,830,979
Trainable parameters: 112,830,979
Percentage of trainable parameters: 100.00%
Using optimizer: AdamW, Use Zero: True, Learning Rate: 2e-05, L2 strength: 0.01
Using scheduler: CosineAnnealingWarmRestarts
Scheduler arguments:
- T_0: 5
- T_mult: 1
- eta_min: 1e-07

Starting training loop...
Start epoch: 1, Max Iterations: 100, Early Stop: None, Tolerance: 0.00001, Number Iterations No Change: 5
Epoch 1/100:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                | 382/798 [03:07<03:21,  2.06it/s, loss=0.8430, lr=1.96e-05, grad=M:0.0989]^C
Ctrl+C received. Terminating all processes...
Rank 0 - Current process: MainProcess cleaning up...
Terminating all child processes of MainProcess...
Terminated child process: SpawnProcess-2
Terminated child process: SpawnProcess-7
Terminated child process: SpawnProcess-6
Terminated child process: SpawnProcess-1
Terminated child process: SpawnProcess-5

KeyboardInterrupt received. Terminating all processes...

KeyboardInterrupt received. Terminating all processes...
Terminated child process: SpawnProcess-4
Terminated child process: SpawnProcess-8
Terminated child process: SpawnProcess-3
Rank 0 - Exiting program...
/usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
(nlp) ubuntu@104-171-203-160:~/nlp-test/sentiment$ python ./ddp_sentiment_finetune.py --dataset 'merged_local' --weights_name 'google/electra-base-discriminator' --save_data --save_model --save_pickle --save_preds --lr 0.00002 --epochs 100 --pooling 'mean' --dropout_rate 0.3 --num_layers 2 --hidden_dim 1024 --hidden_activation 'swishglu' --batch_size 16 --accumulation_steps 2 --finetune_bert --finetune_layers 12 --l2_strength 0.01 --checkpoint_interval 5 --use_zero --optimizer 'adamw' --scheduler 'cosine_warmup' --scheduler_kwargs '{"T_0":5, "T_mult":1, "eta_min":1e-7}' --decimal 6 --val_percent 0.2 --early_stop 'score' --n_iter_no_change 100 --show_progress --wandb --wandb_project 'Electra Multi-class' --wandb_run 'multi_run_1'

Starting DDP PyTorch Training...
Device: cuda, Number of GPUs: 8
Spawning 8 processes...
Rank 7 - Device: cuda:7
Rank 6 - Device: cuda:6
Rank 5 - Device: cuda:5
Rank 1 - Device: cuda:1
Rank 3 - Device: cuda:3
Rank 2 - Device: cuda:2
Rank 4 - Device: cuda:4
Rank 0 - Device: cuda:0
8 process groups initialized with 'nccl' backend on localhost:12355
NCCL Timeout: 1 hr 0 min. NCCL Blocking Wait: Enabled
wandb: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: jbeno (jimbeno). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.3
wandb: Run data is saved locally in /home/ubuntu/nlp-test/sentiment/wandb/run-20241020_020334-69iibd78
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run multi_run_1
wandb: â­ï¸ View project at https://wandb.ai/jimbeno/Electra%20Multi-class
wandb: ðŸš€ View run at https://wandb.ai/jimbeno/Electra%20Multi-class/runs/69iibd78
Wand run initialized.

Initializing 'google/electra-base-discriminator' tokenizer and model...
Tokenizer and model initialized (1s)

Loading data...
Using the same dataset for training and evaluation
Train Data: Merged DynaSent Round 1, Round 2 and SST from Local: 'data/merged'
Dev Data: Merged DynaSent Round 1, Round 2 and SST from Local: 'data/merged'
Train size: 102097, Dev size: 5421
Train label distribution:
	      Negative: 21910
	       Neutral: 49148
	      Positive: 31039
Dev label distribution:
	      Negative: 1868
	       Neutral: 1669
	      Positive: 1884
Data loaded (284ms)

Processing data...
(Batch size: 16, Pooling: Mean, Fine Tune BERT: True, Chunk size: None)...
Extracting sentences and labels...

Data saved to: saves/data_8_gpu_20241020-020337.npz
X Train shape: [102097], X Dev shape: [5421]
y Train shape: [102097], y Dev shape: [5421]
Data processed (704ms)

Initializing DDP Neural Classifier...
Layers: 2, Hidden Dim: 1024, Hidden Act: SwishGLU, Dropout: 0.3, Optimizer: AdamW, L2 Strength: 0.01, Pooling: MEAN, Accumulation Steps: 2, Max Grad Norm: None
Batch Size: 16, Max Epochs: 100, LR: 2e-05, Early Stop: score, Fine-tune BERT: True, Fine-tune Layers: 12, Freeze BERT: False, Target Score: None, Interactive: False
Classifier initialized (15ms)

Fitting DDP Neural Classifier on training data...
Num Workers: 0, Prefetch: None
Building dataset and dataloader...
Score-based early stopping enabled (macro average F1 score against validation set). Validation fraction: 0.2
Training will stop early if the score does not improve by at least 0.00001 for 100 iterations.
Split data into (X:81677, y:81677) Training samples, and (X:20420, y:20420) Validation samples.
Initializing model, graph, optimizer...
BERT's original pooler removed. Using custom pooling type: mean
BERT has 108,891,648 trainable parameters and 0 non-trainable parameters
Number of BERT layers requiring gradients: 12 out of 12
Fine-tuning the last 12 out of 12 BERT layers

Model Architecture Summary:
BERTClassifier(
  (bert): ElectraModel(
    (embeddings): ElectraEmbeddings(
      (word_embeddings): Embedding(30522, 768, padding_idx=0)
      (position_embeddings): Embedding(512, 768)
      (token_type_embeddings): Embedding(2, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): ElectraEncoder(
      (layer): ModuleList(
        (0-11): 12 x ElectraLayer(
          (attention): ElectraAttention(
            (self): ElectraSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): ElectraSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): ElectraIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): ElectraOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
  (custom_pooling): PoolingLayer()
  (classifier): Classifier(
    (layers): Sequential(
      (0): Linear(in_features=768, out_features=1024, bias=True)
      (1): SwishGLU(
        (projection): Linear(in_features=1024, out_features=2048, bias=True)
        (activation): SiLU()
      )
      (2): Dropout(p=0.3, inplace=False)
      (3): Linear(in_features=1024, out_features=1024, bias=True)
      (4): SwishGLU(
        (projection): Linear(in_features=1024, out_features=2048, bias=True)
        (activation): SiLU()
      )
      (5): Dropout(p=0.3, inplace=False)
      (6): Linear(in_features=1024, out_features=3, bias=True)
    )
  )
)

Model Parameters:
  bert.embeddings.word_embeddings: 23,440,896 (trainable)
  bert.embeddings.position_embeddings: 393,216 (trainable)
  bert.embeddings.token_type_embeddings: 1,536 (trainable)
  bert.embeddings.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.0.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.0.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.0.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.0.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.0.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.0.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.0.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.0.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.1.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.1.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.1.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.1.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.1.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.1.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.1.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.1.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.2.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.2.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.2.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.2.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.2.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.2.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.2.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.2.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.3.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.3.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.3.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.3.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.3.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.3.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.3.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.3.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.4.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.4.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.4.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.4.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.4.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.4.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.4.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.4.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.5.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.5.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.5.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.5.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.5.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.5.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.5.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.5.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.6.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.6.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.6.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.6.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.6.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.6.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.6.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.6.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.7.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.7.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.7.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.7.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.7.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.7.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.7.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.7.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.8.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.8.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.8.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.8.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.8.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.8.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.8.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.8.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.9.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.9.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.9.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.9.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.9.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.9.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.9.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.9.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.10.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.10.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.10.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.10.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.10.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.10.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.10.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.10.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.11.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.11.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.11.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.11.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.11.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.11.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.11.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.11.output.LayerNorm: 1,536 (trainable)
  classifier.layers.0: 787,456 (trainable)
  classifier.layers.1.projection: 2,099,200 (trainable)
  classifier.layers.3: 1,049,600 (trainable)
  classifier.layers.6: 3,075 (trainable)

Total layers: 104
Trainable layers: 104
Total parameters: 112,830,979
Trainable parameters: 112,830,979
Percentage of trainable parameters: 100.00%
Using optimizer: AdamW, Use Zero: True, Learning Rate: 2e-05, L2 strength: 0.01
Using scheduler: CosineAnnealingWarmRestarts
Scheduler arguments:
- T_0: 5
- T_mult: 1
- eta_min: 1e-07

Starting training loop...
Start epoch: 1, Max Iterations: 100, Early Stop: score, Tolerance: 0.00001, Number Iterations No Change: 100
Epoch 1/100:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                      | 327/798 [02:39<03:47,  2.07it/s, loss=0.7503, lr=1.97e-05, grad=M:0.1566]^C
Ctrl+C received. Terminating all processes...
Rank 0 - Current process: MainProcess cleaning up...
Terminating all child processes of MainProcess...

KeyboardInterrupt received. Terminating all processes...

KeyboardInterrupt received. Terminating all processes...

KeyboardInterrupt received. Terminating all processes...

KeyboardInterrupt received. Terminating all processes...

KeyboardInterrupt received. Terminating all processes...
Terminated child process: SpawnProcess-1

KeyboardInterrupt received. Terminating all processes...
Terminated child process: SpawnProcess-4
Terminated child process: SpawnProcess-8

KeyboardInterrupt received. Terminating all processes...
Terminated child process: SpawnProcess-3
Terminated child process: SpawnProcess-2
Terminated child process: SpawnProcess-7
Terminated child process: SpawnProcess-6
Terminated child process: SpawnProcess-5
Rank 0 - Exiting program...
/usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
(nlp) ubuntu@104-171-203-160:~/nlp-test/sentiment$ python ./ddp_sentiment_finetune.py --dataset 'merged_local' --weights_name 'google/electra-base-discriminator' --save_data --save_model --save_pickle --save_preds --lr 0.00002 --epochs 100 --pooling 'mean' --dropout_rate 0.3 --num_layers 2 --hidden_dim 1024 --hidden_activation 'swishglu' --batch_size 16 --accumulation_steps 2 --finetune_bert --finetune_layers 12 --l2_strength 0.01 --checkpoint_interval 5 --use_zero --optimizer 'adamw' --scheduler 'cosine_warmup' --scheduler_kwargs '{"T_0":5, "T_mult":1, "eta_min":1e-7}' --decimal 6 --val_percent 0.2 --early_stop 'score' --n_iter_no_change 100 --show_progress --wandb --wandb_project 'Electra Ensemble' --wandb_run 'multi_run_1'

Starting DDP PyTorch Training...
Device: cuda, Number of GPUs: 8
Spawning 8 processes...
Rank 1 - Device: cuda:1
Rank 3 - Device: cuda:3
Rank 6 - Device: cuda:6
Rank 4 - Device: cuda:4
Rank 7 - Device: cuda:7
Rank 5 - Device: cuda:5
Rank 2 - Device: cuda:2
Rank 0 - Device: cuda:0
8 process groups initialized with 'nccl' backend on localhost:12355
NCCL Timeout: 1 hr 0 min. NCCL Blocking Wait: Enabled
wandb: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: jbeno (jimbeno). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.3
wandb: Run data is saved locally in /home/ubuntu/nlp-test/sentiment/wandb/run-20241020_020726-ok367nas
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run multi_run_1
wandb: â­ï¸ View project at https://wandb.ai/jimbeno/Electra%20Ensemble
wandb: ðŸš€ View run at https://wandb.ai/jimbeno/Electra%20Ensemble/runs/ok367nas
Wand run initialized.

Initializing 'google/electra-base-discriminator' tokenizer and model...
Tokenizer and model initialized (1s)

Loading data...
Using the same dataset for training and evaluation
Train Data: Merged DynaSent Round 1, Round 2 and SST from Local: 'data/merged'
Dev Data: Merged DynaSent Round 1, Round 2 and SST from Local: 'data/merged'
Train size: 102097, Dev size: 5421
Train label distribution:
	      Negative: 21910
	       Neutral: 49148
	      Positive: 31039
Dev label distribution:
	      Negative: 1868
	       Neutral: 1669
	      Positive: 1884
Data loaded (261ms)

Processing data...
(Batch size: 16, Pooling: Mean, Fine Tune BERT: True, Chunk size: None)...
Extracting sentences and labels...

Data saved to: saves/data_8_gpu_20241020-020729.npz
X Train shape: [102097], X Dev shape: [5421]
y Train shape: [102097], y Dev shape: [5421]
Data processed (707ms)

Initializing DDP Neural Classifier...
Layers: 2, Hidden Dim: 1024, Hidden Act: SwishGLU, Dropout: 0.3, Optimizer: AdamW, L2 Strength: 0.01, Pooling: MEAN, Accumulation Steps: 2, Max Grad Norm: None
Batch Size: 16, Max Epochs: 100, LR: 2e-05, Early Stop: score, Fine-tune BERT: True, Fine-tune Layers: 12, Freeze BERT: False, Target Score: None, Interactive: False
Classifier initialized (14ms)

Fitting DDP Neural Classifier on training data...
Num Workers: 0, Prefetch: None
Building dataset and dataloader...
Score-based early stopping enabled (macro average F1 score against validation set). Validation fraction: 0.2
Training will stop early if the score does not improve by at least 0.00001 for 100 iterations.
Split data into (X:81677, y:81677) Training samples, and (X:20420, y:20420) Validation samples.
Initializing model, graph, optimizer...
BERT's original pooler removed. Using custom pooling type: mean
BERT has 108,891,648 trainable parameters and 0 non-trainable parameters
Number of BERT layers requiring gradients: 12 out of 12
Fine-tuning the last 12 out of 12 BERT layers

Model Architecture Summary:
BERTClassifier(
  (bert): ElectraModel(
    (embeddings): ElectraEmbeddings(
      (word_embeddings): Embedding(30522, 768, padding_idx=0)
      (position_embeddings): Embedding(512, 768)
      (token_type_embeddings): Embedding(2, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): ElectraEncoder(
      (layer): ModuleList(
        (0-11): 12 x ElectraLayer(
          (attention): ElectraAttention(
            (self): ElectraSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): ElectraSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): ElectraIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): ElectraOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
  (custom_pooling): PoolingLayer()
  (classifier): Classifier(
    (layers): Sequential(
      (0): Linear(in_features=768, out_features=1024, bias=True)
      (1): SwishGLU(
        (projection): Linear(in_features=1024, out_features=2048, bias=True)
        (activation): SiLU()
      )
      (2): Dropout(p=0.3, inplace=False)
      (3): Linear(in_features=1024, out_features=1024, bias=True)
      (4): SwishGLU(
        (projection): Linear(in_features=1024, out_features=2048, bias=True)
        (activation): SiLU()
      )
      (5): Dropout(p=0.3, inplace=False)
      (6): Linear(in_features=1024, out_features=3, bias=True)
    )
  )
)

Model Parameters:
  bert.embeddings.word_embeddings: 23,440,896 (trainable)
  bert.embeddings.position_embeddings: 393,216 (trainable)
  bert.embeddings.token_type_embeddings: 1,536 (trainable)
  bert.embeddings.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.0.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.0.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.0.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.0.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.0.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.0.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.0.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.0.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.1.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.1.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.1.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.1.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.1.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.1.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.1.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.1.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.2.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.2.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.2.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.2.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.2.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.2.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.2.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.2.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.3.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.3.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.3.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.3.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.3.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.3.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.3.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.3.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.4.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.4.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.4.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.4.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.4.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.4.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.4.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.4.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.5.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.5.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.5.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.5.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.5.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.5.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.5.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.5.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.6.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.6.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.6.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.6.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.6.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.6.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.6.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.6.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.7.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.7.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.7.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.7.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.7.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.7.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.7.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.7.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.8.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.8.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.8.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.8.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.8.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.8.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.8.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.8.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.9.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.9.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.9.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.9.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.9.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.9.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.9.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.9.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.10.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.10.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.10.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.10.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.10.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.10.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.10.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.10.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.11.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.11.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.11.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.11.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.11.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.11.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.11.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.11.output.LayerNorm: 1,536 (trainable)
  classifier.layers.0: 787,456 (trainable)
  classifier.layers.1.projection: 2,099,200 (trainable)
  classifier.layers.3: 1,049,600 (trainable)
  classifier.layers.6: 3,075 (trainable)

Total layers: 104
Trainable layers: 104
Total parameters: 112,830,979
Trainable parameters: 112,830,979
Percentage of trainable parameters: 100.00%
Using optimizer: AdamW, Use Zero: True, Learning Rate: 2e-05, L2 strength: 0.01
Using scheduler: CosineAnnealingWarmRestarts
Scheduler arguments:
- T_0: 5
- T_mult: 1
- eta_min: 1e-07

Starting training loop...
Start epoch: 1, Max Iterations: 100, Early Stop: score, Tolerance: 0.00001, Number Iterations No Change: 100
Epoch 1/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:17<00:00,  1.43it/s, loss=1.7215, lr=1.81e-05, grad=M:0.3150, status=Epoch complete]
â–ˆ Epoch   1: Loss T 1.721453 V 0.673973 | F1 T 0.760318 V 0.757801 B 0.757801 SC 0/100 | Acc T 0.779971 V 0.777761 | LR 1.81e-05 | Grad â†“ 0.000000 â†‘ 2.411573 M 0.315028 | 9m 17s
Epoch 2/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:15<00:00,  1.44it/s, loss=1.1242, lr=1.31e-05, grad=M:0.2320, status=Epoch complete]
â–ˆ Epoch   2: Loss T 1.124242 V 0.425653 | F1 T 0.828838 V 0.827656 B 0.827656 SC 0/100 | Acc T 0.838247 V 0.837005 | LR 1.31e-05 | Grad â†“ 0.000000 â†‘ 1.502891 M 0.232025 | 9m 15s
Epoch 3/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:15<00:00,  1.44it/s, loss=0.8885, lr=6.99e-06, grad=M:0.2883, status=Epoch complete]
â–ˆ Epoch   3: Loss T 0.888518 V 0.371685 | F1 T 0.856019 V 0.855921 B 0.855921 SC 0/100 | Acc T 0.861619 V 0.860801 | LR 6.99e-06 | Grad â†“ 0.000000 â†‘ 1.944870 M 0.288307 | 9m 15s
Epoch 4/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:13<00:00,  1.44it/s, loss=0.7877, lr=2.01e-06, grad=M:0.4044, status=Epoch complete]
â–ˆ Epoch   4: Loss T 0.787681 V 0.341844 | F1 T 0.867889 V 0.868165 B 0.868165 SC 0/100 | Acc T 0.872649 V 0.872062 | LR 2.01e-06 | Grad â†“ 0.000000 â†‘ 2.803343 M 0.404370 | 9m 13s
Epoch 5/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:14<00:00,  1.44it/s, loss=0.7398, lr=1.00e-07, grad=M:0.1844, status=Epoch complete]
â–ˆ Epoch   5: Loss T 0.739767 V 0.337158 | F1 T 0.870356 V 0.870342 B 0.870342 SC 0/100 | Acc T 0.875073 V 0.874168 | LR 1.00e-07 | Grad â†“ 0.000000 â†‘ 1.228556 M 0.184388 | 9m 14s
Saved model state: checkpoints/checkpoint_epoch_5_20241020-025347.pth
Epoch 6/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:15<00:00,  1.44it/s, loss=0.7875, lr=1.81e-05, grad=M:0.2830, status=Epoch complete]
â–ˆ Epoch   6: Loss T 0.787502 V 0.296530 | F1 T 0.887795 V 0.886135 B 0.886135 SC 0/100 | Acc T 0.891981 V 0.890080 | LR 1.81e-05 | Grad â†“ 0.000000 â†‘ 1.614187 M 0.283016 | 9m 15s
Epoch 7/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:14<00:00,  1.44it/s, loss=0.6735, lr=1.31e-05, grad=M:0.2826, status=Epoch complete]
â–ˆ Epoch   7: Loss T 0.673522 V 0.235609 | F1 T 0.914297 V 0.912415 B 0.912415 SC 0/100 | Acc T 0.916540 V 0.914806 | LR 1.31e-05 | Grad â†“ 0.000000 â†‘ 1.699845 M 0.282567 | 9m 14s
Epoch 8/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:14<00:00,  1.44it/s, loss=0.5669, lr=6.99e-06, grad=M:0.2131, status=Epoch complete]
â–ˆ Epoch   8: Loss T 0.566928 V 0.193373 | F1 T 0.932804 V 0.932029 B 0.932029 SC 0/100 | Acc T 0.934439 V 0.933412 | LR 6.99e-06 | Grad â†“ 0.000000 â†‘ 1.236735 M 0.213070 | 9m 14s
Epoch 9/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:16<00:00,  1.43it/s, loss=0.4797, lr=2.01e-06, grad=M:0.2972, status=Epoch complete]
â–ˆ Epoch   9: Loss T 0.479697 V 0.167221 | F1 T 0.943027 V 0.942224 B 0.942224 SC 0/100 | Acc T 0.944319 V 0.943498 | LR 2.01e-06 | Grad â†“ 0.000000 â†‘ 1.995894 M 0.297191 | 9m 16s
Epoch 10/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:14<00:00,  1.44it/s, loss=0.4323, lr=1.00e-07, grad=M:0.3120, status=Epoch complete]
â–ˆ Epoch  10: Loss T 0.432330 V 0.162435 | F1 T 0.945294 V 0.942774 B 0.942774 SC 0/100 | Acc T 0.946499 V 0.943890 | LR 1.00e-07 | Grad â†“ 0.000000 â†‘ 1.825865 M 0.312019 | 9m 14s
Memory: Rank 0: 13.82 GB | Rank 1: 14.10 GB | Rank 2: 14.00 GB | Rank 3: 14.00 GB | Rank 4: 14.08 GB | Rank 5: 14.09 GB | Rank 6: 14.04 GB | Rank 7: 14.02 GB (Max: 16.94 GB, Total: 135.49 GB)
Saved model state: checkpoints/checkpoint_epoch_10_20241020-034008.pth
Epoch 11/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:15<00:00,  1.44it/s, loss=0.4999, lr=1.81e-05, grad=M:0.3603, status=Epoch complete]
â–ˆ Epoch  11: Loss T 0.499918 V 0.153635 | F1 T 0.950909 V 0.949076 B 0.949076 SC 0/100 | Acc T 0.951849 V 0.949667 | LR 1.81e-05 | Grad â†“ 0.000000 â†‘ 1.961738 M 0.360331 | 9m 15s
Epoch 12/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:16<00:00,  1.43it/s, loss=0.4087, lr=1.31e-05, grad=M:0.3607, status=Epoch complete]
â–ˆ Epoch  12: Loss T 0.408657 V 0.107519 | F1 T 0.967239 V 0.965849 B 0.965849 SC 0/100 | Acc T 0.967862 V 0.966265 | LR 1.31e-05 | Grad â†“ 0.000000 â†‘ 1.810829 M 0.360680 | 9m 16s
Epoch 13/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:14<00:00,  1.44it/s, loss=0.3265, lr=6.99e-06, grad=M:0.1444, status=Epoch complete]
â–ˆ Epoch  13: Loss T 0.326545 V 0.080769 | F1 T 0.977945 V 0.976178 B 0.976178 SC 0/100 | Acc T 0.978452 V 0.976596 | LR 6.99e-06 | Grad â†“ 0.000000 â†‘ 0.749693 M 0.144380 | 9m 14s
Epoch 14/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:15<00:00,  1.44it/s, loss=0.2583, lr=2.01e-06, grad=M:0.2761, status=Epoch complete]
â–ˆ Epoch  14: Loss T 0.258285 V 0.067571 | F1 T 0.981131 V 0.979609 B 0.979609 SC 0/100 | Acc T 0.981574 V 0.980024 | LR 2.01e-06 | Grad â†“ 0.000000 â†‘ 1.533591 M 0.276069 | 9m 15s
Epoch 15/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:14<00:00,  1.44it/s, loss=0.2256, lr=1.00e-07, grad=M:0.2304, status=Epoch complete]
â–ˆ Epoch  15: Loss T 0.225616 V 0.063581 | F1 T 0.981701 V 0.980631 B 0.980631 SC 0/100 | Acc T 0.982113 V 0.981052 | LR 1.00e-07 | Grad â†“ 0.000000 â†‘ 1.157431 M 0.230438 | 9m 14s
Saved model state: checkpoints/checkpoint_epoch_15_20241020-042628.pth
Epoch 16/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:13<00:00,  1.44it/s, loss=0.2942, lr=1.81e-05, grad=M:0.3732, status=Epoch complete]
â–ˆ Epoch  16: Loss T 0.294219 V 0.065011 | F1 T 0.981374 V 0.979488 B 0.980631 SC 1/100 | Acc T 0.982015 V 0.980072 | LR 1.81e-05 | Grad â†“ 0.000000 â†‘ 2.119753 M 0.373216 | 9m 13s
Epoch 17/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:16<00:00,  1.43it/s, loss=0.2399, lr=1.31e-05, grad=M:0.3625, status=Epoch complete]
â–ˆ Epoch  17: Loss T 0.239856 V 0.045641 | F1 T 0.988305 V 0.987274 B 0.987274 SC 0/100 | Acc T 0.988467 V 0.987368 | LR 1.31e-05 | Grad â†“ 0.000000 â†‘ 2.178056 M 0.362477 | 9m 16s
Epoch 18/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:15<00:00,  1.44it/s, loss=0.1815, lr=6.99e-06, grad=M:0.4296, status=Epoch complete]
â–ˆ Epoch  18: Loss T 0.181539 V 0.031991 | F1 T 0.990759 V 0.990484 B 0.990484 SC 0/100 | Acc T 0.990904 V 0.990501 | LR 6.99e-06 | Grad â†“ 0.000000 â†‘ 3.297686 M 0.429611 | 9m 15s
Epoch 19/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:14<00:00,  1.44it/s, loss=0.1410, lr=2.01e-06, grad=M:0.4931, status=Epoch complete]
â–ˆ Epoch  19: Loss T 0.141036 V 0.026595 | F1 T 0.992528 V 0.992335 B 0.992335 SC 0/100 | Acc T 0.992667 V 0.992362 | LR 2.01e-06 | Grad â†“ 0.000000 â†‘ 2.782018 M 0.493087 | 9m 14s
Epoch 20/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:13<00:00,  1.44it/s, loss=0.1218, lr=1.00e-07, grad=M:0.3982, status=Epoch complete]
â–ˆ Epoch  20: Loss T 0.121788 V 0.025564 | F1 T 0.992835 V 0.992577 B 0.992577 SC 0/100 | Acc T 0.992936 V 0.992607 | LR 1.00e-07 | Grad â†“ 0.000000 â†‘ 2.514914 M 0.398187 | 9m 13s
Memory: Rank 0: 13.82 GB | Rank 1: 14.10 GB | Rank 2: 14.00 GB | Rank 3: 14.00 GB | Rank 4: 14.08 GB | Rank 5: 14.09 GB | Rank 6: 14.04 GB | Rank 7: 14.02 GB (Max: 16.94 GB, Total: 135.49 GB)
Saved model state: checkpoints/checkpoint_epoch_20_20241020-051247.pth
Epoch 21/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:14<00:00,  1.44it/s, loss=0.1848, lr=1.81e-05, grad=M:0.2172, status=Epoch complete]
â–ˆ Epoch  21: Loss T 0.184836 V 0.029110 | F1 T 0.991864 V 0.990956 B 0.992577 SC 1/100 | Acc T 0.992018 V 0.991089 | LR 1.81e-05 | Grad â†“ 0.000000 â†‘ 1.472115 M 0.217173 | 9m 14s
Epoch 22/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:15<00:00,  1.44it/s, loss=0.1620, lr=1.31e-05, grad=M:0.3384, status=Epoch complete]
â–ˆ Epoch  22: Loss T 0.162024 V 0.020602 | F1 T 0.994385 V 0.994819 B 0.994819 SC 0/100 | Acc T 0.994503 V 0.994810 | LR 1.31e-05 | Grad â†“ 0.000000 â†‘ 1.635111 M 0.338398 | 9m 15s
Epoch 23/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:15<00:00,  1.44it/s, loss=0.1176, lr=6.99e-06, grad=M:0.1053, status=Epoch complete]
â–ˆ Epoch  23: Loss T 0.117572 V 0.014064 | F1 T 0.995907 V 0.996060 B 0.996060 SC 0/100 | Acc T 0.996009 V 0.996083 | LR 6.99e-06 | Grad â†“ 0.000000 â†‘ 0.617481 M 0.105274 | 9m 15s
Epoch 24/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:15<00:00,  1.44it/s, loss=0.0883, lr=2.01e-06, grad=M:0.3482, status=Epoch complete]
â–ˆ Epoch  24: Loss T 0.088327 V 0.012943 | F1 T 0.996285 V 0.996508 B 0.996508 SC 0/100 | Acc T 0.996364 V 0.996524 | LR 2.01e-06 | Grad â†“ 0.000000 â†‘ 1.873920 M 0.348205 | 9m 15s
Epoch 25/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:14<00:00,  1.44it/s, loss=0.0769, lr=1.00e-07, grad=M:0.1399, status=Epoch complete]
â–ˆ Epoch  25: Loss T 0.076910 V 0.011031 | F1 T 0.996640 V 0.996803 B 0.996803 SC 0/100 | Acc T 0.996731 V 0.996817 | LR 1.00e-07 | Grad â†“ 0.000000 â†‘ 0.965994 M 0.139934 | 9m 14s
Saved model state: checkpoints/checkpoint_epoch_25_20241020-055907.pth
Epoch 26/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:14<00:00,  1.44it/s, loss=0.1278, lr=1.81e-05, grad=M:0.4882, status=Epoch complete]
â–ˆ Epoch  26: Loss T 0.127810 V 0.015922 | F1 T 0.994969 V 0.995100 B 0.996803 SC 1/100 | Acc T 0.995029 V 0.995006 | LR 1.81e-05 | Grad â†“ 0.000000 â†‘ 2.910232 M 0.488188 | 9m 14s
Epoch 27/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:14<00:00,  1.44it/s, loss=0.1104, lr=1.31e-05, grad=M:0.0475, status=Epoch complete]
â–ˆ Epoch  27: Loss T 0.110434 V 0.014127 | F1 T 0.995789 V 0.996143 B 0.996803 SC 2/100 | Acc T 0.995801 V 0.996132 | LR 1.31e-05 | Grad â†“ 0.000000 â†‘ 0.270192 M 0.047479 | 9m 14s
Epoch 28/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:16<00:00,  1.44it/s, loss=0.0793, lr=6.99e-06, grad=M:0.2185, status=Epoch complete]
â–ˆ Epoch  28: Loss T 0.079269 V 0.008688 | F1 T 0.997249 V 0.997607 B 0.997607 SC 0/100 | Acc T 0.997343 V 0.997650 | LR 6.99e-06 | Grad â†“ 0.000000 â†‘ 1.143582 M 0.218479 | 9m 16s
Epoch 29/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:15<00:00,  1.44it/s, loss=0.0595, lr=2.01e-06, grad=M:0.2377, status=Epoch complete]
â–ˆ Epoch  29: Loss T 0.059459 V 0.006401 | F1 T 0.997844 V 0.997903 B 0.997903 SC 0/100 | Acc T 0.997931 V 0.997944 | LR 2.01e-06 | Grad â†“ 0.000000 â†‘ 1.302745 M 0.237701 | 9m 15s
Epoch 30/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:14<00:00,  1.44it/s, loss=0.0504, lr=1.00e-07, grad=M:0.6362, status=Epoch complete]
â–ˆ Epoch  30: Loss T 0.050427 V 0.005905 | F1 T 0.997863 V 0.997957 B 0.997957 SC 0/100 | Acc T 0.997943 V 0.997993 | LR 1.00e-07 | Grad â†“ 0.000000 â†‘ 3.868739 M 0.636168 | 9m 14s
Memory: Rank 0: 13.82 GB | Rank 1: 14.10 GB | Rank 2: 14.00 GB | Rank 3: 14.00 GB | Rank 4: 14.08 GB | Rank 5: 14.09 GB | Rank 6: 14.04 GB | Rank 7: 14.02 GB (Max: 16.94 GB, Total: 135.49 GB)
Saved model state: checkpoints/checkpoint_epoch_30_20241020-064527.pth
Epoch 31/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [07:13<00:00,  2.26it/s, loss=0.0992, lr=1.81e-05, grad=M:0.2083, status=Computing train metrics...]^C
Ctrl+C received. Terminating all processes...
Rank 0 - Current process: MainProcess cleaning up...
Terminating all child processes of MainProcess...
Terminated child process: SpawnProcess-1
Terminated child process: SpawnProcess-4
Terminated child process: SpawnProcess-8
Terminated child process: SpawnProcess-3
Terminated child process: SpawnProcess-2
Terminated child process: SpawnProcess-7
Terminated child process: SpawnProcess-6
Terminated child process: SpawnProcess-5
Rank 0 - Exiting program...
/usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
(nlp) ubuntu@104-171-203-160:~/nlp-test/sentiment$ python ./ddp_sentiment_finetune.py --dataset 'merged_local' --weights_name 'google/electra-base-discriminator' --save_data --save_model --save_pickle --save_preds --lr 0.00002 --epochs 100 --pooling 'mean' --dropout_rate 0.3 --num_layers 2 --hidden_dim 1024 --hidden_activation 'swishglu' --batch_size 16 --accumulation_steps 2 --finetune_bert --finetune_layers 12 --l2_strength 0.01 --checkpoint_interval 5 --use_zero --optimizer 'adamw' --scheduler 'cosine_warmup' --scheduler_kwargs '{"T_0":5, "T_mult":1, "eta_min":1e-7}' --decimal 6 --val_percent 0.2 --early_stop 'score' --n_iter_no_change 100 --show_progress --wandb --wandb_project 'Electra Ensemble' --wandb_run 'multi_run_1' --interactive --model_file 'checkpoint_epoch_30_20241020-064527.pth'

Starting DDP PyTorch Training...
Device: cuda, Number of GPUs: 8
Spawning 8 processes...
Rank 2 - Device: cuda:2
Rank 5 - Device: cuda:5
Rank 4 - Device: cuda:4
Rank 3 - Device: cuda:3
Rank 1 - Device: cuda:1
Rank 7 - Device: cuda:7
Rank 6 - Device: cuda:6
Rank 0 - Device: cuda:0
8 process groups initialized with 'nccl' backend on localhost:12355
NCCL Timeout: 1 hr 0 min. NCCL Blocking Wait: Enabled
wandb: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: jbeno (jimbeno). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.3
wandb: Run data is saved locally in /home/ubuntu/nlp-test/sentiment/wandb/run-20241020_065352-a2d3imzs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run multi_run_1
wandb: â­ï¸ View project at https://wandb.ai/jimbeno/Electra%20Ensemble
wandb: ðŸš€ View run at https://wandb.ai/jimbeno/Electra%20Ensemble/runs/a2d3imzs
Wand run initialized.

Initializing 'google/electra-base-discriminator' tokenizer and model...
Tokenizer and model initialized (1s)

Loading data...
Using the same dataset for training and evaluation
Train Data: Merged DynaSent Round 1, Round 2 and SST from Local: 'data/merged'
Dev Data: Merged DynaSent Round 1, Round 2 and SST from Local: 'data/merged'
Train size: 102097, Dev size: 5421
Train label distribution:
	      Negative: 21910
	       Neutral: 49148
	      Positive: 31039
Dev label distribution:
	      Negative: 1868
	       Neutral: 1669
	      Positive: 1884
Data loaded (259ms)

Processing data...
(Batch size: 16, Pooling: Mean, Fine Tune BERT: True, Chunk size: None)...
Extracting sentences and labels...

Data saved to: saves/data_8_gpu_20241020-065355.npz
X Train shape: [102097], X Dev shape: [5421]
y Train shape: [102097], y Dev shape: [5421]
Data processed (692ms)

Initializing DDP Neural Classifier...
Layers: 2, Hidden Dim: 1024, Hidden Act: SwishGLU, Dropout: 0.3, Optimizer: AdamW, L2 Strength: 0.01, Pooling: MEAN, Accumulation Steps: 2, Max Grad Norm: None
Batch Size: 16, Max Epochs: 100, LR: 2e-05, Early Stop: score, Fine-tune BERT: True, Fine-tune Layers: 12, Freeze BERT: False, Target Score: None, Interactive: True
Loading model from: checkpoints/checkpoint_epoch_30_20241020-064527.pth...
Loaded checkpoint: checkpoints/checkpoint_epoch_30_20241020-064527.pth
Retrieved model state dictionary.
Retrieved optimizer state dictionary.
Classifier initialized (8s)

Fitting DDP Neural Classifier on training data...
Num Workers: 0, Prefetch: None
Building dataset and dataloader...
Score-based early stopping enabled (macro average F1 score against validation set). Validation fraction: 0.2
Training will stop early if the score does not improve by at least 0.00001 for 100 iterations.
Split data into (X:81677, y:81677) Training samples, and (X:20420, y:20420) Validation samples.
Initializing model, graph, optimizer...
BERT's original pooler removed. Using custom pooling type: mean
BERT has 108,891,648 trainable parameters and 0 non-trainable parameters
Number of BERT layers requiring gradients: 12 out of 12
Fine-tuning the last 12 out of 12 BERT layers

Model Architecture Summary:
BERTClassifier(
  (bert): ElectraModel(
    (embeddings): ElectraEmbeddings(
      (word_embeddings): Embedding(30522, 768, padding_idx=0)
      (position_embeddings): Embedding(512, 768)
      (token_type_embeddings): Embedding(2, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): ElectraEncoder(
      (layer): ModuleList(
        (0-11): 12 x ElectraLayer(
          (attention): ElectraAttention(
            (self): ElectraSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): ElectraSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): ElectraIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): ElectraOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
  (custom_pooling): PoolingLayer()
  (classifier): Classifier(
    (layers): Sequential(
      (0): Linear(in_features=768, out_features=1024, bias=True)
      (1): SwishGLU(
        (projection): Linear(in_features=1024, out_features=2048, bias=True)
        (activation): SiLU()
      )
      (2): Dropout(p=0.3, inplace=False)
      (3): Linear(in_features=1024, out_features=1024, bias=True)
      (4): SwishGLU(
        (projection): Linear(in_features=1024, out_features=2048, bias=True)
        (activation): SiLU()
      )
      (5): Dropout(p=0.3, inplace=False)
      (6): Linear(in_features=1024, out_features=3, bias=True)
    )
  )
)

Model Parameters:
  bert.embeddings.word_embeddings: 23,440,896 (trainable)
  bert.embeddings.position_embeddings: 393,216 (trainable)
  bert.embeddings.token_type_embeddings: 1,536 (trainable)
  bert.embeddings.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.0.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.0.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.0.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.0.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.0.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.0.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.0.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.0.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.1.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.1.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.1.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.1.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.1.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.1.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.1.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.1.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.2.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.2.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.2.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.2.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.2.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.2.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.2.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.2.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.3.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.3.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.3.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.3.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.3.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.3.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.3.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.3.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.4.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.4.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.4.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.4.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.4.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.4.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.4.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.4.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.5.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.5.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.5.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.5.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.5.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.5.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.5.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.5.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.6.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.6.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.6.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.6.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.6.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.6.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.6.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.6.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.7.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.7.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.7.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.7.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.7.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.7.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.7.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.7.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.8.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.8.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.8.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.8.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.8.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.8.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.8.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.8.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.9.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.9.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.9.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.9.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.9.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.9.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.9.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.9.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.10.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.10.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.10.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.10.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.10.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.10.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.10.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.10.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.11.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.11.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.11.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.11.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.11.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.11.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.11.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.11.output.LayerNorm: 1,536 (trainable)
  classifier.layers.0: 787,456 (trainable)
  classifier.layers.1.projection: 2,099,200 (trainable)
  classifier.layers.3: 1,049,600 (trainable)
  classifier.layers.6: 3,075 (trainable)

Total layers: 104
Trainable layers: 104
Total parameters: 112,830,979
Trainable parameters: 112,830,979
Percentage of trainable parameters: 100.00%
Using optimizer: AdamW, Use Zero: True, Learning Rate: 2e-05, L2 strength: 0.01
Using scheduler: CosineAnnealingWarmRestarts
Scheduler arguments:
- T_0: 5
- T_mult: 1
- eta_min: 1e-07

Starting training loop...
Start epoch: 31, Max Iterations: 100, Early Stop: score, Tolerance: 0.00001, Number Iterations No Change: 100

[Enter] to continue for 1 epoch, [Q]uit, [S]ave, [H]elp: q
Quitting training...
Saving model in ONNX format...
Model saved in ONNX format to saves/model_20241020-065923.onnx and uploaded to Weights & Biases.
Saved model state: checkpoints/final_model_20241020-065930.pth
Saved model pickle: checkpoints/final_model_20241020-065930.pkl
Training completed (5m 32s)

Evaluating model...

multi_run_1 Multi-Class Classification Report

              precision    recall  f1-score   support

    negative   0.855035  0.713597  0.777940      1868
     neutral   0.685567  0.796884  0.737046      1669
    positive   0.802289  0.818471  0.810300      1884

    accuracy                       0.775687      5421
   macro avg   0.780964  0.776318  0.775095      5421
weighted avg   0.784529  0.775687  0.776596      5421

ROC AUC: 0.906911

Predicted  negative  neutral  positive
Actual                                
negative       1333      357       178
neutral         137     1330       202
positive         89      253      1542

Saved predictions: saves/predictions_20241020-070119.csv

Macro F1 Score: 0.78

Evaluation completed (2m 33s)
wandb:                                                                                
wandb: 
wandb: Run history:
wandb: eval/macro_f1_score â–
wandb: 
wandb: Run summary:
wandb: eval/macro_f1_score 0.7751
wandb: 
wandb: ðŸš€ View run multi_run_1 at: https://wandb.ai/jimbeno/Electra%20Ensemble/runs/a2d3imzs
wandb: â­ï¸ View project at: https://wandb.ai/jimbeno/Electra%20Ensemble
wandb: Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 2 other file(s)
wandb: Find logs at: ./wandb/run-20241020_065352-a2d3imzs/logs
TOTAL Time: 8m 34s
(nlp) ubuntu@104-171-203-160:~/nlp-test/sentiment$ python ./ddp_sentiment_finetune.py --dataset 'merged_local' --weights_name 'google/electra-base-discriminator' --save_data --save_model --save_pickle --save_preds --lr 0.00002 --epochs 70 --pooling 'mean' --dropout_rate 0.3 --num_layers 2 --hidden_dim 1024 --hidden_activation 'swishglu' --batch_size 16 --accumulation_steps 2 --finetune_bert --finetune_layers 12 --l2_strength 0.01 --checkpoint_interval 5 --use_zero --optimizer 'adamw' --scheduler 'cosine_warmup' --scheduler_kwargs '{"T_0":5, "T_mult":1, "eta_min":1e-7}' --decimal 6 --val_percent 0.2 --early_stop 'score' --n_iter_no_change 70 --show_progress --wandb --wandb_project 'Electra Ensemble' --wandb_run 'multi_run_2' --interactive --model_file 'checkpoint_epoch_30_20241020-064527.pth'

Starting DDP PyTorch Training...
Device: cuda, Number of GPUs: 8
Spawning 8 processes...
Rank 6 - Device: cuda:6
Rank 1 - Device: cuda:1
Rank 2 - Device: cuda:2
Rank 3 - Device: cuda:3
Rank 5 - Device: cuda:5
Rank 4 - Device: cuda:4
Rank 7 - Device: cuda:7
Rank 0 - Device: cuda:0
8 process groups initialized with 'nccl' backend on localhost:12355
NCCL Timeout: 1 hr 0 min. NCCL Blocking Wait: Enabled
wandb: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: jbeno (jimbeno). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.3
wandb: Run data is saved locally in /home/ubuntu/nlp-test/sentiment/wandb/run-20241020_070621-r862zgyy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run multi_run_2
wandb: â­ï¸ View project at https://wandb.ai/jimbeno/Electra%20Ensemble
wandb: ðŸš€ View run at https://wandb.ai/jimbeno/Electra%20Ensemble/runs/r862zgyy
Wand run initialized.

Initializing 'google/electra-base-discriminator' tokenizer and model...
Tokenizer and model initialized (1s)

Loading data...
Using the same dataset for training and evaluation
Train Data: Merged DynaSent Round 1, Round 2 and SST from Local: 'data/merged'
Dev Data: Merged DynaSent Round 1, Round 2 and SST from Local: 'data/merged'
Train size: 102097, Dev size: 5421
Train label distribution:
	      Negative: 21910
	       Neutral: 49148
	      Positive: 31039
Dev label distribution:
	      Negative: 1868
	       Neutral: 1669
	      Positive: 1884
Data loaded (282ms)

Processing data...
(Batch size: 16, Pooling: Mean, Fine Tune BERT: True, Chunk size: None)...
Extracting sentences and labels...

Data saved to: saves/data_8_gpu_20241020-070623.npz
X Train shape: [102097], X Dev shape: [5421]
y Train shape: [102097], y Dev shape: [5421]
Data processed (707ms)

Initializing DDP Neural Classifier...
Layers: 2, Hidden Dim: 1024, Hidden Act: SwishGLU, Dropout: 0.3, Optimizer: AdamW, L2 Strength: 0.01, Pooling: MEAN, Accumulation Steps: 2, Max Grad Norm: None
Batch Size: 16, Max Epochs: 70, LR: 2e-05, Early Stop: score, Fine-tune BERT: True, Fine-tune Layers: 12, Freeze BERT: False, Target Score: None, Interactive: True
Loading model from: checkpoints/checkpoint_epoch_30_20241020-064527.pth...
Loaded checkpoint: checkpoints/checkpoint_epoch_30_20241020-064527.pth
Retrieved model state dictionary.
Retrieved optimizer state dictionary.
Classifier initialized (7s)

Fitting DDP Neural Classifier on training data...
Num Workers: 0, Prefetch: None
Building dataset and dataloader...
Score-based early stopping enabled (macro average F1 score against validation set). Validation fraction: 0.2
Training will stop early if the score does not improve by at least 0.00001 for 70 iterations.
Split data into (X:81677, y:81677) Training samples, and (X:20420, y:20420) Validation samples.
Initializing model, graph, optimizer...
BERT's original pooler removed. Using custom pooling type: mean
BERT has 108,891,648 trainable parameters and 0 non-trainable parameters
Number of BERT layers requiring gradients: 12 out of 12
Fine-tuning the last 12 out of 12 BERT layers

Model Architecture Summary:
BERTClassifier(
  (bert): ElectraModel(
    (embeddings): ElectraEmbeddings(
      (word_embeddings): Embedding(30522, 768, padding_idx=0)
      (position_embeddings): Embedding(512, 768)
      (token_type_embeddings): Embedding(2, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): ElectraEncoder(
      (layer): ModuleList(
        (0-11): 12 x ElectraLayer(
          (attention): ElectraAttention(
            (self): ElectraSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): ElectraSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): ElectraIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): ElectraOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
  (custom_pooling): PoolingLayer()
  (classifier): Classifier(
    (layers): Sequential(
      (0): Linear(in_features=768, out_features=1024, bias=True)
      (1): SwishGLU(
        (projection): Linear(in_features=1024, out_features=2048, bias=True)
        (activation): SiLU()
      )
      (2): Dropout(p=0.3, inplace=False)
      (3): Linear(in_features=1024, out_features=1024, bias=True)
      (4): SwishGLU(
        (projection): Linear(in_features=1024, out_features=2048, bias=True)
        (activation): SiLU()
      )
      (5): Dropout(p=0.3, inplace=False)
      (6): Linear(in_features=1024, out_features=3, bias=True)
    )
  )
)

Model Parameters:
  bert.embeddings.word_embeddings: 23,440,896 (trainable)
  bert.embeddings.position_embeddings: 393,216 (trainable)
  bert.embeddings.token_type_embeddings: 1,536 (trainable)
  bert.embeddings.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.0.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.0.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.0.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.0.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.0.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.0.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.0.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.0.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.1.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.1.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.1.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.1.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.1.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.1.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.1.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.1.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.2.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.2.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.2.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.2.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.2.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.2.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.2.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.2.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.3.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.3.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.3.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.3.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.3.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.3.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.3.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.3.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.4.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.4.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.4.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.4.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.4.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.4.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.4.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.4.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.5.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.5.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.5.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.5.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.5.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.5.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.5.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.5.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.6.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.6.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.6.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.6.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.6.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.6.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.6.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.6.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.7.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.7.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.7.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.7.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.7.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.7.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.7.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.7.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.8.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.8.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.8.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.8.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.8.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.8.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.8.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.8.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.9.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.9.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.9.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.9.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.9.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.9.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.9.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.9.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.10.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.10.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.10.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.10.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.10.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.10.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.10.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.10.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.11.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.11.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.11.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.11.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.11.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.11.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.11.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.11.output.LayerNorm: 1,536 (trainable)
  classifier.layers.0: 787,456 (trainable)
  classifier.layers.1.projection: 2,099,200 (trainable)
  classifier.layers.3: 1,049,600 (trainable)
  classifier.layers.6: 3,075 (trainable)

Total layers: 104
Trainable layers: 104
Total parameters: 112,830,979
Trainable parameters: 112,830,979
Percentage of trainable parameters: 100.00%
Using optimizer: AdamW, Use Zero: True, Learning Rate: 2e-05, L2 strength: 0.01
Using scheduler: CosineAnnealingWarmRestarts
Scheduler arguments:
- T_0: 5
- T_mult: 1
- eta_min: 1e-07

Starting training loop...
Start epoch: 31, Max Iterations: 70, Early Stop: score, Tolerance: 0.00001, Number Iterations No Change: 70

[Enter] to continue for 1 epoch, [Q]uit, [S]ave, [H]elp: 
Skipping 1 epochs.
Epoch 31/101:   1%|â–                                                                                            | 4/798 [00:03<08:46,  1.51it/s, loss=0.0044, lr=2.00e-05, grad=M:0.0291]^C
Ctrl+C received. Terminating all processes...
Rank 0 - Current process: MainProcess cleaning up...
Terminating all child processes of MainProcess...
Terminated child process: SpawnProcess-7
Terminated child process: SpawnProcess-3
Terminated child process: SpawnProcess-4
Terminated child process: SpawnProcess-1
Terminated child process: SpawnProcess-2
Terminated child process: SpawnProcess-6
Terminated child process: SpawnProcess-8
Terminated child process: SpawnProcess-5
Rank 0 - Exiting program...
/usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
(nlp) ubuntu@104-171-203-160:~/nlp-test/sentiment$ python ./ddp_sentiment_finetune.py --dataset 'merged_local' --weights_name 'google/electra-base-discriminator' --save_data --save_model --save_pickle --save_preds --lr 0.00002 --epochs 69 --pooling 'mean' --dropout_rate 0.3 --num_layers 2 --hidden_dim 1024 --hidden_activation 'swishglu' --batch_size 16 --accumulation_steps 2 --finetune_bert --finetune_layers 12 --l2_strength 0.01 --checkpoint_interval 5 --use_zero --optimizer 'adamw' --scheduler 'cosine_warmup' --scheduler_kwargs '{"T_0":5, "T_mult":1, "eta_min":1e-7}' --decimal 6 --val_percent 0.2 --early_stop 'score' --n_iter_no_change 70 --show_progress --wandb --wandb_project 'Electra Ensemble' --wandb_run 'multi_run_2' --model_file 'checkpoint_epoch_30_20241020-064527.pth'

Starting DDP PyTorch Training...
Device: cuda, Number of GPUs: 8
Spawning 8 processes...
Rank 2 - Device: cuda:2
Rank 5 - Device: cuda:5
Rank 4 - Device: cuda:4
Rank 3 - Device: cuda:3
Rank 1 - Device: cuda:1
Rank 7 - Device: cuda:7
Rank 6 - Device: cuda:6
Rank 0 - Device: cuda:0
8 process groups initialized with 'nccl' backend on localhost:12355
NCCL Timeout: 1 hr 0 min. NCCL Blocking Wait: Enabled
wandb: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: jbeno (jimbeno). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.3
wandb: Run data is saved locally in /home/ubuntu/nlp-test/sentiment/wandb/run-20241020_070835-u27j1efz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run multi_run_2
wandb: â­ï¸ View project at https://wandb.ai/jimbeno/Electra%20Ensemble
wandb: ðŸš€ View run at https://wandb.ai/jimbeno/Electra%20Ensemble/runs/u27j1efz
Wand run initialized.

Initializing 'google/electra-base-discriminator' tokenizer and model...
Tokenizer and model initialized (1s)

Loading data...
Using the same dataset for training and evaluation
Train Data: Merged DynaSent Round 1, Round 2 and SST from Local: 'data/merged'
Dev Data: Merged DynaSent Round 1, Round 2 and SST from Local: 'data/merged'
Train size: 102097, Dev size: 5421
Train label distribution:
	      Negative: 21910
	       Neutral: 49148
	      Positive: 31039
Dev label distribution:
	      Negative: 1868
	       Neutral: 1669
	      Positive: 1884
Data loaded (446ms)

Processing data...
(Batch size: 16, Pooling: Mean, Fine Tune BERT: True, Chunk size: None)...
Extracting sentences and labels...

Data saved to: saves/data_8_gpu_20241020-070838.npz
X Train shape: [102097], X Dev shape: [5421]
y Train shape: [102097], y Dev shape: [5421]
Data processed (781ms)

Initializing DDP Neural Classifier...
Layers: 2, Hidden Dim: 1024, Hidden Act: SwishGLU, Dropout: 0.3, Optimizer: AdamW, L2 Strength: 0.01, Pooling: MEAN, Accumulation Steps: 2, Max Grad Norm: None
Batch Size: 16, Max Epochs: 69, LR: 2e-05, Early Stop: score, Fine-tune BERT: True, Fine-tune Layers: 12, Freeze BERT: False, Target Score: None, Interactive: False
Loading model from: checkpoints/checkpoint_epoch_30_20241020-064527.pth...
Loaded checkpoint: checkpoints/checkpoint_epoch_30_20241020-064527.pth
Retrieved model state dictionary.
Retrieved optimizer state dictionary.
Classifier initialized (3s)

Fitting DDP Neural Classifier on training data...
Num Workers: 0, Prefetch: None
Building dataset and dataloader...
Score-based early stopping enabled (macro average F1 score against validation set). Validation fraction: 0.2
Training will stop early if the score does not improve by at least 0.00001 for 70 iterations.
Split data into (X:81677, y:81677) Training samples, and (X:20420, y:20420) Validation samples.
Initializing model, graph, optimizer...
BERT's original pooler removed. Using custom pooling type: mean
BERT has 108,891,648 trainable parameters and 0 non-trainable parameters
Number of BERT layers requiring gradients: 12 out of 12
Fine-tuning the last 12 out of 12 BERT layers

Model Architecture Summary:
BERTClassifier(
  (bert): ElectraModel(
    (embeddings): ElectraEmbeddings(
      (word_embeddings): Embedding(30522, 768, padding_idx=0)
      (position_embeddings): Embedding(512, 768)
      (token_type_embeddings): Embedding(2, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): ElectraEncoder(
      (layer): ModuleList(
        (0-11): 12 x ElectraLayer(
          (attention): ElectraAttention(
            (self): ElectraSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): ElectraSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): ElectraIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): ElectraOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
  (custom_pooling): PoolingLayer()
  (classifier): Classifier(
    (layers): Sequential(
      (0): Linear(in_features=768, out_features=1024, bias=True)
      (1): SwishGLU(
        (projection): Linear(in_features=1024, out_features=2048, bias=True)
        (activation): SiLU()
      )
      (2): Dropout(p=0.3, inplace=False)
      (3): Linear(in_features=1024, out_features=1024, bias=True)
      (4): SwishGLU(
        (projection): Linear(in_features=1024, out_features=2048, bias=True)
        (activation): SiLU()
      )
      (5): Dropout(p=0.3, inplace=False)
      (6): Linear(in_features=1024, out_features=3, bias=True)
    )
  )
)

Model Parameters:
  bert.embeddings.word_embeddings: 23,440,896 (trainable)
  bert.embeddings.position_embeddings: 393,216 (trainable)
  bert.embeddings.token_type_embeddings: 1,536 (trainable)
  bert.embeddings.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.0.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.0.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.0.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.0.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.0.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.0.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.0.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.0.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.1.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.1.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.1.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.1.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.1.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.1.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.1.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.1.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.2.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.2.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.2.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.2.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.2.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.2.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.2.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.2.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.3.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.3.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.3.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.3.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.3.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.3.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.3.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.3.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.4.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.4.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.4.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.4.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.4.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.4.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.4.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.4.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.5.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.5.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.5.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.5.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.5.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.5.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.5.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.5.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.6.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.6.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.6.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.6.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.6.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.6.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.6.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.6.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.7.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.7.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.7.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.7.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.7.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.7.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.7.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.7.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.8.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.8.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.8.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.8.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.8.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.8.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.8.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.8.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.9.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.9.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.9.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.9.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.9.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.9.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.9.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.9.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.10.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.10.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.10.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.10.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.10.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.10.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.10.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.10.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.11.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.11.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.11.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.11.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.11.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.11.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.11.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.11.output.LayerNorm: 1,536 (trainable)
  classifier.layers.0: 787,456 (trainable)
  classifier.layers.1.projection: 2,099,200 (trainable)
  classifier.layers.3: 1,049,600 (trainable)
  classifier.layers.6: 3,075 (trainable)

Total layers: 104
Trainable layers: 104
Total parameters: 112,830,979
Trainable parameters: 112,830,979
Percentage of trainable parameters: 100.00%
Using optimizer: AdamW, Use Zero: True, Learning Rate: 2e-05, L2 strength: 0.01
Using scheduler: CosineAnnealingWarmRestarts
Scheduler arguments:
- T_0: 5
- T_mult: 1
- eta_min: 1e-07

Starting training loop...
Start epoch: 31, Max Iterations: 69, Early Stop: score, Tolerance: 0.00001, Number Iterations No Change: 70
Epoch 31/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:17<00:00,  1.43it/s, loss=0.0969, lr=1.81e-05, grad=M:0.4710, status=Epoch complete]
â–ˆ Epoch 31: Loss T 0.096931 V 0.017859 | F1 T 0.994991 V 0.994958 B 0.994958 SC 0/70 | Acc T 0.994980 V 0.994957 | LR 1.81e-05 | Grad â†“ 0.000000 â†‘ 3.026342 M 0.471015 | 9m 17s
Epoch 32/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:17<00:00,  1.43it/s, loss=0.0853, lr=1.31e-05, grad=M:0.0674, status=Epoch complete]
â–ˆ Epoch 32: Loss T 0.085338 V 0.011219 | F1 T 0.996832 V 0.996905 B 0.996905 SC 0/70 | Acc T 0.996927 V 0.996866 | LR 1.31e-05 | Grad â†“ 0.000000 â†‘ 0.368062 M 0.067384 | 9m 17s
Epoch 33/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:18<00:00,  1.43it/s, loss=0.0623, lr=6.99e-06, grad=M:0.4625, status=Epoch complete]
â–ˆ Epoch 33: Loss T 0.062311 V 0.004855 | F1 T 0.998227 V 0.998274 B 0.998274 SC 0/70 | Acc T 0.998237 V 0.998286 | LR 6.99e-06 | Grad â†“ 0.000000 â†‘ 2.979912 M 0.462465 | 9m 18s
Epoch 34/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:17<00:00,  1.43it/s, loss=0.0403, lr=2.01e-06, grad=M:0.4507, status=Epoch complete]
â–ˆ Epoch 34: Loss T 0.040344 V 0.003370 | F1 T 0.998464 V 0.999026 B 0.999026 SC 0/70 | Acc T 0.998482 V 0.999021 | LR 2.01e-06 | Grad â†“ 0.000000 â†‘ 2.830137 M 0.450721 | 9m 17s
Epoch 35/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:17<00:00,  1.43it/s, loss=0.0347, lr=1.00e-07, grad=M:0.2557, status=Epoch complete]
â–ˆ Epoch 35: Loss T 0.034667 V 0.003189 | F1 T 0.998573 V 0.999114 B 0.999114 SC 0/70 | Acc T 0.998592 V 0.999119 | LR 1.00e-07 | Grad â†“ 0.000000 â†‘ 1.505364 M 0.255741 | 9m 17s
Saved model state: checkpoints/checkpoint_epoch_35_20241020-075511.pth
Epoch 36/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:17<00:00,  1.43it/s, loss=0.0750, lr=1.81e-05, grad=M:0.2426, status=Epoch complete]
â–ˆ Epoch 36: Loss T 0.074955 V 0.008347 | F1 T 0.997533 V 0.997714 B 0.999114 SC 1/70 | Acc T 0.997551 V 0.997650 | LR 1.81e-05 | Grad â†“ 0.000000 â†‘ 1.455178 M 0.242624 | 9m 17s
Epoch 37/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:15<00:00,  1.44it/s, loss=0.0676, lr=1.31e-05, grad=M:0.3554, status=Epoch complete]
â–ˆ Epoch 37: Loss T 0.067598 V 0.004684 | F1 T 0.998331 V 0.998589 B 0.999114 SC 2/70 | Acc T 0.998359 V 0.998629 | LR 1.31e-05 | Grad â†“ 0.000000 â†‘ 2.220431 M 0.355443 | 9m 15s
Epoch 38/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:16<00:00,  1.43it/s, loss=0.0470, lr=6.99e-06, grad=M:0.0229, status=Epoch complete]
â–ˆ Epoch 38: Loss T 0.046971 V 0.003755 | F1 T 0.998779 V 0.998895 B 0.999114 SC 3/70 | Acc T 0.998751 V 0.998874 | LR 6.99e-06 | Grad â†“ 0.000000 â†‘ 0.146067 M 0.022916 | 9m 16s
Epoch 39/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:16<00:00,  1.43it/s, loss=0.0333, lr=2.01e-06, grad=M:0.0131, status=Epoch complete]
â–ˆ Epoch 39: Loss T 0.033314 V 0.002609 | F1 T 0.999039 V 0.999070 B 0.999114 SC 4/70 | Acc T 0.999033 V 0.999070 | LR 2.01e-06 | Grad â†“ 0.000000 â†‘ 0.075880 M 0.013063 | 9m 16s
Epoch 40/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:17<00:00,  1.43it/s, loss=0.0255, lr=1.00e-07, grad=M:0.0152, status=Epoch complete]
â–ˆ Epoch 40: Loss T 0.025514 V 0.002248 | F1 T 0.999088 V 0.999114 B 0.999114 SC 5/70 | Acc T 0.999082 V 0.999119 | LR 1.00e-07 | Grad â†“ 0.000000 â†‘ 0.089706 M 0.015214 | 9m 17s
Memory: Rank 0: 14.82 GB | Rank 1: 14.95 GB | Rank 2: 14.85 GB | Rank 3: 14.88 GB | Rank 4: 14.93 GB | Rank 5: 14.90 GB | Rank 6: 14.85 GB | Rank 7: 14.87 GB (Max: 16.94 GB, Total: 135.49 GB)
Saved model state: checkpoints/checkpoint_epoch_40_20241020-084141.pth
Epoch 41/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:17<00:00,  1.43it/s, loss=0.0664, lr=1.81e-05, grad=M:0.1329, status=Epoch complete]
â–ˆ Epoch 41: Loss T 0.066373 V 0.008239 | F1 T 0.997711 V 0.997932 B 0.999114 SC 6/70 | Acc T 0.997674 V 0.997846 | LR 1.81e-05 | Grad â†“ 0.000000 â†‘ 0.898925 M 0.132937 | 9m 17s
Epoch 42/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:17<00:00,  1.43it/s, loss=0.0540, lr=1.31e-05, grad=M:0.2451, status=Epoch complete]
â–ˆ Epoch 42: Loss T 0.054012 V 0.005990 | F1 T 0.998162 V 0.997690 B 0.999114 SC 7/70 | Acc T 0.998078 V 0.997601 | LR 1.31e-05 | Grad â†“ 0.000000 â†‘ 1.477476 M 0.245083 | 9m 17s
Epoch 43/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:16<00:00,  1.43it/s, loss=0.0377, lr=6.99e-06, grad=M:0.1681, status=Epoch complete]
â–ˆ Epoch 43: Loss T 0.037707 V 0.002394 | F1 T 0.998877 V 0.999014 B 0.999114 SC 8/70 | Acc T 0.998874 V 0.999021 | LR 6.99e-06 | Grad â†“ 0.000000 â†‘ 1.055068 M 0.168108 | 9m 16s
Epoch 44/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:18<00:00,  1.43it/s, loss=0.0238, lr=2.01e-06, grad=M:0.0177, status=Epoch complete]
â–ˆ Epoch 44: Loss T 0.023826 V 0.001888 | F1 T 0.999153 V 0.999222 B 0.999222 SC 0/70 | Acc T 0.999143 V 0.999217 | LR 2.01e-06 | Grad â†“ 0.000000 â†‘ 0.089255 M 0.017740 | 9m 18s
Epoch 45/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:17<00:00,  1.43it/s, loss=0.0220, lr=1.00e-07, grad=M:0.0297, status=Epoch complete]
â–ˆ Epoch 45: Loss T 0.021951 V 0.001846 | F1 T 0.999208 V 0.999321 B 0.999321 SC 0/70 | Acc T 0.999192 V 0.999315 | LR 1.00e-07 | Grad â†“ 0.000000 â†‘ 0.182585 M 0.029731 | 9m 17s
Saved model state: checkpoints/checkpoint_epoch_45_20241020-092813.pth
Epoch 46/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:16<00:00,  1.43it/s, loss=0.0529, lr=1.81e-05, grad=M:0.2182, status=Epoch complete]
â–ˆ Epoch 46: Loss T 0.052943 V 0.005782 | F1 T 0.997853 V 0.997776 B 0.999321 SC 1/70 | Acc T 0.997845 V 0.997846 | LR 1.81e-05 | Grad â†“ 0.000000 â†‘ 1.379992 M 0.218215 | 9m 16s
Epoch 47/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:18<00:00,  1.43it/s, loss=0.0486, lr=1.31e-05, grad=M:0.0373, status=Epoch complete]
â–ˆ Epoch 47: Loss T 0.048642 V 0.002986 | F1 T 0.998929 V 0.998927 B 0.999321 SC 2/70 | Acc T 0.998898 V 0.998874 | LR 1.31e-05 | Grad â†“ 0.000000 â†‘ 0.221915 M 0.037268 | 9m 18s
Epoch 48/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:18<00:00,  1.43it/s, loss=0.0341, lr=6.99e-06, grad=M:0.0525, status=Epoch complete]
â–ˆ Epoch 48: Loss T 0.034090 V 0.001544 | F1 T 0.999244 V 0.999495 B 0.999495 SC 0/70 | Acc T 0.999216 V 0.999510 | LR 6.99e-06 | Grad â†“ 0.000000 â†‘ 0.314433 M 0.052484 | 9m 18s
Epoch 49/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:16<00:00,  1.43it/s, loss=0.0220, lr=2.01e-06, grad=M:0.0054, status=Epoch complete]
â–ˆ Epoch 49: Loss T 0.022000 V 0.001422 | F1 T 0.999238 V 0.999353 B 0.999495 SC 1/70 | Acc T 0.999216 V 0.999363 | LR 2.01e-06 | Grad â†“ 0.000000 â†‘ 0.031313 M 0.005363 | 9m 16s
Epoch 50/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:17<00:00,  1.43it/s, loss=0.0180, lr=1.00e-07, grad=M:0.0468, status=Epoch complete]
â–ˆ Epoch 50: Loss T 0.017961 V 0.001177 | F1 T 0.999326 V 0.999561 B 0.999561 SC 0/70 | Acc T 0.999314 V 0.999559 | LR 1.00e-07 | Grad â†“ 0.000000 â†‘ 0.284834 M 0.046843 | 9m 17s
Memory: Rank 0: 14.83 GB | Rank 1: 14.95 GB | Rank 2: 14.85 GB | Rank 3: 14.88 GB | Rank 4: 14.93 GB | Rank 5: 14.90 GB | Rank 6: 14.85 GB | Rank 7: 14.87 GB (Max: 16.94 GB, Total: 135.49 GB)
Saved model state: checkpoints/checkpoint_epoch_50_20241020-101443.pth
Epoch 51/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:17<00:00,  1.43it/s, loss=0.0508, lr=1.81e-05, grad=M:0.2682, status=Epoch complete]
â–ˆ Epoch 51: Loss T 0.050799 V 0.004683 | F1 T 0.998647 V 0.998706 B 0.999561 SC 1/70 | Acc T 0.998629 V 0.998678 | LR 1.81e-05 | Grad â†“ 0.000000 â†‘ 1.513346 M 0.268228 | 9m 17s
Epoch 52/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:18<00:00,  1.43it/s, loss=0.0411, lr=1.31e-05, grad=M:0.3573, status=Epoch complete]
â–ˆ Epoch 52: Loss T 0.041110 V 0.002353 | F1 T 0.998848 V 0.999135 B 0.999561 SC 2/70 | Acc T 0.998825 V 0.999119 | LR 1.31e-05 | Grad â†“ 0.000000 â†‘ 2.054573 M 0.357274 | 9m 18s
Epoch 53/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:18<00:00,  1.43it/s, loss=0.0280, lr=6.99e-06, grad=M:0.0270, status=Epoch complete]
â–ˆ Epoch 53: Loss T 0.028034 V 0.001427 | F1 T 0.999353 V 0.999561 B 0.999561 SC 3/70 | Acc T 0.999339 V 0.999559 | LR 6.99e-06 | Grad â†“ 0.000000 â†‘ 0.140717 M 0.027031 | 9m 18s
Epoch 54/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:16<00:00,  1.43it/s, loss=0.0186, lr=2.01e-06, grad=M:0.4087, status=Epoch complete]
â–ˆ Epoch 54: Loss T 0.018596 V 0.001220 | F1 T 0.999389 V 0.999386 B 0.999561 SC 4/70 | Acc T 0.999388 V 0.999363 | LR 2.01e-06 | Grad â†“ 0.000000 â†‘ 3.046542 M 0.408714 | 9m 16s
Epoch 55/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:17<00:00,  1.43it/s, loss=0.0147, lr=1.00e-07, grad=M:0.0080, status=Epoch complete]
â–ˆ Epoch 55: Loss T 0.014732 V 0.001198 | F1 T 0.999365 V 0.999430 B 0.999561 SC 5/70 | Acc T 0.999363 V 0.999412 | LR 1.00e-07 | Grad â†“ 0.000000 â†‘ 0.055185 M 0.007952 | 9m 17s
Saved model state: checkpoints/checkpoint_epoch_55_20241020-110116.pth
Epoch 56/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:17<00:00,  1.43it/s, loss=0.0408, lr=1.81e-05, grad=M:0.5425, status=Epoch complete]
â–ˆ Epoch 56: Loss T 0.040837 V 0.004360 | F1 T 0.998196 V 0.998667 B 0.999561 SC 6/70 | Acc T 0.998200 V 0.998727 | LR 1.81e-05 | Grad â†“ 0.000000 â†‘ 4.691325 M 0.542475 | 9m 17s
Epoch 57/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:19<00:00,  1.43it/s, loss=0.0375, lr=1.31e-05, grad=M:0.0794, status=Epoch complete]
â–ˆ Epoch 57: Loss T 0.037513 V 0.002617 | F1 T 0.999151 V 0.999166 B 0.999561 SC 7/70 | Acc T 0.999143 V 0.999168 | LR 1.31e-05 | Grad â†“ 0.000000 â†‘ 0.457354 M 0.079409 | 9m 19s
Epoch 58/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:16<00:00,  1.44it/s, loss=0.0277, lr=6.99e-06, grad=M:0.0066, status=Epoch complete]
â–ˆ Epoch 58: Loss T 0.027704 V 0.001045 | F1 T 0.999416 V 0.999561 B 0.999561 SC 8/70 | Acc T 0.999400 V 0.999559 | LR 6.99e-06 | Grad â†“ 0.000000 â†‘ 0.036524 M 0.006619 | 9m 16s
Epoch 59/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:19<00:00,  1.43it/s, loss=0.0173, lr=2.01e-06, grad=M:0.1616, status=Epoch complete]
â–ˆ Epoch 59: Loss T 0.017267 V 0.001454 | F1 T 0.999372 V 0.999320 B 0.999561 SC 9/70 | Acc T 0.999351 V 0.999315 | LR 2.01e-06 | Grad â†“ 0.000000 â†‘ 0.866266 M 0.161564 | 9m 19s
Epoch 60/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:07<00:00,  1.46it/s, loss=0.0128, lr=1.00e-07, grad=M:0.0612, status=Epoch complete]
â–ˆ Epoch 60: Loss T 0.012789 V 0.001078 | F1 T 0.999394 V 0.999517 B 0.999561 SC 10/70 | Acc T 0.999376 V 0.999510 | LR 1.00e-07 | Grad â†“ 0.000000 â†‘ 0.336498 M 0.061194 | 9m 7s
Memory: Rank 0: 14.83 GB | Rank 1: 14.95 GB | Rank 2: 14.85 GB | Rank 3: 14.88 GB | Rank 4: 14.93 GB | Rank 5: 14.90 GB | Rank 6: 14.85 GB | Rank 7: 14.87 GB (Max: 16.94 GB, Total: 135.49 GB)
Saved model state: checkpoints/checkpoint_epoch_60_20241020-114741.pth
Epoch 61/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:26<00:00,  1.41it/s, loss=0.0416, lr=1.81e-05, grad=M:0.0665, status=Epoch complete]
â–ˆ Epoch 61: Loss T 0.041614 V 0.003680 | F1 T 0.998669 V 0.999287 B 0.999561 SC 11/70 | Acc T 0.998641 V 0.999266 | LR 1.81e-05 | Grad â†“ 0.000000 â†‘ 0.439281 M 0.066457 | 9m 26s
Epoch 62/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:17<00:00,  1.43it/s, loss=0.0353, lr=1.31e-05, grad=M:0.0354, status=Epoch complete]
â–ˆ Epoch 62: Loss T 0.035280 V 0.001658 | F1 T 0.999222 V 0.999188 B 0.999561 SC 12/70 | Acc T 0.999204 V 0.999168 | LR 1.31e-05 | Grad â†“ 0.000000 â†‘ 0.205578 M 0.035430 | 9m 17s
Epoch 63/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:17<00:00,  1.43it/s, loss=0.0212, lr=6.99e-06, grad=M:0.0443, status=Epoch complete]
â–ˆ Epoch 63: Loss T 0.021184 V 0.001481 | F1 T 0.999356 V 0.999298 B 0.999561 SC 13/70 | Acc T 0.999339 V 0.999266 | LR 6.99e-06 | Grad â†“ 0.000000 â†‘ 0.293709 M 0.044308 | 9m 17s
Epoch 64/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:17<00:00,  1.43it/s, loss=0.0153, lr=2.01e-06, grad=M:0.0005, status=Epoch complete]
â–ˆ Epoch 64: Loss T 0.015292 V 0.001137 | F1 T 0.999509 V 0.999309 B 0.999561 SC 14/70 | Acc T 0.999498 V 0.999315 | LR 2.01e-06 | Grad â†“ 0.000000 â†‘ 0.002888 M 0.000534 | 9m 17s
Epoch 65/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:17<00:00,  1.43it/s, loss=0.0117, lr=1.00e-07, grad=M:0.2679, status=Epoch complete]
â–ˆ Epoch 65: Loss T 0.011652 V 0.000938 | F1 T 0.999548 V 0.999462 B 0.999561 SC 15/70 | Acc T 0.999535 V 0.999461 | LR 1.00e-07 | Grad â†“ 0.000000 â†‘ 1.499129 M 0.267875 | 9m 17s
Saved model state: checkpoints/checkpoint_epoch_65_20241020-123421.pth
Epoch 66/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:19<00:00,  1.43it/s, loss=0.0399, lr=1.81e-05, grad=M:0.0740, status=Epoch complete]
â–ˆ Epoch 66: Loss T 0.039853 V 0.003763 | F1 T 0.998709 V 0.998916 B 0.999561 SC 16/70 | Acc T 0.998702 V 0.998874 | LR 1.81e-05 | Grad â†“ 0.000000 â†‘ 0.382419 M 0.074011 | 9m 19s
Epoch 67/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:17<00:00,  1.43it/s, loss=0.0308, lr=1.31e-05, grad=M:0.3086, status=Epoch complete]
â–ˆ Epoch 67: Loss T 0.030809 V 0.001852 | F1 T 0.999359 V 0.999090 B 0.999561 SC 17/70 | Acc T 0.999351 V 0.999070 | LR 1.31e-05 | Grad â†“ 0.000000 â†‘ 1.596474 M 0.308605 | 9m 17s
Epoch 68/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:16<00:00,  1.43it/s, loss=0.0205, lr=6.99e-06, grad=M:0.0006, status=Epoch complete]
â–ˆ Epoch 68: Loss T 0.020542 V 0.001935 | F1 T 0.999411 V 0.999145 B 0.999561 SC 18/70 | Acc T 0.999388 V 0.999119 | LR 6.99e-06 | Grad â†“ 0.000000 â†‘ 0.003152 M 0.000594 | 9m 16s
Epoch 69/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:17<00:00,  1.43it/s, loss=0.0142, lr=2.01e-06, grad=M:0.0596, status=Epoch complete]
â–ˆ Epoch 69: Loss T 0.014208 V 0.001424 | F1 T 0.999474 V 0.999342 B 0.999561 SC 19/70 | Acc T 0.999449 V 0.999315 | LR 2.01e-06 | Grad â†“ 0.000000 â†‘ 0.319071 M 0.059601 | 9m 17s
Epoch 70/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:17<00:00,  1.43it/s, loss=0.0110, lr=1.00e-07, grad=M:0.0012, status=Epoch complete]
â–ˆ Epoch 70: Loss T 0.010981 V 0.001295 | F1 T 0.999496 V 0.999386 B 0.999561 SC 20/70 | Acc T 0.999474 V 0.999363 | LR 1.00e-07 | Grad â†“ 0.000000 â†‘ 0.007392 M 0.001188 | 9m 17s
Memory: Rank 0: 14.83 GB | Rank 1: 14.95 GB | Rank 2: 14.85 GB | Rank 3: 14.88 GB | Rank 4: 14.93 GB | Rank 5: 14.90 GB | Rank 6: 14.85 GB | Rank 7: 14.87 GB (Max: 16.94 GB, Total: 135.49 GB)
Saved model state: checkpoints/checkpoint_epoch_70_20241020-132055.pth
Epoch 71/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:17<00:00,  1.43it/s, loss=0.0331, lr=1.81e-05, grad=M:0.0124, status=Epoch complete]
â–ˆ Epoch 71: Loss T 0.033086 V 0.003385 | F1 T 0.998853 V 0.998926 B 0.999561 SC 21/70 | Acc T 0.998788 V 0.998874 | LR 1.81e-05 | Grad â†“ 0.000000 â†‘ 0.069064 M 0.012442 | 9m 17s
Epoch 72/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:18<00:00,  1.43it/s, loss=0.0308, lr=1.31e-05, grad=M:0.0389, status=Epoch complete]
â–ˆ Epoch 72: Loss T 0.030822 V 0.001657 | F1 T 0.999351 V 0.999188 B 0.999561 SC 22/70 | Acc T 0.999327 V 0.999168 | LR 1.31e-05 | Grad â†“ 0.000000 â†‘ 0.236370 M 0.038862 | 9m 18s
Epoch 73/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:17<00:00,  1.43it/s, loss=0.0189, lr=6.99e-06, grad=M:0.1113, status=Epoch complete]
â–ˆ Epoch 73: Loss T 0.018935 V 0.001381 | F1 T 0.999362 V 0.999287 B 0.999561 SC 23/70 | Acc T 0.999351 V 0.999266 | LR 6.99e-06 | Grad â†“ 0.000000 â†‘ 0.585036 M 0.111319 | 9m 17s
Epoch 74/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:18<00:00,  1.43it/s, loss=0.0119, lr=2.01e-06, grad=M:0.0439, status=Epoch complete]
â–ˆ Epoch 74: Loss T 0.011914 V 0.001056 | F1 T 0.999466 V 0.999375 B 0.999561 SC 24/70 | Acc T 0.999449 V 0.999363 | LR 2.01e-06 | Grad â†“ 0.000000 â†‘ 0.292344 M 0.043869 | 9m 18s
Epoch 75/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:18<00:00,  1.43it/s, loss=0.0095, lr=1.00e-07, grad=M:0.0618, status=Epoch complete]
â–ˆ Epoch 75: Loss T 0.009523 V 0.000968 | F1 T 0.999499 V 0.999386 B 0.999561 SC 25/70 | Acc T 0.999486 V 0.999363 | LR 1.00e-07 | Grad â†“ 0.000000 â†‘ 0.338146 M 0.061792 | 9m 18s
Saved model state: checkpoints/checkpoint_epoch_75_20241020-140729.pth
Epoch 76/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:18<00:00,  1.43it/s, loss=0.0314, lr=1.81e-05, grad=M:0.0174, status=Epoch complete]
â–ˆ Epoch 76: Loss T 0.031419 V 0.001773 | F1 T 0.999283 V 0.999342 B 0.999561 SC 26/70 | Acc T 0.999290 V 0.999315 | LR 1.81e-05 | Grad â†“ 0.000000 â†‘ 0.093312 M 0.017351 | 9m 18s
Epoch 77/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:17<00:00,  1.43it/s, loss=0.0277, lr=1.31e-05, grad=M:0.0720, status=Epoch complete]
â–ˆ Epoch 77: Loss T 0.027694 V 0.001498 | F1 T 0.999369 V 0.999386 B 0.999561 SC 27/70 | Acc T 0.999363 V 0.999363 | LR 1.31e-05 | Grad â†“ 0.000000 â†‘ 0.439396 M 0.071993 | 9m 17s
Epoch 78/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:16<00:00,  1.43it/s, loss=0.0173, lr=6.99e-06, grad=M:0.0137, status=Epoch complete]
â–ˆ Epoch 78: Loss T 0.017277 V 0.001156 | F1 T 0.999512 V 0.999343 B 0.999561 SC 28/70 | Acc T 0.999498 V 0.999363 | LR 6.99e-06 | Grad â†“ 0.000000 â†‘ 0.078304 M 0.013722 | 9m 16s
Epoch 79/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:17<00:00,  1.43it/s, loss=0.0104, lr=2.01e-06, grad=M:0.0319, status=Epoch complete]
â–ˆ Epoch 79: Loss T 0.010377 V 0.000878 | F1 T 0.999501 V 0.999584 B 0.999584 SC 0/70 | Acc T 0.999486 V 0.999608 | LR 2.01e-06 | Grad â†“ 0.000000 â†‘ 0.173608 M 0.031918 | 9m 17s
Epoch 80/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:17<00:00,  1.43it/s, loss=0.0088, lr=1.00e-07, grad=M:0.4615, status=Epoch complete]
â–ˆ Epoch 80: Loss T 0.008753 V 0.000786 | F1 T 0.999512 V 0.999605 B 0.999605 SC 0/70 | Acc T 0.999498 V 0.999608 | LR 1.00e-07 | Grad â†“ 0.000000 â†‘ 2.570064 M 0.461464 | 9m 17s
Memory: Rank 0: 14.83 GB | Rank 1: 14.95 GB | Rank 2: 14.85 GB | Rank 3: 14.88 GB | Rank 4: 14.93 GB | Rank 5: 14.90 GB | Rank 6: 14.85 GB | Rank 7: 14.87 GB (Max: 16.94 GB, Total: 135.49 GB)
Saved model state: checkpoints/checkpoint_epoch_80_20241020-145401.pth
Epoch 81/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:18<00:00,  1.43it/s, loss=0.0324, lr=1.81e-05, grad=M:0.0443, status=Epoch complete]
â–ˆ Epoch 81: Loss T 0.032381 V 0.002843 | F1 T 0.999063 V 0.998925 B 0.999605 SC 1/70 | Acc T 0.999045 V 0.998923 | LR 1.81e-05 | Grad â†“ 0.000000 â†‘ 0.263246 M 0.044315 | 9m 18s
Epoch 82/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:18<00:00,  1.43it/s, loss=0.0249, lr=1.31e-05, grad=M:0.0531, status=Epoch complete]
â–ˆ Epoch 82: Loss T 0.024902 V 0.001287 | F1 T 0.999358 V 0.999495 B 0.999605 SC 2/70 | Acc T 0.999339 V 0.999510 | LR 1.31e-05 | Grad â†“ 0.000000 â†‘ 0.281502 M 0.053130 | 9m 18s
Epoch 83/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:16<00:00,  1.43it/s, loss=0.0175, lr=6.99e-06, grad=M:0.2064, status=Epoch complete]
â–ˆ Epoch 83: Loss T 0.017521 V 0.001063 | F1 T 0.999502 V 0.999550 B 0.999605 SC 3/70 | Acc T 0.999486 V 0.999559 | LR 6.99e-06 | Grad â†“ 0.000000 â†‘ 1.175501 M 0.206355 | 9m 16s
Epoch 84/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:19<00:00,  1.43it/s, loss=0.0107, lr=2.01e-06, grad=M:0.1687, status=Epoch complete]
â–ˆ Epoch 84: Loss T 0.010710 V 0.000840 | F1 T 0.999537 V 0.999528 B 0.999605 SC 4/70 | Acc T 0.999510 V 0.999559 | LR 2.01e-06 | Grad â†“ 0.000000 â†‘ 1.233636 M 0.168729 | 9m 19s
Epoch 85/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:19<00:00,  1.43it/s, loss=0.0079, lr=1.00e-07, grad=M:0.0186, status=Epoch complete]
â–ˆ Epoch 85: Loss T 0.007947 V 0.000785 | F1 T 0.999570 V 0.999484 B 0.999605 SC 5/70 | Acc T 0.999547 V 0.999510 | LR 1.00e-07 | Grad â†“ 0.000000 â†‘ 0.120882 M 0.018583 | 9m 19s
Saved model state: checkpoints/checkpoint_epoch_85_20241020-154038.pth
Epoch 86/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:17<00:00,  1.43it/s, loss=0.0292, lr=1.81e-05, grad=M:0.0125, status=Epoch complete]
â–ˆ Epoch 86: Loss T 0.029240 V 0.002974 | F1 T 0.998967 V 0.998873 B 0.999605 SC 6/70 | Acc T 0.998923 V 0.998874 | LR 1.81e-05 | Grad â†“ 0.000000 â†‘ 0.073462 M 0.012496 | 9m 17s
Epoch 87/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:18<00:00,  1.43it/s, loss=0.0218, lr=1.31e-05, grad=M:0.0053, status=Epoch complete]
â–ˆ Epoch 87: Loss T 0.021843 V 0.001538 | F1 T 0.999427 V 0.999419 B 0.999605 SC 7/70 | Acc T 0.999400 V 0.999412 | LR 1.31e-05 | Grad â†“ 0.000000 â†‘ 0.029659 M 0.005265 | 9m 18s
Epoch 88/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:17<00:00,  1.43it/s, loss=0.0148, lr=6.99e-06, grad=M:0.0053, status=Epoch complete]
â–ˆ Epoch 88: Loss T 0.014776 V 0.000893 | F1 T 0.999570 V 0.999407 B 0.999605 SC 8/70 | Acc T 0.999559 V 0.999412 | LR 6.99e-06 | Grad â†“ 0.000000 â†‘ 0.035839 M 0.005298 | 9m 17s
Epoch 89/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:18<00:00,  1.43it/s, loss=0.0094, lr=2.01e-06, grad=M:0.0038, status=Epoch complete]
â–ˆ Epoch 89: Loss T 0.009392 V 0.000834 | F1 T 0.999567 V 0.999462 B 0.999605 SC 9/70 | Acc T 0.999547 V 0.999461 | LR 2.01e-06 | Grad â†“ 0.000000 â†‘ 0.018818 M 0.003806 | 9m 18s
Epoch 90/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:17<00:00,  1.43it/s, loss=0.0074, lr=1.00e-07, grad=M:0.0002, status=Epoch complete]
â–ˆ Epoch 90: Loss T 0.007425 V 0.000920 | F1 T 0.999564 V 0.999386 B 0.999605 SC 10/70 | Acc T 0.999547 V 0.999363 | LR 1.00e-07 | Grad â†“ 0.000000 â†‘ 0.001086 M 0.000194 | 9m 17s
Memory: Rank 0: 14.83 GB | Rank 1: 14.95 GB | Rank 2: 14.85 GB | Rank 3: 14.88 GB | Rank 4: 14.93 GB | Rank 5: 14.90 GB | Rank 6: 14.85 GB | Rank 7: 14.87 GB (Max: 16.94 GB, Total: 135.49 GB)
Saved model state: checkpoints/checkpoint_epoch_90_20241020-162711.pth
Epoch 91/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:17<00:00,  1.43it/s, loss=0.0318, lr=1.81e-05, grad=M:0.0832, status=Epoch complete]
â–ˆ Epoch 91: Loss T 0.031829 V 0.002747 | F1 T 0.998943 V 0.998994 B 0.999605 SC 11/70 | Acc T 0.998898 V 0.999021 | LR 1.81e-05 | Grad â†“ 0.000000 â†‘ 0.495438 M 0.083215 | 9m 17s
Epoch 92/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:16<00:00,  1.43it/s, loss=0.0233, lr=1.31e-05, grad=M:0.0080, status=Epoch complete]
â–ˆ Epoch 92: Loss T 0.023304 V 0.002730 | F1 T 0.999090 V 0.999036 B 0.999605 SC 12/70 | Acc T 0.999033 V 0.998972 | LR 1.31e-05 | Grad â†“ 0.000000 â†‘ 0.044876 M 0.007978 | 9m 16s
Epoch 93/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:17<00:00,  1.43it/s, loss=0.0155, lr=6.99e-06, grad=M:0.0030, status=Epoch complete]
â–ˆ Epoch 93: Loss T 0.015497 V 0.000885 | F1 T 0.999515 V 0.999517 B 0.999605 SC 13/70 | Acc T 0.999510 V 0.999510 | LR 6.99e-06 | Grad â†“ 0.000000 â†‘ 0.018333 M 0.003041 | 9m 17s
Epoch 94/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:16<00:00,  1.43it/s, loss=0.0087, lr=2.01e-06, grad=M:0.0143, status=Epoch complete]
â–ˆ Epoch 94: Loss T 0.008730 V 0.000714 | F1 T 0.999592 V 0.999517 B 0.999605 SC 14/70 | Acc T 0.999584 V 0.999510 | LR 2.01e-06 | Grad â†“ 0.000000 â†‘ 0.088013 M 0.014318 | 9m 16s
Epoch 95/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:17<00:00,  1.43it/s, loss=0.0079, lr=1.00e-07, grad=M:0.0006, status=Epoch complete]
â–ˆ Epoch 95: Loss T 0.007869 V 0.000702 | F1 T 0.999597 V 0.999517 B 0.999605 SC 15/70 | Acc T 0.999584 V 0.999510 | LR 1.00e-07 | Grad â†“ 0.000000 â†‘ 0.003411 M 0.000571 | 9m 17s
Saved model state: checkpoints/checkpoint_epoch_95_20241020-171342.pth
Epoch 96/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:17<00:00,  1.43it/s, loss=0.0237, lr=1.81e-05, grad=M:0.0122, status=Epoch complete]
â–ˆ Epoch 96: Loss T 0.023687 V 0.002396 | F1 T 0.999217 V 0.999572 B 0.999605 SC 16/70 | Acc T 0.999216 V 0.999559 | LR 1.81e-05 | Grad â†“ 0.000000 â†‘ 0.078289 M 0.012158 | 9m 17s
Epoch 97/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:17<00:00,  1.43it/s, loss=0.0213, lr=1.31e-05, grad=M:0.1672, status=Epoch complete]
â–ˆ Epoch 97: Loss T 0.021348 V 0.000790 | F1 T 0.999474 V 0.999736 B 0.999736 SC 0/70 | Acc T 0.999449 V 0.999755 | LR 1.31e-05 | Grad â†“ 0.000000 â†‘ 1.044098 M 0.167169 | 9m 17s
Epoch 98/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:19<00:00,  1.43it/s, loss=0.0137, lr=6.99e-06, grad=M:0.1178, status=Epoch complete]
â–ˆ Epoch 98: Loss T 0.013691 V 0.000783 | F1 T 0.999539 V 0.999529 B 0.999736 SC 1/70 | Acc T 0.999523 V 0.999559 | LR 6.99e-06 | Grad â†“ 0.000000 â†‘ 0.869989 M 0.117809 | 9m 19s
Epoch 99/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:17<00:00,  1.43it/s, loss=0.0093, lr=2.01e-06, grad=M:0.0687, status=Epoch complete]
â–ˆ Epoch 99: Loss T 0.009274 V 0.000663 | F1 T 0.999575 V 0.999605 B 0.999736 SC 2/70 | Acc T 0.999559 V 0.999608 | LR 2.01e-06 | Grad â†“ 0.000000 â†‘ 0.381115 M 0.068705 | 9m 17s
Epoch 100/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:17<00:00,  1.43it/s, loss=0.0062, lr=1.00e-07, grad=M:0.0072, status=Epoch complete]
â–ˆ Epoch 100: Loss T 0.006208 V 0.000663 | F1 T 0.999575 V 0.999605 B 0.999736 SC 3/70 | Acc T 0.999559 V 0.999608 | LR 1.00e-07 | Grad â†“ 0.000000 â†‘ 0.053080 M 0.007162 | 9m 17s
Memory: Rank 0: 14.83 GB | Rank 1: 14.95 GB | Rank 2: 14.85 GB | Rank 3: 14.88 GB | Rank 4: 14.93 GB | Rank 5: 14.90 GB | Rank 6: 14.85 GB | Rank 7: 14.87 GB (Max: 16.94 GB, Total: 135.49 GB)
Saved model state: checkpoints/checkpoint_epoch_100_20241020-180015.pth
Saving model in ONNX format...
Model saved in ONNX format to saves/model_20241020-180019.onnx and uploaded to Weights & Biases.
Saved model state: checkpoints/final_model_20241020-180024.pth
Saved model pickle: checkpoints/final_model_20241020-180024.pkl
Training completed (10h 51m 48s)

Evaluating model...

multi_run_2 Multi-Class Classification Report

              precision    recall  f1-score   support

    negative   0.857695  0.713062  0.778720      1868
     neutral   0.689390  0.805872  0.743094      1669
    positive   0.803339  0.817410  0.810313      1884

    accuracy                       0.777901      5421
   macro avg   0.783474  0.778781  0.777376      5421
weighted avg   0.786987  0.777901  0.778731      5421

ROC AUC: 0.912498

Predicted  negative  neutral  positive
Actual                                
negative       1332      352       184
neutral         131     1345       193
positive         90      254      1540

Saved predictions: saves/predictions_20241020-180213.csv

Macro F1 Score: 0.78

Evaluation completed (2m 33s)
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:            eval/macro_f1_score â–
wandb:             gradients/max_norm â–†â–‚â–…â–…â–ƒâ–â–â–ƒâ–ƒâ–â–ƒâ–â–â–â–ƒâ–â–ˆâ–‚â–â–â–â–ƒâ–â–â–â–‚â–â–â–â–â–â–ƒâ–ƒâ–â–â–â–â–â–â–‚
wandb:            gradients/mean_norm â–‡â–‚â–‡â–‡â–„â–†â–â–â–ƒâ–„â–â–â–„â–‚â–‚â–â–†â–â–ˆâ–â–‚â–â–â–…â–â–â–â–‚â–‚â–â–â–â–‡â–ƒâ–â–â–â–‚â–â–‚
wandb:             gradients/min_norm â–‡â–ˆâ–ƒâ–â–â–â–â–„â–‚â–‚â–„â–‡â–â–…â–…â–ƒâ–‚â–‚â–‚â–ƒâ–â–‚â–â–â–â–‚â–‚â–‚â–â–â–â–â–â–â–ƒâ–â–â–ƒâ–‚â–
wandb:                    other/epoch â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:            other/learning_rate â–ˆâ–†â–„â–â–ˆâ–„â–‚â–â–„â–‚â–†â–„â–â–„â–â–†â–„â–â–†â–‚â–„â–‚â–â–ˆâ–„â–â–„â–‚â–†â–„â–â–ˆâ–„â–â–ˆâ–„â–‚â–â–ˆâ–„
wandb:               other/stop_limit â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 train/accuracy â–â–…â–ƒâ–…â–†â–‡â–‡â–ƒâ–†â–‡â–…â–‡â–ˆâ–‡â–‡â–‡â–‡â–ˆâ–ˆâ–†â–‡â–ˆâ–ˆâ–†â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆ
wandb:                     train/loss â–ˆâ–†â–„â–‡â–…â–†â–…â–„â–ƒâ–‚â–‚â–‚â–…â–„â–ƒâ–„â–ƒâ–‚â–‚â–„â–‚â–„â–ƒâ–‚â–‚â–ƒâ–ƒâ–‚â–‚â–â–ƒâ–â–ƒâ–ƒâ–â–‚â–â–ƒâ–‚â–
wandb:           train/macro_f1_score â–â–†â–†â–‡â–‡â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–†â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆ
wandb:               train/stop_count â–â–â–â–â–â–ƒâ–ƒâ–ƒâ–â–â–â–â–â–â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–…â–…â–…â–†â–†â–‡â–ˆâ–ˆâ–â–â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–…â–…â–â–‚
wandb:            validation/accuracy â–ƒâ–†â–â–†â–†â–‡â–‚â–…â–ˆâ–‡â–‡â–‡â–…â–ˆâ–‡â–‡â–†â–‡â–‡â–‡â–†â–†â–‡â–…â–‡â–‡â–ˆâ–ˆâ–†â–ˆâ–ˆâ–…â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb: validation/best_macro_f1_score â–â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                validation/loss â–ˆâ–ƒâ–ƒâ–†â–„â–‚â–†â–…â–‚â–‚â–„â–ƒâ–‚â–‚â–„â–‚â–â–â–ƒâ–‚â–â–ƒâ–â–ƒâ–‚â–‚â–ƒâ–â–â–‚â–â–â–â–â–â–‚â–‚â–â–â–
wandb:      validation/macro_f1_score â–â–„â–‡â–‡â–…â–‡â–‡â–…â–…â–‡â–‡â–ˆâ–‡â–†â–‡â–ˆâ–†â–ˆâ–‡â–ˆâ–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb: 
wandb: Run summary:
wandb:            eval/macro_f1_score 0.77738
wandb:             gradients/max_norm 0.05308
wandb:            gradients/mean_norm 0.00716
wandb:             gradients/min_norm 0.0
wandb:                    other/epoch 100
wandb:            other/learning_rate 0.0
wandb:               other/stop_limit 70
wandb:                 train/accuracy 0.99956
wandb:                     train/loss 0.00621
wandb:           train/macro_f1_score 0.99958
wandb:               train/stop_count 3
wandb:            validation/accuracy 0.99961
wandb: validation/best_macro_f1_score 0.99974
wandb:                validation/loss 0.00066
wandb:      validation/macro_f1_score 0.9996
wandb: 
wandb: ðŸš€ View run multi_run_2 at: https://wandb.ai/jimbeno/Electra%20Ensemble/runs/u27j1efz
wandb: â­ï¸ View project at: https://wandb.ai/jimbeno/Electra%20Ensemble
wandb: Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 2 other file(s)
wandb: Find logs at: ./wandb/run-20241020_070835-u27j1efz/logs
TOTAL Time: 10h 54m 46s
(nlp) ubuntu@104-171-203-160:~/nlp-test/sentiment$ logout
Connection to 104.171.203.160 closed.
(base) Jims-MBP:~ jim$ scp ubuntu@104.171.203.160:~/nlp-test/sentiment/checkpoints/checkpoint_epoch_100_20241020-180015.pth .
Enter passphrase for key '/Users/jim/.ssh/id_rsa': 
(base) Jims-MBP:~ jim$ pwd
/Users/jim
(base) Jims-MBP:~ jim$ cd Desktop/
(base) Jims-MBP:Desktop jim$ cd final_project/
(base) Jims-MBP:final_project jim$ cd multiclass/
(base) Jims-MBP:multiclass jim$ ls
checkpoint_epoch_30_20241020-064527.pth	final_model_20241020-065930.pkl		predictions_20241020-070119.csv
(base) Jims-MBP:multiclass jim$ scp ubuntu@104.171.203.160:~/nlp-test/sentiment/checkpoints/checkpoint_epoch_100_20241020-180015.pth .
Enter passphrase for key '/Users/jim/.ssh/id_rsa': 
checkpoint_epoch_100_20241020-180015.pth                                                                                                               100% 1292MB   9.4MB/s   02:18    
(base) Jims-MBP:multiclass jim$ scp ubuntu@104.171.203.160:~/nlp-test/sentiment/saves/predictions_20241020-180213.csv .
Enter passphrase for key '/Users/jim/.ssh/id_rsa': 
predictions_20241020-180213.csv                                                                                                                        100%  515KB   1.8MB/s   00:00    
(base) Jims-MBP:multiclass jim$ scp ubuntu@104.171.203.160:~/nlp-test/sentiment/checkpoints/final_model_20241020-180024.pkl .
Enter passphrase for key '/Users/jim/.ssh/id_rsa': 
final_model_20241020-180024.pkl                                                                                                                        100%  610MB  29.7MB/s   00:20    
(base) Jims-MBP:multiclass jim$ ssh ubuntu@104.171.203.160
Enter passphrase for key '/Users/jim/.ssh/id_rsa': 
Welcome to Ubuntu 22.04.3 LTS (GNU/Linux 6.2.0-37-generic x86_64)
 .============.
 ||   __      ||    _                    _         _
 ||   \_\     ||   | |    __ _ _ __ ___ | |__   __| | __ _
 ||    \_\    ||   | |   / _` | '_ ` _ \| '_ \ / _` |/ _` |
 ||   /_Î»_\   ||   | |__| (_| | | | | | | |_) | (_| | (_| |
 ||  /_/ \_\  ||   |_____\__,_|_| |_| |_|_.__/ \__,_|\__,_|
  .============.                                  GPU CLOUD

 * Documentation:  https://help.ubuntu.com
 * Management:     https://landscape.canonical.com
 * Support:        https://ubuntu.com/advantage

  System information as of Sun Oct 20 21:22:55 UTC 2024

  System load:  0.201171875      Processes:                859
  Usage of /:   0.4% of 5.68TB   Users logged in:          0
  Memory usage: 0%               IPv4 address for docker0: 172.17.0.1
  Swap usage:   0%               IPv4 address for eno1:    104.171.203.160

 * Strictly confined Kubernetes makes edge and IoT secure. Learn how MicroK8s
   just raised the bar for easy, resilient and secure K8s cluster deployment.

   https://ubuntu.com/engage/secure-kubernetes-at-the-edge

Expanded Security Maintenance for Applications is not enabled.

270 updates can be applied immediately.
158 of these updates are standard security updates.
To see these additional updates run: apt list --upgradable

20 additional security updates can be applied with ESM Apps.
Learn more about enabling ESM Apps service at https://ubuntu.com/esm

New release '24.04.1 LTS' available.
Run 'do-release-upgrade' to upgrade to it.


Last login: Sun Oct 20 01:54:09 2024 from 69.209.27.147
ubuntu@104-171-203-160:~$ cd nlp-test/sentiment/
ubuntu@104-171-203-160:~/nlp-test/sentiment$ source nlp/bin/activate
(nlp) ubuntu@104-171-203-160:~/nlp-test/sentiment$ wandb login
wandb: Currently logged in as: jbeno (jimbeno). Use `wandb login --relogin` to force relogin
(nlp) ubuntu@104-171-203-160:~/nlp-test/sentiment$ python ./ddp_sentiment_finetune.py --dataset 'merged_local' --weights_name 'google/electra-base-discriminator' --save_data --save_model --save_pickle --save_preds --lr 0.00002 --epochs 69 --pooling 'mean' --dropout_rate 0.3 --num_layers 2 --hidden_dim 1024 --hidden_activation 'swishglu' --batch_size 16 --accumulation_steps 2 --finetune_bert --finetune_layers 12 --l2_strength 0.01 --checkpoint_interval 5 --use_zero --optimizer 'adamw' --scheduler 'cosine_warmup' --scheduler_kwargs '{"T_0":5, "T_mult":1, "eta_min":1e-7}' --decimal 6 --val_percent 0.2 --early_stop 'score' --n_iter_no_change 70 --show_progress --wandb --wandb_project 'Electra Ensemble' --wandb_run 'multi_run_2' --model_file 'checkpoint_epoch_50_20241020-101443.pth' --interactive

Starting DDP PyTorch Training...
Device: cuda, Number of GPUs: 8
Spawning 8 processes...
Rank 6 - Device: cuda:6
Rank 2 - Device: cuda:2
Rank 1 - Device: cuda:1
Rank 5 - Device: cuda:5
Rank 7 - Device: cuda:7
Rank 4 - Device: cuda:4
Rank 3 - Device: cuda:3
Rank 0 - Device: cuda:0
8 process groups initialized with 'nccl' backend on localhost:12355
NCCL Timeout: 1 hr 0 min. NCCL Blocking Wait: Enabled
wandb: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: jbeno (jimbeno). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.3
wandb: Run data is saved locally in /home/ubuntu/nlp-test/sentiment/wandb/run-20241020_212512-jaf853fq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run multi_run_2
wandb: â­ï¸ View project at https://wandb.ai/jimbeno/Electra%20Ensemble
wandb: ðŸš€ View run at https://wandb.ai/jimbeno/Electra%20Ensemble/runs/jaf853fq
Wand run initialized.

Initializing 'google/electra-base-discriminator' tokenizer and model...
Tokenizer and model initialized (1s)

Loading data...
Using the same dataset for training and evaluation
Train Data: Merged DynaSent Round 1, Round 2 and SST from Local: 'data/merged'
Dev Data: Merged DynaSent Round 1, Round 2 and SST from Local: 'data/merged'
Train size: 102097, Dev size: 5421
Train label distribution:
	      Negative: 21910
	       Neutral: 49148
	      Positive: 31039
Dev label distribution:
	      Negative: 1868
	       Neutral: 1669
	      Positive: 1884
Data loaded (370ms)

Processing data...
(Batch size: 16, Pooling: Mean, Fine Tune BERT: True, Chunk size: None)...
Extracting sentences and labels...

Data saved to: saves/data_8_gpu_20241020-212515.npz
X Train shape: [102097], X Dev shape: [5421]
y Train shape: [102097], y Dev shape: [5421]
Data processed (706ms)

Initializing DDP Neural Classifier...
Layers: 2, Hidden Dim: 1024, Hidden Act: SwishGLU, Dropout: 0.3, Optimizer: AdamW, L2 Strength: 0.01, Pooling: MEAN, Accumulation Steps: 2, Max Grad Norm: None
Batch Size: 16, Max Epochs: 69, LR: 2e-05, Early Stop: score, Fine-tune BERT: True, Fine-tune Layers: 12, Freeze BERT: False, Target Score: None, Interactive: True
Loading model from: checkpoints/checkpoint_epoch_50_20241020-101443.pth...
Loaded checkpoint: checkpoints/checkpoint_epoch_50_20241020-101443.pth
Retrieved model state dictionary.
Retrieved optimizer state dictionary.
Classifier initialized (7s)

Fitting DDP Neural Classifier on training data...
Num Workers: 0, Prefetch: None
Building dataset and dataloader...
Score-based early stopping enabled (macro average F1 score against validation set). Validation fraction: 0.2
Training will stop early if the score does not improve by at least 0.00001 for 70 iterations.
Split data into (X:81677, y:81677) Training samples, and (X:20420, y:20420) Validation samples.
Initializing model, graph, optimizer...
BERT's original pooler removed. Using custom pooling type: mean
BERT has 108,891,648 trainable parameters and 0 non-trainable parameters
Number of BERT layers requiring gradients: 12 out of 12
Fine-tuning the last 12 out of 12 BERT layers

Model Architecture Summary:
BERTClassifier(
  (bert): ElectraModel(
    (embeddings): ElectraEmbeddings(
      (word_embeddings): Embedding(30522, 768, padding_idx=0)
      (position_embeddings): Embedding(512, 768)
      (token_type_embeddings): Embedding(2, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): ElectraEncoder(
      (layer): ModuleList(
        (0-11): 12 x ElectraLayer(
          (attention): ElectraAttention(
            (self): ElectraSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): ElectraSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): ElectraIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): ElectraOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
  (custom_pooling): PoolingLayer()
  (classifier): Classifier(
    (layers): Sequential(
      (0): Linear(in_features=768, out_features=1024, bias=True)
      (1): SwishGLU(
        (projection): Linear(in_features=1024, out_features=2048, bias=True)
        (activation): SiLU()
      )
      (2): Dropout(p=0.3, inplace=False)
      (3): Linear(in_features=1024, out_features=1024, bias=True)
      (4): SwishGLU(
        (projection): Linear(in_features=1024, out_features=2048, bias=True)
        (activation): SiLU()
      )
      (5): Dropout(p=0.3, inplace=False)
      (6): Linear(in_features=1024, out_features=3, bias=True)
    )
  )
)

Model Parameters:
  bert.embeddings.word_embeddings: 23,440,896 (trainable)
  bert.embeddings.position_embeddings: 393,216 (trainable)
  bert.embeddings.token_type_embeddings: 1,536 (trainable)
  bert.embeddings.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.0.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.0.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.0.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.0.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.0.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.0.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.0.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.0.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.1.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.1.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.1.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.1.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.1.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.1.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.1.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.1.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.2.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.2.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.2.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.2.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.2.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.2.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.2.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.2.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.3.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.3.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.3.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.3.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.3.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.3.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.3.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.3.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.4.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.4.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.4.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.4.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.4.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.4.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.4.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.4.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.5.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.5.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.5.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.5.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.5.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.5.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.5.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.5.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.6.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.6.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.6.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.6.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.6.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.6.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.6.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.6.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.7.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.7.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.7.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.7.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.7.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.7.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.7.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.7.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.8.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.8.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.8.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.8.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.8.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.8.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.8.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.8.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.9.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.9.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.9.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.9.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.9.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.9.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.9.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.9.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.10.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.10.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.10.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.10.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.10.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.10.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.10.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.10.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.11.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.11.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.11.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.11.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.11.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.11.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.11.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.11.output.LayerNorm: 1,536 (trainable)
  classifier.layers.0: 787,456 (trainable)
  classifier.layers.1.projection: 2,099,200 (trainable)
  classifier.layers.3: 1,049,600 (trainable)
  classifier.layers.6: 3,075 (trainable)

Total layers: 104
Trainable layers: 104
Total parameters: 112,830,979
Trainable parameters: 112,830,979
Percentage of trainable parameters: 100.00%
Using optimizer: AdamW, Use Zero: True, Learning Rate: 2e-05, L2 strength: 0.01
Using scheduler: CosineAnnealingWarmRestarts
Scheduler arguments:
- T_0: 5
- T_mult: 1
- eta_min: 1e-07

Starting training loop...
Start epoch: 51, Max Iterations: 69, Early Stop: score, Tolerance: 0.00001, Number Iterations No Change: 70

[Enter] to continue for 1 epoch, [Q]uit, [S]ave, [H]elp: q
Quitting training...
Saving model in ONNX format...
Model saved in ONNX format to saves/model_20241020-212615.onnx and uploaded to Weights & Biases.
Saved model state: checkpoints/final_model_20241020-212621.pth
Saved model pickle: checkpoints/final_model_20241020-212621.pkl
Training completed (1m 5s)

Evaluating model...

multi_run_2 Multi-Class Classification Report

              precision    recall  f1-score   support

    negative   0.855035  0.713597  0.777940      1868
     neutral   0.685393  0.804074  0.740006      1669
    positive   0.803571  0.812102  0.807814      1884

    accuracy                       0.775687      5421
   macro avg   0.781333  0.776591  0.775253      5421
weighted avg   0.784921  0.775687  0.776643      5421

ROC AUC: 0.914188

Predicted  negative  neutral  positive
Actual                                
negative       1333      355       180
neutral         133     1342       194
positive         93      261      1530

Saved predictions: saves/predictions_20241020-212811.csv

Macro F1 Score: 0.78

Evaluation completed (2m 34s)
wandb:                                                                                
wandb: 
wandb: Run history:
wandb: eval/macro_f1_score â–
wandb: 
wandb: Run summary:
wandb: eval/macro_f1_score 0.77525
wandb: 
wandb: ðŸš€ View run multi_run_2 at: https://wandb.ai/jimbeno/Electra%20Ensemble/runs/jaf853fq
wandb: â­ï¸ View project at: https://wandb.ai/jimbeno/Electra%20Ensemble
wandb: Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 2 other file(s)
wandb: Find logs at: ./wandb/run-20241020_212512-jaf853fq/logs
TOTAL Time: 4m 9s
(nlp) ubuntu@104-171-203-160:~/nlp-test/sentiment$ logout
Connection to 104.171.203.160 closed.
(base) Jims-MBP:multiclass jim$ ssh ubuntu@104.171.202.130
The authenticity of host '104.171.202.130 (104.171.202.130)' can't be established.
ED25519 key fingerprint is SHA256:2ftqHPtuGT3+OrP7HO3NtnkeX2xb+PZ6WM6D3PJAXyM.
This key is not known by any other names
Are you sure you want to continue connecting (yes/no/[fingerprint])? yes
Warning: Permanently added '104.171.202.130' (ED25519) to the list of known hosts.
Enter passphrase for key '/Users/jim/.ssh/id_rsa': 
Enter passphrase for key '/Users/jim/.ssh/id_rsa': 
Welcome to Ubuntu 22.04.3 LTS (GNU/Linux 6.2.0-37-generic x86_64)
 .============.
 ||   __      ||    _                    _         _
 ||   \_\     ||   | |    __ _ _ __ ___ | |__   __| | __ _
 ||    \_\    ||   | |   / _` | '_ ` _ \| '_ \ / _` |/ _` |
 ||   /_Î»_\   ||   | |__| (_| | | | | | | |_) | (_| | (_| |
 ||  /_/ \_\  ||   |_____\__,_|_| |_| |_|_.__/ \__,_|\__,_|
  .============.                                  GPU CLOUD

 * Documentation:  https://help.ubuntu.com
 * Management:     https://landscape.canonical.com
 * Support:        https://ubuntu.com/advantage

  System information as of Mon Oct 21 04:10:01 UTC 2024

  System load:  0.67529296875    Processes:                902
  Usage of /:   0.4% of 5.68TB   Users logged in:          0
  Memory usage: 0%               IPv4 address for docker0: 172.17.0.1
  Swap usage:   0%               IPv4 address for eno1:    104.171.202.130


Expanded Security Maintenance for Applications is not enabled.

4 updates can be applied immediately.
4 of these updates are standard security updates.
To see these additional updates run: apt list --upgradable

17 additional security updates can be applied with ESM Apps.
Learn more about enabling ESM Apps service at https://ubuntu.com/esm


The list of available updates is more than a week old.
To check for new updates run: sudo apt update

ubuntu@104-171-202-130:~$ cd nlp-test/sentiment/
ubuntu@104-171-202-130:~/nlp-test/sentiment$ source nlp/bin/activate
(nlp) ubuntu@104-171-202-130:~/nlp-test/sentiment$ wandb login
wandb: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)
wandb: You can find your API key in your browser here: https://wandb.ai/authorize
wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit: 
wandb: Appending key for api.wandb.ai to your netrc file: /home/ubuntu/.netrc
(nlp) ubuntu@104-171-202-130:~/nlp-test/sentiment$ python ./ddp_sentiment_finetune.py --dataset 'merged_local' --weights_name 'google/electra-base-discriminator' --save_data --save_model --save_pickle --save_preds --save_plots --lr 0.00002 --epochs 29 --pooling 'mean' --dropout_rate 0.3 --num_layers 2 --hidden_dim 1024 --hidden_activation 'swishglu' --batch_size 16 --accumulation_steps 2 --finetune_bert --finetune_layers 12 --l2_strength 0.01 --checkpoint_interval 5 --use_zero --optimizer 'adamw' --scheduler 'cosine_warmup' --scheduler_kwargs '{"T_0":5, "T_mult":1, "eta_min":1e-7}' --decimal 6 --val_percent 0.2 --early_stop 'score' --n_iter_no_change 70 --show_progress --wandb --wandb_project 'Electra Ensemble' --wandb_run 'multi_run_2' --model_file 'checkpoint_epoch_30_20241020-064527.pth' --interactive

Starting DDP PyTorch Training...
Device: cuda, Number of GPUs: 8
Spawning 8 processes...
Rank 3 - Device: cuda:3
Rank 4 - Device: cuda:4
Rank 7 - Device: cuda:7
Rank 2 - Device: cuda:2
Rank 5 - Device: cuda:5
Rank 6 - Device: cuda:6
Rank 1 - Device: cuda:1
Rank 0 - Device: cuda:0
8 process groups initialized with 'nccl' backend on localhost:12355
NCCL Timeout: 1 hr 0 min. NCCL Blocking Wait: Enabled
wandb: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.
tokenizer_config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48.0/48.0 [00:00<00:00, 151kB/s]
An error occurred during training: [Errno 2] No such file or directory: '/home/ubuntu/.cache/huggingface/hub/models--google--electra-base-discriminator/snapshots/1ae76a97c7e84a4e640876a07453fccd636f0667/tokenizer_config.json'
Traceback (most recent call last):
  File "/home/ubuntu/nlp-test/sentiment/ddp_sentiment_finetune.py", line 1044, in main
    tokenizer, transformer_model = initialize_transformer_model(weights_name, device, rank, debug)
  File "/home/ubuntu/nlp-test/sentiment/ddp_sentiment_finetune.py", line 189, in initialize_transformer_model
    tokenizer = AutoTokenizer.from_pretrained(weights_name)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py", line 758, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py", line 610, in get_tokenizer_config
    with open(resolved_config_file, encoding="utf-8") as reader:
FileNotFoundError: [Errno 2] No such file or directory: '/home/ubuntu/.cache/huggingface/hub/models--google--electra-base-discriminator/snapshots/1ae76a97c7e84a4e640876a07453fccd636f0667/tokenizer_config.json'
config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 666/666 [00:00<00:00, 2.56MB/s]
vocab.txt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 232k/232k [00:00<00:00, 3.87MB/s]
wandb: Currently logged in as: jbeno (jimbeno). Use `wandb login --relogin` to force relogin
tokenizer.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 466k/466k [00:00<00:00, 11.7MB/s]
wandb: Tracking run with wandb version 0.18.3
wandb: Run data is saved locally in /home/ubuntu/nlp-test/sentiment/wandb/run-20241021_041309-rb6pea7a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run multi_run_2
wandb: â­ï¸ View project at https://wandb.ai/jimbeno/Electra%20Ensemble
wandb: ðŸš€ View run at https://wandb.ai/jimbeno/Electra%20Ensemble/runs/rb6pea7a
Wand run initialized.

Initializing 'google/electra-base-discriminator' tokenizer and model...
pytorch_model.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 440M/440M [00:01<00:00, 282MB/s]
An error occurred during training: [Errno 2] No such file or directory: '/home/ubuntu/.cache/huggingface/hub/models--google--electra-base-discriminator/snapshots/1ae76a97c7e84a4e640876a07453fccd636f0667/pytorch_model.bin'
Traceback (most recent call last):
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/transformers/modeling_utils.py", line 533, in load_state_dict
    return torch.load(
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/serialization.py", line 986, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/serialization.py", line 435, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/serialization.py", line 416, in __init__
    super().__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: '/home/ubuntu/.cache/huggingface/hub/models--google--electra-base-discriminator/snapshots/1ae76a97c7e84a4e640876a07453fccd636f0667/pytorch_model.bin'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/ubuntu/nlp-test/sentiment/ddp_sentiment_finetune.py", line 1044, in main
    tokenizer, transformer_model = initialize_transformer_model(weights_name, device, rank, debug)
  File "/home/ubuntu/nlp-test/sentiment/ddp_sentiment_finetune.py", line 190, in initialize_transformer_model
    model = AutoModel.from_pretrained(weights_name).to(device)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py", line 566, in from_pretrained
    return model_class.from_pretrained(
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/transformers/modeling_utils.py", line 3527, in from_pretrained
    state_dict = load_state_dict(resolved_archive_file)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/transformers/modeling_utils.py", line 541, in load_state_dict
    with open(checkpoint_file) as f:
FileNotFoundError: [Errno 2] No such file or directory: '/home/ubuntu/.cache/huggingface/hub/models--google--electra-base-discriminator/snapshots/1ae76a97c7e84a4e640876a07453fccd636f0667/pytorch_model.bin'
^C
Ctrl+C received. Terminating all processes...
Rank 0 - Current process: MainProcess cleaning up...
Terminating all child processes of MainProcess...
Terminated child process: SpawnProcess-6
Terminated child process: SpawnProcess-5
Terminated child process: SpawnProcess-3
Terminated child process: SpawnProcess-7
Terminated child process: SpawnProcess-4
Terminated child process: SpawnProcess-1
Terminated child process: SpawnProcess-2
Terminated child process: SpawnProcess-8
Rank 0 - Exiting program...
/usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 2 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
(nlp) ubuntu@104-171-202-130:~/nlp-test/sentiment$ python ./ddp_sentiment_finetune.py --dataset 'merged_local' --weights_name 'google/electra-base-discriminator' --save_data --save_model --save_pickle --save_preds --save_plots --lr 0.00002 --epochs 29 --pooling 'mean' --dropout_rate 0.3 --num_layers 2 --hidden_dim 1024 --hidden_activation 'swishglu' --batch_size 16 --accumulation_steps 2 --finetune_bert --finetune_layers 12 --l2_strength 0.01 --checkpoint_interval 5 --use_zero --optimizer 'adamw' --scheduler 'cosine_warmup' --scheduler_kwargs '{"T_0":5, "T_mult":1, "eta_min":1e-7}' --decimal 6 --val_percent 0.2 --early_stop 'score' --n_iter_no_change 70 --show_progress --wandb --wandb_project 'Electra Ensemble' --wandb_run 'multi_run_2' --model_file 'checkpoint_epoch_30_20241020-064527.pth' --interactive

Starting DDP PyTorch Training...
Device: cuda, Number of GPUs: 8
Spawning 8 processes...
Rank 5 - Device: cuda:5
Rank 3 - Device: cuda:3
Rank 1 - Device: cuda:1
Rank 2 - Device: cuda:2
Rank 4 - Device: cuda:4
Rank 7 - Device: cuda:7
Rank 6 - Device: cuda:6
Rank 0 - Device: cuda:0
8 process groups initialized with 'nccl' backend on localhost:12355
NCCL Timeout: 1 hr 0 min. NCCL Blocking Wait: Enabled
wandb: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: jbeno (jimbeno). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.3
wandb: Run data is saved locally in /home/ubuntu/nlp-test/sentiment/wandb/run-20241021_041416-aewwfr8w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run multi_run_2
wandb: â­ï¸ View project at https://wandb.ai/jimbeno/Electra%20Ensemble
wandb: ðŸš€ View run at https://wandb.ai/jimbeno/Electra%20Ensemble/runs/aewwfr8w
Wand run initialized.

Initializing 'google/electra-base-discriminator' tokenizer and model...
Tokenizer and model initialized (1s)

Loading data...
Using the same dataset for training and evaluation
Train Data: Merged DynaSent Round 1, Round 2 and SST from Local: 'data/merged'
Dev Data: Merged DynaSent Round 1, Round 2 and SST from Local: 'data/merged'
Train size: 102097, Dev size: 5421
Train label distribution:
	      Negative: 21910
	       Neutral: 49148
	      Positive: 31039
Dev label distribution:
	      Negative: 1868
	       Neutral: 1669
	      Positive: 1884
Data loaded (308ms)

Processing data...
(Batch size: 16, Pooling: Mean, Fine Tune BERT: True, Chunk size: None)...
Extracting sentences and labels...

Data saved to: saves/data_8_gpu_20241021-041419.npz
X Train shape: [102097], X Dev shape: [5421]
y Train shape: [102097], y Dev shape: [5421]
Data processed (710ms)

Initializing DDP Neural Classifier...
Layers: 2, Hidden Dim: 1024, Hidden Act: SwishGLU, Dropout: 0.3, Optimizer: AdamW, L2 Strength: 0.01, Pooling: MEAN, Accumulation Steps: 2, Max Grad Norm: None
Batch Size: 16, Max Epochs: 29, LR: 2e-05, Early Stop: score, Fine-tune BERT: True, Fine-tune Layers: 12, Freeze BERT: False, Target Score: None, Interactive: True
Loading model from: checkpoints/checkpoint_epoch_30_20241020-064527.pth...
Loaded checkpoint: checkpoints/checkpoint_epoch_30_20241020-064527.pth
Retrieved model state dictionary.
Retrieved optimizer state dictionary.
Classifier initialized (12s)

Fitting DDP Neural Classifier on training data...
Num Workers: 0, Prefetch: None
Building dataset and dataloader...
Score-based early stopping enabled (macro average F1 score against validation set). Validation fraction: 0.2
Training will stop early if the score does not improve by at least 0.00001 for 70 iterations.
Split data into (X:81677, y:81677) Training samples, and (X:20420, y:20420) Validation samples.
Initializing model, graph, optimizer...
BERT's original pooler removed. Using custom pooling type: mean
BERT has 108,891,648 trainable parameters and 0 non-trainable parameters
Number of BERT layers requiring gradients: 12 out of 12
Fine-tuning the last 12 out of 12 BERT layers

Model Architecture Summary:
BERTClassifier(
  (bert): ElectraModel(
    (embeddings): ElectraEmbeddings(
      (word_embeddings): Embedding(30522, 768, padding_idx=0)
      (position_embeddings): Embedding(512, 768)
      (token_type_embeddings): Embedding(2, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): ElectraEncoder(
      (layer): ModuleList(
        (0-11): 12 x ElectraLayer(
          (attention): ElectraAttention(
            (self): ElectraSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): ElectraSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): ElectraIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): ElectraOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
  (custom_pooling): PoolingLayer()
  (classifier): Classifier(
    (layers): Sequential(
      (0): Linear(in_features=768, out_features=1024, bias=True)
      (1): SwishGLU(
        (projection): Linear(in_features=1024, out_features=2048, bias=True)
        (activation): SiLU()
      )
      (2): Dropout(p=0.3, inplace=False)
      (3): Linear(in_features=1024, out_features=1024, bias=True)
      (4): SwishGLU(
        (projection): Linear(in_features=1024, out_features=2048, bias=True)
        (activation): SiLU()
      )
      (5): Dropout(p=0.3, inplace=False)
      (6): Linear(in_features=1024, out_features=3, bias=True)
    )
  )
)

Model Parameters:
  bert.embeddings.word_embeddings: 23,440,896 (trainable)
  bert.embeddings.position_embeddings: 393,216 (trainable)
  bert.embeddings.token_type_embeddings: 1,536 (trainable)
  bert.embeddings.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.0.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.0.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.0.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.0.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.0.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.0.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.0.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.0.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.1.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.1.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.1.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.1.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.1.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.1.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.1.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.1.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.2.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.2.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.2.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.2.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.2.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.2.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.2.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.2.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.3.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.3.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.3.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.3.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.3.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.3.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.3.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.3.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.4.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.4.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.4.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.4.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.4.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.4.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.4.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.4.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.5.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.5.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.5.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.5.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.5.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.5.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.5.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.5.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.6.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.6.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.6.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.6.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.6.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.6.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.6.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.6.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.7.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.7.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.7.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.7.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.7.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.7.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.7.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.7.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.8.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.8.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.8.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.8.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.8.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.8.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.8.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.8.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.9.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.9.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.9.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.9.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.9.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.9.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.9.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.9.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.10.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.10.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.10.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.10.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.10.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.10.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.10.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.10.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.11.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.11.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.11.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.11.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.11.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.11.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.11.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.11.output.LayerNorm: 1,536 (trainable)
  classifier.layers.0: 787,456 (trainable)
  classifier.layers.1.projection: 2,099,200 (trainable)
  classifier.layers.3: 1,049,600 (trainable)
  classifier.layers.6: 3,075 (trainable)

Total layers: 104
Trainable layers: 104
Total parameters: 112,830,979
Trainable parameters: 112,830,979
Percentage of trainable parameters: 100.00%
Using optimizer: AdamW, Use Zero: True, Learning Rate: 2e-05, L2 strength: 0.01
Using scheduler: CosineAnnealingWarmRestarts
Scheduler arguments:
- T_0: 5
- T_mult: 1
- eta_min: 1e-07

Starting training loop...
Start epoch: 31, Max Iterations: 29, Early Stop: score, Tolerance: 0.00001, Number Iterations No Change: 70

[Enter] to continue for 1 epoch, [Q]uit, [S]ave, [H]elp: q
Quitting training...
Saving model in ONNX format...
Model saved in ONNX format to saves/model_20241021-041525.onnx and uploaded to Weights & Biases.
Saved model state: checkpoints/final_model_20241021-041531.pth
Saved model pickle: checkpoints/final_model_20241021-041531.pkl
Training completed (1m 5s)

Evaluating model...

multi_run_2 Multi-Class Classification Report

              precision    recall  f1-score   support

    negative   0.855035  0.713597  0.777940      1868
     neutral   0.685567  0.796884  0.737046      1669
    positive   0.802289  0.818471  0.810300      1884

    accuracy                       0.775687      5421
   macro avg   0.780964  0.776318  0.775095      5421
weighted avg   0.784529  0.775687  0.776596      5421

ROC AUC: 0.906911

Predicted  negative  neutral  positive
Actual                                
negative       1333      357       178
neutral         137     1330       202
positive         89      253      1542

Saved predictions: saves/predictions_20241021-041721.csv

Macro F1 Score: 0.78

Evaluation completed (2m 34s)
wandb:                                                                                
wandb: 
wandb: Run history:
wandb: eval/macro_f1_score â–
wandb: 
wandb: Run summary:
wandb: eval/macro_f1_score 0.7751
wandb: 
wandb: ðŸš€ View run multi_run_2 at: https://wandb.ai/jimbeno/Electra%20Ensemble/runs/aewwfr8w
wandb: â­ï¸ View project at: https://wandb.ai/jimbeno/Electra%20Ensemble
wandb: Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 3 other file(s)
wandb: Find logs at: ./wandb/run-20241021_041416-aewwfr8w/logs
TOTAL Time: 4m 15s
(nlp) ubuntu@104-171-202-130:~/nlp-test/sentiment$ python ./ddp_sentiment_finetune.py --dataset 'dynasent_r1' --weights_name 'google/electra-base-discriminator' --save_data --save_model --save_pickle --save_preds --save_plots --lr 0.00002 --epochs 29 --pooling 'mean' --dropout_rate 0.3 --num_layers 2 --hidden_dim 1024 --hidden_activation 'swishglu' --batch_size 16 --accumulation_steps 2 --finetune_bert --finetune_layers 12 --l2_strength 0.01 --checkpoint_interval 5 --use_zero --optimizer 'adamw' --scheduler 'cosine_warmup' --scheduler_kwargs '{"T_0":5, "T_mult":1, "eta_min":1e-7}' --decimal 6 --val_percent 0.2 --early_stop 'score' --n_iter_no_change 30 --show_progress --wandb --wandb_project 'Electra Ensemble' --wandb_run 'multi_run_2' --model_file 'checkpoint_epoch_30_20241020-064527.pth' --interactive
^CTraceback (most recent call last):
  File "/home/ubuntu/nlp-test/sentiment/./ddp_sentiment_finetune.py", line 21, in <module>
    import torch
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/__init__.py", line 1750, in <module>
    from . import _meta_registrations
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/_meta_registrations.py", line 8, in <module>
    from torch._decomp import (
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/_decomp/__init__.py", line 190, in <module>
    import torch._decomp.decompositions
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/_decomp/decompositions.py", line 10, in <module>
    import torch._prims as prims
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/_prims/__init__.py", line 2968, in <module>
    register_debug_prims()
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/_prims/debug_prims.py", line 41, in register_debug_prims
    def load_tensor_factory(name, size, stride, dtype, device):
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/_custom_op/impl.py", line 330, in inner
    self._register_impl("factory", f)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/_custom_op/impl.py", line 221, in _register_impl
    frame = inspect.getframeinfo(sys._getframe(stacklevel))
  File "/usr/lib/python3.10/inspect.py", line 1624, in getframeinfo
    lines, lnum = findsource(frame)
  File "/usr/lib/python3.10/inspect.py", line 952, in findsource
    module = getmodule(object, file)
  File "/usr/lib/python3.10/inspect.py", line 875, in getmodule
    f = getabsfile(module)
  File "/usr/lib/python3.10/inspect.py", line 844, in getabsfile
    _filename = getsourcefile(object) or getfile(object)
  File "/usr/lib/python3.10/inspect.py", line 826, in getsourcefile
    if os.path.exists(filename):
  File "/usr/lib/python3.10/genericpath.py", line 19, in exists
    os.stat(path)
KeyboardInterrupt

(nlp) ubuntu@104-171-202-130:~/nlp-test/sentiment$ python ./ddp_sentiment_finetune.py --dataset 'dynasent_r1' --weights_name 'google/electra-base-discriminator' --save_data --save_model --save_pickle --save_preds --save_plots --lr 0.00002 --epochs 29 --pooling 'mean' --dropout_rate 0.3 --num_layers 2 --hidden_dim 1024 --hidden_activation 'swishglu' --batch_size 16 --accumulation_steps 2 --finetune_bert --finetune_layers 12 --l2_strength 0.01 --checkpoint_interval 5 --use_zero --optimizer 'adamw' --scheduler 'cosine_warmup' --scheduler_kwargs '{"T_0":5, "T_mult":1, "eta_min":1e-7}' --decimal 6 --val_percent 0.2 --early_stop 'score' --n_iter_no_change 30 --show_progress --wandb --wandb_project 'Electra Ensemble' --wandb_run 'multi_run_2' --model_file 'checkpoint_epoch_30_20241020-064527.pth'
^CTraceback (most recent call last):
  File "/home/ubuntu/nlp-test/sentiment/./ddp_sentiment_finetune.py", line 34, in <module>
    from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/sklearn/__init__.py", line 84, in <module>
    from .base import clone
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/sklearn/base.py", line 19, in <module>
    from .utils._estimator_html_repr import _HTMLDocumentationLinkMixin, estimator_html_repr
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/sklearn/utils/__init__.py", line 11, in <module>
    from ._chunking import gen_batches, gen_even_slices
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/sklearn/utils/_chunking.py", line 8, in <module>
    from ._param_validation import Interval, validate_params
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 14, in <module>
    from .validation import _is_arraylike_not_scalar
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/sklearn/utils/validation.py", line 26, in <module>
    from ..utils._array_api import _asarray_with_order, _is_numpy_namespace, get_namespace
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/sklearn/utils/_array_api.py", line 11, in <module>
    from .fixes import parse_version
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/sklearn/utils/fixes.py", line 20, in <module>
    import scipy.stats
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/scipy/stats/__init__.py", line 610, in <module>
    from ._stats_py import *
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/scipy/stats/_stats_py.py", line 56, in <module>
    from ._hypotests import _all_partitions
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/scipy/stats/_hypotests.py", line 13, in <module>
    from scipy.fft import ifft
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/scipy/fft/__init__.py", line 86, in <module>
    from ._basic import (
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/scipy/fft/_basic.py", line 1, in <module>
    from scipy._lib.uarray import generate_multimethod, Dispatchable
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 879, in exec_module
  File "<frozen importlib._bootstrap_external>", line 975, in get_code
  File "<frozen importlib._bootstrap_external>", line 1074, in get_data
KeyboardInterrupt
^C
(nlp) ubuntu@104-171-202-130:~/nlp-test/sentiment$ ^C
(nlp) ubuntu@104-171-202-130:~/nlp-test/sentiment$ python ./ddp_sentiment_finetune.py --dataset 'dynasent_r1' --weights_name 'google/electra-base-discriminator' --save_data --save_model --save_pickle --save_preds --save_plots --lr 0.00002 --epochs 29 --pooling 'mean' --dropout_rate 0.3 --num_layers 2 --hidden_dim 1024 --hidden_activation 'swishglu' --batch_size 16 --accumulation_steps 2 --finetune_bert --finetune_layers 12 --l2_strength 0.01 --checkpoint_interval 5 --use_zero --optimizer 'adamw' --scheduler 'cosine_warmup' --scheduler_kwargs '{"T_0":5, "T_mult":1, "eta_min":1e-7}' --decimal 6 --val_percent 0.2 --early_stop 'score' --n_iter_no_change 30 --show_progress --wandb --wandb_project 'Electra Ensemble' --wandb_run 'multi_run_3_dynasent_r2' --model_file 'checkpoint_epoch_30_20241020-064527.pth'

Starting DDP PyTorch Training...
Device: cuda, Number of GPUs: 8
Spawning 8 processes...
Rank 5 - Device: cuda:5
Rank 2 - Device: cuda:2
Rank 7 - Device: cuda:7
Rank 6 - Device: cuda:6
Rank 4 - Device: cuda:4
Rank 3 - Device: cuda:3
Rank 0 - Device: cuda:0
Rank 1 - Device: cuda:1
8 process groups initialized with 'nccl' backend on localhost:12355
NCCL Timeout: 1 hr 0 min. NCCL Blocking Wait: Enabled
wandb: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: jbeno (jimbeno). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.3
wandb: Run data is saved locally in /home/ubuntu/nlp-test/sentiment/wandb/run-20241021_042818-1qduzct8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run multi_run_3_dynasent_r2
wandb: â­ï¸ View project at https://wandb.ai/jimbeno/Electra%20Ensemble
wandb: ðŸš€ View run at https://wandb.ai/jimbeno/Electra%20Ensemble/runs/1qduzct8
Wand run initialized.

Initializing 'google/electra-base-discriminator' tokenizer and model...
Tokenizer and model initialized (1s)

Loading data...
Using the same dataset for training and evaluation
Train Data: DynaSent Round 1 from Hugging Face: 'dynabench/dynasent'
Dataset URL: https://huggingface.co/datasets/dynabench/dynasent
Downloading builder script: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16.5k/16.5k [00:00<00:00, 24.1MB/s]
Downloading metadata: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.97k/6.97k [00:00<00:00, 14.1MB/s]
^C
Ctrl+C received. Terminating all processes...
Rank 0 - Current process: MainProcess cleaning up...
Terminating all child processes of MainProcess...

KeyboardInterrupt received. Terminating all processes...Terminated child process: SpawnProcess-4
Terminated child process: SpawnProcess-1
Terminated child process: SpawnProcess-8
Terminated child process: SpawnProcess-3
Terminated child process: SpawnProcess-2
Terminated child process: SpawnProcess-7
Terminated child process: SpawnProcess-6
Terminated child process: SpawnProcess-5
Rank 0 - Exiting program...
/usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
(nlp) ubuntu@104-171-202-130:~/nlp-test/sentiment$ python ./ddp_sentiment_finetune.py --dataset 'dynasent_r2' --weights_name 'google/electra-base-discriminator' --save_data --save_model --save_pickle --save_preds --save_plots --lr 0.00002 --epochs 29 --pooling 'mean' --dropout_rate 0.3 --num_layers 2 --hidden_dim 1024 --hidden_activation 'swishglu' --batch_size 16 --accumulation_steps 2 --finetune_bert --finetune_layers 12 --l2_strength 0.01 --checkpoint_interval 5 --use_zero --optimizer 'adamw' --scheduler 'cosine_warmup' --scheduler_kwargs '{"T_0":5, "T_mult":1, "eta_min":1e-7}' --decimal 6 --val_percent 0.2 --early_stop 'score' --n_iter_no_change 30 --show_progress --wandb --wandb_project 'Electra Ensemble' --wandb_run 'multi_run_3_dynasent_r2' --model_file 'checkpoint_epoch_30_20241020-064527.pth'

Starting DDP PyTorch Training...
Device: cuda, Number of GPUs: 8
Spawning 8 processes...
Rank 3 - Device: cuda:3
Rank 2 - Device: cuda:2
Rank 5 - Device: cuda:5
Rank 1 - Device: cuda:1
Rank 7 - Device: cuda:7
Rank 6 - Device: cuda:6
Rank 4 - Device: cuda:4
Rank 0 - Device: cuda:0
8 process groups initialized with 'nccl' backend on localhost:12355
NCCL Timeout: 1 hr 0 min. NCCL Blocking Wait: Enabled
wandb: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: jbeno (jimbeno). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.3
wandb: Run data is saved locally in /home/ubuntu/nlp-test/sentiment/wandb/run-20241021_043028-geqnid3m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run multi_run_3_dynasent_r2
wandb: â­ï¸ View project at https://wandb.ai/jimbeno/Electra%20Ensemble
wandb: ðŸš€ View run at https://wandb.ai/jimbeno/Electra%20Ensemble/runs/geqnid3m
Wand run initialized.

Initializing 'google/electra-base-discriminator' tokenizer and model...
Tokenizer and model initialized (1s)

Loading data...
Using the same dataset for training and evaluation
Train Data: DynaSent Round 2 from Hugging Face: 'dynabench/dynasent'
Dataset URL: https://huggingface.co/datasets/dynabench/dynasent
Downloading readme: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13.7k/13.7k [00:00<00:00, 11.0MB/s]
Downloading data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17.1M/17.1M [00:00<00:00, 60.6MB/s]
Generating train split: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13065/13065 [00:02<00:00, 5060.44 examples/s]
Generating validation split: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [00:00<00:00, 5781.41 examples/s]
Generating test split: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [00:00<00:00, 5792.88 examples/s]
Dev Data: DynaSent Round 2 from Hugging Face: 'dynabench/dynasent'
Dataset URL: https://huggingface.co/datasets/dynabench/dynasent
Train size: 13065, Dev size: 720
Train label distribution:
	      Negative: 4579
	       Neutral: 2448
	      Positive: 6038
Dev label distribution:
	      Negative: 240
	       Neutral: 240
	      Positive: 240
Data loaded (7s)

Processing data...
(Batch size: 16, Pooling: Mean, Fine Tune BERT: True, Chunk size: None)...
Extracting sentences and labels...

Data saved to: saves/data_8_gpu_20241021-043038.npz
X Train shape: [13065], X Dev shape: [720]
y Train shape: [13065], y Dev shape: [720]
Data processed (95ms)

Initializing DDP Neural Classifier...
Layers: 2, Hidden Dim: 1024, Hidden Act: SwishGLU, Dropout: 0.3, Optimizer: AdamW, L2 Strength: 0.01, Pooling: MEAN, Accumulation Steps: 2, Max Grad Norm: None
Batch Size: 16, Max Epochs: 29, LR: 2e-05, Early Stop: score, Fine-tune BERT: True, Fine-tune Layers: 12, Freeze BERT: False, Target Score: None, Interactive: False
Loading model from: checkpoints/checkpoint_epoch_30_20241020-064527.pth...
Loaded checkpoint: checkpoints/checkpoint_epoch_30_20241020-064527.pth
Retrieved model state dictionary.
Retrieved optimizer state dictionary.
Classifier initialized (7s)

Fitting DDP Neural Classifier on training data...
Num Workers: 0, Prefetch: None
Building dataset and dataloader...
Score-based early stopping enabled (macro average F1 score against validation set). Validation fraction: 0.2
Training will stop early if the score does not improve by at least 0.00001 for 30 iterations.
Split data into (X:10452, y:10452) Training samples, and (X:2613, y:2613) Validation samples.
Initializing model, graph, optimizer...
BERT's original pooler removed. Using custom pooling type: mean
BERT has 108,891,648 trainable parameters and 0 non-trainable parameters
Number of BERT layers requiring gradients: 12 out of 12
Fine-tuning the last 12 out of 12 BERT layers

Model Architecture Summary:
BERTClassifier(
  (bert): ElectraModel(
    (embeddings): ElectraEmbeddings(
      (word_embeddings): Embedding(30522, 768, padding_idx=0)
      (position_embeddings): Embedding(512, 768)
      (token_type_embeddings): Embedding(2, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): ElectraEncoder(
      (layer): ModuleList(
        (0-11): 12 x ElectraLayer(
          (attention): ElectraAttention(
            (self): ElectraSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): ElectraSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): ElectraIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): ElectraOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
  (custom_pooling): PoolingLayer()
  (classifier): Classifier(
    (layers): Sequential(
      (0): Linear(in_features=768, out_features=1024, bias=True)
      (1): SwishGLU(
        (projection): Linear(in_features=1024, out_features=2048, bias=True)
        (activation): SiLU()
      )
      (2): Dropout(p=0.3, inplace=False)
      (3): Linear(in_features=1024, out_features=1024, bias=True)
      (4): SwishGLU(
        (projection): Linear(in_features=1024, out_features=2048, bias=True)
        (activation): SiLU()
      )
      (5): Dropout(p=0.3, inplace=False)
      (6): Linear(in_features=1024, out_features=3, bias=True)
    )
  )
)

Model Parameters:
  bert.embeddings.word_embeddings: 23,440,896 (trainable)
  bert.embeddings.position_embeddings: 393,216 (trainable)
  bert.embeddings.token_type_embeddings: 1,536 (trainable)
  bert.embeddings.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.0.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.0.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.0.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.0.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.0.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.0.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.0.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.0.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.1.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.1.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.1.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.1.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.1.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.1.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.1.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.1.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.2.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.2.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.2.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.2.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.2.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.2.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.2.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.2.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.3.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.3.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.3.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.3.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.3.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.3.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.3.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.3.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.4.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.4.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.4.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.4.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.4.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.4.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.4.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.4.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.5.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.5.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.5.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.5.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.5.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.5.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.5.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.5.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.6.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.6.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.6.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.6.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.6.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.6.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.6.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.6.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.7.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.7.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.7.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.7.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.7.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.7.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.7.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.7.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.8.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.8.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.8.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.8.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.8.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.8.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.8.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.8.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.9.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.9.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.9.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.9.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.9.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.9.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.9.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.9.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.10.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.10.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.10.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.10.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.10.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.10.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.10.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.10.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.11.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.11.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.11.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.11.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.11.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.11.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.11.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.11.output.LayerNorm: 1,536 (trainable)
  classifier.layers.0: 787,456 (trainable)
  classifier.layers.1.projection: 2,099,200 (trainable)
  classifier.layers.3: 1,049,600 (trainable)
  classifier.layers.6: 3,075 (trainable)

Total layers: 104
Trainable layers: 104
Total parameters: 112,830,979
Trainable parameters: 112,830,979
Percentage of trainable parameters: 100.00%
Using optimizer: AdamW, Use Zero: True, Learning Rate: 2e-05, L2 strength: 0.01
Using scheduler: CosineAnnealingWarmRestarts
Scheduler arguments:
- T_0: 5
- T_mult: 1
- eta_min: 1e-07

Starting training loop...
Start epoch: 31, Max Iterations: 29, Early Stop: score, Tolerance: 0.00001, Number Iterations No Change: 30
Epoch 31/60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [01:53<00:00,  1.10s/it, loss=0.0613, lr=1.81e-05, grad=M:1.7073, status=Epoch complete]
â–ˆ Epoch 31: Loss T 0.061260 V 0.003002 | F1 T 0.998530 V 0.998042 B 0.998042 SC 0/30 | Acc T 0.998757 V 0.998471 | LR 1.81e-05 | Grad â†“ 0.000000 â†‘ 11.609963 M 1.707288 | 1m 53s
Epoch 32/60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [01:52<00:00,  1.09s/it, loss=0.0559, lr=1.32e-05, grad=M:0.1958, status=Epoch complete]
â–ˆ Epoch 32: Loss T 0.055949 V 0.002367 | F1 T 0.998810 V 0.999522 B 0.999522 SC 0/30 | Acc T 0.998948 V 0.999618 | LR 1.32e-05 | Grad â†“ 0.000000 â†‘ 1.201589 M 0.195761 | 1m 52s
Epoch 33/60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [01:52<00:00,  1.09s/it, loss=0.0355, lr=7.03e-06, grad=M:0.3106, status=Epoch complete]
â–ˆ Epoch 33: Loss T 0.035485 V 0.002981 | F1 T 0.999260 V 0.999479 B 0.999522 SC 1/30 | Acc T 0.999331 V 0.999618 | LR 7.03e-06 | Grad â†“ 0.000000 â†‘ 1.983142 M 0.310577 | 1m 52s
Epoch 34/60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [01:52<00:00,  1.09s/it, loss=0.0230, lr=2.04e-06, grad=M:0.0262, status=Epoch complete]
â–ˆ Epoch 34: Loss T 0.023005 V 0.002876 | F1 T 0.999721 V 0.999479 B 0.999522 SC 2/30 | Acc T 0.999713 V 0.999618 | LR 2.04e-06 | Grad â†“ 0.000000 â†‘ 0.149524 M 0.026158 | 1m 52s
Epoch 35/60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [01:51<00:00,  1.08s/it, loss=0.0210, lr=1.00e-07, grad=M:0.2190, status=Epoch complete]
â–ˆ Epoch 35: Loss T 0.021031 V 0.002359 | F1 T 0.999800 V 0.999479 B 0.999522 SC 3/30 | Acc T 0.999809 V 0.999618 | LR 1.00e-07 | Grad â†“ 0.000000 â†‘ 1.593096 M 0.219024 | 1m 51s
Saved model state: checkpoints/checkpoint_epoch_35_20241021-044007.pth
Epoch 36/60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [01:52<00:00,  1.09s/it, loss=0.0347, lr=1.81e-05, grad=M:0.1442, status=Epoch complete]
â–ˆ Epoch 36: Loss T 0.034690 V 0.001776 | F1 T 0.999361 V 0.999000 B 0.999522 SC 4/30 | Acc T 0.999331 V 0.999235 | LR 1.81e-05 | Grad â†“ 0.000000 â†‘ 0.847982 M 0.144183 | 1m 52s
Epoch 37/60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [01:52<00:00,  1.09s/it, loss=0.0387, lr=1.32e-05, grad=M:0.2506, status=Epoch complete]
â–ˆ Epoch 37: Loss T 0.038724 V 0.002048 | F1 T 0.999031 V 0.998479 B 0.999522 SC 5/30 | Acc T 0.999139 V 0.998853 | LR 1.32e-05 | Grad â†“ 0.000000 â†‘ 1.386251 M 0.250638 | 1m 52s
Epoch 38/60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [01:52<00:00,  1.09s/it, loss=0.0291, lr=7.03e-06, grad=M:0.1218, status=Epoch complete]
â–ˆ Epoch 38: Loss T 0.029069 V 0.001718 | F1 T 0.999601 V 0.999203 B 0.999522 SC 6/30 | Acc T 0.999617 V 0.999235 | LR 7.03e-06 | Grad â†“ 0.000000 â†‘ 0.706518 M 0.121752 | 1m 52s
Epoch 39/60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [01:52<00:00,  1.09s/it, loss=0.0190, lr=2.04e-06, grad=M:0.0373, status=Epoch complete]
â–ˆ Epoch 39: Loss T 0.019031 V 0.001116 | F1 T 0.999800 V 0.999203 B 0.999522 SC 7/30 | Acc T 0.999809 V 0.999235 | LR 2.04e-06 | Grad â†“ 0.000000 â†‘ 0.212565 M 0.037333 | 1m 52s
Epoch 40/60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [01:52<00:00,  1.09s/it, loss=0.0124, lr=1.00e-07, grad=M:0.4207, status=Epoch complete]
â–ˆ Epoch 40: Loss T 0.012395 V 0.001187 | F1 T 0.999800 V 0.999203 B 0.999522 SC 8/30 | Acc T 0.999809 V 0.999235 | LR 1.00e-07 | Grad â†“ 0.000000 â†‘ 2.956303 M 0.420709 | 1m 52s
Memory: Rank 0: 14.42 GB | Rank 1: 14.62 GB | Rank 2: 14.52 GB | Rank 3: 14.52 GB | Rank 4: 14.60 GB | Rank 5: 14.61 GB | Rank 6: 14.57 GB | Rank 7: 14.54 GB (Max: 16.94 GB, Total: 135.49 GB)
Saved model state: checkpoints/checkpoint_epoch_40_20241021-044936.pth
Epoch 41/60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [01:52<00:00,  1.09s/it, loss=0.0282, lr=1.81e-05, grad=M:0.1819, status=Epoch complete]
â–ˆ Epoch 41: Loss T 0.028242 V 0.003237 | F1 T 0.999551 V 0.998203 B 0.999522 SC 9/30 | Acc T 0.999617 V 0.998471 | LR 1.81e-05 | Grad â†“ 0.000000 â†‘ 0.951014 M 0.181916 | 1m 52s
Epoch 42/60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [01:52<00:00,  1.09s/it, loss=0.0268, lr=1.32e-05, grad=M:0.4652, status=Epoch complete]
â–ˆ Epoch 42: Loss T 0.026839 V 0.002724 | F1 T 0.999709 V 0.998839 B 0.999522 SC 10/30 | Acc T 0.999713 V 0.998853 | LR 1.32e-05 | Grad â†“ 0.000000 â†‘ 2.524163 M 0.465181 | 1m 52s
Epoch 43/60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [01:51<00:00,  1.08s/it, loss=0.0223, lr=7.03e-06, grad=M:0.2507, status=Epoch complete]
â–ˆ Epoch 43: Loss T 0.022255 V 0.000634 | F1 T 0.999789 V 1.000000 B 1.000000 SC 0/30 | Acc T 0.999809 V 1.000000 | LR 7.03e-06 | Grad â†“ 0.000000 â†‘ 1.653625 M 0.250671 | 1m 51s
Epoch 44/60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [01:51<00:00,  1.08s/it, loss=0.0114, lr=2.04e-06, grad=M:0.0232, status=Epoch complete]
â–ˆ Epoch 44: Loss T 0.011351 V 0.000198 | F1 T 0.999789 V 1.000000 B 1.000000 SC 1/30 | Acc T 0.999809 V 1.000000 | LR 2.04e-06 | Grad â†“ 0.000000 â†‘ 0.138555 M 0.023228 | 1m 51s
Epoch 45/60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [01:51<00:00,  1.09s/it, loss=0.0093, lr=1.00e-07, grad=M:0.0738, status=Epoch complete]
â–ˆ Epoch 45: Loss T 0.009343 V 0.000170 | F1 T 0.999920 V 1.000000 B 1.000000 SC 2/30 | Acc T 0.999904 V 1.000000 | LR 1.00e-07 | Grad â†“ 0.000000 â†‘ 0.480359 M 0.073795 | 1m 51s
Saved model state: checkpoints/checkpoint_epoch_45_20241021-045901.pth
Epoch 46/60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [01:52<00:00,  1.09s/it, loss=0.0178, lr=1.81e-05, grad=M:0.0892, status=Epoch complete]
â–ˆ Epoch 46: Loss T 0.017827 V 0.003258 | F1 T 0.999681 V 0.998523 B 1.000000 SC 3/30 | Acc T 0.999713 V 0.998853 | LR 1.81e-05 | Grad â†“ 0.000000 â†‘ 0.506878 M 0.089201 | 1m 52s
Epoch 47/60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [01:52<00:00,  1.09s/it, loss=0.0185, lr=1.32e-05, grad=M:0.0251, status=Epoch complete]
â–ˆ Epoch 47: Loss T 0.018531 V 0.001422 | F1 T 0.999561 V 0.998724 B 1.000000 SC 4/30 | Acc T 0.999617 V 0.998853 | LR 1.32e-05 | Grad â†“ 0.000000 â†‘ 0.139612 M 0.025145 | 1m 52s
Epoch 48/60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [01:52<00:00,  1.09s/it, loss=0.0179, lr=7.03e-06, grad=M:0.0383, status=Epoch complete]
â–ˆ Epoch 48: Loss T 0.017874 V 0.000387 | F1 T 0.999800 V 1.000000 B 1.000000 SC 5/30 | Acc T 0.999809 V 1.000000 | LR 7.03e-06 | Grad â†“ 0.000000 â†‘ 0.219065 M 0.038347 | 1m 52s
Epoch 49/60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [01:51<00:00,  1.09s/it, loss=0.0113, lr=2.04e-06, grad=M:0.3583, status=Epoch complete]
â–ˆ Epoch 49: Loss T 0.011336 V 0.000277 | F1 T 0.999800 V 1.000000 B 1.000000 SC 6/30 | Acc T 0.999809 V 1.000000 | LR 2.04e-06 | Grad â†“ 0.000000 â†‘ 1.895450 M 0.358283 | 1m 51s
Epoch 50/60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [01:52<00:00,  1.09s/it, loss=0.0125, lr=1.00e-07, grad=M:0.0030, status=Epoch complete]
â–ˆ Epoch 50: Loss T 0.012452 V 0.000292 | F1 T 0.999800 V 1.000000 B 1.000000 SC 7/30 | Acc T 0.999809 V 1.000000 | LR 1.00e-07 | Grad â†“ 0.000000 â†‘ 0.017352 M 0.002961 | 1m 52s
Memory: Rank 0: 14.42 GB | Rank 1: 14.62 GB | Rank 2: 14.52 GB | Rank 3: 14.52 GB | Rank 4: 14.60 GB | Rank 5: 14.61 GB | Rank 6: 14.57 GB | Rank 7: 14.54 GB (Max: 16.94 GB, Total: 135.49 GB)
Saved model state: checkpoints/checkpoint_epoch_50_20241021-050826.pth
Epoch 51/60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [01:52<00:00,  1.09s/it, loss=0.0172, lr=1.81e-05, grad=M:0.0214, status=Epoch complete]
â–ˆ Epoch 51: Loss T 0.017184 V 0.000414 | F1 T 0.999681 V 1.000000 B 1.000000 SC 8/30 | Acc T 0.999713 V 1.000000 | LR 1.81e-05 | Grad â†“ 0.000000 â†‘ 0.134793 M 0.021378 | 1m 52s
Epoch 52/60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [01:52<00:00,  1.09s/it, loss=0.0158, lr=1.32e-05, grad=M:0.1407, status=Epoch complete]
â–ˆ Epoch 52: Loss T 0.015820 V 0.000287 | F1 T 0.999800 V 1.000000 B 1.000000 SC 9/30 | Acc T 0.999809 V 1.000000 | LR 1.32e-05 | Grad â†“ 0.000000 â†‘ 0.723790 M 0.140653 | 1m 52s
Epoch 53/60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [01:51<00:00,  1.09s/it, loss=0.0103, lr=7.03e-06, grad=M:0.0184, status=Epoch complete]
â–ˆ Epoch 53: Loss T 0.010281 V 0.000144 | F1 T 0.999920 V 1.000000 B 1.000000 SC 10/30 | Acc T 0.999904 V 1.000000 | LR 7.03e-06 | Grad â†“ 0.000000 â†‘ 0.111816 M 0.018445 | 1m 51s
Epoch 54/60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [01:52<00:00,  1.09s/it, loss=0.0083, lr=2.04e-06, grad=M:0.0073, status=Epoch complete]
â–ˆ Epoch 54: Loss T 0.008297 V 0.000122 | F1 T 0.999920 V 1.000000 B 1.000000 SC 11/30 | Acc T 0.999904 V 1.000000 | LR 2.04e-06 | Grad â†“ 0.000000 â†‘ 0.046842 M 0.007285 | 1m 52s
Epoch 55/60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [01:52<00:00,  1.09s/it, loss=0.0066, lr=1.00e-07, grad=M:0.0095, status=Epoch complete]
â–ˆ Epoch 55: Loss T 0.006594 V 0.000118 | F1 T 0.999920 V 1.000000 B 1.000000 SC 12/30 | Acc T 0.999904 V 1.000000 | LR 1.00e-07 | Grad â†“ 0.000000 â†‘ 0.053647 M 0.009460 | 1m 52s
Saved model state: checkpoints/checkpoint_epoch_55_20241021-051752.pth
Epoch 56/60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [01:52<00:00,  1.09s/it, loss=0.0138, lr=1.81e-05, grad=M:0.1550, status=Epoch complete]
â–ˆ Epoch 56: Loss T 0.013805 V 0.000172 | F1 T 0.999880 V 1.000000 B 1.000000 SC 13/30 | Acc T 0.999904 V 1.000000 | LR 1.81e-05 | Grad â†“ 0.000000 â†‘ 0.954795 M 0.154986 | 1m 52s
Epoch 57/60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [01:52<00:00,  1.09s/it, loss=0.0140, lr=1.32e-05, grad=M:0.0494, status=Epoch complete]
â–ˆ Epoch 57: Loss T 0.014015 V 0.000123 | F1 T 1.000000 V 1.000000 B 1.000000 SC 14/30 | Acc T 1.000000 V 1.000000 | LR 1.32e-05 | Grad â†“ 0.000000 â†‘ 0.308289 M 0.049385 | 1m 52s
Epoch 58/60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [01:52<00:00,  1.09s/it, loss=0.0141, lr=7.03e-06, grad=M:0.0223, status=Epoch complete]
â–ˆ Epoch 58: Loss T 0.014082 V 0.000067 | F1 T 0.999920 V 1.000000 B 1.000000 SC 15/30 | Acc T 0.999904 V 1.000000 | LR 7.03e-06 | Grad â†“ 0.000000 â†‘ 0.142471 M 0.022334 | 1m 52s
Epoch 59/60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [01:52<00:00,  1.09s/it, loss=0.0081, lr=2.04e-06, grad=M:0.0016, status=Epoch complete]
â–ˆ Epoch 59: Loss T 0.008137 V 0.000065 | F1 T 0.999920 V 1.000000 B 1.000000 SC 16/30 | Acc T 0.999904 V 1.000000 | LR 2.04e-06 | Grad â†“ 0.000000 â†‘ 0.011237 M 0.001633 | 1m 52s
Epoch 60/60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [01:52<00:00,  1.10s/it, loss=0.0065, lr=1.00e-07, grad=M:0.4725, status=Epoch complete]
â–ˆ Epoch 60: Loss T 0.006496 V 0.000067 | F1 T 0.999920 V 1.000000 B 1.000000 SC 17/30 | Acc T 0.999904 V 1.000000 | LR 1.00e-07 | Grad â†“ 0.000000 â†‘ 2.502510 M 0.472467 | 1m 52s
Memory: Rank 0: 14.42 GB | Rank 1: 14.62 GB | Rank 2: 14.52 GB | Rank 3: 14.52 GB | Rank 4: 14.60 GB | Rank 5: 14.61 GB | Rank 6: 14.57 GB | Rank 7: 14.54 GB (Max: 16.94 GB, Total: 135.49 GB)
Saved model state: checkpoints/checkpoint_epoch_60_20241021-052718.pth
Saving model in ONNX format...
Model saved in ONNX format to saves/model_20241021-052722.onnx and uploaded to Weights & Biases.
Saved model state: checkpoints/final_model_20241021-052728.pth
Saved model pickle: checkpoints/final_model_20241021-052728.pkl
Training completed (56m 49s)

Evaluating model...

multi_run_3_dynasent_r2 Multi-Class Classification Report

              precision    recall  f1-score   support

    negative   0.697674  0.750000  0.722892       240
     neutral   0.755208  0.604167  0.671296       240
    positive   0.729630  0.820833  0.772549       240

    accuracy                       0.725000       720
   macro avg   0.727504  0.725000  0.722246       720
weighted avg   0.727504  0.725000  0.722246       720

ROC AUC: 0.875081

Predicted  negative  neutral  positive
Actual                                
negative        180       33        27
neutral          49      145        46
positive         29       14       197

Saved predictions: saves/predictions_20241021-052749.csv

Macro F1 Score: 0.72

Evaluation completed (20s)
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:            eval/macro_f1_score â–
wandb:             gradients/max_norm â–ˆâ–‚â–‚â–â–‚â–‚â–‚â–â–â–ƒâ–‚â–ƒâ–‚â–â–â–â–â–â–‚â–â–â–â–â–â–â–‚â–â–â–â–ƒ
wandb:            gradients/mean_norm â–ˆâ–‚â–‚â–â–‚â–‚â–‚â–â–â–ƒâ–‚â–ƒâ–‚â–â–â–â–â–â–‚â–â–â–‚â–â–â–â–‚â–â–â–â–ƒ
wandb:             gradients/min_norm â–ˆâ–‚â–‚â–â–‚â–‚â–‚â–â–â–‚â–‚â–‚â–‚â–â–â–â–â–â–‚â–â–â–‚â–â–â–â–‚â–â–â–â–‚
wandb:                    other/epoch â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:            other/learning_rate â–ˆâ–†â–„â–‚â–â–ˆâ–†â–„â–‚â–â–ˆâ–†â–„â–‚â–â–ˆâ–†â–„â–‚â–â–ˆâ–†â–„â–‚â–â–ˆâ–†â–„â–‚â–
wandb:               other/stop_limit â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 train/accuracy â–â–‚â–„â–†â–‡â–„â–ƒâ–†â–‡â–‡â–†â–†â–‡â–‡â–‡â–†â–†â–‡â–‡â–‡â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡
wandb:                     train/loss â–ˆâ–‡â–…â–ƒâ–ƒâ–…â–…â–„â–ƒâ–‚â–„â–„â–ƒâ–‚â–â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–â–â–â–‚â–‚â–‚â–â–
wandb:           train/macro_f1_score â–â–‚â–„â–‡â–‡â–…â–ƒâ–†â–‡â–‡â–†â–‡â–‡â–‡â–ˆâ–†â–†â–‡â–‡â–‡â–†â–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:               train/stop_count â–â–â–â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–…â–…â–â–â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–…â–…â–†â–†â–†â–‡â–‡â–ˆâ–ˆ
wandb:            validation/accuracy â–â–†â–†â–†â–†â–„â–ƒâ–„â–„â–„â–â–ƒâ–ˆâ–ˆâ–ˆâ–ƒâ–ƒâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb: validation/best_macro_f1_score â–â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                validation/loss â–‡â–†â–‡â–‡â–†â–…â–…â–…â–ƒâ–ƒâ–ˆâ–‡â–‚â–â–â–ˆâ–„â–‚â–â–â–‚â–â–â–â–â–â–â–â–â–
wandb:      validation/macro_f1_score â–â–†â–†â–†â–†â–„â–ƒâ–…â–…â–…â–‚â–„â–ˆâ–ˆâ–ˆâ–ƒâ–ƒâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb: 
wandb: Run summary:
wandb:            eval/macro_f1_score 0.72225
wandb:             gradients/max_norm 2.50251
wandb:            gradients/mean_norm 0.47247
wandb:             gradients/min_norm 0.0
wandb:                    other/epoch 60
wandb:            other/learning_rate 0.0
wandb:               other/stop_limit 30
wandb:                 train/accuracy 0.9999
wandb:                     train/loss 0.0065
wandb:           train/macro_f1_score 0.99992
wandb:               train/stop_count 17
wandb:            validation/accuracy 1
wandb: validation/best_macro_f1_score 1
wandb:                validation/loss 7e-05
wandb:      validation/macro_f1_score 1
wandb: 
wandb: ðŸš€ View run multi_run_3_dynasent_r2 at: https://wandb.ai/jimbeno/Electra%20Ensemble/runs/geqnid3m
wandb: â­ï¸ View project at: https://wandb.ai/jimbeno/Electra%20Ensemble
wandb: Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 3 other file(s)
wandb: Find logs at: ./wandb/run-20241021_043028-geqnid3m/logs
TOTAL Time: 57m 44s
^[[C(nlp) ubuntu@104-171-202-130:~/nlp-test/sentiment$ python ./ddp_sentiment_finetune.py --dataset 'dynasent_r2' --weights_name 'google/electra-base-discriminator' --save_data --save_model --save_pickle --save_preds --save_plots --lr 0.00002 --epochs 29 --pooling 'mean' --dropout_rate 0.3 --num_layers 2 --hidden_dim 1024 --hidden_activation 'swishglu' --batch_size 16 --accumulation_steps 2 --finetune_bert --finetune_layers 12 --l2_strength 0.01 --checkpoint_interval 5 --use_zero --optimizer 'adamw' --scheduler 'cosine_warmup' --scheduler_kwargs '{"T_0":5, "T_mult":1, "eta_min":1e-7}' --decimal 6 --val_percent 0.2 --early_stop 'score' --n_iter_no_change 30 --show_progress --wandb --wandb_project 'Electra Ensemble' --wandb_run 'multi_run_3_dynasent_r2' --model_ficheckpoint_epoch_60_20241021-052718.^Ch'pth
(nlp) ubuntu@104-171-202-130:~/nlp-test/sentiment$ python ./ddp_sentiment_finetune.py --dataset 'dynasent_r2' --weights_name 'google/electra-base-discriminator' --save_data --save_model --save_pickle --save_preds --save_plots --lr 0.00002 --epochs 29 --pooling 'mean' --dropout_rate 0.3 --num_layers 2 --hidden_dim 1024 --hidden_activation 'swishglu' --batch_size 16 --accumulation_steps 2 --finetune_bert --finetune_layers 12 --l2_strength 0.01 --checkpoint_interval 5 --use_zero --optimi^Cr 'adamw' --scheduler 'cosine_warmup' --scheduler_kwargs '{"T_0":5, "T_mult":1, "eta_min":1e-7}' --decimal 6 --val_percent 0.2 --early_stop 'score' --n_iter_no_change 10 --show_progress --wandb --wandb_project 'Electra Ensemble' --wandb_run 'multi_run_4_dynasent_r2' --model_file 'checkpoint_epoch_60_20241021-052718.pth'
(nlp) ubuntu@104-171-202-130:~/nlp-test/sentiment$ python ./ddp_sentiment_finetune.py --dataset 'dynasent_r2' --weights_name 'google/electra-base-discriminator' --save_data --save_model --save_pickle --save_preds --save_plots --lr 0.00002 --epochs 9 --pooling 'mean' --dropout_rate 0.3 --num_layers 2 --hidden_dim 1024 --hidden_activation 'swishglu' --batch_size 16 --accumulation_steps 2 --finetune_bert --finetune_layers 12 --l2_strength 0.01 --checkpoint_interval 5 --use_zero --optimizer 'adamw' --scheduler 'cosine_warmup' --scheduler_kwargs '{"T_0":5, "T_mult":1, "eta_min":1e-7}' --decimal 6 --val_percent 0.2 --early_stop 'score' --n_iter_no_change 10 --show_progress --wandb --wandb_project 'Electra Ensemble' --wandb_run 'multi_run_4_dynasent_r2' --model_file 'checkpoint_epoch_60_20241021-052718.pth'

Starting DDP PyTorch Training...
Device: cuda, Number of GPUs: 8
Spawning 8 processes...
Rank 7 - Device: cuda:7
Rank 6 - Device: cuda:6
Rank 1 - Device: cuda:1
Rank 2 - Device: cuda:2
Rank 5 - Device: cuda:5
Rank 3 - Device: cuda:3
Rank 4 - Device: cuda:4
Rank 0 - Device: cuda:0
8 process groups initialized with 'nccl' backend on localhost:12355
NCCL Timeout: 1 hr 0 min. NCCL Blocking Wait: Enabled
wandb: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: jbeno (jimbeno). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.3
wandb: Run data is saved locally in /home/ubuntu/nlp-test/sentiment/wandb/run-20241021_053054-avya1rnw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run multi_run_4_dynasent_r2
wandb: â­ï¸ View project at https://wandb.ai/jimbeno/Electra%20Ensemble
wandb: ðŸš€ View run at https://wandb.ai/jimbeno/Electra%20Ensemble/runs/avya1rnw
Wand run initialized.

Initializing 'google/electra-base-discriminator' tokenizer and model...
Tokenizer and model initialized (1s)

Loading data...
Using the same dataset for training and evaluation
Train Data: DynaSent Round 2 from Hugging Face: 'dynabench/dynasent'
Dataset URL: https://huggingface.co/datasets/dynabench/dynasent
Dev Data: DynaSent Round 2 from Hugging Face: 'dynabench/dynasent'
Dataset URL: https://huggingface.co/datasets/dynabench/dynasent
Train size: 13065, Dev size: 720
Train label distribution:
	      Negative: 4579
	       Neutral: 2448
	      Positive: 6038
Dev label distribution:
	      Negative: 240
	       Neutral: 240
	      Positive: 240
Data loaded (2s)

Processing data...
(Batch size: 16, Pooling: Mean, Fine Tune BERT: True, Chunk size: None)...
Extracting sentences and labels...

Data saved to: saves/data_8_gpu_20241021-053100.npz
X Train shape: [13065], X Dev shape: [720]
y Train shape: [13065], y Dev shape: [720]
Data processed (94ms)

Initializing DDP Neural Classifier...
Layers: 2, Hidden Dim: 1024, Hidden Act: SwishGLU, Dropout: 0.3, Optimizer: AdamW, L2 Strength: 0.01, Pooling: MEAN, Accumulation Steps: 2, Max Grad Norm: None
Batch Size: 16, Max Epochs: 9, LR: 2e-05, Early Stop: score, Fine-tune BERT: True, Fine-tune Layers: 12, Freeze BERT: False, Target Score: None, Interactive: False
Loading model from: checkpoints/checkpoint_epoch_60_20241021-052718.pth...
Loaded checkpoint: checkpoints/checkpoint_epoch_60_20241021-052718.pth
Retrieved model state dictionary.
Retrieved optimizer state dictionary.
Classifier initialized (7s)

Fitting DDP Neural Classifier on training data...
Num Workers: 0, Prefetch: None
Building dataset and dataloader...
Score-based early stopping enabled (macro average F1 score against validation set). Validation fraction: 0.2
Training will stop early if the score does not improve by at least 0.00001 for 10 iterations.
Split data into (X:10452, y:10452) Training samples, and (X:2613, y:2613) Validation samples.
Initializing model, graph, optimizer...
BERT's original pooler removed. Using custom pooling type: mean
BERT has 108,891,648 trainable parameters and 0 non-trainable parameters
Number of BERT layers requiring gradients: 12 out of 12
Fine-tuning the last 12 out of 12 BERT layers

Model Architecture Summary:
BERTClassifier(
  (bert): ElectraModel(
    (embeddings): ElectraEmbeddings(
      (word_embeddings): Embedding(30522, 768, padding_idx=0)
      (position_embeddings): Embedding(512, 768)
      (token_type_embeddings): Embedding(2, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): ElectraEncoder(
      (layer): ModuleList(
        (0-11): 12 x ElectraLayer(
          (attention): ElectraAttention(
            (self): ElectraSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): ElectraSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): ElectraIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): ElectraOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
  (custom_pooling): PoolingLayer()
  (classifier): Classifier(
    (layers): Sequential(
      (0): Linear(in_features=768, out_features=1024, bias=True)
      (1): SwishGLU(
        (projection): Linear(in_features=1024, out_features=2048, bias=True)
        (activation): SiLU()
      )
      (2): Dropout(p=0.3, inplace=False)
      (3): Linear(in_features=1024, out_features=1024, bias=True)
      (4): SwishGLU(
        (projection): Linear(in_features=1024, out_features=2048, bias=True)
        (activation): SiLU()
      )
      (5): Dropout(p=0.3, inplace=False)
      (6): Linear(in_features=1024, out_features=3, bias=True)
    )
  )
)

Model Parameters:
  bert.embeddings.word_embeddings: 23,440,896 (trainable)
  bert.embeddings.position_embeddings: 393,216 (trainable)
  bert.embeddings.token_type_embeddings: 1,536 (trainable)
  bert.embeddings.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.0.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.0.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.0.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.0.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.0.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.0.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.0.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.0.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.1.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.1.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.1.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.1.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.1.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.1.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.1.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.1.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.2.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.2.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.2.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.2.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.2.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.2.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.2.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.2.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.3.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.3.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.3.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.3.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.3.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.3.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.3.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.3.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.4.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.4.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.4.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.4.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.4.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.4.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.4.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.4.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.5.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.5.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.5.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.5.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.5.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.5.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.5.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.5.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.6.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.6.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.6.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.6.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.6.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.6.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.6.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.6.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.7.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.7.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.7.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.7.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.7.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.7.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.7.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.7.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.8.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.8.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.8.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.8.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.8.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.8.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.8.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.8.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.9.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.9.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.9.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.9.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.9.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.9.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.9.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.9.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.10.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.10.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.10.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.10.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.10.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.10.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.10.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.10.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.11.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.11.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.11.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.11.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.11.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.11.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.11.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.11.output.LayerNorm: 1,536 (trainable)
  classifier.layers.0: 787,456 (trainable)
  classifier.layers.1.projection: 2,099,200 (trainable)
  classifier.layers.3: 1,049,600 (trainable)
  classifier.layers.6: 3,075 (trainable)

Total layers: 104
Trainable layers: 104
Total parameters: 112,830,979
Trainable parameters: 112,830,979
Percentage of trainable parameters: 100.00%
Using optimizer: AdamW, Use Zero: True, Learning Rate: 2e-05, L2 strength: 0.01
Using scheduler: CosineAnnealingWarmRestarts
Scheduler arguments:
- T_0: 5
- T_mult: 1
- eta_min: 1e-07

Starting training loop...
Start epoch: 61, Max Iterations: 9, Early Stop: score, Tolerance: 0.00001, Number Iterations No Change: 10
Epoch 61/70: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [01:54<00:00,  1.12s/it, loss=0.0125, lr=1.81e-05, grad=M:0.3104, status=Epoch complete]
â–ˆ Epoch 61: Loss T 0.012471 V 0.000136 | F1 T 0.999920 V 1.000000 B 1.000000 SC 0/10 | Acc T 0.999904 V 1.000000 | LR 1.81e-05 | Grad â†“ 0.000000 â†‘ 2.792735 M 0.310353 | 1m 54s
Epoch 62/70: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [01:53<00:00,  1.11s/it, loss=0.0151, lr=1.32e-05, grad=M:0.3197, status=Epoch complete]
â–ˆ Epoch 62: Loss T 0.015093 V 0.000082 | F1 T 1.000000 V 1.000000 B 1.000000 SC 1/10 | Acc T 1.000000 V 1.000000 | LR 1.32e-05 | Grad â†“ 0.000000 â†‘ 2.217473 M 0.319737 | 1m 53s
Epoch 63/70: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [01:53<00:00,  1.11s/it, loss=0.0076, lr=7.03e-06, grad=M:0.0055, status=Epoch complete]
â–ˆ Epoch 63: Loss T 0.007630 V 0.000138 | F1 T 1.000000 V 1.000000 B 1.000000 SC 2/10 | Acc T 1.000000 V 1.000000 | LR 7.03e-06 | Grad â†“ 0.000000 â†‘ 0.030643 M 0.005485 | 1m 53s
Epoch 64/70: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [01:54<00:00,  1.11s/it, loss=0.0054, lr=2.04e-06, grad=M:0.0175, status=Epoch complete]
â–ˆ Epoch 64: Loss T 0.005387 V 0.000099 | F1 T 1.000000 V 1.000000 B 1.000000 SC 3/10 | Acc T 1.000000 V 1.000000 | LR 2.04e-06 | Grad â†“ 0.000000 â†‘ 0.099252 M 0.017492 | 1m 54s
Epoch 65/70: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [01:54<00:00,  1.11s/it, loss=0.0051, lr=1.00e-07, grad=M:0.0083, status=Epoch complete]
â–ˆ Epoch 65: Loss T 0.005087 V 0.000074 | F1 T 1.000000 V 1.000000 B 1.000000 SC 4/10 | Acc T 1.000000 V 1.000000 | LR 1.00e-07 | Grad â†“ 0.000000 â†‘ 0.046289 M 0.008296 | 1m 54s
Saved model state: checkpoints/checkpoint_epoch_65_20241021-054038.pth
Epoch 66/70: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [01:53<00:00,  1.10s/it, loss=0.0145, lr=1.81e-05, grad=M:0.0181, status=Epoch complete]
â–ˆ Epoch 66: Loss T 0.014470 V 0.000367 | F1 T 0.999880 V 1.000000 B 1.000000 SC 5/10 | Acc T 0.999904 V 1.000000 | LR 1.81e-05 | Grad â†“ 0.000000 â†‘ 0.089475 M 0.018135 | 1m 53s
Epoch 67/70: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [01:53<00:00,  1.11s/it, loss=0.0160, lr=1.32e-05, grad=M:0.0246, status=Epoch complete]
â–ˆ Epoch 67: Loss T 0.015972 V 0.001483 | F1 T 0.999521 V 0.998957 B 1.000000 SC 6/10 | Acc T 0.999522 V 0.999235 | LR 1.32e-05 | Grad â†“ 0.000000 â†‘ 0.148994 M 0.024565 | 1m 53s
Epoch 68/70: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [01:54<00:00,  1.12s/it, loss=0.0089, lr=7.03e-06, grad=M:0.0322, status=Epoch complete]
â–ˆ Epoch 68: Loss T 0.008898 V 0.001055 | F1 T 1.000000 V 0.999479 B 1.000000 SC 7/10 | Acc T 1.000000 V 0.999618 | LR 7.03e-06 | Grad â†“ 0.000000 â†‘ 0.199158 M 0.032158 | 1m 54s
Epoch 69/70: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [01:53<00:00,  1.11s/it, loss=0.0067, lr=2.04e-06, grad=M:0.0152, status=Epoch complete]
â–ˆ Epoch 69: Loss T 0.006681 V 0.000127 | F1 T 1.000000 V 1.000000 B 1.000000 SC 8/10 | Acc T 1.000000 V 1.000000 | LR 2.04e-06 | Grad â†“ 0.000000 â†‘ 0.082502 M 0.015157 | 1m 53s
Epoch 70/70: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [01:53<00:00,  1.10s/it, loss=0.0048, lr=1.00e-07, grad=M:0.1732, status=Epoch complete]
â–ˆ Epoch 70: Loss T 0.004777 V 0.000105 | F1 T 1.000000 V 1.000000 B 1.000000 SC 9/10 | Acc T 1.000000 V 1.000000 | LR 1.00e-07 | Grad â†“ 0.000000 â†‘ 1.054373 M 0.173171 | 1m 53s
Memory: Rank 0: 14.42 GB | Rank 1: 14.62 GB | Rank 2: 14.52 GB | Rank 3: 14.52 GB | Rank 4: 14.60 GB | Rank 5: 14.61 GB | Rank 6: 14.57 GB | Rank 7: 14.54 GB (Max: 16.94 GB, Total: 135.49 GB)
Saved model state: checkpoints/checkpoint_epoch_70_20241021-055014.pth
Saving model in ONNX format...
Model saved in ONNX format to saves/model_20241021-055019.onnx and uploaded to Weights & Biases.
Saved model state: checkpoints/final_model_20241021-055025.pth
Saved model pickle: checkpoints/final_model_20241021-055025.pkl
Training completed (19m 25s)

Evaluating model...

multi_run_4_dynasent_r2 Multi-Class Classification Report

              precision    recall  f1-score   support

    negative   0.693798  0.745833  0.718876       240
     neutral   0.741463  0.633333  0.683146       240
    positive   0.731518  0.783333  0.756539       240

    accuracy                       0.720833       720
   macro avg   0.722260  0.720833  0.719520       720
weighted avg   0.722260  0.720833  0.719520       720

ROC AUC: 0.867771

Predicted  negative  neutral  positive
Actual                                
negative        179       33        28
neutral          47      152        41
positive         32       20       188

Saved predictions: saves/predictions_20241021-055046.csv

Macro F1 Score: 0.72

Evaluation completed (20s)
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:            eval/macro_f1_score â–
wandb:             gradients/max_norm â–ˆâ–‡â–â–â–â–â–â–â–â–„
wandb:            gradients/mean_norm â–ˆâ–ˆâ–â–â–â–â–â–‚â–â–…
wandb:             gradients/min_norm â–‡â–ˆâ–â–â–â–ƒâ–â–ƒâ–â–„
wandb:                    other/epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:            other/learning_rate â–ˆâ–†â–„â–‚â–â–ˆâ–†â–„â–‚â–
wandb:               other/stop_limit â–â–â–â–â–â–â–â–â–â–
wandb:                 train/accuracy â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–â–ˆâ–ˆâ–ˆ
wandb:                     train/loss â–†â–‡â–ƒâ–â–â–‡â–ˆâ–„â–‚â–
wandb:           train/macro_f1_score â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–†â–â–ˆâ–ˆâ–ˆ
wandb:               train/stop_count â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:            validation/accuracy â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–…â–ˆâ–ˆ
wandb: validation/best_macro_f1_score â–â–â–â–â–â–â–â–â–â–
wandb:                validation/loss â–â–â–â–â–â–‚â–ˆâ–†â–â–
wandb:      validation/macro_f1_score â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–…â–ˆâ–ˆ
wandb: 
wandb: Run summary:
wandb:            eval/macro_f1_score 0.71952
wandb:             gradients/max_norm 1.05437
wandb:            gradients/mean_norm 0.17317
wandb:             gradients/min_norm 0.0
wandb:                    other/epoch 70
wandb:            other/learning_rate 0.0
wandb:               other/stop_limit 10
wandb:                 train/accuracy 1
wandb:                     train/loss 0.00478
wandb:           train/macro_f1_score 1
wandb:               train/stop_count 9
wandb:            validation/accuracy 1
wandb: validation/best_macro_f1_score 1
wandb:                validation/loss 0.0001
wandb:      validation/macro_f1_score 1
wandb: 
wandb: ðŸš€ View run multi_run_4_dynasent_r2 at: https://wandb.ai/jimbeno/Electra%20Ensemble/runs/avya1rnw
wandb: â­ï¸ View project at: https://wandb.ai/jimbeno/Electra%20Ensemble
wandb: Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 3 other file(s)
wandb: Find logs at: ./wandb/run-20241021_053054-avya1rnw/logs
TOTAL Time: 20m 20s
(nlp) ubuntu@104-171-202-130:~/nlp-test/sentiment$ python ./ddp_sentiment_finetune.py --dataset 'sst_local' --weights_name 'google/electra-base-discriminator' --save_data --save_model --save_pickle --save_preds --save_plots --lr 0.00002 --epochs 29 --pooling 'mean' --dropout_rate 0.3 --num_layers 2 --hidden_dim 1024 --hidden_activation 'swishglu' --batch_size 16 --accumulation_steps 2 --finetune_bert --finetune_layers 12 --l2_strength 0.01 --checkpoint_interval 5 --use_zero --optimizer 'adamw' --scheduler 'cosine_warmup' --scheduler_kwargs '{"T_0":5, "T_mult":1, "eta_min":1e-7}' --decimal 6 --val_percent 0.2 --early_stop 'score' --n_iter_no_change 30 --show_progress --wandb --wandb_project 'Electra Ensemble' --wandb_run 'multi_run_5_sst' --model_file 'checkpoint_epoch_60_20241021-052718.pth'

Starting DDP PyTorch Training...
Device: cuda, Number of GPUs: 8
Spawning 8 processes...
Rank 7 - Device: cuda:7
Rank 1 - Device: cuda:1
Rank 3 - Device: cuda:3
Rank 5 - Device: cuda:5
Rank 4 - Device: cuda:4
Rank 2 - Device: cuda:2
Rank 6 - Device: cuda:6
Rank 0 - Device: cuda:0
8 process groups initialized with 'nccl' backend on localhost:12355
NCCL Timeout: 1 hr 0 min. NCCL Blocking Wait: Enabled
wandb: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: jbeno (jimbeno). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.3
wandb: Run data is saved locally in /home/ubuntu/nlp-test/sentiment/wandb/run-20241021_061720-s4yjbdoh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run multi_run_5_sst
wandb: â­ï¸ View project at https://wandb.ai/jimbeno/Electra%20Ensemble
wandb: ðŸš€ View run at https://wandb.ai/jimbeno/Electra%20Ensemble/runs/s4yjbdoh
Wand run initialized.

Initializing 'google/electra-base-discriminator' tokenizer and model...
Tokenizer and model initialized (1s)

Loading data...
Using the same dataset for training and evaluation
Train Data: Stanford Sentiment Treebank (SST) from Local: 'data/sentiment'
Dev Data: Stanford Sentiment Treebank (SST) from Local: 'data/sentiment'
Train size: 8544, Dev size: 1101
Train label distribution:
	      Negative: 3310
	       Neutral: 1624
	      Positive: 3610
Dev label distribution:
	      Negative: 428
	       Neutral: 229
	      Positive: 444
Data loaded (382ms)

Processing data...
(Batch size: 16, Pooling: Mean, Fine Tune BERT: True, Chunk size: None)...
Extracting sentences and labels...

Data saved to: saves/data_8_gpu_20241021-061722.npz
X Train shape: [8544], X Dev shape: [1101]
y Train shape: [8544], y Dev shape: [1101]
Data processed (138ms)

Initializing DDP Neural Classifier...
Layers: 2, Hidden Dim: 1024, Hidden Act: SwishGLU, Dropout: 0.3, Optimizer: AdamW, L2 Strength: 0.01, Pooling: MEAN, Accumulation Steps: 2, Max Grad Norm: None
Batch Size: 16, Max Epochs: 29, LR: 2e-05, Early Stop: score, Fine-tune BERT: True, Fine-tune Layers: 12, Freeze BERT: False, Target Score: None, Interactive: False
Loading model from: checkpoints/checkpoint_epoch_60_20241021-052718.pth...
Loaded checkpoint: checkpoints/checkpoint_epoch_60_20241021-052718.pth
Retrieved model state dictionary.
Retrieved optimizer state dictionary.
Classifier initialized (3s)

Fitting DDP Neural Classifier on training data...
Num Workers: 0, Prefetch: None
Building dataset and dataloader...
Score-based early stopping enabled (macro average F1 score against validation set). Validation fraction: 0.2
Training will stop early if the score does not improve by at least 0.00001 for 30 iterations.
Split data into (X:6835, y:6835) Training samples, and (X:1709, y:1709) Validation samples.
Initializing model, graph, optimizer...
BERT's original pooler removed. Using custom pooling type: mean
BERT has 108,891,648 trainable parameters and 0 non-trainable parameters
Number of BERT layers requiring gradients: 12 out of 12
Fine-tuning the last 12 out of 12 BERT layers

Model Architecture Summary:
BERTClassifier(
  (bert): ElectraModel(
    (embeddings): ElectraEmbeddings(
      (word_embeddings): Embedding(30522, 768, padding_idx=0)
      (position_embeddings): Embedding(512, 768)
      (token_type_embeddings): Embedding(2, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): ElectraEncoder(
      (layer): ModuleList(
        (0-11): 12 x ElectraLayer(
          (attention): ElectraAttention(
            (self): ElectraSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): ElectraSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): ElectraIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): ElectraOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
  (custom_pooling): PoolingLayer()
  (classifier): Classifier(
    (layers): Sequential(
      (0): Linear(in_features=768, out_features=1024, bias=True)
      (1): SwishGLU(
        (projection): Linear(in_features=1024, out_features=2048, bias=True)
        (activation): SiLU()
      )
      (2): Dropout(p=0.3, inplace=False)
      (3): Linear(in_features=1024, out_features=1024, bias=True)
      (4): SwishGLU(
        (projection): Linear(in_features=1024, out_features=2048, bias=True)
        (activation): SiLU()
      )
      (5): Dropout(p=0.3, inplace=False)
      (6): Linear(in_features=1024, out_features=3, bias=True)
    )
  )
)

Model Parameters:
  bert.embeddings.word_embeddings: 23,440,896 (trainable)
  bert.embeddings.position_embeddings: 393,216 (trainable)
  bert.embeddings.token_type_embeddings: 1,536 (trainable)
  bert.embeddings.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.0.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.0.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.0.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.0.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.0.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.0.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.0.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.0.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.1.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.1.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.1.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.1.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.1.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.1.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.1.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.1.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.2.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.2.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.2.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.2.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.2.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.2.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.2.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.2.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.3.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.3.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.3.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.3.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.3.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.3.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.3.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.3.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.4.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.4.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.4.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.4.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.4.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.4.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.4.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.4.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.5.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.5.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.5.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.5.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.5.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.5.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.5.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.5.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.6.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.6.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.6.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.6.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.6.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.6.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.6.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.6.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.7.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.7.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.7.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.7.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.7.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.7.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.7.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.7.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.8.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.8.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.8.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.8.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.8.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.8.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.8.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.8.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.9.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.9.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.9.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.9.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.9.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.9.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.9.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.9.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.10.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.10.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.10.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.10.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.10.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.10.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.10.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.10.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.11.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.11.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.11.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.11.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.11.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.11.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.11.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.11.output.LayerNorm: 1,536 (trainable)
  classifier.layers.0: 787,456 (trainable)
  classifier.layers.1.projection: 2,099,200 (trainable)
  classifier.layers.3: 1,049,600 (trainable)
  classifier.layers.6: 3,075 (trainable)

Total layers: 104
Trainable layers: 104
Total parameters: 112,830,979
Trainable parameters: 112,830,979
Percentage of trainable parameters: 100.00%
Using optimizer: AdamW, Use Zero: True, Learning Rate: 2e-05, L2 strength: 0.01
Using scheduler: CosineAnnealingWarmRestarts
Scheduler arguments:
- T_0: 5
- T_mult: 1
- eta_min: 1e-07

Starting training loop...
Start epoch: 61, Max Iterations: 29, Early Stop: score, Tolerance: 0.00001, Number Iterations No Change: 30
Epoch 61/90: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [01:32<00:00,  1.38s/it, loss=0.1655, lr=1.82e-05, grad=M:0.7470, status=Epoch complete]
â–ˆ Epoch 61: Loss T 0.165543 V 0.019597 | F1 T 0.993850 V 0.990438 B 0.990438 SC 0/30 | Acc T 0.995175 V 0.992407 | LR 1.82e-05 | Grad â†“ 0.000000 â†‘ 4.486171 M 0.746978 | 1m 32s
Epoch 62/90: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [01:30<00:00,  1.35s/it, loss=0.1092, lr=1.32e-05, grad=M:0.3390, status=Epoch complete]
â–ˆ Epoch 62: Loss T 0.109159 V 0.007131 | F1 T 0.995869 V 0.998511 B 0.998511 SC 0/30 | Acc T 0.996784 V 0.998832 | LR 1.32e-05 | Grad â†“ 0.000000 â†‘ 2.407739 M 0.339011 | 1m 30s
Epoch 63/90: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [01:30<00:00,  1.34s/it, loss=0.0700, lr=7.06e-06, grad=M:0.5901, status=Epoch complete]
â–ˆ Epoch 63: Loss T 0.069981 V 0.004958 | F1 T 0.997889 V 0.997764 B 0.998511 SC 1/30 | Acc T 0.998246 V 0.998248 | LR 7.06e-06 | Grad â†“ 0.000000 â†‘ 3.667189 M 0.590083 | 1m 30s
Epoch 64/90: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [01:29<00:00,  1.34s/it, loss=0.0430, lr=2.06e-06, grad=M:0.3116, status=Epoch complete]
â–ˆ Epoch 64: Loss T 0.042998 V 0.002090 | F1 T 0.998009 V 0.999256 B 0.999256 SC 0/30 | Acc T 0.998392 V 0.999416 | LR 2.06e-06 | Grad â†“ 0.000000 â†‘ 1.727555 M 0.311647 | 1m 29s
Epoch 65/90: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [01:29<00:00,  1.34s/it, loss=0.0335, lr=1.00e-07, grad=M:0.3149, status=Epoch complete]
â–ˆ Epoch 65: Loss T 0.033484 V 0.001827 | F1 T 0.998386 V 0.999256 B 0.999256 SC 1/30 | Acc T 0.998684 V 0.999416 | LR 1.00e-07 | Grad â†“ 0.000000 â†‘ 2.257108 M 0.314858 | 1m 29s
Saved model state: checkpoints/checkpoint_epoch_65_20241021-062459.pth
Epoch 66/90: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [01:29<00:00,  1.34s/it, loss=0.0789, lr=1.82e-05, grad=M:0.1216, status=Epoch complete]
â–ˆ Epoch 66: Loss T 0.078854 V 0.013130 | F1 T 0.997244 V 0.996954 B 0.999256 SC 2/30 | Acc T 0.997807 V 0.997664 | LR 1.82e-05 | Grad â†“ 0.000000 â†‘ 0.689351 M 0.121558 | 1m 29s
Epoch 67/90: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [01:30<00:00,  1.35s/it, loss=0.0727, lr=1.32e-05, grad=M:0.2582, status=Epoch complete]
â–ˆ Epoch 67: Loss T 0.072729 V 0.011698 | F1 T 0.995935 V 0.995723 B 0.999256 SC 3/30 | Acc T 0.996784 V 0.996495 | LR 1.32e-05 | Grad â†“ 0.000000 â†‘ 1.479808 M 0.258234 | 1m 30s
Epoch 68/90: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [01:30<00:00,  1.35s/it, loss=0.0508, lr=7.06e-06, grad=M:0.1514, status=Epoch complete]
â–ˆ Epoch 68: Loss T 0.050798 V 0.000593 | F1 T 0.998884 V 1.000000 B 1.000000 SC 0/30 | Acc T 0.999123 V 1.000000 | LR 7.06e-06 | Grad â†“ 0.000000 â†‘ 0.784803 M 0.151386 | 1m 30s
Epoch 69/90: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [01:29<00:00,  1.34s/it, loss=0.0313, lr=2.06e-06, grad=M:0.0354, status=Epoch complete]
â–ˆ Epoch 69: Loss T 0.031293 V 0.000229 | F1 T 0.999256 V 1.000000 B 1.000000 SC 1/30 | Acc T 0.999415 V 1.000000 | LR 2.06e-06 | Grad â†“ 0.000000 â†‘ 0.218188 M 0.035362 | 1m 29s
Epoch 70/90: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [01:29<00:00,  1.34s/it, loss=0.0231, lr=1.00e-07, grad=M:0.5459, status=Epoch complete]
â–ˆ Epoch 70: Loss T 0.023053 V 0.000176 | F1 T 0.999442 V 1.000000 B 1.000000 SC 2/30 | Acc T 0.999561 V 1.000000 | LR 1.00e-07 | Grad â†“ 0.000000 â†‘ 4.158917 M 0.545901 | 1m 29s
Memory: Rank 0: 14.39 GB | Rank 1: 14.60 GB | Rank 2: 14.50 GB | Rank 3: 14.50 GB | Rank 4: 14.57 GB | Rank 5: 14.59 GB | Rank 6: 14.54 GB | Rank 7: 14.52 GB (Max: 16.94 GB, Total: 135.49 GB)
Saved model state: checkpoints/checkpoint_epoch_70_20241021-063236.pth
Epoch 71/90: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [01:29<00:00,  1.33s/it, loss=0.0409, lr=1.82e-05, grad=M:0.4320, status=Epoch complete]
â–ˆ Epoch 71: Loss T 0.040915 V 0.005882 | F1 T 0.997200 V 0.997743 B 1.000000 SC 3/30 | Acc T 0.997807 V 0.998248 | LR 1.82e-05 | Grad â†“ 0.000000 â†‘ 2.615561 M 0.431979 | 1m 29s
Epoch 72/90: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [01:30<00:00,  1.35s/it, loss=0.0532, lr=1.32e-05, grad=M:0.2298, status=Epoch complete]
â–ˆ Epoch 72: Loss T 0.053230 V 0.000941 | F1 T 0.999065 V 1.000000 B 1.000000 SC 4/30 | Acc T 0.999269 V 1.000000 | LR 1.32e-05 | Grad â†“ 0.000000 â†‘ 1.397680 M 0.229770 | 1m 30s
Epoch 73/90: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [01:30<00:00,  1.35s/it, loss=0.0304, lr=7.06e-06, grad=M:0.2757, status=Epoch complete]
â–ˆ Epoch 73: Loss T 0.030423 V 0.000195 | F1 T 0.999628 V 1.000000 B 1.000000 SC 5/30 | Acc T 0.999708 V 1.000000 | LR 7.06e-06 | Grad â†“ 0.000000 â†‘ 1.754996 M 0.275723 | 1m 30s
Epoch 74/90: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [01:30<00:00,  1.35s/it, loss=0.0219, lr=2.06e-06, grad=M:0.1142, status=Epoch complete]
â–ˆ Epoch 74: Loss T 0.021902 V 0.000118 | F1 T 0.999814 V 1.000000 B 1.000000 SC 6/30 | Acc T 0.999854 V 1.000000 | LR 2.06e-06 | Grad â†“ 0.000000 â†‘ 0.785392 M 0.114236 | 1m 30s
Epoch 75/90: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [01:32<00:00,  1.38s/it, loss=0.0131, lr=1.00e-07, grad=M:0.4059, status=Epoch complete]
â–ˆ Epoch 75: Loss T 0.013148 V 0.000120 | F1 T 0.999814 V 1.000000 B 1.000000 SC 7/30 | Acc T 0.999854 V 1.000000 | LR 1.00e-07 | Grad â†“ 0.000000 â†‘ 2.785051 M 0.405904 | 1m 32s
Saved model state: checkpoints/checkpoint_epoch_75_20241021-064013.pth
Epoch 76/90: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [01:30<00:00,  1.35s/it, loss=0.0245, lr=1.82e-05, grad=M:0.0163, status=Epoch complete]
â–ˆ Epoch 76: Loss T 0.024512 V 0.001435 | F1 T 0.998862 V 0.999236 B 1.000000 SC 8/30 | Acc T 0.999123 V 0.999416 | LR 1.82e-05 | Grad â†“ 0.000000 â†‘ 0.099024 M 0.016285 | 1m 30s
Epoch 77/90: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [01:29<00:00,  1.34s/it, loss=0.0349, lr=1.32e-05, grad=M:0.4918, status=Epoch complete]
â–ˆ Epoch 77: Loss T 0.034917 V 0.002301 | F1 T 0.999437 V 0.999236 B 1.000000 SC 9/30 | Acc T 0.999561 V 0.999416 | LR 1.32e-05 | Grad â†“ 0.000000 â†‘ 2.479452 M 0.491750 | 1m 29s
Epoch 78/90: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [01:30<00:00,  1.36s/it, loss=0.0308, lr=7.06e-06, grad=M:0.1124, status=Epoch complete]
â–ˆ Epoch 78: Loss T 0.030757 V 0.001254 | F1 T 0.999617 V 0.999256 B 1.000000 SC 10/30 | Acc T 0.999708 V 0.999416 | LR 7.06e-06 | Grad â†“ 0.000000 â†‘ 0.673890 M 0.112375 | 1m 30s
Epoch 79/90: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [01:30<00:00,  1.36s/it, loss=0.0213, lr=2.06e-06, grad=M:0.2180, status=Epoch complete]
â–ˆ Epoch 79: Loss T 0.021285 V 0.003133 | F1 T 0.999809 V 0.999257 B 1.000000 SC 11/30 | Acc T 0.999854 V 0.999416 | LR 2.06e-06 | Grad â†“ 0.000000 â†‘ 1.364594 M 0.217976 | 1m 30s
Epoch 80/90: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [01:30<00:00,  1.35s/it, loss=0.0142, lr=1.00e-07, grad=M:0.0570, status=Epoch complete]
â–ˆ Epoch 80: Loss T 0.014189 V 0.002823 | F1 T 1.000000 V 0.999257 B 1.000000 SC 12/30 | Acc T 1.000000 V 0.999416 | LR 1.00e-07 | Grad â†“ 0.000000 â†‘ 0.383549 M 0.057034 | 1m 30s
Memory: Rank 0: 14.40 GB | Rank 1: 14.60 GB | Rank 2: 14.50 GB | Rank 3: 14.50 GB | Rank 4: 14.57 GB | Rank 5: 14.59 GB | Rank 6: 14.54 GB | Rank 7: 14.52 GB (Max: 16.94 GB, Total: 135.49 GB)
Saved model state: checkpoints/checkpoint_epoch_80_20241021-064748.pth
Epoch 81/90: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [01:30<00:00,  1.36s/it, loss=0.0176, lr=1.82e-05, grad=M:0.2331, status=Epoch complete]
â–ˆ Epoch 81: Loss T 0.017587 V 0.022669 | F1 T 0.999623 V 0.997747 B 1.000000 SC 13/30 | Acc T 0.999708 V 0.998248 | LR 1.82e-05 | Grad â†“ 0.000000 â†‘ 1.359013 M 0.233074 | 1m 30s
Epoch 82/90: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [01:31<00:00,  1.36s/it, loss=0.0323, lr=1.32e-05, grad=M:0.1130, status=Epoch complete]
â–ˆ Epoch 82: Loss T 0.032347 V 0.009224 | F1 T 0.999628 V 0.998490 B 1.000000 SC 14/30 | Acc T 0.999708 V 0.998832 | LR 1.32e-05 | Grad â†“ 0.000000 â†‘ 0.558469 M 0.113031 | 1m 31s
Epoch 83/90: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [01:30<00:00,  1.35s/it, loss=0.0195, lr=7.06e-06, grad=M:0.3772, status=Epoch complete]
â–ˆ Epoch 83: Loss T 0.019459 V 0.006993 | F1 T 0.999814 V 0.997747 B 1.000000 SC 15/30 | Acc T 0.999854 V 0.998248 | LR 7.06e-06 | Grad â†“ 0.000000 â†‘ 2.265645 M 0.377201 | 1m 30s
Epoch 84/90: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [01:30<00:00,  1.35s/it, loss=0.0129, lr=2.06e-06, grad=M:0.1401, status=Epoch complete]
â–ˆ Epoch 84: Loss T 0.012859 V 0.005295 | F1 T 0.999814 V 0.999236 B 1.000000 SC 16/30 | Acc T 0.999854 V 0.999416 | LR 2.06e-06 | Grad â†“ 0.000000 â†‘ 0.892899 M 0.140066 | 1m 30s
Epoch 85/90: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [01:30<00:00,  1.35s/it, loss=0.0133, lr=1.00e-07, grad=M:0.1738, status=Epoch complete]
â–ˆ Epoch 85: Loss T 0.013253 V 0.004958 | F1 T 0.999814 V 0.999236 B 1.000000 SC 17/30 | Acc T 0.999854 V 0.999416 | LR 1.00e-07 | Grad â†“ 0.000000 â†‘ 1.070088 M 0.173751 | 1m 30s
Saved model state: checkpoints/checkpoint_epoch_85_20241021-065527.pth
Epoch 86/90: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [01:30<00:00,  1.36s/it, loss=0.0312, lr=1.82e-05, grad=M:0.2201, status=Epoch complete]
â–ˆ Epoch 86: Loss T 0.031153 V 0.002745 | F1 T 0.999251 V 0.999236 B 1.000000 SC 18/30 | Acc T 0.999415 V 0.999416 | LR 1.82e-05 | Grad â†“ 0.000000 â†‘ 1.311130 M 0.220139 | 1m 30s
Epoch 87/90: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [01:30<00:00,  1.35s/it, loss=0.0254, lr=1.32e-05, grad=M:0.0306, status=Epoch complete]
â–ˆ Epoch 87: Loss T 0.025356 V 0.001053 | F1 T 1.000000 V 0.999256 B 1.000000 SC 19/30 | Acc T 1.000000 V 0.999416 | LR 1.32e-05 | Grad â†“ 0.000000 â†‘ 0.199581 M 0.030577 | 1m 30s
Epoch 88/90: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [01:30<00:00,  1.35s/it, loss=0.0129, lr=7.06e-06, grad=M:0.0250, status=Epoch complete]
â–ˆ Epoch 88: Loss T 0.012938 V 0.000776 | F1 T 0.999809 V 0.999256 B 1.000000 SC 20/30 | Acc T 0.999854 V 0.999416 | LR 7.06e-06 | Grad â†“ 0.000000 â†‘ 0.143445 M 0.025023 | 1m 30s
Epoch 89/90: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [01:30<00:00,  1.36s/it, loss=0.0119, lr=2.06e-06, grad=M:0.1598, status=Epoch complete]
â–ˆ Epoch 89: Loss T 0.011884 V 0.000444 | F1 T 0.999879 V 1.000000 B 1.000000 SC 21/30 | Acc T 0.999854 V 1.000000 | LR 2.06e-06 | Grad â†“ 0.000000 â†‘ 0.976727 M 0.159820 | 1m 30s
Epoch 90/90: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [01:29<00:00,  1.33s/it, loss=0.0051, lr=1.00e-07, grad=M:0.0230, status=Epoch complete]
â–ˆ Epoch 90: Loss T 0.005143 V 0.000384 | F1 T 0.999879 V 1.000000 B 1.000000 SC 22/30 | Acc T 0.999854 V 1.000000 | LR 1.00e-07 | Grad â†“ 0.000000 â†‘ 0.154155 M 0.023007 | 1m 29s
Memory: Rank 0: 14.40 GB | Rank 1: 14.60 GB | Rank 2: 14.50 GB | Rank 3: 14.50 GB | Rank 4: 14.57 GB | Rank 5: 14.59 GB | Rank 6: 14.54 GB | Rank 7: 14.52 GB (Max: 16.94 GB, Total: 135.49 GB)
Saved model state: checkpoints/checkpoint_epoch_90_20241021-070303.pth
Saving model in ONNX format...
Model saved in ONNX format to saves/model_20241021-070307.onnx and uploaded to Weights & Biases.
Saved model state: checkpoints/final_model_20241021-070313.pth
Saved model pickle: checkpoints/final_model_20241021-070313.pkl
Training completed (45m 55s)

Evaluating model...

multi_run_5_sst Multi-Class Classification Report

              precision    recall  f1-score   support

    negative   0.808962  0.801402  0.805164       428
     neutral   0.436170  0.358079  0.393285       229
    positive   0.797546  0.878378  0.836013       444

    accuracy                       0.740236      1101
   macro avg   0.680893  0.679286  0.678154      1101
weighted avg   0.726820  0.740236  0.731937      1101

ROC AUC: 0.861363

Predicted  negative  neutral  positive
Actual                                
negative        343       67        18
neutral          66       82        81
positive         15       39       390

Saved predictions: saves/predictions_20241021-070342.csv

Macro F1 Score: 0.68

Evaluation completed (30s)
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:            eval/macro_f1_score â–
wandb:             gradients/max_norm â–ˆâ–…â–‡â–„â–„â–‚â–ƒâ–‚â–â–‡â–…â–ƒâ–„â–‚â–…â–â–…â–‚â–ƒâ–â–ƒâ–‚â–„â–‚â–ƒâ–ƒâ–â–â–‚â–
wandb:            gradients/mean_norm â–ˆâ–„â–†â–„â–„â–‚â–ƒâ–‚â–â–†â–…â–ƒâ–ƒâ–‚â–…â–â–†â–‚â–ƒâ–â–ƒâ–‚â–„â–‚â–ƒâ–ƒâ–â–â–‚â–
wandb:             gradients/min_norm â–ˆâ–„â–†â–†â–ƒâ–‚â–ƒâ–ƒâ–â–ƒâ–„â–ƒâ–ˆâ–‚â–‚â–â–†â–ƒâ–„â–‚â–„â–‚â–†â–‚â–‚â–‚â–â–â–‚â–
wandb:                    other/epoch â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:            other/learning_rate â–ˆâ–†â–„â–‚â–â–ˆâ–†â–„â–‚â–â–ˆâ–†â–„â–‚â–â–ˆâ–†â–„â–‚â–â–ˆâ–†â–„â–‚â–â–ˆâ–†â–„â–‚â–
wandb:               other/stop_limit â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 train/accuracy â–â–ƒâ–…â–†â–†â–…â–ƒâ–‡â–‡â–‡â–…â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                     train/loss â–ˆâ–†â–„â–ƒâ–‚â–„â–„â–ƒâ–‚â–‚â–ƒâ–ƒâ–‚â–‚â–â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–â–â–‚â–‚â–â–â–
wandb:           train/macro_f1_score â–â–ƒâ–†â–†â–†â–…â–ƒâ–‡â–‡â–‡â–…â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:               train/stop_count â–â–â–â–â–â–‚â–‚â–â–â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–‡â–‡â–‡â–ˆâ–ˆ
wandb:            validation/accuracy â–â–‡â–†â–‡â–‡â–†â–…â–ˆâ–ˆâ–ˆâ–†â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–†â–‡â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆ
wandb: validation/best_macro_f1_score â–â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                validation/loss â–‡â–ƒâ–ƒâ–‚â–‚â–…â–…â–â–â–â–ƒâ–â–â–â–â–â–‚â–â–‚â–‚â–ˆâ–„â–ƒâ–ƒâ–ƒâ–‚â–â–â–â–
wandb:      validation/macro_f1_score â–â–‡â–†â–‡â–‡â–†â–…â–ˆâ–ˆâ–ˆâ–†â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–†â–‡â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆ
wandb: 
wandb: Run summary:
wandb:            eval/macro_f1_score 0.67815
wandb:             gradients/max_norm 0.15415
wandb:            gradients/mean_norm 0.02301
wandb:             gradients/min_norm 0.0
wandb:                    other/epoch 90
wandb:            other/learning_rate 0.0
wandb:               other/stop_limit 30
wandb:                 train/accuracy 0.99985
wandb:                     train/loss 0.00514
wandb:           train/macro_f1_score 0.99988
wandb:               train/stop_count 22
wandb:            validation/accuracy 1
wandb: validation/best_macro_f1_score 1
wandb:                validation/loss 0.00038
wandb:      validation/macro_f1_score 1
wandb: 
wandb: ðŸš€ View run multi_run_5_sst at: https://wandb.ai/jimbeno/Electra%20Ensemble/runs/s4yjbdoh
wandb: â­ï¸ View project at: https://wandb.ai/jimbeno/Electra%20Ensemble
wandb: Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 3 other file(s)
wandb: Find logs at: ./wandb/run-20241021_061720-s4yjbdoh/logs
TOTAL Time: 46m 49s
(nlp) ubuntu@104-171-202-130:~/nlp-test/sentiment$ python ./ddp_sentiment_finetune.py --dataset 'sst_local' --weights_name 'google/electra-base-discriminator' --save_data --save_model --save_pickle --save_preds --save_plots --lr 0.00002 --epochs 29 --pooling 'mean' --dropout_rate 0.3 --num_layers 2 --hidden_dim 1024 --hidden_activation 'swishglu' --batch_size 16 --accumulation_steps 2 --finetune_bert --finetune_layers 12 --l2_strength 0.01 --checkpoint_interval 5 --use_zero --optimizer 'adamw' --scheduler 'cosine_warmup' --scheduler_kwargs '{"T_0":5, "T_mult":1, "eta_min":1e-7}' --decimal 6 --val_percent 0.2 --early_stop 'score' --n_iter_no_change 30 --show_progress --wandb --wandb_project 'Electra Ensemble' --wandb_run 'multi_run_5_sst' --model_file 'checkpoint_epoch_70_20241021-063236.pth'^C
(nlp) ubuntu@104-171-202-130:~/nlp-test/sentiment$ python ./ddp_sentiment_finetune.py --dataset 'sst_local' --weights_name 'google/electra-base-discriminator' --save_data --save_model --save_pickle --save_preds --save_plots --lr 0.00002 --epochs 29 --pooling 'mean' --dropout_rate 0.3 --num_layers 2 --hidden_dim 1024 --hidden_activation 'swishglu' --batch_size 16 --accumulation_steps 2 --finetune_bert --finetune_layers 12 --l2_strength 0.01 --checkpoint_interval 5 --use_zero --optimizer 'adamw' --scheduler 'cosine_warmup' --scheduler_kwargs '{"T_0":5, "T_mult":1, "eta_min":1e-7}' --decimal 6 --val_percent 0.2 --early_stop 'score' --n_iter_no_change 30 --show_progress --wandb --wandb_project 'Electra Ensemble' --wandb_run 'multi_run_eval_sst' --model_file 'checkpoint_epoch_70_20241021-063236.pth' --interactive

Starting DDP PyTorch Training...
Device: cuda, Number of GPUs: 8
Spawning 8 processes...
Rank 1 - Device: cuda:1
Rank 6 - Device: cuda:6
Rank 4 - Device: cuda:4
Rank 7 - Device: cuda:7
Rank 3 - Device: cuda:3
Rank 2 - Device: cuda:2
Rank 5 - Device: cuda:5
Rank 0 - Device: cuda:0
8 process groups initialized with 'nccl' backend on localhost:12355
NCCL Timeout: 1 hr 0 min. NCCL Blocking Wait: Enabled
wandb: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: jbeno (jimbeno). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.3
wandb: Run data is saved locally in /home/ubuntu/nlp-test/sentiment/wandb/run-20241021_070805-asb7p7f9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run multi_run_eval_sst
wandb: â­ï¸ View project at https://wandb.ai/jimbeno/Electra%20Ensemble
wandb: ðŸš€ View run at https://wandb.ai/jimbeno/Electra%20Ensemble/runs/asb7p7f9
Wand run initialized.

Initializing 'google/electra-base-discriminator' tokenizer and model...
Tokenizer and model initialized (1s)

Loading data...
Using the same dataset for training and evaluation
Train Data: Stanford Sentiment Treebank (SST) from Local: 'data/sentiment'
Dev Data: Stanford Sentiment Treebank (SST) from Local: 'data/sentiment'
Train size: 8544, Dev size: 1101
Train label distribution:
	      Negative: 3310
	       Neutral: 1624
	      Positive: 3610
Dev label distribution:
	      Negative: 428
	       Neutral: 229
	      Positive: 444
Data loaded (378ms)

Processing data...
(Batch size: 16, Pooling: Mean, Fine Tune BERT: True, Chunk size: None)...
Extracting sentences and labels...

Data saved to: saves/data_8_gpu_20241021-070808.npz
X Train shape: [8544], X Dev shape: [1101]
y Train shape: [8544], y Dev shape: [1101]
Data processed (97ms)

Initializing DDP Neural Classifier...
Layers: 2, Hidden Dim: 1024, Hidden Act: SwishGLU, Dropout: 0.3, Optimizer: AdamW, L2 Strength: 0.01, Pooling: MEAN, Accumulation Steps: 2, Max Grad Norm: None
Batch Size: 16, Max Epochs: 29, LR: 2e-05, Early Stop: score, Fine-tune BERT: True, Fine-tune Layers: 12, Freeze BERT: False, Target Score: None, Interactive: True
Loading model from: checkpoints/checkpoint_epoch_70_20241021-063236.pth...
Loaded checkpoint: checkpoints/checkpoint_epoch_70_20241021-063236.pth
Retrieved model state dictionary.
Retrieved optimizer state dictionary.
Classifier initialized (7s)

Fitting DDP Neural Classifier on training data...
Num Workers: 0, Prefetch: None
Building dataset and dataloader...
Score-based early stopping enabled (macro average F1 score against validation set). Validation fraction: 0.2
Training will stop early if the score does not improve by at least 0.00001 for 30 iterations.
Split data into (X:6835, y:6835) Training samples, and (X:1709, y:1709) Validation samples.
Initializing model, graph, optimizer...
BERT's original pooler removed. Using custom pooling type: mean
BERT has 108,891,648 trainable parameters and 0 non-trainable parameters
Number of BERT layers requiring gradients: 12 out of 12
Fine-tuning the last 12 out of 12 BERT layers

Model Architecture Summary:
BERTClassifier(
  (bert): ElectraModel(
    (embeddings): ElectraEmbeddings(
      (word_embeddings): Embedding(30522, 768, padding_idx=0)
      (position_embeddings): Embedding(512, 768)
      (token_type_embeddings): Embedding(2, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): ElectraEncoder(
      (layer): ModuleList(
        (0-11): 12 x ElectraLayer(
          (attention): ElectraAttention(
            (self): ElectraSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): ElectraSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): ElectraIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): ElectraOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
  (custom_pooling): PoolingLayer()
  (classifier): Classifier(
    (layers): Sequential(
      (0): Linear(in_features=768, out_features=1024, bias=True)
      (1): SwishGLU(
        (projection): Linear(in_features=1024, out_features=2048, bias=True)
        (activation): SiLU()
      )
      (2): Dropout(p=0.3, inplace=False)
      (3): Linear(in_features=1024, out_features=1024, bias=True)
      (4): SwishGLU(
        (projection): Linear(in_features=1024, out_features=2048, bias=True)
        (activation): SiLU()
      )
      (5): Dropout(p=0.3, inplace=False)
      (6): Linear(in_features=1024, out_features=3, bias=True)
    )
  )
)

Model Parameters:
  bert.embeddings.word_embeddings: 23,440,896 (trainable)
  bert.embeddings.position_embeddings: 393,216 (trainable)
  bert.embeddings.token_type_embeddings: 1,536 (trainable)
  bert.embeddings.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.0.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.0.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.0.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.0.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.0.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.0.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.0.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.0.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.1.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.1.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.1.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.1.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.1.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.1.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.1.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.1.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.2.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.2.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.2.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.2.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.2.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.2.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.2.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.2.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.3.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.3.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.3.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.3.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.3.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.3.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.3.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.3.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.4.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.4.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.4.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.4.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.4.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.4.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.4.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.4.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.5.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.5.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.5.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.5.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.5.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.5.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.5.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.5.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.6.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.6.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.6.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.6.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.6.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.6.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.6.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.6.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.7.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.7.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.7.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.7.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.7.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.7.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.7.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.7.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.8.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.8.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.8.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.8.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.8.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.8.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.8.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.8.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.9.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.9.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.9.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.9.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.9.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.9.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.9.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.9.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.10.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.10.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.10.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.10.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.10.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.10.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.10.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.10.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.11.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.11.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.11.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.11.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.11.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.11.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.11.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.11.output.LayerNorm: 1,536 (trainable)
  classifier.layers.0: 787,456 (trainable)
  classifier.layers.1.projection: 2,099,200 (trainable)
  classifier.layers.3: 1,049,600 (trainable)
  classifier.layers.6: 3,075 (trainable)

Total layers: 104
Trainable layers: 104
Total parameters: 112,830,979
Trainable parameters: 112,830,979
Percentage of trainable parameters: 100.00%
Using optimizer: AdamW, Use Zero: True, Learning Rate: 2e-05, L2 strength: 0.01
Using scheduler: CosineAnnealingWarmRestarts
Scheduler arguments:
- T_0: 5
- T_mult: 1
- eta_min: 1e-07

Starting training loop...
Start epoch: 71, Max Iterations: 29, Early Stop: score, Tolerance: 0.00001, Number Iterations No Change: 30

[Enter] to continue for 1 epoch, [Q]uit, [S]ave, [H]elp: q
Quitting training...
Saving model in ONNX format...
Model saved in ONNX format to saves/model_20241021-070909.onnx and uploaded to Weights & Biases.
Saved model state: checkpoints/final_model_20241021-070915.pth
Saved model pickle: checkpoints/final_model_20241021-070915.pkl
Training completed (1m 6s)

Evaluating model...

multi_run_eval_sst Multi-Class Classification Report

              precision    recall  f1-score   support

    negative   0.814458  0.789720  0.801898       428
     neutral   0.438424  0.388646  0.412037       229
    positive   0.807453  0.878378  0.841424       444

    accuracy                       0.742053      1101
   macro avg   0.686778  0.685581  0.685120      1101
weighted avg   0.733421  0.742053  0.736749      1101

ROC AUC: 0.861146

Predicted  negative  neutral  positive
Actual                                
negative        338       73        17
neutral          64       89        76
positive         13       41       390

Saved predictions: saves/predictions_20241021-070943.csv

Macro F1 Score: 0.69

Evaluation completed (32s)
wandb:                                                                                
wandb: 
wandb: Run history:
wandb: eval/macro_f1_score â–
wandb: 
wandb: Run summary:
wandb: eval/macro_f1_score 0.68512
wandb: 
wandb: ðŸš€ View run multi_run_eval_sst at: https://wandb.ai/jimbeno/Electra%20Ensemble/runs/asb7p7f9
wandb: â­ï¸ View project at: https://wandb.ai/jimbeno/Electra%20Ensemble
wandb: Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 3 other file(s)
wandb: Find logs at: ./wandb/run-20241021_070805-asb7p7f9/logs
TOTAL Time: 2m 10s
(nlp) ubuntu@104-171-202-130:~/nlp-test/sentiment$ python ./ddp_sentiment_finetune.py --dataset 'sst_local' --weights_name 'google/electra-base-discriminator' --save_data --save_model --save_pickle --save_preds --save_plots --lr 0.00002 --epochs 29 --pooling 'mean' --dropout_rate 0.3 --num_layers 2 --hidden_dim 1024 --hidden_activation 'swishglu' --batch_size 16 --accumulation_steps 2 --finetune_bert --finetune_layers 12 --l2_strength 0.01 --checkpoint_interval 5 --use_zero --optimizer 'adamw' --scheduler 'cosine_warmup' --scheduler_kwargs '{"T_0":5, "T_mult":1, "eta_min":1e-7}' --decimal 6 --val_percent 0.2 --early_stop 'score' --n_iter_no_change 30 --show_progress --wandb --wandb_project 'Electra Ensemble' --wandb_run 'multi_run_eval_sst' --model_file 'checkpoint_epoch_70_20241021-063236.pth' --interactive^C
(nlp) ubuntu@104-171-202-130:~/nlp-test/sentiment$ python ./ddp_sentiment_finetune.py --dataset 'dynasent_r2' --weights_name 'google/electra-base-discriminator' --save_data --save_model --save_pickle --save_preds --save_plots --lr 0.00002 --epochs 9 --pooling 'mean' --dropout_rate 0.3 --num_layers 2 --hidden_dim 1024 --hidden_activation 'swishglu' --batch_size 16 --accumulation_steps 2 --finetune_bert --finetune_layers 12 --l2_strength 0.01 --checkpoint_interval 5 --use_zero --optimizer 'adamw' --scheduler 'cosine_warmup' --scheduler_kwargs '{"T_0":5, "T_mult":1, "eta_min":1e-7}' --decimal 6 --val_percent 0.2 --early_stop 'score' --n_iter_no_change 10 --show_progress --wandb --wandb_project 'Electra Ensemble' --wandb_run 'multi_run_4_dynasent_eval' --model_file 'checkpoint_epoch_40_20241021-044936.pth' --interactive

Starting DDP PyTorch Training...
Device: cuda, Number of GPUs: 8
Spawning 8 processes...
Rank 7 - Device: cuda:7
Rank 6 - Device: cuda:6
Rank 1 - Device: cuda:1
Rank 4 - Device: cuda:4
Rank 3 - Device: cuda:3
Rank 5 - Device: cuda:5
Rank 2 - Device: cuda:2
Rank 0 - Device: cuda:0
8 process groups initialized with 'nccl' backend on localhost:12355
NCCL Timeout: 1 hr 0 min. NCCL Blocking Wait: Enabled
wandb: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: jbeno (jimbeno). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.3
wandb: Run data is saved locally in /home/ubuntu/nlp-test/sentiment/wandb/run-20241021_071819-eegl3v2e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run multi_run_4_dynasent_eval
wandb: â­ï¸ View project at https://wandb.ai/jimbeno/Electra%20Ensemble
wandb: ðŸš€ View run at https://wandb.ai/jimbeno/Electra%20Ensemble/runs/eegl3v2e
Wand run initialized.

Initializing 'google/electra-base-discriminator' tokenizer and model...
Tokenizer and model initialized (2s)

Loading data...
Using the same dataset for training and evaluation
Train Data: DynaSent Round 2 from Hugging Face: 'dynabench/dynasent'
Dataset URL: https://huggingface.co/datasets/dynabench/dynasent
Dev Data: DynaSent Round 2 from Hugging Face: 'dynabench/dynasent'
Dataset URL: https://huggingface.co/datasets/dynabench/dynasent
Train size: 13065, Dev size: 720
Train label distribution:
	      Negative: 4579
	       Neutral: 2448
	      Positive: 6038
Dev label distribution:
	      Negative: 240
	       Neutral: 240
	      Positive: 240
Data loaded (2s)

Processing data...
(Batch size: 16, Pooling: Mean, Fine Tune BERT: True, Chunk size: None)...
Extracting sentences and labels...

Data saved to: saves/data_8_gpu_20241021-071825.npz
X Train shape: [13065], X Dev shape: [720]
y Train shape: [13065], y Dev shape: [720]
Data processed (98ms)

Initializing DDP Neural Classifier...
Layers: 2, Hidden Dim: 1024, Hidden Act: SwishGLU, Dropout: 0.3, Optimizer: AdamW, L2 Strength: 0.01, Pooling: MEAN, Accumulation Steps: 2, Max Grad Norm: None
Batch Size: 16, Max Epochs: 9, LR: 2e-05, Early Stop: score, Fine-tune BERT: True, Fine-tune Layers: 12, Freeze BERT: False, Target Score: None, Interactive: True
Loading model from: checkpoints/checkpoint_epoch_40_20241021-044936.pth...
Loaded checkpoint: checkpoints/checkpoint_epoch_40_20241021-044936.pth
Retrieved model state dictionary.
Retrieved optimizer state dictionary.
Classifier initialized (7s)

Fitting DDP Neural Classifier on training data...
Num Workers: 0, Prefetch: None
Building dataset and dataloader...
Score-based early stopping enabled (macro average F1 score against validation set). Validation fraction: 0.2
Training will stop early if the score does not improve by at least 0.00001 for 10 iterations.
Split data into (X:10452, y:10452) Training samples, and (X:2613, y:2613) Validation samples.
Initializing model, graph, optimizer...
BERT's original pooler removed. Using custom pooling type: mean
BERT has 108,891,648 trainable parameters and 0 non-trainable parameters
Number of BERT layers requiring gradients: 12 out of 12
Fine-tuning the last 12 out of 12 BERT layers

Model Architecture Summary:
BERTClassifier(
  (bert): ElectraModel(
    (embeddings): ElectraEmbeddings(
      (word_embeddings): Embedding(30522, 768, padding_idx=0)
      (position_embeddings): Embedding(512, 768)
      (token_type_embeddings): Embedding(2, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): ElectraEncoder(
      (layer): ModuleList(
        (0-11): 12 x ElectraLayer(
          (attention): ElectraAttention(
            (self): ElectraSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): ElectraSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): ElectraIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): ElectraOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
  (custom_pooling): PoolingLayer()
  (classifier): Classifier(
    (layers): Sequential(
      (0): Linear(in_features=768, out_features=1024, bias=True)
      (1): SwishGLU(
        (projection): Linear(in_features=1024, out_features=2048, bias=True)
        (activation): SiLU()
      )
      (2): Dropout(p=0.3, inplace=False)
      (3): Linear(in_features=1024, out_features=1024, bias=True)
      (4): SwishGLU(
        (projection): Linear(in_features=1024, out_features=2048, bias=True)
        (activation): SiLU()
      )
      (5): Dropout(p=0.3, inplace=False)
      (6): Linear(in_features=1024, out_features=3, bias=True)
    )
  )
)

Model Parameters:
  bert.embeddings.word_embeddings: 23,440,896 (trainable)
  bert.embeddings.position_embeddings: 393,216 (trainable)
  bert.embeddings.token_type_embeddings: 1,536 (trainable)
  bert.embeddings.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.0.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.0.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.0.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.0.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.0.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.0.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.0.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.0.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.1.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.1.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.1.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.1.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.1.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.1.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.1.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.1.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.2.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.2.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.2.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.2.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.2.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.2.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.2.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.2.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.3.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.3.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.3.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.3.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.3.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.3.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.3.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.3.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.4.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.4.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.4.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.4.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.4.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.4.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.4.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.4.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.5.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.5.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.5.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.5.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.5.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.5.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.5.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.5.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.6.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.6.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.6.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.6.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.6.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.6.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.6.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.6.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.7.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.7.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.7.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.7.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.7.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.7.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.7.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.7.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.8.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.8.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.8.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.8.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.8.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.8.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.8.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.8.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.9.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.9.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.9.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.9.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.9.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.9.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.9.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.9.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.10.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.10.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.10.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.10.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.10.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.10.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.10.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.10.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.11.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.11.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.11.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.11.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.11.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.11.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.11.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.11.output.LayerNorm: 1,536 (trainable)
  classifier.layers.0: 787,456 (trainable)
  classifier.layers.1.projection: 2,099,200 (trainable)
  classifier.layers.3: 1,049,600 (trainable)
  classifier.layers.6: 3,075 (trainable)

Total layers: 104
Trainable layers: 104
Total parameters: 112,830,979
Trainable parameters: 112,830,979
Percentage of trainable parameters: 100.00%
Using optimizer: AdamW, Use Zero: True, Learning Rate: 2e-05, L2 strength: 0.01
Using scheduler: CosineAnnealingWarmRestarts
Scheduler arguments:
- T_0: 5
- T_mult: 1
- eta_min: 1e-07

Starting training loop...
Start epoch: 41, Max Iterations: 9, Early Stop: score, Tolerance: 0.00001, Number Iterations No Change: 10

[Enter] to continue for 1 epoch, [Q]uit, [S]ave, [H]elp: q
Quitting training...
Saving model in ONNX format...
Model saved in ONNX format to saves/model_20241021-071923.onnx and uploaded to Weights & Biases.
Saved model state: checkpoints/final_model_20241021-071929.pth
Saved model pickle: checkpoints/final_model_20241021-071929.pkl
Training completed (1m 3s)

Evaluating model...

multi_run_4_dynasent_eval Multi-Class Classification Report

              precision    recall  f1-score   support

    negative   0.697211  0.729167  0.712831       240
     neutral   0.735294  0.625000  0.675676       240
    positive   0.713208  0.787500  0.748515       240

    accuracy                       0.713889       720
   macro avg   0.715238  0.713889  0.712340       720
weighted avg   0.715238  0.713889  0.712340       720

ROC AUC: 0.875911

Predicted  negative  neutral  positive
Actual                                
negative        175       36        29
neutral          43      150        47
positive         33       18       189

Saved predictions: saves/predictions_20241021-071950.csv

Macro F1 Score: 0.71

Evaluation completed (21s)
wandb:                                                                                
wandb: 
wandb: Run history:
wandb: eval/macro_f1_score â–
wandb: 
wandb: Run summary:
wandb: eval/macro_f1_score 0.71234
wandb: 
wandb: ðŸš€ View run multi_run_4_dynasent_eval at: https://wandb.ai/jimbeno/Electra%20Ensemble/runs/eegl3v2e
wandb: â­ï¸ View project at: https://wandb.ai/jimbeno/Electra%20Ensemble
wandb: Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 3 other file(s)
wandb: Find logs at: ./wandb/run-20241021_071819-eegl3v2e/logs
TOTAL Time: 1m 53s
(nlp) ubuntu@104-171-202-130:~/nlp-test/sentiment$ python ./ddp_sentiment_finetune.py --dataset 'sst_local' --weights_name 'google/electra-base-discriminator' --save_data --save_model --save_pickle --save_preds --save_plots --lr 0.00002 --epochs 29 --pooling 'mean' --dropout_rate 0.3 --num_layers 2 --hidden_dim 1024 --hidden_activation 'swishglu' --batch_size 16 --accumulation_steps 2 --finetune_bert --finetune_layers 12 --l2_strength 0.01 --checkpoint_interval 5 --use_zero --optimizer 'adamw' --scheduler 'cosine_warmup' --scheduler_kwargs '{"T_0":5, "T_mult":1, "eta_min":1e-7}' --decimal 6 --val_percent 0.2 --early_stop 'score' --n_iter_no_change 30 --show_progress --wandb --wandb_project 'Electra Ensemble' --wandb_run 'multi_run_eval_sst' --model_file 'checkpoint_epoch_70_20241021-063236.pth' --interactive --eval_dataset 'merged_local'
^CTraceback (most recent call last):
  File "/home/ubuntu/nlp-test/sentiment/./ddp_sentiment_finetune.py", line 21, in <module>
    import torch
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/__init__.py", line 1504, in <module>
    from . import masked
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/masked/__init__.py", line 3, in <module>
    from ._ops import (
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/masked/_ops.py", line 11, in <module>
    from torch._prims_common import corresponding_real_dtype
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/_prims_common/__init__.py", line 23, in <module>
    import sympy
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/sympy/__init__.py", line 30, in <module>
    from sympy.core.cache import lazy_function
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/sympy/core/__init__.py", line 4, in <module>
    from .sympify import sympify, SympifyError
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/sympy/core/sympify.py", line 10, in <module>
    from sympy.core.random import choice
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/sympy/core/random.py", line 25, in <module>
    from sympy.utilities.iterables import is_sequence
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/sympy/utilities/__init__.py", line 4, in <module>
    from .iterables import (flatten, group, take, subsets,
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1002, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 945, in _find_spec
  File "<frozen importlib._bootstrap_external>", line 1439, in find_spec
  File "<frozen importlib._bootstrap_external>", line 1411, in _get_spec
  File "<frozen importlib._bootstrap_external>", line 1548, in find_spec
  File "<frozen importlib._bootstrap_external>", line 1591, in _fill_cache
KeyboardInterrupt

(nlp) ubuntu@104-171-202-130:~/nlp-test/sentiment$ python ./ddp_sentiment_finetune.py --dataset 'sst_local' --weights_name 'google/electra-base-discriminator' --save_data --save_model --save_pickle --save_preds --save_plots --lr 0.00002 --epochs 29 --pooling 'mean' --dropout_rate 0.3 --num_layers 2 --hidden_dim 1024 --hidden_activation 'swishglu' --batch_size 16 --accumulation_steps 2 --finetune_bert --finetune_layers 12 --l2_strength 0.01 --checkpoint_interval 5 --use_zero --optimizer 'adamw' --scheduler 'cosine_warmup' --scheduler_kwargs '{"T_0":5, "T_mult":1, "eta_min":1e-7}' --decimal 6 --val_percent 0.2 --early_stop 'score' --n_iter_no_change 30 --show_progress --wandb --wandb_project 'Electra Ensemble' --wandb_run 'multi_run_eval_merged' --model_file 'checkpoint_epoch_70_20241021-063236.pth' --interactive --eval_dataset 'merged_local'

Starting DDP PyTorch Training...
Device: cuda, Number of GPUs: 8
Spawning 8 processes...
Rank 6 - Device: cuda:6
Rank 7 - Device: cuda:7
Rank 3 - Device: cuda:3
Rank 4 - Device: cuda:4
Rank 5 - Device: cuda:5
Rank 1 - Device: cuda:1
Rank 2 - Device: cuda:2
Rank 0 - Device: cuda:0
8 process groups initialized with 'nccl' backend on localhost:12355
NCCL Timeout: 1 hr 0 min. NCCL Blocking Wait: Enabled
wandb: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: jbeno (jimbeno). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.3
wandb: Run data is saved locally in /home/ubuntu/nlp-test/sentiment/wandb/run-20241021_072226-62etmiur
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run multi_run_eval_merged
wandb: â­ï¸ View project at https://wandb.ai/jimbeno/Electra%20Ensemble
wandb: ðŸš€ View run at https://wandb.ai/jimbeno/Electra%20Ensemble/runs/62etmiur
Wand run initialized.

Initializing 'google/electra-base-discriminator' tokenizer and model...
Tokenizer and model initialized (1s)

Loading data...
Using different datasets for training and evaluation
Train Data: Stanford Sentiment Treebank (SST) from Local: 'data/sentiment'
Dev Data: Merged DynaSent Round 1, Round 2 and SST from Local: 'data/merged'
Train size: 8544, Dev size: 5421
Train label distribution:
	      Negative: 3310
	       Neutral: 1624
	      Positive: 3610
Dev label distribution:
	      Negative: 1868
	       Neutral: 1669
	      Positive: 1884
Data loaded (359ms)

Processing data...
(Batch size: 16, Pooling: Mean, Fine Tune BERT: True, Chunk size: None)...
Extracting sentences and labels...

Data saved to: saves/data_8_gpu_20241021-072230.npz
X Train shape: [8544], X Dev shape: [5421]
y Train shape: [8544], y Dev shape: [5421]
Data processed (143ms)

Initializing DDP Neural Classifier...
Layers: 2, Hidden Dim: 1024, Hidden Act: SwishGLU, Dropout: 0.3, Optimizer: AdamW, L2 Strength: 0.01, Pooling: MEAN, Accumulation Steps: 2, Max Grad Norm: None
Batch Size: 16, Max Epochs: 29, LR: 2e-05, Early Stop: score, Fine-tune BERT: True, Fine-tune Layers: 12, Freeze BERT: False, Target Score: None, Interactive: True
Loading model from: checkpoints/checkpoint_epoch_70_20241021-063236.pth...
Loaded checkpoint: checkpoints/checkpoint_epoch_70_20241021-063236.pth
Retrieved model state dictionary.
Retrieved optimizer state dictionary.
Classifier initialized (2s)

Fitting DDP Neural Classifier on training data...
Num Workers: 0, Prefetch: None
Building dataset and dataloader...
Score-based early stopping enabled (macro average F1 score against validation set). Validation fraction: 0.2
Training will stop early if the score does not improve by at least 0.00001 for 30 iterations.
Split data into (X:6835, y:6835) Training samples, and (X:1709, y:1709) Validation samples.
Initializing model, graph, optimizer...
BERT's original pooler removed. Using custom pooling type: mean
BERT has 108,891,648 trainable parameters and 0 non-trainable parameters
Number of BERT layers requiring gradients: 12 out of 12
Fine-tuning the last 12 out of 12 BERT layers

Model Architecture Summary:
BERTClassifier(
  (bert): ElectraModel(
    (embeddings): ElectraEmbeddings(
      (word_embeddings): Embedding(30522, 768, padding_idx=0)
      (position_embeddings): Embedding(512, 768)
      (token_type_embeddings): Embedding(2, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): ElectraEncoder(
      (layer): ModuleList(
        (0-11): 12 x ElectraLayer(
          (attention): ElectraAttention(
            (self): ElectraSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): ElectraSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): ElectraIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): ElectraOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
  (custom_pooling): PoolingLayer()
  (classifier): Classifier(
    (layers): Sequential(
      (0): Linear(in_features=768, out_features=1024, bias=True)
      (1): SwishGLU(
        (projection): Linear(in_features=1024, out_features=2048, bias=True)
        (activation): SiLU()
      )
      (2): Dropout(p=0.3, inplace=False)
      (3): Linear(in_features=1024, out_features=1024, bias=True)
      (4): SwishGLU(
        (projection): Linear(in_features=1024, out_features=2048, bias=True)
        (activation): SiLU()
      )
      (5): Dropout(p=0.3, inplace=False)
      (6): Linear(in_features=1024, out_features=3, bias=True)
    )
  )
)

Model Parameters:
  bert.embeddings.word_embeddings: 23,440,896 (trainable)
  bert.embeddings.position_embeddings: 393,216 (trainable)
  bert.embeddings.token_type_embeddings: 1,536 (trainable)
  bert.embeddings.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.0.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.0.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.0.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.0.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.0.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.0.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.0.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.0.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.1.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.1.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.1.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.1.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.1.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.1.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.1.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.1.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.2.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.2.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.2.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.2.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.2.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.2.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.2.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.2.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.3.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.3.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.3.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.3.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.3.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.3.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.3.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.3.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.4.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.4.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.4.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.4.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.4.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.4.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.4.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.4.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.5.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.5.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.5.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.5.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.5.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.5.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.5.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.5.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.6.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.6.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.6.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.6.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.6.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.6.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.6.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.6.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.7.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.7.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.7.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.7.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.7.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.7.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.7.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.7.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.8.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.8.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.8.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.8.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.8.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.8.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.8.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.8.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.9.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.9.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.9.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.9.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.9.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.9.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.9.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.9.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.10.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.10.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.10.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.10.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.10.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.10.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.10.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.10.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.11.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.11.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.11.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.11.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.11.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.11.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.11.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.11.output.LayerNorm: 1,536 (trainable)
  classifier.layers.0: 787,456 (trainable)
  classifier.layers.1.projection: 2,099,200 (trainable)
  classifier.layers.3: 1,049,600 (trainable)
  classifier.layers.6: 3,075 (trainable)

Total layers: 104
Trainable layers: 104
Total parameters: 112,830,979
Trainable parameters: 112,830,979
Percentage of trainable parameters: 100.00%
Using optimizer: AdamW, Use Zero: True, Learning Rate: 2e-05, L2 strength: 0.01
Using scheduler: CosineAnnealingWarmRestarts
Scheduler arguments:
- T_0: 5
- T_mult: 1
- eta_min: 1e-07

Starting training loop...
Start epoch: 71, Max Iterations: 29, Early Stop: score, Tolerance: 0.00001, Number Iterations No Change: 30

[Enter] to continue for 1 epoch, [Q]uit, [S]ave, [H]elp: q
Quitting training...
Saving model in ONNX format...
Model saved in ONNX format to saves/model_20241021-072327.onnx and uploaded to Weights & Biases.
Saved model state: checkpoints/final_model_20241021-072333.pth
Saved model pickle: checkpoints/final_model_20241021-072333.pkl
Training completed (1m 7s)

Evaluating model...

multi_run_eval_merged Multi-Class Classification Report

              precision    recall  f1-score   support

    negative   0.832038  0.745182  0.786219      1868
     neutral   0.700054  0.774715  0.735495      1669
    positive   0.800631  0.807856  0.804227      1884

    accuracy                       0.776056      5421
   macro avg   0.777575  0.775918  0.775314      5421
weighted avg   0.780488  0.776056  0.776861      5421

ROC AUC: 0.907728

Predicted  negative  neutral  positive
Actual                                
negative       1392      309       167
neutral         164     1293       212
positive        117      245      1522

Saved predictions: saves/predictions_20241021-072525.csv

Macro F1 Score: 0.78

Evaluation completed (2m 36s)
wandb:                                                                                
wandb: 
wandb: Run history:
wandb: eval/macro_f1_score â–
wandb: 
wandb: Run summary:
wandb: eval/macro_f1_score 0.77531
wandb: 
wandb: ðŸš€ View run multi_run_eval_merged at: https://wandb.ai/jimbeno/Electra%20Ensemble/runs/62etmiur
wandb: â­ï¸ View project at: https://wandb.ai/jimbeno/Electra%20Ensemble
wandb: Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 3 other file(s)
wandb: Find logs at: ./wandb/run-20241021_072226-62etmiur/logs
TOTAL Time: 4m 6s
(nlp) ubuntu@104-171-202-130:~/nlp-test/sentiment$ logout
Connection to 104.171.202.130 closed.
(base) Jims-MBP:multiclass jim$ ssh ubuntu@104.171.203.140
The authenticity of host '104.171.203.140 (104.171.203.140)' can't be established.
ED25519 key fingerprint is SHA256:2KzUQMBySKxYnT/cIL87pR1nFVBuM8ttsI3fFODAKTQ.
This key is not known by any other names
Are you sure you want to continue connecting (yes/no/[fingerprint])? yes
Warning: Permanently added '104.171.203.140' (ED25519) to the list of known hosts.
Enter passphrase for key '/Users/jim/.ssh/id_rsa': 
Welcome to Ubuntu 22.04.5 LTS (GNU/Linux 6.8.0-47-generic x86_64)
 .============.
 ||   __      ||    _                    _         _
 ||   \_\     ||   | |    __ _ _ __ ___ | |__   __| | __ _
 ||    \_\    ||   | |   / _` | '_ ` _ \| '_ \ / _` |/ _` |
 ||   /_Î»_\   ||   | |__| (_| | | | | | | |_) | (_| | (_| |
 ||  /_/ \_\  ||   |_____\__,_|_| |_| |_|_.__/ \__,_|\__,_|
  .============.                                  GPU CLOUD

ubuntu@104-171-203-140:~$ cd nlp-test/sentiment/
ubuntu@104-171-203-140:~/nlp-test/sentiment$ source nlp/bin/activate
(nlp) ubuntu@104-171-203-140:~/nlp-test/sentiment$ wandb login
wandb: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)
wandb: You can find your API key in your browser here: https://wandb.ai/authorize
wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit: 
wandb: Appending key for api.wandb.ai to your netrc file: /home/ubuntu/.netrc
(nlp) ubuntu@104-171-203-140:~/nlp-test/sentiment$ git pull
Username for 'https://github.com': jim@jimbeno.net
Password for 'https://jim@jimbeno.net@github.com': 
remote: Enumerating objects: 20, done.
remote: Counting objects: 100% (20/20), done.
remote: Compressing objects: 100% (5/5), done.
remote: Total 13 (delta 8), reused 13 (delta 8), pack-reused 0 (from 0)
Unpacking objects: 100% (13/13), 4.25 MiB | 3.58 MiB/s, done.
From https://github.com/jbeno/sentiment
   661360a..a1be65f  main       -> origin/main
Updating 661360a..a1be65f
Fast-forward
 data/merged/test_all.csv                               |   5484 ++++
 data/merged/test_all_binary.csv                        |   5484 ++++
 data/merged/train_all.csv                              | 204196 +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++------------------------------------------------------------
 data/merged/train_all_binary.csv                       | 204196 +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++------------------------------------------------------------
 data/merged/{dev_all.csv => val_all.csv}               |  10844 +++----
 data/merged/{dev_all_binary.csv => val_all_binary.csv} |  10844 +++----
 data_processing.ipynb                                  |   1037 +-
 ddp_sentiment_finetune.py                              |    384 +-
 torch_ddp_finetune_neural_classifier.py                |     63 +-
 9 files changed, 227120 insertions(+), 215412 deletions(-)
 create mode 100644 data/merged/test_all.csv
 create mode 100644 data/merged/test_all_binary.csv
 rename data/merged/{dev_all.csv => val_all.csv} (61%)
 rename data/merged/{dev_all_binary.csv => val_all_binary.csv} (54%)
(nlp) ubuntu@104-171-203-140:~/nlp-test/sentiment$ python ./ddp_sentiment_finetune.py --dataset 'merged_local' --weights_name 'google/electra-large-discriminator' --save_data --save_model --save_pickle --save_preds --lr 0.00001 --epochs 100 --pooling 'mean' --dropout_rate 0.3 --num_layers 2 --hidden_dim 1024 --hidden_activation 'swishglu' --batch_size 16 --accumulation_steps 2 --finetune_bert --finetune_layers 12 --l2_strength 0.01 --checkpoint_interval 5 --use_zero --optimizer 'adamw' --scheduler 'cosine_warmup' --scheduler_kwargs '{"T_0":5, "T_mult":1, "eta_min":1e-7}' --decimal 6 --use_val_split --eval_split 'test' --early_stop 'score' --n_iter_no_change 100 --show_progress --wandb --wandb_project 'Electra Large' --wandb_run 'large_ft_run_1'

Starting DDP PyTorch Training...
Device: cuda, Number of GPUs: 8
Spawning 8 processes...
Rank 4 - Device: cuda:4
Rank 1 - Device: cuda:1
Rank 6 - Device: cuda:6
Rank 3 - Device: cuda:3
Rank 5 - Device: cuda:5
Rank 7 - Device: cuda:7
Rank 2 - Device: cuda:2
Rank 0 - Device: cuda:0
8 process groups initialized with 'nccl' backend on localhost:12355
NCCL Timeout: 1 hr 0 min. NCCL Blocking Wait: Enabled
wandb: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: jbeno (jimbeno). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.3
wandb: Run data is saved locally in /home/ubuntu/nlp-test/sentiment/wandb/run-20241023_055318-r1n3oulk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run large_ft_run_1
wandb: â­ï¸ View project at https://wandb.ai/jimbeno/Electra%20Large
wandb: ðŸš€ View run at https://wandb.ai/jimbeno/Electra%20Large/runs/r1n3oulk
Wand run initialized.

Initializing 'google/electra-large-discriminator' tokenizer and model...
Checking for local files...
Some files not found locally, downloading...
tokenizer_config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48.0/48.0 [00:00<00:00, 129kB/s]
config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 668/668 [00:00<00:00, 1.77MB/s]
vocab.txt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 232k/232k [00:00<00:00, 38.4MB/s]
tokenizer.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 466k/466k [00:00<00:00, 5.16MB/s]
pytorch_model.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.34G/1.34G [00:06<00:00, 210MB/s]
Download complete
All ranks loading tokenizer from local files...
All ranks loading model from local files...
Tokenizer and model initialized (15s)

Loading data...
Using the same dataset for training and evaluation
Splits:
- Train: Using merged_local 'train' split
- Validation: Using merged_local 'validation' split
- Evaluation: Using merged_local 'test' split
Train Data: Merged DynaSent Round 1, Round 2 and SST from Local: 'data/merged'
Validation Data: Merged DynaSent Round 1, Round 2 and SST from Local: 'data/merged'
Evaluation Data: Merged DynaSent Round 1, Round 2 and SST from Local: 'data/merged'
Train size: 102097
Validation size: 5421
Evaluation size: 5421
Train label distribution:
	      Negative: 21910
	       Neutral: 49148
	      Positive: 31039
Validation label distribution:
	      Negative: 1868
	       Neutral: 1669
	      Positive: 1884
Evaluation label distribution:
	      Negative: 1868
	       Neutral: 1669
	      Positive: 1884
Data loaded (556ms)

Processing data...
(Batch size: 16, Pooling: Mean, Fine Tune BERT: True, Chunk size: None)...
Extracting sentences and labels...

Data saved to: saves/data_8_gpu_20241023-055335.npz
X Train shape: [102097], X Validation shape: [5421], X Test shape: [5421]
y Train shape: [102097], y Validation shape: [5421], y Test shape: [5421]
Data processed (730ms)

Initializing DDP Neural Classifier...
Layers: 2, Hidden Dim: 1024, Hidden Act: SwishGLU, Dropout: 0.3, Optimizer: AdamW, L2 Strength: 0.01, Pooling: MEAN, Accumulation Steps: 2, Max Grad Norm: None
Batch Size: 16, Max Epochs: 100, LR: 1e-05, Early Stop: score, Fine-tune BERT: True, Fine-tune Layers: 12, Freeze BERT: False, Target Score: None, Interactive: False
Classifier initialized (17ms)

Fitting DDP Neural Classifier on training data...
Num Workers: 0, Prefetch: None
Score-based early stopping enabled (macro average F1 score against validation set). Validation fraction: 0.1
Training will stop early if the score does not improve by at least 0.00001 for 100 iterations.
Using provided validation set for early stopping.
Building dataset and dataloader...
Initializing model, graph, optimizer...
BERT's original pooler removed. Using custom pooling type: mean
BERT has 151,154,688 trainable parameters and 182,937,600 non-trainable parameters
Number of BERT layers requiring gradients: 12 out of 24
Fine-tuning the last 12 out of 24 BERT layers

Model Architecture Summary:
BERTClassifier(
  (bert): ElectraModel(
    (embeddings): ElectraEmbeddings(
      (word_embeddings): Embedding(30522, 1024, padding_idx=0)
      (position_embeddings): Embedding(512, 1024)
      (token_type_embeddings): Embedding(2, 1024)
      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): ElectraEncoder(
      (layer): ModuleList(
        (0-23): 24 x ElectraLayer(
          (attention): ElectraAttention(
            (self): ElectraSelfAttention(
              (query): Linear(in_features=1024, out_features=1024, bias=True)
              (key): Linear(in_features=1024, out_features=1024, bias=True)
              (value): Linear(in_features=1024, out_features=1024, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): ElectraSelfOutput(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): ElectraIntermediate(
            (dense): Linear(in_features=1024, out_features=4096, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): ElectraOutput(
            (dense): Linear(in_features=4096, out_features=1024, bias=True)
            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
  (custom_pooling): PoolingLayer()
  (classifier): Classifier(
    (layers): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): SwishGLU(
        (projection): Linear(in_features=1024, out_features=2048, bias=True)
        (activation): SiLU()
      )
      (2): Dropout(p=0.3, inplace=False)
      (3): Linear(in_features=1024, out_features=1024, bias=True)
      (4): SwishGLU(
        (projection): Linear(in_features=1024, out_features=2048, bias=True)
        (activation): SiLU()
      )
      (5): Dropout(p=0.3, inplace=False)
      (6): Linear(in_features=1024, out_features=3, bias=True)
    )
  )
)

Model Parameters:
  bert.embeddings.word_embeddings: 31,254,528 (frozen)
  bert.embeddings.position_embeddings: 524,288 (frozen)
  bert.embeddings.token_type_embeddings: 2,048 (frozen)
  bert.embeddings.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.0.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.0.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.0.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.0.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.0.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.0.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.0.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.0.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.1.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.1.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.1.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.1.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.1.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.1.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.1.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.1.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.2.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.2.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.2.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.2.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.2.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.2.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.2.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.2.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.3.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.3.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.3.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.3.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.3.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.3.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.3.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.3.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.4.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.4.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.4.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.4.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.4.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.4.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.4.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.4.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.5.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.5.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.5.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.5.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.5.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.5.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.5.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.5.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.6.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.6.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.6.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.6.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.6.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.6.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.6.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.6.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.7.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.7.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.7.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.7.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.7.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.7.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.7.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.7.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.8.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.8.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.8.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.8.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.8.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.8.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.8.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.8.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.9.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.9.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.9.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.9.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.9.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.9.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.9.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.9.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.10.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.10.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.10.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.10.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.10.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.10.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.10.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.10.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.11.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.11.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.11.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.11.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.11.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.11.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.11.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.11.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.12.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.12.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.12.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.12.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.12.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.12.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.12.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.12.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.13.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.13.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.13.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.13.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.13.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.13.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.13.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.13.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.14.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.14.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.14.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.14.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.14.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.14.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.14.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.14.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.15.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.15.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.15.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.15.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.15.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.15.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.15.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.15.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.16.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.16.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.16.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.16.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.16.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.16.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.16.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.16.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.17.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.17.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.17.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.17.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.17.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.17.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.17.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.17.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.18.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.18.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.18.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.18.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.18.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.18.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.18.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.18.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.19.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.19.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.19.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.19.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.19.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.19.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.19.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.19.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.20.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.20.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.20.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.20.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.20.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.20.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.20.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.20.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.21.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.21.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.21.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.21.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.21.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.21.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.21.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.21.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.22.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.22.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.22.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.22.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.22.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.22.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.22.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.22.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.23.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.23.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.23.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.23.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.23.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.23.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.23.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.23.output.LayerNorm: 2,048 (trainable)
  classifier.layers.0: 1,049,600 (trainable)
  classifier.layers.1.projection: 2,099,200 (trainable)
  classifier.layers.3: 1,049,600 (trainable)
  classifier.layers.6: 3,075 (trainable)

Total layers: 200
Trainable layers: 100
Total parameters: 338,293,763
Trainable parameters: 155,356,163
Percentage of trainable parameters: 45.92%
Using optimizer: AdamW, Use Zero: True, Learning Rate: 1e-05, L2 strength: 0.01
Using scheduler: CosineAnnealingWarmRestarts
Scheduler arguments:
- T_0: 5
- T_mult: 1
- eta_min: 1e-07

Starting training loop...
Start epoch: 1, Max Iterations: 100, Early Stop: score, Tolerance: 0.00001, Number Iterations No Change: 100
Epoch 1/100:   0%|                                                                                                                                               | 0/798 [00:00<?, ?it/s]An error occurred during training: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 7 has a total capacty of 15.77 GiB of which 8.44 MiB is free. Including non-PyTorch memory, this process has 15.75 GiB memory in use. Of the allocated memory 14.82 GiB is allocated by PyTorch, and 57.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
An error occurred during training: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 6 has a total capacty of 15.77 GiB of which 16.44 MiB is free. Including non-PyTorch memory, this process has 15.75 GiB memory in use. Of the allocated memory 14.80 GiB is allocated by PyTorch, and 41.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
An error occurred during training: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 5 has a total capacty of 15.77 GiB of which 448.00 KiB is free. Including non-PyTorch memory, this process has 15.76 GiB memory in use. Of the allocated memory 14.77 GiB is allocated by PyTorch, and 41.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
An error occurred during training: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 3 has a total capacty of 15.77 GiB of which 24.44 MiB is free. Including non-PyTorch memory, this process has 15.74 GiB memory in use. Of the allocated memory 14.82 GiB is allocated by PyTorch, and 57.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
An error occurred during training: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 2 has a total capacty of 15.77 GiB of which 28.44 MiB is free. Including non-PyTorch memory, this process has 15.73 GiB memory in use. Of the allocated memory 14.82 GiB is allocated by PyTorch, and 57.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
An error occurred during training: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 1 has a total capacty of 15.77 GiB of which 28.44 MiB is free. Including non-PyTorch memory, this process has 15.73 GiB memory in use. Of the allocated memory 14.74 GiB is allocated by PyTorch, and 41.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
An error occurred during training: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 4 has a total capacty of 15.77 GiB of which 16.44 MiB is free. Including non-PyTorch memory, this process has 15.75 GiB memory in use. Of the allocated memory 14.77 GiB is allocated by PyTorch, and 41.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
An error occurred during training: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacty of 15.77 GiB of which 24.44 MiB is free. Including non-PyTorch memory, this process has 15.74 GiB memory in use. Of the allocated memory 14.77 GiB is allocated by PyTorch, and 41.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
  File "/home/ubuntu/nlp-test/sentiment/ddp_sentiment_finetune.py", line 1205, in main
    classifier.fit(X_train, X_val, y_train, y_val, rank, world_size, debug, start_epoch, model_state_dict, optimizer_state_dict,
Traceback (most recent call last):
  File "/home/ubuntu/nlp-test/sentiment/torch_ddp_finetune_neural_classifier.py", line 1310, in fit
    outputs = self.model(input_ids, attention_mask=attention_mask)
  File "/home/ubuntu/nlp-test/sentiment/ddp_sentiment_finetune.py", line 1205, in main
    classifier.fit(X_train, X_val, y_train, y_val, rank, world_size, debug, start_epoch, model_state_dict, optimizer_state_dict,
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/torch_ddp_finetune_neural_classifier.py", line 1310, in fit
    outputs = self.model(input_ids, attention_mask=attention_mask)
Traceback (most recent call last):
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1519, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1355, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1519, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1355, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
  File "/home/ubuntu/nlp-test/sentiment/torch_ddp_finetune_neural_classifier.py", line 111, in forward
    bert_outputs = self.bert(input_ids, attention_mask=attention_mask)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/ddp_sentiment_finetune.py", line 1205, in main
    classifier.fit(X_train, X_val, y_train, y_val, rank, world_size, debug, start_epoch, model_state_dict, optimizer_state_dict,
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/torch_ddp_finetune_neural_classifier.py", line 1310, in fit
    outputs = self.model(input_ids, attention_mask=attention_mask)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/torch_ddp_finetune_neural_classifier.py", line 111, in forward
    bert_outputs = self.bert(input_ids, attention_mask=attention_mask)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 913, in forward
    hidden_states = self.encoder(
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1519, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1355, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 913, in forward
    hidden_states = self.encoder(
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 585, in forward
    layer_outputs = layer_module(
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/torch_ddp_finetune_neural_classifier.py", line 111, in forward
    bert_outputs = self.bert(input_ids, attention_mask=attention_mask)
  File "/home/ubuntu/nlp-test/sentiment/ddp_sentiment_finetune.py", line 1205, in main
    classifier.fit(X_train, X_val, y_train, y_val, rank, world_size, debug, start_epoch, model_state_dict, optimizer_state_dict,
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 585, in forward
    layer_outputs = layer_module(
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 474, in forward
    self_attention_outputs = self.attention(
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/torch_ddp_finetune_neural_classifier.py", line 1310, in fit
    outputs = self.model(input_ids, attention_mask=attention_mask)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 401, in forward
    self_outputs = self.self(
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 913, in forward
    hidden_states = self.encoder(
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/ddp_sentiment_finetune.py", line 1205, in main
    classifier.fit(X_train, X_val, y_train, y_val, rank, world_size, debug, start_epoch, model_state_dict, optimizer_state_dict,
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 337, in forward
    context_layer = torch.matmul(attention_probs, value_layer)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1519, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 474, in forward
    self_attention_outputs = self.attention(
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 585, in forward
    layer_outputs = layer_module(
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1355, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 4 has a total capacty of 15.77 GiB of which 16.44 MiB is free. Including non-PyTorch memory, this process has 15.75 GiB memory in use. Of the allocated memory 14.77 GiB is allocated by PyTorch, and 41.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 401, in forward
    self_outputs = self.self(
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 474, in forward
    self_attention_outputs = self.attention(
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/torch_ddp_finetune_neural_classifier.py", line 1310, in fit
    outputs = self.model(input_ids, attention_mask=attention_mask)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/torch_ddp_finetune_neural_classifier.py", line 111, in forward
    bert_outputs = self.bert(input_ids, attention_mask=attention_mask)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 401, in forward
    self_outputs = self.self(
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 339, in forward
    context_layer = context_layer.permute(0, 2, 1, 3).contiguous()
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 337, in forward
    context_layer = torch.matmul(attention_probs, value_layer)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 913, in forward
    hidden_states = self.encoder(
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 6 has a total capacty of 15.77 GiB of which 16.44 MiB is free. Including non-PyTorch memory, this process has 15.75 GiB memory in use. Of the allocated memory 14.80 GiB is allocated by PyTorch, and 41.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 5 has a total capacty of 15.77 GiB of which 448.00 KiB is free. Including non-PyTorch memory, this process has 15.76 GiB memory in use. Of the allocated memory 14.77 GiB is allocated by PyTorch, and 41.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 585, in forward
    layer_outputs = layer_module(
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 474, in forward
    self_attention_outputs = self.attention(
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 401, in forward
    self_outputs = self.self(
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 337, in forward
    context_layer = torch.matmul(attention_probs, value_layer)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 1 has a total capacty of 15.77 GiB of which 28.44 MiB is free. Including non-PyTorch memory, this process has 15.73 GiB memory in use. Of the allocated memory 14.74 GiB is allocated by PyTorch, and 41.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1519, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1355, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/torch_ddp_finetune_neural_classifier.py", line 111, in forward
    bert_outputs = self.bert(input_ids, attention_mask=attention_mask)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 913, in forward
    hidden_states = self.encoder(
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 585, in forward
    layer_outputs = layer_module(
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 474, in forward
    self_attention_outputs = self.attention(
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 401, in forward
    self_outputs = self.self(
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 337, in forward
    context_layer = torch.matmul(attention_probs, value_layer)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacty of 15.77 GiB of which 24.44 MiB is free. Including non-PyTorch memory, this process has 15.74 GiB memory in use. Of the allocated memory 14.77 GiB is allocated by PyTorch, and 41.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
Traceback (most recent call last):
Traceback (most recent call last):
  File "/home/ubuntu/nlp-test/sentiment/ddp_sentiment_finetune.py", line 1205, in main
    classifier.fit(X_train, X_val, y_train, y_val, rank, world_size, debug, start_epoch, model_state_dict, optimizer_state_dict,
  File "/home/ubuntu/nlp-test/sentiment/torch_ddp_finetune_neural_classifier.py", line 1310, in fit
    outputs = self.model(input_ids, attention_mask=attention_mask)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1519, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1355, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/torch_ddp_finetune_neural_classifier.py", line 111, in forward
    bert_outputs = self.bert(input_ids, attention_mask=attention_mask)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/ddp_sentiment_finetune.py", line 1205, in main
    classifier.fit(X_train, X_val, y_train, y_val, rank, world_size, debug, start_epoch, model_state_dict, optimizer_state_dict,
Traceback (most recent call last):
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 913, in forward
    hidden_states = self.encoder(
  File "/home/ubuntu/nlp-test/sentiment/torch_ddp_finetune_neural_classifier.py", line 1310, in fit
    outputs = self.model(input_ids, attention_mask=attention_mask)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 585, in forward
    layer_outputs = layer_module(
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 516, in forward
    layer_output = apply_chunking_to_forward(
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/transformers/pytorch_utils.py", line 236, in apply_chunking_to_forward
    return forward_fn(*input_tensors)
  File "/home/ubuntu/nlp-test/sentiment/ddp_sentiment_finetune.py", line 1205, in main
    classifier.fit(X_train, X_val, y_train, y_val, rank, world_size, debug, start_epoch, model_state_dict, optimizer_state_dict,
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1519, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 529, in feed_forward_chunk
    layer_output = self.output(intermediate_output, attention_output)
  File "/home/ubuntu/nlp-test/sentiment/torch_ddp_finetune_neural_classifier.py", line 1310, in fit
    outputs = self.model(input_ids, attention_mask=attention_mask)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1355, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 441, in forward
    hidden_states = self.dropout(hidden_states)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1519, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/torch_ddp_finetune_neural_classifier.py", line 111, in forward
    bert_outputs = self.bert(input_ids, attention_mask=attention_mask)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1355, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/dropout.py", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/functional.py", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
  File "/home/ubuntu/nlp-test/sentiment/torch_ddp_finetune_neural_classifier.py", line 111, in forward
    bert_outputs = self.bert(input_ids, attention_mask=attention_mask)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 913, in forward
    hidden_states = self.encoder(
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 913, in forward
    hidden_states = self.encoder(
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 3 has a total capacty of 15.77 GiB of which 24.44 MiB is free. Including non-PyTorch memory, this process has 15.74 GiB memory in use. Of the allocated memory 14.82 GiB is allocated by PyTorch, and 57.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 585, in forward
    layer_outputs = layer_module(
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 585, in forward
    layer_outputs = layer_module(
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 516, in forward
    layer_output = apply_chunking_to_forward(
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/transformers/pytorch_utils.py", line 236, in apply_chunking_to_forward
    return forward_fn(*input_tensors)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 516, in forward
    layer_output = apply_chunking_to_forward(
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 529, in feed_forward_chunk
    layer_output = self.output(intermediate_output, attention_output)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/transformers/pytorch_utils.py", line 236, in apply_chunking_to_forward
    return forward_fn(*input_tensors)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 529, in feed_forward_chunk
    layer_output = self.output(intermediate_output, attention_output)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 441, in forward
    hidden_states = self.dropout(hidden_states)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 441, in forward
    hidden_states = self.dropout(hidden_states)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/dropout.py", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/functional.py", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/dropout.py", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/functional.py", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 2 has a total capacty of 15.77 GiB of which 28.44 MiB is free. Including non-PyTorch memory, this process has 15.73 GiB memory in use. Of the allocated memory 14.82 GiB is allocated by PyTorch, and 57.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 7 has a total capacty of 15.77 GiB of which 8.44 MiB is free. Including non-PyTorch memory, this process has 15.75 GiB memory in use. Of the allocated memory 14.82 GiB is allocated by PyTorch, and 57.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
Epoch 1/100:   0%|                                                                                                                                               | 0/798 [00:01<?, ?it/s]
wandb: ðŸš€ View run large_ft_run_1 at: https://wandb.ai/jimbeno/Electra Large/runs/r1n3oulk
wandb: Find logs at: wandb/run-20241023_055318-r1n3oulk/logs
(nlp) ubuntu@104-171-203-140:~/nlp-test/sentiment$ python ./ddp_sentiment_finetune.py --dataset 'merged_local' --weights_name 'google/electra-large-discriminator' --save_data --save_model --save_pickle --save_preds --lr 0.00001 --epochs 100 --pooling 'mean' --dropout_rate 0.3 --num_layers 2 --hidden_dim 1024 --hidden_activation 'swishglu' --batch_size 8 --accumulation_steps 4 --finetune_bert --finetune_layers 12 --l2_strength 0.01 --checkpoint_interval 5 --use_zero --optimizer 'adamw' --scheduler 'cosine_warmup' --scheduler_kwargs '{"T_0":5, "T_mult":1, "eta_min":1e-7}' --decimal 6 --use_val_split --eval_split 'test' --early_stop 'score' --n_iter_no_change 100 --show_progress --wandb --wandb_project 'Electra Large' --wandb_run 'large_ft_run_1'

Starting DDP PyTorch Training...
Device: cuda, Number of GPUs: 8
Spawning 8 processes...
Rank 7 - Device: cuda:7
Rank 1 - Device: cuda:1
Rank 4 - Device: cuda:4
Rank 3 - Device: cuda:3
Rank 5 - Device: cuda:5
Rank 2 - Device: cuda:2
Rank 6 - Device: cuda:6
Rank 0 - Device: cuda:0
8 process groups initialized with 'nccl' backend on localhost:12355
NCCL Timeout: 1 hr 0 min. NCCL Blocking Wait: Enabled
wandb: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: jbeno (jimbeno). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.3
wandb: Run data is saved locally in /home/ubuntu/nlp-test/sentiment/wandb/run-20241023_055507-r7j6p7te
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run large_ft_run_1
wandb: â­ï¸ View project at https://wandb.ai/jimbeno/Electra%20Large
wandb: ðŸš€ View run at https://wandb.ai/jimbeno/Electra%20Large/runs/r7j6p7te
Wand run initialized.

Initializing 'google/electra-large-discriminator' tokenizer and model...
Checking for local files...
Found all files in cache, skipping download
All ranks loading tokenizer from local files...
All ranks loading model from local files...
Tokenizer and model initialized (8s)

Loading data...
Using the same dataset for training and evaluation
Splits:
- Train: Using merged_local 'train' split
- Validation: Using merged_local 'validation' split
- Evaluation: Using merged_local 'test' split
Train Data: Merged DynaSent Round 1, Round 2 and SST from Local: 'data/merged'
Validation Data: Merged DynaSent Round 1, Round 2 and SST from Local: 'data/merged'
Evaluation Data: Merged DynaSent Round 1, Round 2 and SST from Local: 'data/merged'
Train size: 102097
Validation size: 5421
Evaluation size: 5421
Train label distribution:
	      Negative: 21910
	       Neutral: 49148
	      Positive: 31039
Validation label distribution:
	      Negative: 1868
	       Neutral: 1669
	      Positive: 1884
Evaluation label distribution:
	      Negative: 1868
	       Neutral: 1669
	      Positive: 1884
Data loaded (372ms)

Processing data...
(Batch size: 8, Pooling: Mean, Fine Tune BERT: True, Chunk size: None)...
Extracting sentences and labels...

Data saved to: saves/data_8_gpu_20241023-055516.npz
X Train shape: [102097], X Validation shape: [5421], X Test shape: [5421]
y Train shape: [102097], y Validation shape: [5421], y Test shape: [5421]
Data processed (734ms)

Initializing DDP Neural Classifier...
Layers: 2, Hidden Dim: 1024, Hidden Act: SwishGLU, Dropout: 0.3, Optimizer: AdamW, L2 Strength: 0.01, Pooling: MEAN, Accumulation Steps: 4, Max Grad Norm: None
Batch Size: 8, Max Epochs: 100, LR: 1e-05, Early Stop: score, Fine-tune BERT: True, Fine-tune Layers: 12, Freeze BERT: False, Target Score: None, Interactive: False
Classifier initialized (15ms)

Fitting DDP Neural Classifier on training data...
Num Workers: 0, Prefetch: None
Score-based early stopping enabled (macro average F1 score against validation set). Validation fraction: 0.1
Training will stop early if the score does not improve by at least 0.00001 for 100 iterations.
Using provided validation set for early stopping.
Building dataset and dataloader...
Initializing model, graph, optimizer...
BERT's original pooler removed. Using custom pooling type: mean
BERT has 151,154,688 trainable parameters and 182,937,600 non-trainable parameters
Number of BERT layers requiring gradients: 12 out of 24
Fine-tuning the last 12 out of 24 BERT layers

Model Architecture Summary:
BERTClassifier(
  (bert): ElectraModel(
    (embeddings): ElectraEmbeddings(
      (word_embeddings): Embedding(30522, 1024, padding_idx=0)
      (position_embeddings): Embedding(512, 1024)
      (token_type_embeddings): Embedding(2, 1024)
      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): ElectraEncoder(
      (layer): ModuleList(
        (0-23): 24 x ElectraLayer(
          (attention): ElectraAttention(
            (self): ElectraSelfAttention(
              (query): Linear(in_features=1024, out_features=1024, bias=True)
              (key): Linear(in_features=1024, out_features=1024, bias=True)
              (value): Linear(in_features=1024, out_features=1024, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): ElectraSelfOutput(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): ElectraIntermediate(
            (dense): Linear(in_features=1024, out_features=4096, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): ElectraOutput(
            (dense): Linear(in_features=4096, out_features=1024, bias=True)
            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
  (custom_pooling): PoolingLayer()
  (classifier): Classifier(
    (layers): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): SwishGLU(
        (projection): Linear(in_features=1024, out_features=2048, bias=True)
        (activation): SiLU()
      )
      (2): Dropout(p=0.3, inplace=False)
      (3): Linear(in_features=1024, out_features=1024, bias=True)
      (4): SwishGLU(
        (projection): Linear(in_features=1024, out_features=2048, bias=True)
        (activation): SiLU()
      )
      (5): Dropout(p=0.3, inplace=False)
      (6): Linear(in_features=1024, out_features=3, bias=True)
    )
  )
)

Model Parameters:
  bert.embeddings.word_embeddings: 31,254,528 (frozen)
  bert.embeddings.position_embeddings: 524,288 (frozen)
  bert.embeddings.token_type_embeddings: 2,048 (frozen)
  bert.embeddings.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.0.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.0.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.0.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.0.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.0.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.0.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.0.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.0.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.1.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.1.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.1.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.1.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.1.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.1.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.1.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.1.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.2.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.2.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.2.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.2.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.2.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.2.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.2.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.2.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.3.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.3.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.3.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.3.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.3.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.3.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.3.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.3.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.4.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.4.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.4.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.4.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.4.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.4.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.4.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.4.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.5.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.5.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.5.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.5.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.5.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.5.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.5.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.5.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.6.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.6.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.6.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.6.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.6.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.6.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.6.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.6.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.7.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.7.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.7.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.7.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.7.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.7.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.7.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.7.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.8.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.8.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.8.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.8.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.8.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.8.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.8.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.8.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.9.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.9.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.9.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.9.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.9.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.9.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.9.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.9.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.10.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.10.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.10.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.10.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.10.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.10.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.10.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.10.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.11.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.11.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.11.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.11.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.11.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.11.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.11.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.11.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.12.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.12.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.12.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.12.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.12.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.12.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.12.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.12.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.13.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.13.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.13.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.13.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.13.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.13.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.13.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.13.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.14.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.14.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.14.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.14.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.14.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.14.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.14.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.14.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.15.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.15.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.15.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.15.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.15.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.15.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.15.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.15.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.16.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.16.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.16.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.16.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.16.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.16.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.16.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.16.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.17.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.17.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.17.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.17.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.17.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.17.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.17.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.17.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.18.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.18.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.18.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.18.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.18.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.18.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.18.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.18.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.19.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.19.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.19.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.19.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.19.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.19.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.19.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.19.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.20.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.20.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.20.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.20.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.20.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.20.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.20.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.20.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.21.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.21.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.21.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.21.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.21.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.21.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.21.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.21.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.22.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.22.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.22.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.22.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.22.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.22.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.22.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.22.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.23.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.23.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.23.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.23.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.23.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.23.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.23.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.23.output.LayerNorm: 2,048 (trainable)
  classifier.layers.0: 1,049,600 (trainable)
  classifier.layers.1.projection: 2,099,200 (trainable)
  classifier.layers.3: 1,049,600 (trainable)
  classifier.layers.6: 3,075 (trainable)

Total layers: 200
Trainable layers: 100
Total parameters: 338,293,763
Trainable parameters: 155,356,163
Percentage of trainable parameters: 45.92%
Using optimizer: AdamW, Use Zero: True, Learning Rate: 1e-05, L2 strength: 0.01
Using scheduler: CosineAnnealingWarmRestarts
Scheduler arguments:
- T_0: 5
- T_mult: 1
- eta_min: 1e-07

Starting training loop...
Start epoch: 1, Max Iterations: 100, Early Stop: score, Tolerance: 0.00001, Number Iterations No Change: 100
Epoch 1/100:   4%|â–ˆâ–ˆâ–ˆâ–Œ                                                                                       | 63/1596 [00:34<13:34,  1.88it/s, loss=1.0982, lr=1.00e-05, grad=M:0.0018]^C
Ctrl+C received. Terminating all processes...
Rank 0 - Current process: MainProcess cleaning up...
Terminating all child processes of MainProcess...
Terminated child process: SpawnProcess-6
Terminated child process: SpawnProcess-5
Terminated child process: SpawnProcess-1
Terminated child process: SpawnProcess-4
Terminated child process: SpawnProcess-3
Terminated child process: SpawnProcess-8
Terminated child process: SpawnProcess-2
Terminated child process: SpawnProcess-7
Rank 0 - Exiting program...
/usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
(nlp) ubuntu@104-171-203-140:~/nlp-test/sentiment$ python ./ddp_sentiment_finetune.py --dataset 'merged_local' --weights_name 'google/electra-large-discriminator' --save_data --save_model --save_pickle --save_preds --lr 0.00001 --epochs 100 --pooling 'mean' --dropout_rate 0.3 --num_layers 2 --hidden_dim 1024 --hidden_activation 'swishglu' --batch_size 15 --accumulation_steps 2 --finetune_bert --finetune_layers 12 --l2_strength 0.01 --checkpoint_interval 5 --use_zero --optimizer 'adamw' --scheduler 'cosine_warmup' --scheduler_kwargs '{"T_0":5, "T_mult":1, "eta_min":1e-7}' --decimal 6 --use_val_split --eval_split 'test' --early_stop 'score' --n_iter_no_change 100 --show_progress --wandb --wandb_project 'Electra Large' --wandb_run 'large_ft_run_1'

Starting DDP PyTorch Training...
Device: cuda, Number of GPUs: 8
Spawning 8 processes...
Rank 1 - Device: cuda:1
Rank 6 - Device: cuda:6
Rank 7 - Device: cuda:7
Rank 3 - Device: cuda:3
Rank 5 - Device: cuda:5
Rank 4 - Device: cuda:4
Rank 2 - Device: cuda:2
Rank 0 - Device: cuda:0
8 process groups initialized with 'nccl' backend on localhost:12355
NCCL Timeout: 1 hr 0 min. NCCL Blocking Wait: Enabled
wandb: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: jbeno (jimbeno). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.3
wandb: Run data is saved locally in /home/ubuntu/nlp-test/sentiment/wandb/run-20241023_055658-wvahxb8k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run large_ft_run_1
wandb: â­ï¸ View project at https://wandb.ai/jimbeno/Electra%20Large
wandb: ðŸš€ View run at https://wandb.ai/jimbeno/Electra%20Large/runs/wvahxb8k
Wand run initialized.

Initializing 'google/electra-large-discriminator' tokenizer and model...
Checking for local files...
Found all files in cache, skipping download
All ranks loading tokenizer from local files...
All ranks loading model from local files...
Tokenizer and model initialized (8s)

Loading data...
Using the same dataset for training and evaluation
Splits:
- Train: Using merged_local 'train' split
- Validation: Using merged_local 'validation' split
- Evaluation: Using merged_local 'test' split
Train Data: Merged DynaSent Round 1, Round 2 and SST from Local: 'data/merged'
Validation Data: Merged DynaSent Round 1, Round 2 and SST from Local: 'data/merged'
Evaluation Data: Merged DynaSent Round 1, Round 2 and SST from Local: 'data/merged'
Train size: 102097
Validation size: 5421
Evaluation size: 5421
Train label distribution:
	      Negative: 21910
	       Neutral: 49148
	      Positive: 31039
Validation label distribution:
	      Negative: 1868
	       Neutral: 1669
	      Positive: 1884
Evaluation label distribution:
	      Negative: 1868
	       Neutral: 1669
	      Positive: 1884
Data loaded (578ms)

Processing data...
(Batch size: 15, Pooling: Mean, Fine Tune BERT: True, Chunk size: None)...
Extracting sentences and labels...

Data saved to: saves/data_8_gpu_20241023-055708.npz
X Train shape: [102097], X Validation shape: [5421], X Test shape: [5421]
y Train shape: [102097], y Validation shape: [5421], y Test shape: [5421]
Data processed (752ms)

Initializing DDP Neural Classifier...
Layers: 2, Hidden Dim: 1024, Hidden Act: SwishGLU, Dropout: 0.3, Optimizer: AdamW, L2 Strength: 0.01, Pooling: MEAN, Accumulation Steps: 2, Max Grad Norm: None
Batch Size: 15, Max Epochs: 100, LR: 1e-05, Early Stop: score, Fine-tune BERT: True, Fine-tune Layers: 12, Freeze BERT: False, Target Score: None, Interactive: False
Classifier initialized (20ms)

Fitting DDP Neural Classifier on training data...
Num Workers: 0, Prefetch: None
Score-based early stopping enabled (macro average F1 score against validation set). Validation fraction: 0.1
Training will stop early if the score does not improve by at least 0.00001 for 100 iterations.
Using provided validation set for early stopping.
Building dataset and dataloader...
Initializing model, graph, optimizer...
BERT's original pooler removed. Using custom pooling type: mean
BERT has 151,154,688 trainable parameters and 182,937,600 non-trainable parameters
Number of BERT layers requiring gradients: 12 out of 24
Fine-tuning the last 12 out of 24 BERT layers

Model Architecture Summary:
BERTClassifier(
  (bert): ElectraModel(
    (embeddings): ElectraEmbeddings(
      (word_embeddings): Embedding(30522, 1024, padding_idx=0)
      (position_embeddings): Embedding(512, 1024)
      (token_type_embeddings): Embedding(2, 1024)
      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): ElectraEncoder(
      (layer): ModuleList(
        (0-23): 24 x ElectraLayer(
          (attention): ElectraAttention(
            (self): ElectraSelfAttention(
              (query): Linear(in_features=1024, out_features=1024, bias=True)
              (key): Linear(in_features=1024, out_features=1024, bias=True)
              (value): Linear(in_features=1024, out_features=1024, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): ElectraSelfOutput(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): ElectraIntermediate(
            (dense): Linear(in_features=1024, out_features=4096, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): ElectraOutput(
            (dense): Linear(in_features=4096, out_features=1024, bias=True)
            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
  (custom_pooling): PoolingLayer()
  (classifier): Classifier(
    (layers): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): SwishGLU(
        (projection): Linear(in_features=1024, out_features=2048, bias=True)
        (activation): SiLU()
      )
      (2): Dropout(p=0.3, inplace=False)
      (3): Linear(in_features=1024, out_features=1024, bias=True)
      (4): SwishGLU(
        (projection): Linear(in_features=1024, out_features=2048, bias=True)
        (activation): SiLU()
      )
      (5): Dropout(p=0.3, inplace=False)
      (6): Linear(in_features=1024, out_features=3, bias=True)
    )
  )
)

Model Parameters:
  bert.embeddings.word_embeddings: 31,254,528 (frozen)
  bert.embeddings.position_embeddings: 524,288 (frozen)
  bert.embeddings.token_type_embeddings: 2,048 (frozen)
  bert.embeddings.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.0.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.0.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.0.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.0.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.0.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.0.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.0.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.0.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.1.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.1.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.1.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.1.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.1.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.1.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.1.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.1.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.2.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.2.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.2.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.2.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.2.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.2.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.2.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.2.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.3.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.3.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.3.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.3.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.3.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.3.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.3.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.3.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.4.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.4.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.4.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.4.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.4.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.4.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.4.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.4.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.5.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.5.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.5.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.5.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.5.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.5.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.5.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.5.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.6.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.6.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.6.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.6.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.6.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.6.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.6.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.6.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.7.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.7.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.7.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.7.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.7.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.7.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.7.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.7.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.8.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.8.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.8.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.8.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.8.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.8.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.8.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.8.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.9.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.9.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.9.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.9.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.9.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.9.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.9.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.9.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.10.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.10.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.10.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.10.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.10.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.10.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.10.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.10.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.11.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.11.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.11.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.11.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.11.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.11.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.11.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.11.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.12.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.12.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.12.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.12.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.12.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.12.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.12.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.12.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.13.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.13.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.13.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.13.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.13.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.13.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.13.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.13.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.14.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.14.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.14.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.14.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.14.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.14.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.14.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.14.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.15.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.15.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.15.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.15.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.15.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.15.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.15.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.15.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.16.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.16.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.16.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.16.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.16.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.16.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.16.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.16.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.17.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.17.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.17.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.17.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.17.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.17.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.17.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.17.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.18.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.18.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.18.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.18.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.18.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.18.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.18.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.18.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.19.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.19.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.19.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.19.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.19.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.19.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.19.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.19.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.20.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.20.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.20.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.20.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.20.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.20.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.20.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.20.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.21.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.21.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.21.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.21.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.21.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.21.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.21.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.21.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.22.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.22.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.22.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.22.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.22.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.22.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.22.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.22.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.23.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.23.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.23.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.23.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.23.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.23.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.23.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.23.output.LayerNorm: 2,048 (trainable)
  classifier.layers.0: 1,049,600 (trainable)
  classifier.layers.1.projection: 2,099,200 (trainable)
  classifier.layers.3: 1,049,600 (trainable)
  classifier.layers.6: 3,075 (trainable)

Total layers: 200
Trainable layers: 100
Total parameters: 338,293,763
Trainable parameters: 155,356,163
Percentage of trainable parameters: 45.92%
Using optimizer: AdamW, Use Zero: True, Learning Rate: 1e-05, L2 strength: 0.01
Using scheduler: CosineAnnealingWarmRestarts
Scheduler arguments:
- T_0: 5
- T_mult: 1
- eta_min: 1e-07

Starting training loop...
Start epoch: 1, Max Iterations: 100, Early Stop: score, Tolerance: 0.00001, Number Iterations No Change: 100
Epoch 1/100:   0%|â–                                                                                            | 2/851 [00:02<17:45,  1.25s/it, loss=1.0982, lr=1.00e-05, grad=M:0.0008]An error occurred during training: CUDA out of memory. Tried to allocate 240.00 MiB. GPU 7 has a total capacty of 15.77 GiB of which 118.44 MiB is free. Including non-PyTorch memory, this process has 15.65 GiB memory in use. Of the allocated memory 14.45 GiB is allocated by PyTorch, and 319.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
An error occurred during training: CUDA out of memory. Tried to allocate 240.00 MiB. GPU 1 has a total capacty of 15.77 GiB of which 42.44 MiB is free. Including non-PyTorch memory, this process has 15.72 GiB memory in use. Of the allocated memory 14.44 GiB is allocated by PyTorch, and 329.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
An error occurred during training: CUDA out of memory. Tried to allocate 240.00 MiB. GPU 4 has a total capacty of 15.77 GiB of which 62.44 MiB is free. Including non-PyTorch memory, this process has 15.70 GiB memory in use. Of the allocated memory 14.46 GiB is allocated by PyTorch, and 304.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
An error occurred during training: CUDA out of memory. Tried to allocate 240.00 MiB. GPU 3 has a total capacty of 15.77 GiB of which 134.44 MiB is free. Including non-PyTorch memory, this process has 15.63 GiB memory in use. Of the allocated memory 14.43 GiB is allocated by PyTorch, and 336.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
An error occurred during training: CUDA out of memory. Tried to allocate 240.00 MiB. GPU 6 has a total capacty of 15.77 GiB of which 94.44 MiB is free. Including non-PyTorch memory, this process has 15.67 GiB memory in use. Of the allocated memory 14.46 GiB is allocated by PyTorch, and 304.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
An error occurred during training: CUDA out of memory. Tried to allocate 240.00 MiB. GPU 0 has a total capacty of 15.77 GiB of which 70.44 MiB is free. Including non-PyTorch memory, this process has 15.69 GiB memory in use. Of the allocated memory 14.34 GiB is allocated by PyTorch, and 425.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
An error occurred during training: CUDA out of memory. Tried to allocate 240.00 MiB. GPU 5 has a total capacty of 15.77 GiB of which 46.44 MiB is free. Including non-PyTorch memory, this process has 15.72 GiB memory in use. Of the allocated memory 14.46 GiB is allocated by PyTorch, and 304.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
An error occurred during training: CUDA out of memory. Tried to allocate 240.00 MiB. GPU 2 has a total capacty of 15.77 GiB of which 138.44 MiB is free. Including non-PyTorch memory, this process has 15.63 GiB memory in use. Of the allocated memory 14.43 GiB is allocated by PyTorch, and 336.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
Traceback (most recent call last):
Traceback (most recent call last):
  File "/home/ubuntu/nlp-test/sentiment/ddp_sentiment_finetune.py", line 1205, in main
    classifier.fit(X_train, X_val, y_train, y_val, rank, world_size, debug, start_epoch, model_state_dict, optimizer_state_dict,
  File "/home/ubuntu/nlp-test/sentiment/torch_ddp_finetune_neural_classifier.py", line 1310, in fit
    outputs = self.model(input_ids, attention_mask=attention_mask)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/ddp_sentiment_finetune.py", line 1205, in main
    classifier.fit(X_train, X_val, y_train, y_val, rank, world_size, debug, start_epoch, model_state_dict, optimizer_state_dict,
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/torch_ddp_finetune_neural_classifier.py", line 1310, in fit
    outputs = self.model(input_ids, attention_mask=attention_mask)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1519, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1355, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1519, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1355, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
  File "/home/ubuntu/nlp-test/sentiment/torch_ddp_finetune_neural_classifier.py", line 111, in forward
    bert_outputs = self.bert(input_ids, attention_mask=attention_mask)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 913, in forward
    hidden_states = self.encoder(
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 585, in forward
    layer_outputs = layer_module(
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 474, in forward
    self_attention_outputs = self.attention(
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 401, in forward
    self_outputs = self.self(
  File "/home/ubuntu/nlp-test/sentiment/torch_ddp_finetune_neural_classifier.py", line 111, in forward
    bert_outputs = self.bert(input_ids, attention_mask=attention_mask)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 331, in forward
    attention_probs = self.dropout(attention_probs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 913, in forward
    hidden_states = self.encoder(
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 585, in forward
    layer_outputs = layer_module(
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/dropout.py", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)
Traceback (most recent call last):
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/functional.py", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 474, in forward
    self_attention_outputs = self.attention(
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 240.00 MiB. GPU 3 has a total capacty of 15.77 GiB of which 134.44 MiB is free. Including non-PyTorch memory, this process has 15.63 GiB memory in use. Of the allocated memory 14.43 GiB is allocated by PyTorch, and 336.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 401, in forward
    self_outputs = self.self(
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 331, in forward
    attention_probs = self.dropout(attention_probs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/dropout.py", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/functional.py", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 240.00 MiB. GPU 4 has a total capacty of 15.77 GiB of which 62.44 MiB is free. Including non-PyTorch memory, this process has 15.70 GiB memory in use. Of the allocated memory 14.46 GiB is allocated by PyTorch, and 304.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
  File "/home/ubuntu/nlp-test/sentiment/ddp_sentiment_finetune.py", line 1205, in main
    classifier.fit(X_train, X_val, y_train, y_val, rank, world_size, debug, start_epoch, model_state_dict, optimizer_state_dict,
Traceback (most recent call last):
  File "/home/ubuntu/nlp-test/sentiment/ddp_sentiment_finetune.py", line 1205, in main
    classifier.fit(X_train, X_val, y_train, y_val, rank, world_size, debug, start_epoch, model_state_dict, optimizer_state_dict,
  File "/home/ubuntu/nlp-test/sentiment/torch_ddp_finetune_neural_classifier.py", line 1310, in fit
    outputs = self.model(input_ids, attention_mask=attention_mask)
  File "/home/ubuntu/nlp-test/sentiment/torch_ddp_finetune_neural_classifier.py", line 1310, in fit
    outputs = self.model(input_ids, attention_mask=attention_mask)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1519, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1355, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/torch_ddp_finetune_neural_classifier.py", line 111, in forward
    bert_outputs = self.bert(input_ids, attention_mask=attention_mask)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 913, in forward
    hidden_states = self.encoder(
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 585, in forward
    layer_outputs = layer_module(
Traceback (most recent call last):
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 474, in forward
    self_attention_outputs = self.attention(
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 401, in forward
    self_outputs = self.self(
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 331, in forward
    attention_probs = self.dropout(attention_probs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/dropout.py", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/functional.py", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 240.00 MiB. GPU 7 has a total capacty of 15.77 GiB of which 118.44 MiB is free. Including non-PyTorch memory, this process has 15.65 GiB memory in use. Of the allocated memory 14.45 GiB is allocated by PyTorch, and 319.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
  File "/home/ubuntu/nlp-test/sentiment/ddp_sentiment_finetune.py", line 1205, in main
    classifier.fit(X_train, X_val, y_train, y_val, rank, world_size, debug, start_epoch, model_state_dict, optimizer_state_dict,
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1519, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/torch_ddp_finetune_neural_classifier.py", line 1310, in fit
    outputs = self.model(input_ids, attention_mask=attention_mask)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1519, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1355, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/torch_ddp_finetune_neural_classifier.py", line 111, in forward
    bert_outputs = self.bert(input_ids, attention_mask=attention_mask)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 913, in forward
    hidden_states = self.encoder(
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 585, in forward
    layer_outputs = layer_module(
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1355, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 474, in forward
    self_attention_outputs = self.attention(
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 401, in forward
    self_outputs = self.self(
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
Traceback (most recent call last):
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 331, in forward
    attention_probs = self.dropout(attention_probs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/dropout.py", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/functional.py", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
Traceback (most recent call last):
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 240.00 MiB. GPU 6 has a total capacty of 15.77 GiB of which 94.44 MiB is free. Including non-PyTorch memory, this process has 15.67 GiB memory in use. Of the allocated memory 14.46 GiB is allocated by PyTorch, and 304.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/ddp_sentiment_finetune.py", line 1205, in main
    classifier.fit(X_train, X_val, y_train, y_val, rank, world_size, debug, start_epoch, model_state_dict, optimizer_state_dict,
  File "/home/ubuntu/nlp-test/sentiment/torch_ddp_finetune_neural_classifier.py", line 1310, in fit
    outputs = self.model(input_ids, attention_mask=attention_mask)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1519, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1355, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/torch_ddp_finetune_neural_classifier.py", line 111, in forward
    bert_outputs = self.bert(input_ids, attention_mask=attention_mask)
  File "/home/ubuntu/nlp-test/sentiment/torch_ddp_finetune_neural_classifier.py", line 111, in forward
    bert_outputs = self.bert(input_ids, attention_mask=attention_mask)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/ddp_sentiment_finetune.py", line 1205, in main
    classifier.fit(X_train, X_val, y_train, y_val, rank, world_size, debug, start_epoch, model_state_dict, optimizer_state_dict,
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/torch_ddp_finetune_neural_classifier.py", line 1310, in fit
    outputs = self.model(input_ids, attention_mask=attention_mask)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 913, in forward
    hidden_states = self.encoder(
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1519, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 585, in forward
    layer_outputs = layer_module(
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1355, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/torch_ddp_finetune_neural_classifier.py", line 111, in forward
    bert_outputs = self.bert(input_ids, attention_mask=attention_mask)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 913, in forward
    hidden_states = self.encoder(
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 474, in forward
    self_attention_outputs = self.attention(
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 585, in forward
    layer_outputs = layer_module(
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 401, in forward
    self_outputs = self.self(
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 474, in forward
    self_attention_outputs = self.attention(
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 331, in forward
    attention_probs = self.dropout(attention_probs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 401, in forward
    self_outputs = self.self(
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/dropout.py", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/functional.py", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 331, in forward
    attention_probs = self.dropout(attention_probs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/dropout.py", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/functional.py", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 240.00 MiB. GPU 5 has a total capacty of 15.77 GiB of which 46.44 MiB is free. Including non-PyTorch memory, this process has 15.72 GiB memory in use. Of the allocated memory 14.46 GiB is allocated by PyTorch, and 304.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 240.00 MiB. GPU 1 has a total capacty of 15.77 GiB of which 42.44 MiB is free. Including non-PyTorch memory, this process has 15.72 GiB memory in use. Of the allocated memory 14.44 GiB is allocated by PyTorch, and 329.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 913, in forward
    hidden_states = self.encoder(
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 585, in forward
    layer_outputs = layer_module(
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 474, in forward
    self_attention_outputs = self.attention(
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 401, in forward
    self_outputs = self.self(
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 331, in forward
    attention_probs = self.dropout(attention_probs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/dropout.py", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/functional.py", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 240.00 MiB. GPU 0 has a total capacty of 15.77 GiB of which 70.44 MiB is free. Including non-PyTorch memory, this process has 15.69 GiB memory in use. Of the allocated memory 14.34 GiB is allocated by PyTorch, and 425.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
Traceback (most recent call last):
  File "/home/ubuntu/nlp-test/sentiment/ddp_sentiment_finetune.py", line 1205, in main
    classifier.fit(X_train, X_val, y_train, y_val, rank, world_size, debug, start_epoch, model_state_dict, optimizer_state_dict,
  File "/home/ubuntu/nlp-test/sentiment/torch_ddp_finetune_neural_classifier.py", line 1310, in fit
    outputs = self.model(input_ids, attention_mask=attention_mask)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1519, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1355, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/torch_ddp_finetune_neural_classifier.py", line 111, in forward
    bert_outputs = self.bert(input_ids, attention_mask=attention_mask)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 913, in forward
    hidden_states = self.encoder(
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 585, in forward
    layer_outputs = layer_module(
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 474, in forward
    self_attention_outputs = self.attention(
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 401, in forward
    self_outputs = self.self(
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 331, in forward
    attention_probs = self.dropout(attention_probs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/dropout.py", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/torch/nn/functional.py", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 240.00 MiB. GPU 2 has a total capacty of 15.77 GiB of which 138.44 MiB is free. Including non-PyTorch memory, this process has 15.63 GiB memory in use. Of the allocated memory 14.43 GiB is allocated by PyTorch, and 336.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
Epoch 1/100:   0%|â–                                                                                            | 2/851 [00:02<19:21,  1.37s/it, loss=1.0982, lr=1.00e-05, grad=M:0.0008]
wandb: ðŸš€ View run large_ft_run_1 at: https://wandb.ai/jimbeno/Electra Large/runs/wvahxb8k
wandb: Find logs at: wandb/run-20241023_055658-wvahxb8k/logs
(nlp) ubuntu@104-171-203-140:~/nlp-test/sentiment$ logout
Connection to 104.171.203.140 closed.
(base) Jims-MBP:multiclass jim$ ssh ubuntu@192.18.129.105
The authenticity of host '192.18.129.105 (192.18.129.105)' can't be established.
ED25519 key fingerprint is SHA256:oOznp9HMfom6YEO2DCEtWbk3MOK5v+QPiIrvDH3rzPo.
This key is not known by any other names
Are you sure you want to continue connecting (yes/no/[fingerprint])? yes
Warning: Permanently added '192.18.129.105' (ED25519) to the list of known hosts.
Enter passphrase for key '/Users/jim/.ssh/id_rsa': 
Welcome to Ubuntu 22.04.5 LTS (GNU/Linux 6.8.0-47-generic x86_64)
 .============.
 ||   __      ||    _                    _         _
 ||   \_\     ||   | |    __ _ _ __ ___ | |__   __| | __ _
 ||    \_\    ||   | |   / _` | '_ ` _ \| '_ \ / _` |/ _` |
 ||   /_Î»_\   ||   | |__| (_| | | | | | | |_) | (_| | (_| |
 ||  /_/ \_\  ||   |_____\__,_|_| |_| |_|_.__/ \__,_|\__,_|
  .============.                                  GPU CLOUD

ubuntu@192-18-129-105:~$ ls
nlp-ca
ubuntu@192-18-129-105:~$ cd nlp-ca/
ubuntu@192-18-129-105:~/nlp-ca$ git clone https://github.com/jbeno/sentiment.git
Cloning into 'sentiment'...
Username for 'https://github.com': jim@jimbeno.net
Password for 'https://jim@jimbeno.net@github.com': 
remote: Enumerating objects: 216, done.
remote: Counting objects: 100% (216/216), done.
remote: Compressing objects: 100% (127/127), done.
remote: Total 216 (delta 132), reused 168 (delta 85), pack-reused 0 (from 0)
Receiving objects: 100% (216/216), 19.23 MiB | 14.07 MiB/s, done.
Resolving deltas: 100% (132/132), done.
Updating files: 100% (38/38), done.
ubuntu@192-18-129-105:~/nlp-ca$ cd sentiment/
ubuntu@192-18-129-105:~/nlp-ca/sentiment$ ls
README.md   data                   ddp_sentiment.py           dspy_sentiment_final.ipynb  test.ipynb                               torch_ddp_neural_classifier.py      utils.py
colors.py   data_processing.ipynb  ddp_sentiment_finetune.py  requirements.txt            test_input.py                            torch_model_base.py
compare.py  datawaza_funcs.py      dspy_sentiment.ipynb       sst.py                      torch_ddp_finetune_neural_classifier.py  torch_shallow_neural_classifier.py
ubuntu@192-18-129-105:~/nlp-ca/sentiment$ python -m venv nlp
ubuntu@192-18-129-105:~/nlp-ca/sentiment$ ls
README.md   data                   ddp_sentiment.py           dspy_sentiment_final.ipynb  sst.py         torch_ddp_finetune_neural_classifier.py  torch_shallow_neural_classifier.py
colors.py   data_processing.ipynb  ddp_sentiment_finetune.py  nlp                         test.ipynb     torch_ddp_neural_classifier.py           utils.py
compare.py  datawaza_funcs.py      dspy_sentiment.ipynb       requirements.txt            test_input.py  torch_model_base.py
ubuntu@192-18-129-105:~/nlp-ca/sentiment$ source nlp/bin/activate
(nlp) ubuntu@192-18-129-105:~/nlp-ca/sentiment$ more requirements.txt 
numpy>=1.20.0
scipy>=1.7.0
matplotlib>=3.7.0
scikit-learn>=1.0.2
nltk>=3.7
pytest>=7.1
jupyter>=1.0.0
pandas>=1.5
# uncomment the following line to install pytorch and torchvision
torch>=2.2.0; sys_platform != "linux" and sys_platform != "win32"
torch>=2.2.0+${DEVICE}; sys_platform == "linux" or sys_platform == "win32"
torchvision==0.16.2
torchaudio==2.1.2
transformers>=4.38.0
datasets==2.14.6
spacy==3.7.2
dspy-ai==2.3.1
# dependencies for dspy-ai
openai<=0.28.1
python-dotenv
wget
(nlp) ubuntu@192-18-129-105:~/nlp-ca/sentiment$ pip install -r requirements.txt
Ignoring torch: markers 'sys_platform != "linux" and sys_platform != "win32"' don't match your environment
Collecting numpy>=1.20.0
  Downloading numpy-2.1.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.3 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 16.3/16.3 MB 82.0 MB/s eta 0:00:00
Collecting scipy>=1.7.0
  Downloading scipy-1.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (41.2 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 41.2/41.2 MB 46.6 MB/s eta 0:00:00
Collecting matplotlib>=3.7.0
  Downloading matplotlib-3.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 8.3/8.3 MB 90.9 MB/s eta 0:00:00
Collecting scikit-learn>=1.0.2
  Downloading scikit_learn-1.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 13.3/13.3 MB 95.6 MB/s eta 0:00:00
Collecting nltk>=3.7
  Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1.5/1.5 MB 100.6 MB/s eta 0:00:00
Collecting pytest>=7.1
  Downloading pytest-8.3.3-py3-none-any.whl (342 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 342.3/342.3 KB 74.0 MB/s eta 0:00:00
Collecting jupyter>=1.0.0
  Using cached jupyter-1.1.1-py2.py3-none-any.whl (2.7 kB)
Collecting pandas>=1.5
  Downloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 13.1/13.1 MB 102.1 MB/s eta 0:00:00
Collecting torch>=2.2.0+${DEVICE}
  Downloading torch-2.5.0-cp310-cp310-manylinux1_x86_64.whl (906.4 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 906.4/906.4 MB 2.9 MB/s eta 0:00:00
Collecting torchvision==0.16.2
  Downloading torchvision-0.16.2-cp310-cp310-manylinux1_x86_64.whl (6.8 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 6.8/6.8 MB 110.8 MB/s eta 0:00:00
Collecting torchaudio==2.1.2
  Downloading torchaudio-2.1.2-cp310-cp310-manylinux1_x86_64.whl (3.3 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 3.3/3.3 MB 120.6 MB/s eta 0:00:00
Collecting transformers>=4.38.0
  Downloading transformers-4.45.2-py3-none-any.whl (9.9 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 9.9/9.9 MB 117.6 MB/s eta 0:00:00
Collecting datasets==2.14.6
  Downloading datasets-2.14.6-py3-none-any.whl (493 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 493.7/493.7 KB 79.7 MB/s eta 0:00:00
Collecting spacy==3.7.2
  Downloading spacy-3.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.6 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 6.6/6.6 MB 82.0 MB/s eta 0:00:00
Collecting dspy-ai==2.3.1
  Downloading dspy_ai-2.3.1-py3-none-any.whl (164 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 164.8/164.8 KB 46.4 MB/s eta 0:00:00
Collecting openai<=0.28.1
  Downloading openai-0.28.1-py3-none-any.whl (76 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 77.0/77.0 KB 24.1 MB/s eta 0:00:00
Collecting python-dotenv
  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)
Collecting wget
  Downloading wget-3.2.zip (10 kB)
  Preparing metadata (setup.py) ... done
Collecting pillow!=8.3.*,>=5.3.0
  Downloading pillow-11.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.4 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 4.4/4.4 MB 117.1 MB/s eta 0:00:00
Collecting requests
  Using cached requests-2.32.3-py3-none-any.whl (64 kB)
ERROR: Cannot install -r requirements.txt (line 12) and torch>=2.2.0+${DEVICE} because these package versions have conflicting dependencies.

The conflict is caused by:
    The user requested torch>=2.2.0+${DEVICE}
    torchvision 0.16.2 depends on torch==2.1.2

To fix this you could try to:
1. loosen the range of package versions you've specified
2. remove package versions to allow pip attempt to solve the dependency conflict

ERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts
(nlp) ubuntu@192-18-129-105:~/nlp-ca/sentiment$ pip list
Package    Version
---------- -------
pip        22.0.2
setuptools 59.6.0
(nlp) ubuntu@192-18-129-105:~/nlp-ca/sentiment$ ls
README.md   data                   ddp_sentiment.py           dspy_sentiment_final.ipynb  sst.py         torch_ddp_finetune_neural_classifier.py  torch_shallow_neural_classifier.py
colors.py   data_processing.ipynb  ddp_sentiment_finetune.py  nlp                         test.ipynb     torch_ddp_neural_classifier.py           utils.py
compare.py  datawaza_funcs.py      dspy_sentiment.ipynb       requirements.txt            test_input.py  torch_model_base.py
(nlp) ubuntu@192-18-129-105:~/nlp-ca/sentiment$ vi requirements.txt 
(nlp) ubuntu@192-18-129-105:~/nlp-ca/sentiment$ vi requirements.txt 
(nlp) ubuntu@192-18-129-105:~/nlp-ca/sentiment$ pip uninstall torch torchvision torchaudio -y
WARNING: Skipping torch as it is not installed.
WARNING: Skipping torchvision as it is not installed.
WARNING: Skipping torchaudio as it is not installed.
(nlp) ubuntu@192-18-129-105:~/nlp-ca/sentiment$ pip install -r requirements.txt
Collecting numpy>=1.20.0
  Using cached numpy-2.1.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.3 MB)
Collecting scipy>=1.7.0
  Using cached scipy-1.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (41.2 MB)
Collecting matplotlib>=3.7.0
  Using cached matplotlib-3.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)
Collecting scikit-learn>=1.0.2
  Using cached scikit_learn-1.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)
Collecting nltk>=3.7
  Using cached nltk-3.9.1-py3-none-any.whl (1.5 MB)
Collecting pytest>=7.1
  Using cached pytest-8.3.3-py3-none-any.whl (342 kB)
Collecting jupyter>=1.0.0
  Using cached jupyter-1.1.1-py2.py3-none-any.whl (2.7 kB)
Collecting pandas>=1.5
  Using cached pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)
Collecting torch==2.1.2
  Downloading torch-2.1.2-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 670.2/670.2 MB 3.9 MB/s eta 0:00:00
Collecting torchvision==0.16.2
  Using cached torchvision-0.16.2-cp310-cp310-manylinux1_x86_64.whl (6.8 MB)
Collecting torchaudio==2.1.2
  Using cached torchaudio-2.1.2-cp310-cp310-manylinux1_x86_64.whl (3.3 MB)
Collecting transformers>=4.38.0
  Using cached transformers-4.45.2-py3-none-any.whl (9.9 MB)
Collecting datasets==2.14.6
  Using cached datasets-2.14.6-py3-none-any.whl (493 kB)
Collecting spacy==3.7.2
  Using cached spacy-3.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.6 MB)
Collecting dspy-ai==2.3.1
  Using cached dspy_ai-2.3.1-py3-none-any.whl (164 kB)
Collecting openai<=0.28.1
  Using cached openai-0.28.1-py3-none-any.whl (76 kB)
Collecting python-dotenv
  Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)
Collecting wget
  Using cached wget-3.2.zip (10 kB)
  Preparing metadata (setup.py) ... done
Collecting jinja2
  Using cached jinja2-3.1.4-py3-none-any.whl (133 kB)
Collecting nvidia-curand-cu12==10.3.2.106
  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 56.5/56.5 MB 35.7 MB/s eta 0:00:00
Collecting triton==2.1.0
  Downloading triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 89.2/89.2 MB 24.7 MB/s eta 0:00:00
Collecting nvidia-cuda-nvrtc-cu12==12.1.105
  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 23.7/23.7 MB 62.0 MB/s eta 0:00:00
Collecting nvidia-cusparse-cu12==12.1.0.106
  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 196.0/196.0 MB 12.6 MB/s eta 0:00:00
Collecting nvidia-cusolver-cu12==11.4.5.107
  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 124.2/124.2 MB 19.1 MB/s eta 0:00:00
Collecting nvidia-cublas-cu12==12.1.3.1
  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 410.6/410.6 MB 6.4 MB/s eta 0:00:00
Collecting filelock
  Downloading filelock-3.16.1-py3-none-any.whl (16 kB)
Collecting fsspec
  Downloading fsspec-2024.10.0-py3-none-any.whl (179 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 179.6/179.6 KB 40.1 MB/s eta 0:00:00
Collecting nvidia-cudnn-cu12==8.9.2.26
  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 731.7/731.7 MB 3.7 MB/s eta 0:00:00
Collecting nvidia-cufft-cu12==11.0.2.54
  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 121.6/121.6 MB 18.7 MB/s eta 0:00:00
Collecting nvidia-nccl-cu12==2.18.1
  Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 209.8/209.8 MB 11.9 MB/s eta 0:00:00
Collecting sympy
  Downloading sympy-1.13.3-py3-none-any.whl (6.2 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 6.2/6.2 MB 52.5 MB/s eta 0:00:00
Collecting nvidia-cuda-cupti-cu12==12.1.105
  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 14.1/14.1 MB 85.8 MB/s eta 0:00:00
Collecting nvidia-nvtx-cu12==12.1.105
  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 99.1/99.1 KB 25.8 MB/s eta 0:00:00
Collecting networkx
  Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1.7/1.7 MB 95.9 MB/s eta 0:00:00
Collecting typing-extensions
  Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)
Collecting nvidia-cuda-runtime-cu12==12.1.105
  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 823.6/823.6 KB 85.6 MB/s eta 0:00:00
Collecting requests
  Using cached requests-2.32.3-py3-none-any.whl (64 kB)
Collecting pillow!=8.3.*,>=5.3.0
  Using cached pillow-11.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.4 MB)
Collecting fsspec[http]<=2023.10.0,>=2023.1.0
  Downloading fsspec-2023.10.0-py3-none-any.whl (166 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 166.4/166.4 KB 35.3 MB/s eta 0:00:00
Collecting packaging
  Using cached packaging-24.1-py3-none-any.whl (53 kB)
Collecting xxhash
  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 194.1/194.1 KB 44.7 MB/s eta 0:00:00
Collecting huggingface-hub<1.0.0,>=0.14.0
  Downloading huggingface_hub-0.26.1-py3-none-any.whl (447 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 447.4/447.4 KB 72.1 MB/s eta 0:00:00
Collecting pyarrow>=8.0.0
  Downloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (39.9 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 39.9/39.9 MB 44.7 MB/s eta 0:00:00
Collecting tqdm>=4.62.1
  Downloading tqdm-4.66.5-py3-none-any.whl (78 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 78.4/78.4 KB 19.2 MB/s eta 0:00:00
Collecting multiprocess
  Downloading multiprocess-0.70.17-py310-none-any.whl (134 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 134.8/134.8 KB 31.5 MB/s eta 0:00:00
Collecting aiohttp
  Downloading aiohttp-3.10.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1.2/1.2 MB 91.8 MB/s eta 0:00:00
Collecting pyyaml>=5.1
  Using cached PyYAML-6.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (751 kB)
Collecting dill<0.3.8,>=0.3.0
  Downloading dill-0.3.7-py3-none-any.whl (115 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 115.3/115.3 KB 32.3 MB/s eta 0:00:00
Collecting spacy-legacy<3.1.0,>=3.0.11
  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)
Collecting cymem<2.1.0,>=2.0.2
  Downloading cymem-2.0.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (46 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 46.1/46.1 KB 12.9 MB/s eta 0:00:00
Collecting pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4
  Downloading pydantic-2.9.2-py3-none-any.whl (434 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 434.9/434.9 KB 70.0 MB/s eta 0:00:00
Collecting srsly<3.0.0,>=2.4.3
  Downloading srsly-2.4.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (493 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 493.0/493.0 KB 75.7 MB/s eta 0:00:00
Collecting smart-open<7.0.0,>=5.2.1
  Downloading smart_open-6.4.0-py3-none-any.whl (57 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 57.0/57.0 KB 15.4 MB/s eta 0:00:00
Requirement already satisfied: setuptools in ./nlp/lib/python3.10/site-packages (from spacy==3.7.2->-r requirements.txt (line 17)) (59.6.0)
Collecting murmurhash<1.1.0,>=0.28.0
  Downloading murmurhash-1.0.10-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29 kB)
Collecting thinc<8.3.0,>=8.1.8
  Downloading thinc-8.2.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (922 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 922.4/922.4 KB 85.1 MB/s eta 0:00:00
Collecting preshed<3.1.0,>=3.0.2
  Downloading preshed-3.0.9-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (156 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 156.9/156.9 KB 37.9 MB/s eta 0:00:00
Collecting catalogue<2.1.0,>=2.0.6
  Downloading catalogue-2.0.10-py3-none-any.whl (17 kB)
Collecting spacy-loggers<2.0.0,>=1.0.0
  Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)
Collecting langcodes<4.0.0,>=3.2.0
  Downloading langcodes-3.4.1-py3-none-any.whl (182 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 182.4/182.4 KB 42.3 MB/s eta 0:00:00
Collecting typer<0.10.0,>=0.3.0
  Downloading typer-0.9.4-py3-none-any.whl (45 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 46.0/46.0 KB 14.1 MB/s eta 0:00:00
Collecting weasel<0.4.0,>=0.1.0
  Downloading weasel-0.3.4-py3-none-any.whl (50 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 50.1/50.1 KB 16.1 MB/s eta 0:00:00
Collecting wasabi<1.2.0,>=0.9.1
  Downloading wasabi-1.1.3-py3-none-any.whl (27 kB)
Collecting optuna
  Downloading optuna-4.0.0-py3-none-any.whl (362 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 362.8/362.8 KB 67.0 MB/s eta 0:00:00
Collecting joblib~=1.3.2
  Downloading joblib-1.3.2-py3-none-any.whl (302 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 302.2/302.2 KB 62.4 MB/s eta 0:00:00
Collecting regex
  Downloading regex-2024.9.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (782 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 782.7/782.7 KB 72.0 MB/s eta 0:00:00
Collecting ujson
  Downloading ujson-5.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 53.6/53.6 KB 15.0 MB/s eta 0:00:00
Collecting backoff~=2.2.1
  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)
Collecting nvidia-nvjitlink-cu12
  Downloading nvidia_nvjitlink_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (19.7 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 19.7/19.7 MB 82.3 MB/s eta 0:00:00
Collecting kiwisolver>=1.3.1
  Downloading kiwisolver-1.4.7-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1.6/1.6 MB 99.2 MB/s eta 0:00:00
Collecting contourpy>=1.0.1
  Downloading contourpy-1.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (322 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 322.0/322.0 KB 62.2 MB/s eta 0:00:00
Collecting cycler>=0.10
  Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)
Collecting fonttools>=4.22.0
  Downloading fonttools-4.54.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 4.6/4.6 MB 106.8 MB/s eta 0:00:00
Collecting pyparsing>=2.3.1
  Downloading pyparsing-3.2.0-py3-none-any.whl (106 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 106.9/106.9 KB 27.9 MB/s eta 0:00:00
Collecting python-dateutil>=2.7
  Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)
Collecting threadpoolctl>=3.1.0
  Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)
Collecting click
  Downloading click-8.1.7-py3-none-any.whl (97 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 97.9/97.9 KB 26.0 MB/s eta 0:00:00
Collecting iniconfig
  Downloading iniconfig-2.0.0-py3-none-any.whl (5.9 kB)
Collecting tomli>=1
  Using cached tomli-2.0.2-py3-none-any.whl (13 kB)
Collecting pluggy<2,>=1.5
  Downloading pluggy-1.5.0-py3-none-any.whl (20 kB)
Collecting exceptiongroup>=1.0.0rc8
  Using cached exceptiongroup-1.2.2-py3-none-any.whl (16 kB)
Collecting jupyter-console
  Using cached jupyter_console-6.6.3-py3-none-any.whl (24 kB)
Collecting jupyterlab
  Using cached jupyterlab-4.2.5-py3-none-any.whl (11.6 MB)
Collecting ipywidgets
  Using cached ipywidgets-8.1.5-py3-none-any.whl (139 kB)
Collecting nbconvert
  Using cached nbconvert-7.16.4-py3-none-any.whl (257 kB)
Collecting notebook
  Using cached notebook-7.2.2-py3-none-any.whl (5.0 MB)
Collecting ipykernel
  Using cached ipykernel-6.29.5-py3-none-any.whl (117 kB)
Collecting tzdata>=2022.7
  Downloading tzdata-2024.2-py2.py3-none-any.whl (346 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 346.6/346.6 KB 62.0 MB/s eta 0:00:00
Collecting pytz>=2020.1
  Downloading pytz-2024.2-py2.py3-none-any.whl (508 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 508.0/508.0 KB 62.6 MB/s eta 0:00:00
Collecting tokenizers<0.21,>=0.20
  Downloading tokenizers-0.20.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 3.0/3.0 MB 109.6 MB/s eta 0:00:00
Collecting safetensors>=0.4.1
  Downloading safetensors-0.4.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (435 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 435.0/435.0 KB 65.1 MB/s eta 0:00:00
Collecting aiosignal>=1.1.2
  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)
Collecting async-timeout<5.0,>=4.0
  Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)
Collecting multidict<7.0,>=4.5
  Downloading multidict-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 124.6/124.6 KB 1.2 MB/s eta 0:00:00
Collecting attrs>=17.3.0
  Using cached attrs-24.2.0-py3-none-any.whl (63 kB)
Collecting yarl<2.0,>=1.12.0
  Downloading yarl-1.16.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 318.1/318.1 KB 56.3 MB/s eta 0:00:00
Collecting aiohappyeyeballs>=2.3.0
  Downloading aiohappyeyeballs-2.4.3-py3-none-any.whl (14 kB)
Collecting frozenlist>=1.1.1
  Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (239 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 239.5/239.5 KB 51.6 MB/s eta 0:00:00
Collecting language-data>=1.2
  Downloading language_data-1.2.0-py3-none-any.whl (5.4 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 5.4/5.4 MB 111.5 MB/s eta 0:00:00
Collecting pydantic-core==2.23.4
  Downloading pydantic_core-2.23.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2.1/2.1 MB 99.8 MB/s eta 0:00:00
Collecting annotated-types>=0.6.0
  Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)
Collecting six>=1.5
  Using cached six-1.16.0-py2.py3-none-any.whl (11 kB)
Collecting idna<4,>=2.5
  Using cached idna-3.10-py3-none-any.whl (70 kB)
Collecting certifi>=2017.4.17
  Using cached certifi-2024.8.30-py3-none-any.whl (167 kB)
Collecting charset-normalizer<4,>=2
  Using cached charset_normalizer-3.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)
Collecting urllib3<3,>=1.21.1
  Using cached urllib3-2.2.3-py3-none-any.whl (126 kB)
Collecting confection<1.0.0,>=0.0.1
  Downloading confection-0.1.5-py3-none-any.whl (35 kB)
Collecting blis<0.8.0,>=0.7.8
  Downloading blis-0.7.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.2 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 10.2/10.2 MB 110.6 MB/s eta 0:00:00
Collecting numpy>=1.20.0
  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 18.2/18.2 MB 85.1 MB/s eta 0:00:00
Collecting cloudpathlib<0.17.0,>=0.7.0
  Downloading cloudpathlib-0.16.0-py3-none-any.whl (45 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 45.0/45.0 KB 12.4 MB/s eta 0:00:00
Collecting traitlets>=5.4.0
  Using cached traitlets-5.14.3-py3-none-any.whl (85 kB)
Collecting psutil
  Downloading psutil-6.1.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (287 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 287.3/287.3 KB 57.7 MB/s eta 0:00:00
Collecting pyzmq>=24
  Using cached pyzmq-26.2.0-cp310-cp310-manylinux_2_28_x86_64.whl (868 kB)
Collecting jupyter-core!=5.0.*,>=4.12
  Using cached jupyter_core-5.7.2-py3-none-any.whl (28 kB)
Collecting tornado>=6.1
  Using cached tornado-6.4.1-cp38-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (436 kB)
Collecting comm>=0.1.1
  Using cached comm-0.2.2-py3-none-any.whl (7.2 kB)
Collecting matplotlib-inline>=0.1
  Using cached matplotlib_inline-0.1.7-py3-none-any.whl (9.9 kB)
Collecting nest-asyncio
  Using cached nest_asyncio-1.6.0-py3-none-any.whl (5.2 kB)
Collecting debugpy>=1.6.5
  Using cached debugpy-1.8.7-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.5 MB)
Collecting jupyter-client>=6.1.12
  Using cached jupyter_client-8.6.3-py3-none-any.whl (106 kB)
Collecting ipython>=7.23.1
  Using cached ipython-8.28.0-py3-none-any.whl (819 kB)
Collecting jupyterlab-widgets~=3.0.12
  Using cached jupyterlab_widgets-3.0.13-py3-none-any.whl (214 kB)
Collecting widgetsnbextension~=4.0.12
  Using cached widgetsnbextension-4.0.13-py3-none-any.whl (2.3 MB)
Collecting MarkupSafe>=2.0
  Downloading MarkupSafe-3.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20 kB)
Collecting prompt-toolkit>=3.0.30
  Using cached prompt_toolkit-3.0.48-py3-none-any.whl (386 kB)
Collecting pygments
  Using cached pygments-2.18.0-py3-none-any.whl (1.2 MB)
Collecting httpx>=0.25.0
  Using cached httpx-0.27.2-py3-none-any.whl (76 kB)
Collecting jupyter-lsp>=2.0.0
  Using cached jupyter_lsp-2.2.5-py3-none-any.whl (69 kB)
Collecting notebook-shim>=0.2
  Using cached notebook_shim-0.2.4-py3-none-any.whl (13 kB)
Collecting jupyterlab-server<3,>=2.27.1
  Using cached jupyterlab_server-2.27.3-py3-none-any.whl (59 kB)
Collecting async-lru>=1.0.0
  Using cached async_lru-2.0.4-py3-none-any.whl (6.1 kB)
Collecting jupyter-server<3,>=2.4.0
  Using cached jupyter_server-2.14.2-py3-none-any.whl (383 kB)
Collecting multiprocess
  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 134.8/134.8 KB 33.0 MB/s eta 0:00:00
  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 134.8/134.8 KB 36.0 MB/s eta 0:00:00
Collecting nbformat>=5.7
  Using cached nbformat-5.10.4-py3-none-any.whl (78 kB)
Collecting tinycss2
  Using cached tinycss2-1.3.0-py3-none-any.whl (22 kB)
Collecting bleach!=5.0.0
  Using cached bleach-6.1.0-py3-none-any.whl (162 kB)
Collecting jupyterlab-pygments
  Using cached jupyterlab_pygments-0.3.0-py3-none-any.whl (15 kB)
Collecting defusedxml
  Using cached defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)
Collecting mistune<4,>=2.0.3
  Using cached mistune-3.0.2-py3-none-any.whl (47 kB)
Collecting pandocfilters>=1.4.1
  Using cached pandocfilters-1.5.1-py2.py3-none-any.whl (8.7 kB)
Collecting nbclient>=0.5.0
  Using cached nbclient-0.10.0-py3-none-any.whl (25 kB)
Collecting beautifulsoup4
  Using cached beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)
Collecting sqlalchemy>=1.3.0
  Downloading SQLAlchemy-2.0.36-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 3.1/3.1 MB 118.1 MB/s eta 0:00:00
Collecting alembic>=1.5.0
  Downloading alembic-1.13.3-py3-none-any.whl (233 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 233.2/233.2 KB 54.2 MB/s eta 0:00:00
Collecting colorlog
  Downloading colorlog-6.8.2-py3-none-any.whl (11 kB)
Collecting mpmath<1.4,>=1.1.0
  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 536.2/536.2 KB 79.9 MB/s eta 0:00:00
Collecting Mako
  Downloading Mako-1.3.6-py3-none-any.whl (78 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 78.6/78.6 KB 23.7 MB/s eta 0:00:00
Collecting webencodings
  Using cached webencodings-0.5.1-py2.py3-none-any.whl (11 kB)
Collecting anyio
  Using cached anyio-4.6.2.post1-py3-none-any.whl (90 kB)
Collecting httpcore==1.*
  Using cached httpcore-1.0.6-py3-none-any.whl (78 kB)
Collecting sniffio
  Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)
Collecting h11<0.15,>=0.13
  Using cached h11-0.14.0-py3-none-any.whl (58 kB)
Collecting pexpect>4.3
  Using cached pexpect-4.9.0-py2.py3-none-any.whl (63 kB)
Collecting jedi>=0.16
  Using cached jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)
Collecting stack-data
  Using cached stack_data-0.6.3-py3-none-any.whl (24 kB)
Collecting decorator
  Using cached decorator-5.1.1-py3-none-any.whl (9.1 kB)
Collecting platformdirs>=2.5
  Using cached platformdirs-4.3.6-py3-none-any.whl (18 kB)
Collecting jupyter-server-terminals>=0.4.4
  Using cached jupyter_server_terminals-0.5.3-py3-none-any.whl (13 kB)
Collecting jupyter-events>=0.9.0
  Using cached jupyter_events-0.10.0-py3-none-any.whl (18 kB)
Collecting overrides>=5.0
  Using cached overrides-7.7.0-py3-none-any.whl (17 kB)
Collecting prometheus-client>=0.9
  Using cached prometheus_client-0.21.0-py3-none-any.whl (54 kB)
Collecting send2trash>=1.8.2
  Using cached Send2Trash-1.8.3-py3-none-any.whl (18 kB)
Collecting websocket-client>=1.7
  Using cached websocket_client-1.8.0-py3-none-any.whl (58 kB)
Collecting argon2-cffi>=21.1
  Using cached argon2_cffi-23.1.0-py3-none-any.whl (15 kB)
Collecting terminado>=0.8.3
  Using cached terminado-0.18.1-py3-none-any.whl (14 kB)
Collecting babel>=2.10
  Using cached babel-2.16.0-py3-none-any.whl (9.6 MB)
Collecting json5>=0.9.0
  Using cached json5-0.9.25-py3-none-any.whl (30 kB)
Collecting jsonschema>=4.18.0
  Using cached jsonschema-4.23.0-py3-none-any.whl (88 kB)
Collecting marisa-trie>=0.7.7
  Downloading marisa_trie-1.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1.3/1.3 MB 94.0 MB/s eta 0:00:00
Collecting fastjsonschema>=2.15
  Using cached fastjsonschema-2.20.0-py3-none-any.whl (23 kB)
Collecting wcwidth
  Using cached wcwidth-0.2.13-py2.py3-none-any.whl (34 kB)
Collecting greenlet!=0.4.17
  Downloading greenlet-3.1.1-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (599 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 599.5/599.5 KB 40.4 MB/s eta 0:00:00
Collecting propcache>=0.2.0
  Downloading propcache-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (208 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 208.9/208.9 KB 46.3 MB/s eta 0:00:00
Collecting soupsieve>1.2
  Using cached soupsieve-2.6-py3-none-any.whl (36 kB)
Collecting argon2-cffi-bindings
  Using cached argon2_cffi_bindings-21.2.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (86 kB)
Collecting parso<0.9.0,>=0.8.3
  Using cached parso-0.8.4-py2.py3-none-any.whl (103 kB)
Collecting rpds-py>=0.7.1
  Using cached rpds_py-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (354 kB)
Collecting jsonschema-specifications>=2023.03.6
  Using cached jsonschema_specifications-2024.10.1-py3-none-any.whl (18 kB)
Collecting referencing>=0.28.4
  Using cached referencing-0.35.1-py3-none-any.whl (26 kB)
Collecting rfc3339-validator
  Using cached rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)
Collecting python-json-logger>=2.0.4
  Using cached python_json_logger-2.0.7-py3-none-any.whl (8.1 kB)
Collecting rfc3986-validator>=0.1.1
  Using cached rfc3986_validator-0.1.1-py2.py3-none-any.whl (4.2 kB)
Collecting ptyprocess>=0.5
  Using cached ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB)
Collecting executing>=1.2.0
  Using cached executing-2.1.0-py2.py3-none-any.whl (25 kB)
Collecting asttokens>=2.1.0
  Using cached asttokens-2.4.1-py2.py3-none-any.whl (27 kB)
Collecting pure-eval
  Using cached pure_eval-0.2.3-py3-none-any.whl (11 kB)
Collecting uri-template
  Using cached uri_template-1.3.0-py3-none-any.whl (11 kB)
Collecting webcolors>=24.6.0
  Using cached webcolors-24.8.0-py3-none-any.whl (15 kB)
Collecting jsonpointer>1.13
  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)
Collecting isoduration
  Using cached isoduration-20.11.0-py3-none-any.whl (11 kB)
Collecting fqdn
  Using cached fqdn-1.5.1-py3-none-any.whl (9.1 kB)
Collecting cffi>=1.0.1
  Using cached cffi-1.17.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (446 kB)
Collecting pycparser
  Using cached pycparser-2.22-py3-none-any.whl (117 kB)
Collecting arrow>=0.15.0
  Using cached arrow-1.3.0-py3-none-any.whl (66 kB)
Collecting types-python-dateutil>=2.8.10
  Using cached types_python_dateutil-2.9.0.20241003-py3-none-any.whl (9.7 kB)
Using legacy 'setup.py install' for wget, since package 'wheel' is not installed.
Installing collected packages: wget, webencodings, wcwidth, pytz, pure-eval, ptyprocess, mpmath, fastjsonschema, cymem, xxhash, widgetsnbextension, websocket-client, webcolors, wasabi, urllib3, uri-template, ujson, tzdata, typing-extensions, types-python-dateutil, traitlets, tqdm, tornado, tomli, tinycss2, threadpoolctl, sympy, spacy-loggers, spacy-legacy, soupsieve, sniffio, smart-open, six, send2trash, safetensors, rpds-py, rfc3986-validator, regex, pyzmq, pyyaml, python-json-logger, python-dotenv, pyparsing, pygments, pycparser, psutil, propcache, prompt-toolkit, prometheus-client, pluggy, platformdirs, pillow, pexpect, parso, pandocfilters, packaging, overrides, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, nest-asyncio, murmurhash, mistune, MarkupSafe, marisa-trie, kiwisolver, jupyterlab-widgets, jupyterlab-pygments, jsonpointer, json5, joblib, iniconfig, idna, h11, greenlet, fsspec, frozenlist, fqdn, fonttools, filelock, executing, exceptiongroup, dill, defusedxml, decorator, debugpy, cycler, colorlog, click, charset-normalizer, certifi, catalogue, backoff, babel, attrs, async-timeout, annotated-types, aiohappyeyeballs, typer, triton, terminado, srsly, sqlalchemy, scipy, rfc3339-validator, requests, referencing, python-dateutil, pytest, pydantic-core, pyarrow, preshed, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nltk, multiprocess, multidict, matplotlib-inline, Mako, language-data, jupyter-core, jinja2, jedi, httpcore, contourpy, comm, cloudpathlib, cffi, blis, bleach, beautifulsoup4, async-lru, asttokens, anyio, aiosignal, yarl, stack-data, scikit-learn, pydantic, pandas, nvidia-cusolver-cu12, matplotlib, langcodes, jupyter-server-terminals, jupyter-client, jsonschema-specifications, huggingface-hub, httpx, arrow, argon2-cffi-bindings, alembic, torch, tokenizers, optuna, jsonschema, isoduration, ipython, confection, argon2-cffi, aiohttp, weasel, transformers, torchvision, torchaudio, thinc, openai, nbformat, ipywidgets, ipykernel, spacy, nbclient, jupyter-events, jupyter-console, datasets, nbconvert, dspy-ai, jupyter-server, notebook-shim, jupyterlab-server, jupyter-lsp, jupyterlab, notebook, jupyter
  Running setup.py install for wget ... done








Successfully installed Mako-1.3.6 MarkupSafe-3.0.2 aiohappyeyeballs-2.4.3 aiohttp-3.10.10 aiosignal-1.3.1 alembic-1.13.3 annotated-types-0.7.0 anyio-4.6.2.post1 argon2-cffi-23.1.0 argon2-cffi-bindings-21.2.0 arrow-1.3.0 asttokens-2.4.1 async-lru-2.0.4 async-timeout-4.0.3 attrs-24.2.0 babel-2.16.0 backoff-2.2.1 beautifulsoup4-4.12.3 bleach-6.1.0 blis-0.7.11 catalogue-2.0.10 certifi-2024.8.30 cffi-1.17.1 charset-normalizer-3.4.0 click-8.1.7 cloudpathlib-0.16.0 colorlog-6.8.2 comm-0.2.2 confection-0.1.5 contourpy-1.3.0 cycler-0.12.1 cymem-2.0.8 datasets-2.14.6 debugpy-1.8.7 decorator-5.1.1 defusedxml-0.7.1 dill-0.3.7 dspy-ai-2.3.1 exceptiongroup-1.2.2 executing-2.1.0 fastjsonschema-2.20.0 filelock-3.16.1 fonttools-4.54.1 fqdn-1.5.1 frozenlist-1.4.1 fsspec-2023.10.0 greenlet-3.1.1 h11-0.14.0 httpcore-1.0.6 httpx-0.27.2 huggingface-hub-0.26.1 idna-3.10 iniconfig-2.0.0 ipykernel-6.29.5 ipython-8.28.0 ipywidgets-8.1.5 isoduration-20.11.0 jedi-0.19.1 jinja2-3.1.4 joblib-1.3.2 json5-0.9.25 jsonpointer-3.0.0 jsonschema-4.23.0 jsonschema-specifications-2024.10.1 jupyter-1.1.1 jupyter-client-8.6.3 jupyter-console-6.6.3 jupyter-core-5.7.2 jupyter-events-0.10.0 jupyter-lsp-2.2.5 jupyter-server-2.14.2 jupyter-server-terminals-0.5.3 jupyterlab-4.2.5 jupyterlab-pygments-0.3.0 jupyterlab-server-2.27.3 jupyterlab-widgets-3.0.13 kiwisolver-1.4.7 langcodes-3.4.1 language-data-1.2.0 marisa-trie-1.2.1 matplotlib-3.9.2 matplotlib-inline-0.1.7 mistune-3.0.2 mpmath-1.3.0 multidict-6.1.0 multiprocess-0.70.15 murmurhash-1.0.10 nbclient-0.10.0 nbconvert-7.16.4 nbformat-5.10.4 nest-asyncio-1.6.0 networkx-3.4.2 nltk-3.9.1 notebook-7.2.2 notebook-shim-0.2.4 numpy-1.26.4 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvjitlink-cu12-12.6.77 nvidia-nvtx-cu12-12.1.105 openai-0.28.1 optuna-4.0.0 overrides-7.7.0 packaging-24.1 pandas-2.2.3 pandocfilters-1.5.1 parso-0.8.4 pexpect-4.9.0 pillow-11.0.0 platformdirs-4.3.6 pluggy-1.5.0 preshed-3.0.9 prometheus-client-0.21.0 prompt-toolkit-3.0.48 propcache-0.2.0 psutil-6.1.0 ptyprocess-0.7.0 pure-eval-0.2.3 pyarrow-17.0.0 pycparser-2.22 pydantic-2.9.2 pydantic-core-2.23.4 pygments-2.18.0 pyparsing-3.2.0 pytest-8.3.3 python-dateutil-2.9.0.post0 python-dotenv-1.0.1 python-json-logger-2.0.7 pytz-2024.2 pyyaml-6.0.2 pyzmq-26.2.0 referencing-0.35.1 regex-2024.9.11 requests-2.32.3 rfc3339-validator-0.1.4 rfc3986-validator-0.1.1 rpds-py-0.20.0 safetensors-0.4.5 scikit-learn-1.5.2 scipy-1.14.1 send2trash-1.8.3 six-1.16.0 smart-open-6.4.0 sniffio-1.3.1 soupsieve-2.6 spacy-3.7.2 spacy-legacy-3.0.12 spacy-loggers-1.0.5 sqlalchemy-2.0.36 srsly-2.4.8 stack-data-0.6.3 sympy-1.13.3 terminado-0.18.1 thinc-8.2.5 threadpoolctl-3.5.0 tinycss2-1.3.0 tokenizers-0.20.1 tomli-2.0.2 torch-2.1.2 torchaudio-2.1.2 torchvision-0.16.2 tornado-6.4.1 tqdm-4.66.5 traitlets-5.14.3 transformers-4.45.2 triton-2.1.0 typer-0.9.4 types-python-dateutil-2.9.0.20241003 typing-extensions-4.12.2 tzdata-2024.2 ujson-5.10.0 uri-template-1.3.0 urllib3-2.2.3 wasabi-1.1.3 wcwidth-0.2.13 weasel-0.3.4 webcolors-24.8.0 webencodings-0.5.1 websocket-client-1.8.0 wget-3.2 widgetsnbextension-4.0.13 xxhash-3.5.0 yarl-1.16.0
(nlp) ubuntu@192-18-129-105:~/nlp-ca/sentiment$ 
(nlp) ubuntu@192-18-129-105:~/nlp-ca/sentiment$ 
(nlp) ubuntu@192-18-129-105:~/nlp-ca/sentiment$ 
(nlp) ubuntu@192-18-129-105:~/nlp-ca/sentiment$ 
(nlp) ubuntu@192-18-129-105:~/nlp-ca/sentiment$ 
(nlp) ubuntu@192-18-129-105:~/nlp-ca/sentiment$ 
(nlp) ubuntu@192-18-129-105:~/nlp-ca/sentiment$ 
(nlp) ubuntu@192-18-129-105:~/nlp-ca/sentiment$ 
(nlp) ubuntu@192-18-129-105:~/nlp-ca/sentiment$ ls
README.md   data                   ddp_sentiment.py           dspy_sentiment_final.ipynb  sst.py         torch_ddp_finetune_neural_classifier.py  torch_shallow_neural_classifier.py
colors.py   data_processing.ipynb  ddp_sentiment_finetune.py  nlp                         test.ipynb     torch_ddp_neural_classifier.py           utils.py
compare.py  datawaza_funcs.py      dspy_sentiment.ipynb       requirements.txt            test_input.py  torch_model_base.py
(nlp) ubuntu@192-18-129-105:~/nlp-ca/sentiment$ more requirements.txt 
numpy>=1.20.0
scipy>=1.7.0
matplotlib>=3.7.0
scikit-learn>=1.0.2
nltk>=3.7
pytest>=7.1
jupyter>=1.0.0
pandas>=1.5

# Adjust torch and torchvision to compatible versions
torch==2.1.2  # Ensure compatibility with torchvision==0.16.2
torchvision==0.16.2
torchaudio==2.1.2

transformers>=4.38.0
datasets==2.14.6
spacy==3.7.2
dspy-ai==2.3.1

# Dependencies for dspy-ai
openai<=0.28.1
python-dotenv
wget

(nlp) ubuntu@192-18-129-105:~/nlp-ca/sentiment$ wandb login
wandb: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)
wandb: You can find your API key in your browser here: https://wandb.ai/authorize
wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit: 
wandb: Appending key for api.wandb.ai to your netrc file: /home/ubuntu/.netrc
(nlp) ubuntu@192-18-129-105:~/nlp-ca/sentiment$ python ./ddp_sentiment_finetune.py --dataset 'merged_local' --weights_name 'google/electra-large-discriminator' --save_data --save_model --save_pickle --save_preds --lr 0.00001 --epochs 100 --pooling 'mean' --dropout_rate 0.3 --num_layers 2 --hidden_dim 1024 --hidden_activation 'swishglu' --batch_size 32 --finetune_bert --finetune_layers 12 --l2_strength 0.01 --checkpoint_interval 5 --use_zero --optimizer 'adamw' --scheduler 'cosine_warmup' --scheduler_kwargs '{"T_0":5, "T_mult":1, "eta_min":1e-7}' --decimal 6 --use_val_split --eval_split 'test' --early_stop 'score' --n_iter_no_change 100 --show_progress --wandb --wandb_project 'Electra Large' --wandb_run 'large_ft_run_1'

Starting DDP PyTorch Training...
Device: cuda, Number of GPUs: 8
Spawning 8 processes...
Rank 5 - Device: cuda:5
Rank 6 - Device: cuda:6
Rank 2 - Device: cuda:2
Rank 7 - Device: cuda:7
Rank 3 - Device: cuda:3
Rank 1 - Device: cuda:1
Rank 4 - Device: cuda:4
Rank 0 - Device: cuda:0
8 process groups initialized with 'nccl' backend on localhost:12355
NCCL Timeout: 1 hr 0 min. NCCL Blocking Wait: Enabled
wandb: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: jbeno (jimbeno). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.5
wandb: Run data is saved locally in /home/ubuntu/nlp-ca/sentiment/wandb/run-20241023_063139-2jy37a6p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run large_ft_run_1
wandb: â­ï¸ View project at https://wandb.ai/jimbeno/Electra%20Large
wandb: ðŸš€ View run at https://wandb.ai/jimbeno/Electra%20Large/runs/2jy37a6p
Wand run initialized.

Initializing 'google/electra-large-discriminator' tokenizer and model...
Checking for local files...
Some files not found locally, downloading...
tokenizer_config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48.0/48.0 [00:00<00:00, 345kB/s]
config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 668/668 [00:00<00:00, 1.99MB/s]
vocab.txt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 232k/232k [00:00<00:00, 1.83MB/s]
tokenizer.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 466k/466k [00:00<00:00, 3.71MB/s]
pytorch_model.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.34G/1.34G [00:05<00:00, 234MB/s]
Download complete
All ranks loading tokenizer from local files...
All ranks loading model from local files...
Tokenizer and model initialized (15s)

Loading data...
Using the same dataset for training and evaluation
Splits:
- Train: Using merged_local 'train' split
- Validation: Using merged_local 'validation' split
- Evaluation: Using merged_local 'test' split
Train Data: Merged DynaSent Round 1, Round 2 and SST from Local: 'data/merged'
Validation Data: Merged DynaSent Round 1, Round 2 and SST from Local: 'data/merged'
Evaluation Data: Merged DynaSent Round 1, Round 2 and SST from Local: 'data/merged'
Train size: 102097
Validation size: 5421
Evaluation size: 5421
Train label distribution:
	      Negative: 21910
	       Neutral: 49148
	      Positive: 31039
Validation label distribution:
	      Negative: 1868
	       Neutral: 1669
	      Positive: 1884
Evaluation label distribution:
	      Negative: 1868
	       Neutral: 1669
	      Positive: 1884
Data loaded (2s)

Processing data...
(Batch size: 32, Pooling: Mean, Fine Tune BERT: True, Chunk size: None)...
Extracting sentences and labels...

Data saved to: saves/data_8_gpu_20241023-063159.npz
X Train shape: [102097], X Validation shape: [5421], X Test shape: [5421]
y Train shape: [102097], y Validation shape: [5421], y Test shape: [5421]
Data processed (882ms)

Initializing DDP Neural Classifier...
Layers: 2, Hidden Dim: 1024, Hidden Act: SwishGLU, Dropout: 0.3, Optimizer: AdamW, L2 Strength: 0.01, Pooling: MEAN, Accumulation Steps: 1, Max Grad Norm: None
Batch Size: 32, Max Epochs: 100, LR: 1e-05, Early Stop: score, Fine-tune BERT: True, Fine-tune Layers: 12, Freeze BERT: False, Target Score: None, Interactive: False
Classifier initialized (24ms)

Fitting DDP Neural Classifier on training data...
Num Workers: 0, Prefetch: None
Score-based early stopping enabled (macro average F1 score against validation set). Validation fraction: 0.1
Training will stop early if the score does not improve by at least 0.00001 for 100 iterations.
Using provided validation set for early stopping.
Building dataset and dataloader...
Initializing model, graph, optimizer...
BERT's original pooler removed. Using custom pooling type: mean
BERT has 151,154,688 trainable parameters and 182,937,600 non-trainable parameters
Number of BERT layers requiring gradients: 12 out of 24
Fine-tuning the last 12 out of 24 BERT layers

Model Architecture Summary:
BERTClassifier(
  (bert): ElectraModel(
    (embeddings): ElectraEmbeddings(
      (word_embeddings): Embedding(30522, 1024, padding_idx=0)
      (position_embeddings): Embedding(512, 1024)
      (token_type_embeddings): Embedding(2, 1024)
      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): ElectraEncoder(
      (layer): ModuleList(
        (0-23): 24 x ElectraLayer(
          (attention): ElectraAttention(
            (self): ElectraSelfAttention(
              (query): Linear(in_features=1024, out_features=1024, bias=True)
              (key): Linear(in_features=1024, out_features=1024, bias=True)
              (value): Linear(in_features=1024, out_features=1024, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): ElectraSelfOutput(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): ElectraIntermediate(
            (dense): Linear(in_features=1024, out_features=4096, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): ElectraOutput(
            (dense): Linear(in_features=4096, out_features=1024, bias=True)
            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
  (custom_pooling): PoolingLayer()
  (classifier): Classifier(
    (layers): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): SwishGLU(
        (projection): Linear(in_features=1024, out_features=2048, bias=True)
        (activation): SiLU()
      )
      (2): Dropout(p=0.3, inplace=False)
      (3): Linear(in_features=1024, out_features=1024, bias=True)
      (4): SwishGLU(
        (projection): Linear(in_features=1024, out_features=2048, bias=True)
        (activation): SiLU()
      )
      (5): Dropout(p=0.3, inplace=False)
      (6): Linear(in_features=1024, out_features=3, bias=True)
    )
  )
)

Model Parameters:
  bert.embeddings.word_embeddings: 31,254,528 (frozen)
  bert.embeddings.position_embeddings: 524,288 (frozen)
  bert.embeddings.token_type_embeddings: 2,048 (frozen)
  bert.embeddings.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.0.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.0.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.0.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.0.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.0.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.0.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.0.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.0.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.1.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.1.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.1.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.1.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.1.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.1.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.1.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.1.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.2.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.2.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.2.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.2.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.2.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.2.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.2.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.2.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.3.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.3.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.3.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.3.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.3.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.3.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.3.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.3.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.4.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.4.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.4.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.4.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.4.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.4.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.4.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.4.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.5.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.5.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.5.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.5.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.5.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.5.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.5.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.5.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.6.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.6.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.6.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.6.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.6.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.6.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.6.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.6.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.7.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.7.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.7.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.7.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.7.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.7.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.7.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.7.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.8.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.8.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.8.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.8.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.8.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.8.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.8.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.8.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.9.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.9.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.9.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.9.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.9.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.9.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.9.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.9.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.10.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.10.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.10.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.10.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.10.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.10.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.10.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.10.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.11.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.11.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.11.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.11.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.11.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.11.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.11.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.11.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.12.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.12.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.12.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.12.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.12.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.12.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.12.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.12.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.13.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.13.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.13.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.13.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.13.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.13.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.13.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.13.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.14.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.14.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.14.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.14.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.14.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.14.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.14.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.14.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.15.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.15.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.15.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.15.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.15.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.15.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.15.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.15.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.16.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.16.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.16.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.16.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.16.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.16.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.16.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.16.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.17.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.17.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.17.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.17.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.17.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.17.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.17.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.17.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.18.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.18.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.18.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.18.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.18.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.18.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.18.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.18.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.19.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.19.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.19.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.19.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.19.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.19.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.19.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.19.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.20.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.20.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.20.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.20.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.20.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.20.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.20.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.20.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.21.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.21.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.21.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.21.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.21.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.21.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.21.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.21.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.22.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.22.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.22.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.22.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.22.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.22.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.22.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.22.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.23.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.23.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.23.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.23.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.23.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.23.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.23.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.23.output.LayerNorm: 2,048 (trainable)
  classifier.layers.0: 1,049,600 (trainable)
  classifier.layers.1.projection: 2,099,200 (trainable)
  classifier.layers.3: 1,049,600 (trainable)
  classifier.layers.6: 3,075 (trainable)

Total layers: 200
Trainable layers: 100
Total parameters: 338,293,763
Trainable parameters: 155,356,163
Percentage of trainable parameters: 45.92%
Using optimizer: AdamW, Use Zero: True, Learning Rate: 1e-05, L2 strength: 0.01
Using scheduler: CosineAnnealingWarmRestarts
Scheduler arguments:
- T_0: 5
- T_mult: 1
- eta_min: 1e-07

Starting training loop...
Start epoch: 1, Max Iterations: 100, Early Stop: score, Tolerance: 0.00001, Number Iterations No Change: 100
Epoch 1/100:   0%|                                                                                                                                              | 0/399 [00:00<?, ?it/s]An error occurred during training: Tensors must be contiguous
An error occurred during training: Tensors must be contiguous
An error occurred during training: Tensors must be contiguous
An error occurred during training: Tensors must be contiguous
An error occurred during training: Tensors must be contiguous
An error occurred during training: Tensors must be contiguous
An error occurred during training: Tensors must be contiguous
An error occurred during training: Tensors must be contiguous
Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
  File "/home/ubuntu/nlp-ca/sentiment/ddp_sentiment_finetune.py", line 1205, in main
    classifier.fit(X_train, X_val, y_train, y_val, rank, world_size, debug, start_epoch, model_state_dict, optimizer_state_dict,
Traceback (most recent call last):
Traceback (most recent call last):
  File "/home/ubuntu/nlp-ca/sentiment/torch_ddp_finetune_neural_classifier.py", line 1352, in fit
    self.optimizer.step()
  File "/home/ubuntu/nlp-ca/sentiment/ddp_sentiment_finetune.py", line 1205, in main
    classifier.fit(X_train, X_val, y_train, y_val, rank, world_size, debug, start_epoch, model_state_dict, optimizer_state_dict,
  File "/home/ubuntu/nlp-ca/sentiment/ddp_sentiment_finetune.py", line 1205, in main
    classifier.fit(X_train, X_val, y_train, y_val, rank, world_size, debug, start_epoch, model_state_dict, optimizer_state_dict,
  File "/home/ubuntu/nlp-ca/sentiment/ddp_sentiment_finetune.py", line 1205, in main
    classifier.fit(X_train, X_val, y_train, y_val, rank, world_size, debug, start_epoch, model_state_dict, optimizer_state_dict,
  File "/home/ubuntu/nlp-ca/sentiment/ddp_sentiment_finetune.py", line 1205, in main
    classifier.fit(X_train, X_val, y_train, y_val, rank, world_size, debug, start_epoch, model_state_dict, optimizer_state_dict,
  File "/home/ubuntu/nlp-ca/sentiment/ddp_sentiment_finetune.py", line 1205, in main
    classifier.fit(X_train, X_val, y_train, y_val, rank, world_size, debug, start_epoch, model_state_dict, optimizer_state_dict,
  File "/home/ubuntu/nlp-ca/sentiment/torch_ddp_finetune_neural_classifier.py", line 1352, in fit
    self.optimizer.step()
  File "/home/ubuntu/nlp-ca/sentiment/torch_ddp_finetune_neural_classifier.py", line 1352, in fit
    self.optimizer.step()
  File "/home/ubuntu/nlp-ca/sentiment/torch_ddp_finetune_neural_classifier.py", line 1352, in fit
    self.optimizer.step()
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/optim/lr_scheduler.py", line 68, in wrapper
    return wrapped(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/optim/lr_scheduler.py", line 68, in wrapper
    return wrapped(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/torch_ddp_finetune_neural_classifier.py", line 1352, in fit
    self.optimizer.step()
  File "/home/ubuntu/nlp-ca/sentiment/torch_ddp_finetune_neural_classifier.py", line 1352, in fit
    self.optimizer.step()
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/optim/lr_scheduler.py", line 68, in wrapper
    return wrapped(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/optim/lr_scheduler.py", line 68, in wrapper
    return wrapped(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/optim/lr_scheduler.py", line 68, in wrapper
    return wrapped(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/optim/optimizer.py", line 373, in wrapper
    out = func(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/optim/optimizer.py", line 373, in wrapper
    out = func(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py", line 1114, in step
    self._sync_params()
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/optim/lr_scheduler.py", line 68, in wrapper
    return wrapped(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py", line 809, in _sync_params
    handles.extend(self._broadcast_params_from_rank(rank))
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/optim/optimizer.py", line 373, in wrapper
    out = func(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/optim/optimizer.py", line 373, in wrapper
    out = func(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/optim/optimizer.py", line 373, in wrapper
    out = func(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py", line 1114, in step
    self._sync_params()
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py", line 1114, in step
    self._sync_params()
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py", line 809, in _sync_params
    handles.extend(self._broadcast_params_from_rank(rank))
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/optim/optimizer.py", line 373, in wrapper
    out = func(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py", line 788, in _broadcast_params_from_rank
    dist.broadcast(
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py", line 1114, in step
    self._sync_params()
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py", line 1114, in step
    self._sync_params()
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py", line 809, in _sync_params
    handles.extend(self._broadcast_params_from_rank(rank))
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py", line 788, in _broadcast_params_from_rank
    dist.broadcast(
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py", line 788, in _broadcast_params_from_rank
    dist.broadcast(
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py", line 1114, in step
    self._sync_params()
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/c10d_logger.py", line 47, in wrapper
    return func(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py", line 809, in _sync_params
    handles.extend(self._broadcast_params_from_rank(rank))
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py", line 809, in _sync_params
    handles.extend(self._broadcast_params_from_rank(rank))
  File "/home/ubuntu/nlp-ca/sentiment/ddp_sentiment_finetune.py", line 1205, in main
    classifier.fit(X_train, X_val, y_train, y_val, rank, world_size, debug, start_epoch, model_state_dict, optimizer_state_dict,
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/c10d_logger.py", line 47, in wrapper
    return func(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/c10d_logger.py", line 47, in wrapper
    return func(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py", line 809, in _sync_params
    handles.extend(self._broadcast_params_from_rank(rank))
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 1906, in broadcast
    work = default_pg.broadcast([tensor], opts)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py", line 788, in _broadcast_params_from_rank
    dist.broadcast(
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py", line 788, in _broadcast_params_from_rank
    dist.broadcast(
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 1906, in broadcast
    work = default_pg.broadcast([tensor], opts)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 1906, in broadcast
    work = default_pg.broadcast([tensor], opts)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py", line 788, in _broadcast_params_from_rank
    dist.broadcast(
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/c10d_logger.py", line 47, in wrapper
    return func(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/c10d_logger.py", line 47, in wrapper
    return func(*args, **kwargs)
RuntimeError: Tensors must be contiguous
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/c10d_logger.py", line 47, in wrapper
    return func(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 1906, in broadcast
    work = default_pg.broadcast([tensor], opts)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 1906, in broadcast
    work = default_pg.broadcast([tensor], opts)
RuntimeError: Tensors must be contiguous
RuntimeError: Tensors must be contiguous
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 1906, in broadcast
    work = default_pg.broadcast([tensor], opts)
RuntimeError: Tensors must be contiguous
RuntimeError: Tensors must be contiguous
  File "/home/ubuntu/nlp-ca/sentiment/torch_ddp_finetune_neural_classifier.py", line 1352, in fit
    self.optimizer.step()
RuntimeError: Tensors must be contiguous
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/optim/lr_scheduler.py", line 68, in wrapper
    return wrapped(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/optim/optimizer.py", line 373, in wrapper
    out = func(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py", line 1114, in step
    self._sync_params()
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py", line 809, in _sync_params
    handles.extend(self._broadcast_params_from_rank(rank))
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py", line 788, in _broadcast_params_from_rank
    dist.broadcast(
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/c10d_logger.py", line 47, in wrapper
    return func(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 1906, in broadcast
    work = default_pg.broadcast([tensor], opts)
RuntimeError: Tensors must be contiguous
Traceback (most recent call last):
  File "/home/ubuntu/nlp-ca/sentiment/ddp_sentiment_finetune.py", line 1205, in main
    classifier.fit(X_train, X_val, y_train, y_val, rank, world_size, debug, start_epoch, model_state_dict, optimizer_state_dict,
  File "/home/ubuntu/nlp-ca/sentiment/torch_ddp_finetune_neural_classifier.py", line 1352, in fit
    self.optimizer.step()
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/optim/lr_scheduler.py", line 68, in wrapper
    return wrapped(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/optim/optimizer.py", line 373, in wrapper
    out = func(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py", line 1114, in step
    self._sync_params()
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py", line 809, in _sync_params
    handles.extend(self._broadcast_params_from_rank(rank))
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py", line 788, in _broadcast_params_from_rank
    dist.broadcast(
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/c10d_logger.py", line 47, in wrapper
    return func(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 1906, in broadcast
    work = default_pg.broadcast([tensor], opts)
RuntimeError: Tensors must be contiguous
Epoch 1/100:   0%|                                                                                                                                              | 0/399 [00:08<?, ?it/s]
wandb: ðŸš€ View run large_ft_run_1 at: https://wandb.ai/jimbeno/Electra Large/runs/2jy37a6p
wandb: Find logs at: wandb/run-20241023_063139-2jy37a6p/logs
(nlp) ubuntu@192-18-129-105:~/nlp-ca/sentiment$ python ./ddp_sentiment_finetune.py --dataset 'merged_local' --weights_name 'google/electra-large-discriminator' --save_data --save_model --save_pickle --save_preds --lr 0.00001 --epochs 100 --pooling 'mean' --dropout_rate 0.3 --num_layers 2 --hidden_dim 1024 --hidden_activation 'swishglu' --batch_size 32 --finetune_bert --finetune_layers 24 --l2_strength 0.01 --checkpoint_interval 5 --use_zero --optimizer 'adamw' --scheduler 'cosine_warmup' --scheduler_kwargs '{"T_0":5, "T_mult":1, "eta_min":1e-7}' --decimal 6 --use_val_split --eval_split 'test' --early_stop 'score' --n_iter_no_change 100 --show_progress --wandb --wandb_project 'Electra Large' --wandb_run 'large_ft_run_1'

Starting DDP PyTorch Training...
Device: cuda, Number of GPUs: 8
Spawning 8 processes...
Rank 6 - Device: cuda:6
Rank 4 - Device: cuda:4
Rank 1 - Device: cuda:1
Rank 5 - Device: cuda:5
Rank 3 - Device: cuda:3
Rank 7 - Device: cuda:7
Rank 2 - Device: cuda:2
Rank 0 - Device: cuda:0
8 process groups initialized with 'nccl' backend on localhost:12355
NCCL Timeout: 1 hr 0 min. NCCL Blocking Wait: Enabled
wandb: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: jbeno (jimbeno). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.5
wandb: Run data is saved locally in /home/ubuntu/nlp-ca/sentiment/wandb/run-20241023_063514-0f36u1xa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run large_ft_run_1
wandb: â­ï¸ View project at https://wandb.ai/jimbeno/Electra%20Large
wandb: ðŸš€ View run at https://wandb.ai/jimbeno/Electra%20Large/runs/0f36u1xa
Wand run initialized.

Initializing 'google/electra-large-discriminator' tokenizer and model...
Checking for local files...
Found all files in cache, skipping download
All ranks loading tokenizer from local files...
All ranks loading model from local files...
Tokenizer and model initialized (6s)

Loading data...
Using the same dataset for training and evaluation
Splits:
- Train: Using merged_local 'train' split
- Validation: Using merged_local 'validation' split
- Evaluation: Using merged_local 'test' split
Train Data: Merged DynaSent Round 1, Round 2 and SST from Local: 'data/merged'
Validation Data: Merged DynaSent Round 1, Round 2 and SST from Local: 'data/merged'
Evaluation Data: Merged DynaSent Round 1, Round 2 and SST from Local: 'data/merged'
Train size: 102097
Validation size: 5421
Evaluation size: 5421
Train label distribution:
	      Negative: 21910
	       Neutral: 49148
	      Positive: 31039
Validation label distribution:
	      Negative: 1868
	       Neutral: 1669
	      Positive: 1884
Evaluation label distribution:
	      Negative: 1868
	       Neutral: 1669
	      Positive: 1884
Data loaded (2s)

Processing data...
(Batch size: 32, Pooling: Mean, Fine Tune BERT: True, Chunk size: None)...
Extracting sentences and labels...

Data saved to: saves/data_8_gpu_20241023-063525.npz
X Train shape: [102097], X Validation shape: [5421], X Test shape: [5421]
y Train shape: [102097], y Validation shape: [5421], y Test shape: [5421]
Data processed (877ms)

Initializing DDP Neural Classifier...
Layers: 2, Hidden Dim: 1024, Hidden Act: SwishGLU, Dropout: 0.3, Optimizer: AdamW, L2 Strength: 0.01, Pooling: MEAN, Accumulation Steps: 1, Max Grad Norm: None
Batch Size: 32, Max Epochs: 100, LR: 1e-05, Early Stop: score, Fine-tune BERT: True, Fine-tune Layers: 24, Freeze BERT: False, Target Score: None, Interactive: False
Classifier initialized (17ms)

Fitting DDP Neural Classifier on training data...
Num Workers: 0, Prefetch: None
Score-based early stopping enabled (macro average F1 score against validation set). Validation fraction: 0.1
Training will stop early if the score does not improve by at least 0.00001 for 100 iterations.
Using provided validation set for early stopping.
Building dataset and dataloader...
Initializing model, graph, optimizer...
BERT's original pooler removed. Using custom pooling type: mean
BERT has 334,092,288 trainable parameters and 0 non-trainable parameters
Number of BERT layers requiring gradients: 24 out of 24
Fine-tuning the last 24 out of 24 BERT layers

Model Architecture Summary:
BERTClassifier(
  (bert): ElectraModel(
    (embeddings): ElectraEmbeddings(
      (word_embeddings): Embedding(30522, 1024, padding_idx=0)
      (position_embeddings): Embedding(512, 1024)
      (token_type_embeddings): Embedding(2, 1024)
      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): ElectraEncoder(
      (layer): ModuleList(
        (0-23): 24 x ElectraLayer(
          (attention): ElectraAttention(
            (self): ElectraSelfAttention(
              (query): Linear(in_features=1024, out_features=1024, bias=True)
              (key): Linear(in_features=1024, out_features=1024, bias=True)
              (value): Linear(in_features=1024, out_features=1024, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): ElectraSelfOutput(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): ElectraIntermediate(
            (dense): Linear(in_features=1024, out_features=4096, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): ElectraOutput(
            (dense): Linear(in_features=4096, out_features=1024, bias=True)
            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
  (custom_pooling): PoolingLayer()
  (classifier): Classifier(
    (layers): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): SwishGLU(
        (projection): Linear(in_features=1024, out_features=2048, bias=True)
        (activation): SiLU()
      )
      (2): Dropout(p=0.3, inplace=False)
      (3): Linear(in_features=1024, out_features=1024, bias=True)
      (4): SwishGLU(
        (projection): Linear(in_features=1024, out_features=2048, bias=True)
        (activation): SiLU()
      )
      (5): Dropout(p=0.3, inplace=False)
      (6): Linear(in_features=1024, out_features=3, bias=True)
    )
  )
)

Model Parameters:
  bert.embeddings.word_embeddings: 31,254,528 (trainable)
  bert.embeddings.position_embeddings: 524,288 (trainable)
  bert.embeddings.token_type_embeddings: 2,048 (trainable)
  bert.embeddings.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.0.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.0.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.0.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.0.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.0.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.0.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.0.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.0.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.1.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.1.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.1.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.1.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.1.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.1.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.1.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.1.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.2.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.2.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.2.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.2.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.2.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.2.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.2.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.2.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.3.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.3.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.3.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.3.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.3.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.3.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.3.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.3.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.4.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.4.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.4.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.4.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.4.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.4.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.4.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.4.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.5.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.5.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.5.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.5.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.5.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.5.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.5.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.5.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.6.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.6.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.6.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.6.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.6.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.6.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.6.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.6.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.7.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.7.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.7.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.7.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.7.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.7.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.7.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.7.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.8.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.8.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.8.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.8.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.8.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.8.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.8.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.8.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.9.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.9.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.9.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.9.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.9.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.9.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.9.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.9.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.10.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.10.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.10.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.10.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.10.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.10.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.10.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.10.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.11.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.11.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.11.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.11.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.11.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.11.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.11.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.11.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.12.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.12.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.12.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.12.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.12.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.12.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.12.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.12.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.13.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.13.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.13.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.13.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.13.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.13.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.13.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.13.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.14.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.14.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.14.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.14.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.14.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.14.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.14.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.14.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.15.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.15.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.15.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.15.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.15.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.15.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.15.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.15.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.16.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.16.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.16.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.16.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.16.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.16.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.16.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.16.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.17.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.17.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.17.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.17.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.17.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.17.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.17.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.17.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.18.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.18.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.18.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.18.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.18.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.18.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.18.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.18.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.19.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.19.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.19.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.19.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.19.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.19.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.19.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.19.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.20.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.20.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.20.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.20.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.20.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.20.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.20.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.20.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.21.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.21.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.21.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.21.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.21.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.21.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.21.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.21.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.22.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.22.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.22.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.22.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.22.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.22.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.22.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.22.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.23.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.23.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.23.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.23.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.23.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.23.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.23.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.23.output.LayerNorm: 2,048 (trainable)
  classifier.layers.0: 1,049,600 (trainable)
  classifier.layers.1.projection: 2,099,200 (trainable)
  classifier.layers.3: 1,049,600 (trainable)
  classifier.layers.6: 3,075 (trainable)

Total layers: 200
Trainable layers: 200
Total parameters: 338,293,763
Trainable parameters: 338,293,763
Percentage of trainable parameters: 100.00%
Using optimizer: AdamW, Use Zero: True, Learning Rate: 1e-05, L2 strength: 0.01
Using scheduler: CosineAnnealingWarmRestarts
Scheduler arguments:
- T_0: 5
- T_mult: 1
- eta_min: 1e-07

Starting training loop...
Start epoch: 1, Max Iterations: 100, Early Stop: score, Tolerance: 0.00001, Number Iterations No Change: 100
Epoch 1/100:   0%|                                                                                                                                              | 0/399 [00:00<?, ?it/s]An error occurred during training: CUDA out of memory. Tried to allocate 512.00 MiB. GPU 7 has a total capacty of 39.38 GiB of which 15.38 MiB is free. Including non-PyTorch memory, this process has 39.36 GiB memory in use. Of the allocated memory 37.99 GiB is allocated by PyTorch, and 126.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
An error occurred during training: CUDA out of memory. Tried to allocate 512.00 MiB. GPU 3 has a total capacty of 39.38 GiB of which 383.38 MiB is free. Including non-PyTorch memory, this process has 39.00 GiB memory in use. Of the allocated memory 37.49 GiB is allocated by PyTorch, and 126.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
An error occurred during training: CUDA out of memory. Tried to allocate 512.00 MiB. GPU 2 has a total capacty of 39.38 GiB of which 383.38 MiB is free. Including non-PyTorch memory, this process has 39.00 GiB memory in use. Of the allocated memory 37.49 GiB is allocated by PyTorch, and 126.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
An error occurred during training: CUDA out of memory. Tried to allocate 512.00 MiB. GPU 5 has a total capacty of 39.38 GiB of which 383.38 MiB is free. Including non-PyTorch memory, this process has 39.00 GiB memory in use. Of the allocated memory 37.49 GiB is allocated by PyTorch, and 126.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
An error occurred during training: CUDA out of memory. Tried to allocate 512.00 MiB. GPU 0 has a total capacty of 39.38 GiB of which 15.38 MiB is free. Including non-PyTorch memory, this process has 39.36 GiB memory in use. Of the allocated memory 37.99 GiB is allocated by PyTorch, and 126.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
  File "/home/ubuntu/nlp-ca/sentiment/ddp_sentiment_finetune.py", line 1205, in main
    classifier.fit(X_train, X_val, y_train, y_val, rank, world_size, debug, start_epoch, model_state_dict, optimizer_state_dict,
  File "/home/ubuntu/nlp-ca/sentiment/ddp_sentiment_finetune.py", line 1205, in main
    classifier.fit(X_train, X_val, y_train, y_val, rank, world_size, debug, start_epoch, model_state_dict, optimizer_state_dict,
  File "/home/ubuntu/nlp-ca/sentiment/ddp_sentiment_finetune.py", line 1205, in main
    classifier.fit(X_train, X_val, y_train, y_val, rank, world_size, debug, start_epoch, model_state_dict, optimizer_state_dict,
  File "/home/ubuntu/nlp-ca/sentiment/torch_ddp_finetune_neural_classifier.py", line 1310, in fit
    outputs = self.model(input_ids, attention_mask=attention_mask)
  File "/home/ubuntu/nlp-ca/sentiment/ddp_sentiment_finetune.py", line 1205, in main
    classifier.fit(X_train, X_val, y_train, y_val, rank, world_size, debug, start_epoch, model_state_dict, optimizer_state_dict,
  File "/home/ubuntu/nlp-ca/sentiment/torch_ddp_finetune_neural_classifier.py", line 1310, in fit
    outputs = self.model(input_ids, attention_mask=attention_mask)
  File "/home/ubuntu/nlp-ca/sentiment/torch_ddp_finetune_neural_classifier.py", line 1310, in fit
    outputs = self.model(input_ids, attention_mask=attention_mask)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/torch_ddp_finetune_neural_classifier.py", line 1310, in fit
    outputs = self.model(input_ids, attention_mask=attention_mask)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
Traceback (most recent call last):
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1519, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1519, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1519, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1355, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1519, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1355, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1355, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1355, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/torch_ddp_finetune_neural_classifier.py", line 111, in forward
    bert_outputs = self.bert(input_ids, attention_mask=attention_mask)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/torch_ddp_finetune_neural_classifier.py", line 111, in forward
    bert_outputs = self.bert(input_ids, attention_mask=attention_mask)
  File "/home/ubuntu/nlp-ca/sentiment/torch_ddp_finetune_neural_classifier.py", line 111, in forward
    bert_outputs = self.bert(input_ids, attention_mask=attention_mask)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/torch_ddp_finetune_neural_classifier.py", line 111, in forward
    bert_outputs = self.bert(input_ids, attention_mask=attention_mask)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 911, in forward
    hidden_states = self.encoder(
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 911, in forward
    hidden_states = self.encoder(
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 911, in forward
    hidden_states = self.encoder(
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 911, in forward
    hidden_states = self.encoder(
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/ddp_sentiment_finetune.py", line 1205, in main
    classifier.fit(X_train, X_val, y_train, y_val, rank, world_size, debug, start_epoch, model_state_dict, optimizer_state_dict,
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 583, in forward
    layer_outputs = layer_module(
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 583, in forward
    layer_outputs = layer_module(
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 583, in forward
    layer_outputs = layer_module(
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 583, in forward
    layer_outputs = layer_module(
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 472, in forward
    self_attention_outputs = self.attention(
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 472, in forward
    self_attention_outputs = self.attention(
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 472, in forward
    self_attention_outputs = self.attention(
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 472, in forward
    self_attention_outputs = self.attention(
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 399, in forward
    self_outputs = self.self(
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 399, in forward
    self_outputs = self.self(
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/torch_ddp_finetune_neural_classifier.py", line 1310, in fit
    outputs = self.model(input_ids, attention_mask=attention_mask)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 288, in forward
    attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 399, in forward
    self_outputs = self.self(
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 288, in forward
    attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 512.00 MiB. GPU 2 has a total capacty of 39.38 GiB of which 383.38 MiB is free. Including non-PyTorch memory, this process has 39.00 GiB memory in use. Of the allocated memory 37.49 GiB is allocated by PyTorch, and 126.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 399, in forward
    self_outputs = self.self(
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 312, in forward
    attention_scores = attention_scores / math.sqrt(self.attention_head_size)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 512.00 MiB. GPU 5 has a total capacty of 39.38 GiB of which 383.38 MiB is free. Including non-PyTorch memory, this process has 39.00 GiB memory in use. Of the allocated memory 37.49 GiB is allocated by PyTorch, and 126.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 288, in forward
    attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 512.00 MiB. GPU 7 has a total capacty of 39.38 GiB of which 15.38 MiB is free. Including non-PyTorch memory, this process has 39.36 GiB memory in use. Of the allocated memory 37.99 GiB is allocated by PyTorch, and 126.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 512.00 MiB. GPU 3 has a total capacty of 39.38 GiB of which 383.38 MiB is free. Including non-PyTorch memory, this process has 39.00 GiB memory in use. Of the allocated memory 37.49 GiB is allocated by PyTorch, and 126.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1519, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1355, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/torch_ddp_finetune_neural_classifier.py", line 111, in forward
    bert_outputs = self.bert(input_ids, attention_mask=attention_mask)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 911, in forward
    hidden_states = self.encoder(
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 583, in forward
    layer_outputs = layer_module(
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 472, in forward
    self_attention_outputs = self.attention(
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 399, in forward
    self_outputs = self.self(
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 312, in forward
    attention_scores = attention_scores / math.sqrt(self.attention_head_size)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 512.00 MiB. GPU 0 has a total capacty of 39.38 GiB of which 15.38 MiB is free. Including non-PyTorch memory, this process has 39.36 GiB memory in use. Of the allocated memory 37.99 GiB is allocated by PyTorch, and 126.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
Epoch 1/100:   0%|                                                                                                                                              | 0/399 [00:03<?, ?it/s]
An error occurred during training: CUDA out of memory. Tried to allocate 512.00 MiB. GPU 1 has a total capacty of 39.38 GiB of which 385.38 MiB is free. Including non-PyTorch memory, this process has 39.00 GiB memory in use. Of the allocated memory 37.49 GiB is allocated by PyTorch, and 124.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
Traceback (most recent call last):
  File "/home/ubuntu/nlp-ca/sentiment/ddp_sentiment_finetune.py", line 1205, in main
    classifier.fit(X_train, X_val, y_train, y_val, rank, world_size, debug, start_epoch, model_state_dict, optimizer_state_dict,
  File "/home/ubuntu/nlp-ca/sentiment/torch_ddp_finetune_neural_classifier.py", line 1310, in fit
    outputs = self.model(input_ids, attention_mask=attention_mask)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1519, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1355, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/torch_ddp_finetune_neural_classifier.py", line 111, in forward
    bert_outputs = self.bert(input_ids, attention_mask=attention_mask)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 911, in forward
    hidden_states = self.encoder(
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 583, in forward
    layer_outputs = layer_module(
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 472, in forward
    self_attention_outputs = self.attention(
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 399, in forward
    self_outputs = self.self(
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 288, in forward
    attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 512.00 MiB. GPU 1 has a total capacty of 39.38 GiB of which 385.38 MiB is free. Including non-PyTorch memory, this process has 39.00 GiB memory in use. Of the allocated memory 37.49 GiB is allocated by PyTorch, and 124.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
An error occurred during training: CUDA out of memory. Tried to allocate 512.00 MiB. GPU 6 has a total capacty of 39.38 GiB of which 385.38 MiB is free. Including non-PyTorch memory, this process has 39.00 GiB memory in use. Of the allocated memory 37.49 GiB is allocated by PyTorch, and 124.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
Traceback (most recent call last):
  File "/home/ubuntu/nlp-ca/sentiment/ddp_sentiment_finetune.py", line 1205, in main
    classifier.fit(X_train, X_val, y_train, y_val, rank, world_size, debug, start_epoch, model_state_dict, optimizer_state_dict,
  File "/home/ubuntu/nlp-ca/sentiment/torch_ddp_finetune_neural_classifier.py", line 1310, in fit
    outputs = self.model(input_ids, attention_mask=attention_mask)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1519, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1355, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/torch_ddp_finetune_neural_classifier.py", line 111, in forward
    bert_outputs = self.bert(input_ids, attention_mask=attention_mask)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 911, in forward
    hidden_states = self.encoder(
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 583, in forward
    layer_outputs = layer_module(
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 472, in forward
    self_attention_outputs = self.attention(
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 399, in forward
    self_outputs = self.self(
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 288, in forward
    attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 512.00 MiB. GPU 6 has a total capacty of 39.38 GiB of which 385.38 MiB is free. Including non-PyTorch memory, this process has 39.00 GiB memory in use. Of the allocated memory 37.49 GiB is allocated by PyTorch, and 124.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
An error occurred during training: CUDA out of memory. Tried to allocate 512.00 MiB. GPU 4 has a total capacty of 39.38 GiB of which 445.38 MiB is free. Including non-PyTorch memory, this process has 38.94 GiB memory in use. Of the allocated memory 37.49 GiB is allocated by PyTorch, and 64.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
Traceback (most recent call last):
  File "/home/ubuntu/nlp-ca/sentiment/ddp_sentiment_finetune.py", line 1205, in main
    classifier.fit(X_train, X_val, y_train, y_val, rank, world_size, debug, start_epoch, model_state_dict, optimizer_state_dict,
  File "/home/ubuntu/nlp-ca/sentiment/torch_ddp_finetune_neural_classifier.py", line 1310, in fit
    outputs = self.model(input_ids, attention_mask=attention_mask)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1519, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1355, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/torch_ddp_finetune_neural_classifier.py", line 111, in forward
    bert_outputs = self.bert(input_ids, attention_mask=attention_mask)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 911, in forward
    hidden_states = self.encoder(
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 583, in forward
    layer_outputs = layer_module(
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 472, in forward
    self_attention_outputs = self.attention(
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 399, in forward
    self_outputs = self.self(
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py", line 288, in forward
    attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 512.00 MiB. GPU 4 has a total capacty of 39.38 GiB of which 445.38 MiB is free. Including non-PyTorch memory, this process has 38.94 GiB memory in use. Of the allocated memory 37.49 GiB is allocated by PyTorch, and 64.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
wandb: ðŸš€ View run large_ft_run_1 at: https://wandb.ai/jimbeno/Electra Large/runs/0f36u1xa
wandb: Find logs at: wandb/run-20241023_063514-0f36u1xa/logs
(nlp) ubuntu@192-18-129-105:~/nlp-ca/sentiment$ python ./ddp_sentiment_finetune.py --dataset 'merged_local' --weights_name 'google/electra-large-discriminator' --save_data --save_model --save_pickle --save_preds --lr 0.00001 --epochs 100 --pooling 'mean' --dropout_rate 0.3 --num_layers 2 --hidden_dim 1024 --hidden_activation 'swishglu' --batch_size 16 --accumulation_steps 2 --finetune_bert --finetune_layers 24 --l2_strength 0.01 --checkpoint_interval 5 --use_zero --optimizer 'adamw' --scheduler 'cosine_warmup' --scheduler_kwargs '{"T_0":5, "T_mult":1, "eta_min":1e-7}' --decimal 6 --use_val_split --eval_split 'test' --early_stop 'score' --n_iter_no_change 100 --show_progress --wandb --wandb_project 'Electra Large' --wandb_run 'large_ft_run_1'

Starting DDP PyTorch Training...
Device: cuda, Number of GPUs: 8
Spawning 8 processes...
Rank 4 - Device: cuda:4
Rank 7 - Device: cuda:7
Rank 3 - Device: cuda:3
Rank 5 - Device: cuda:5
Rank 2 - Device: cuda:2
Rank 6 - Device: cuda:6
Rank 1 - Device: cuda:1
Rank 0 - Device: cuda:0
8 process groups initialized with 'nccl' backend on localhost:12355
NCCL Timeout: 1 hr 0 min. NCCL Blocking Wait: Enabled
wandb: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: jbeno (jimbeno). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.5
wandb: Run data is saved locally in /home/ubuntu/nlp-ca/sentiment/wandb/run-20241023_063756-2ocuwfg3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run large_ft_run_1
wandb: â­ï¸ View project at https://wandb.ai/jimbeno/Electra%20Large
wandb: ðŸš€ View run at https://wandb.ai/jimbeno/Electra%20Large/runs/2ocuwfg3
Wand run initialized.

Initializing 'google/electra-large-discriminator' tokenizer and model...
Checking for local files...
Found all files in cache, skipping download
All ranks loading tokenizer from local files...
All ranks loading model from local files...
Tokenizer and model initialized (6s)

Loading data...
Using the same dataset for training and evaluation
Splits:
- Train: Using merged_local 'train' split
- Validation: Using merged_local 'validation' split
- Evaluation: Using merged_local 'test' split
Train Data: Merged DynaSent Round 1, Round 2 and SST from Local: 'data/merged'
Validation Data: Merged DynaSent Round 1, Round 2 and SST from Local: 'data/merged'
Evaluation Data: Merged DynaSent Round 1, Round 2 and SST from Local: 'data/merged'
Train size: 102097
Validation size: 5421
Evaluation size: 5421
Train label distribution:
	      Negative: 21910
	       Neutral: 49148
	      Positive: 31039
Validation label distribution:
	      Negative: 1868
	       Neutral: 1669
	      Positive: 1884
Evaluation label distribution:
	      Negative: 1868
	       Neutral: 1669
	      Positive: 1884
Data loaded (2s)

Processing data...
(Batch size: 16, Pooling: Mean, Fine Tune BERT: True, Chunk size: None)...
Extracting sentences and labels...

Data saved to: saves/data_8_gpu_20241023-063806.npz
X Train shape: [102097], X Validation shape: [5421], X Test shape: [5421]
y Train shape: [102097], y Validation shape: [5421], y Test shape: [5421]
Data processed (857ms)

Initializing DDP Neural Classifier...
Layers: 2, Hidden Dim: 1024, Hidden Act: SwishGLU, Dropout: 0.3, Optimizer: AdamW, L2 Strength: 0.01, Pooling: MEAN, Accumulation Steps: 2, Max Grad Norm: None
Batch Size: 16, Max Epochs: 100, LR: 1e-05, Early Stop: score, Fine-tune BERT: True, Fine-tune Layers: 24, Freeze BERT: False, Target Score: None, Interactive: False
Classifier initialized (16ms)

Fitting DDP Neural Classifier on training data...
Num Workers: 0, Prefetch: None
Score-based early stopping enabled (macro average F1 score against validation set). Validation fraction: 0.1
Training will stop early if the score does not improve by at least 0.00001 for 100 iterations.
Using provided validation set for early stopping.
Building dataset and dataloader...
Initializing model, graph, optimizer...
BERT's original pooler removed. Using custom pooling type: mean
BERT has 334,092,288 trainable parameters and 0 non-trainable parameters
Number of BERT layers requiring gradients: 24 out of 24
Fine-tuning the last 24 out of 24 BERT layers

Model Architecture Summary:
BERTClassifier(
  (bert): ElectraModel(
    (embeddings): ElectraEmbeddings(
      (word_embeddings): Embedding(30522, 1024, padding_idx=0)
      (position_embeddings): Embedding(512, 1024)
      (token_type_embeddings): Embedding(2, 1024)
      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): ElectraEncoder(
      (layer): ModuleList(
        (0-23): 24 x ElectraLayer(
          (attention): ElectraAttention(
            (self): ElectraSelfAttention(
              (query): Linear(in_features=1024, out_features=1024, bias=True)
              (key): Linear(in_features=1024, out_features=1024, bias=True)
              (value): Linear(in_features=1024, out_features=1024, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): ElectraSelfOutput(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): ElectraIntermediate(
            (dense): Linear(in_features=1024, out_features=4096, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): ElectraOutput(
            (dense): Linear(in_features=4096, out_features=1024, bias=True)
            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
  (custom_pooling): PoolingLayer()
  (classifier): Classifier(
    (layers): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): SwishGLU(
        (projection): Linear(in_features=1024, out_features=2048, bias=True)
        (activation): SiLU()
      )
      (2): Dropout(p=0.3, inplace=False)
      (3): Linear(in_features=1024, out_features=1024, bias=True)
      (4): SwishGLU(
        (projection): Linear(in_features=1024, out_features=2048, bias=True)
        (activation): SiLU()
      )
      (5): Dropout(p=0.3, inplace=False)
      (6): Linear(in_features=1024, out_features=3, bias=True)
    )
  )
)

Model Parameters:
  bert.embeddings.word_embeddings: 31,254,528 (trainable)
  bert.embeddings.position_embeddings: 524,288 (trainable)
  bert.embeddings.token_type_embeddings: 2,048 (trainable)
  bert.embeddings.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.0.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.0.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.0.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.0.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.0.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.0.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.0.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.0.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.1.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.1.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.1.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.1.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.1.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.1.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.1.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.1.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.2.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.2.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.2.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.2.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.2.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.2.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.2.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.2.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.3.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.3.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.3.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.3.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.3.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.3.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.3.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.3.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.4.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.4.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.4.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.4.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.4.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.4.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.4.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.4.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.5.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.5.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.5.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.5.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.5.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.5.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.5.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.5.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.6.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.6.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.6.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.6.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.6.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.6.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.6.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.6.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.7.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.7.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.7.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.7.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.7.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.7.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.7.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.7.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.8.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.8.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.8.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.8.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.8.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.8.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.8.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.8.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.9.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.9.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.9.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.9.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.9.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.9.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.9.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.9.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.10.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.10.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.10.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.10.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.10.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.10.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.10.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.10.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.11.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.11.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.11.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.11.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.11.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.11.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.11.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.11.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.12.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.12.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.12.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.12.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.12.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.12.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.12.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.12.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.13.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.13.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.13.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.13.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.13.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.13.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.13.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.13.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.14.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.14.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.14.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.14.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.14.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.14.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.14.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.14.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.15.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.15.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.15.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.15.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.15.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.15.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.15.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.15.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.16.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.16.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.16.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.16.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.16.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.16.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.16.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.16.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.17.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.17.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.17.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.17.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.17.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.17.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.17.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.17.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.18.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.18.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.18.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.18.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.18.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.18.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.18.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.18.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.19.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.19.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.19.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.19.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.19.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.19.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.19.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.19.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.20.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.20.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.20.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.20.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.20.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.20.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.20.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.20.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.21.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.21.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.21.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.21.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.21.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.21.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.21.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.21.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.22.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.22.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.22.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.22.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.22.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.22.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.22.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.22.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.23.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.23.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.23.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.23.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.23.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.23.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.23.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.23.output.LayerNorm: 2,048 (trainable)
  classifier.layers.0: 1,049,600 (trainable)
  classifier.layers.1.projection: 2,099,200 (trainable)
  classifier.layers.3: 1,049,600 (trainable)
  classifier.layers.6: 3,075 (trainable)

Total layers: 200
Trainable layers: 200
Total parameters: 338,293,763
Trainable parameters: 338,293,763
Percentage of trainable parameters: 100.00%
Using optimizer: AdamW, Use Zero: True, Learning Rate: 1e-05, L2 strength: 0.01
Using scheduler: CosineAnnealingWarmRestarts
Scheduler arguments:
- T_0: 5
- T_mult: 1
- eta_min: 1e-07

Starting training loop...
Start epoch: 1, Max Iterations: 100, Early Stop: score, Tolerance: 0.00001, Number Iterations No Change: 100
Epoch 1/100:   0%|                                                                                                                                              | 0/798 [00:00<?, ?it/s]An error occurred during training: Tensors must be contiguous
Traceback (most recent call last):
  File "/home/ubuntu/nlp-ca/sentiment/ddp_sentiment_finetune.py", line 1205, in main
    classifier.fit(X_train, X_val, y_train, y_val, rank, world_size, debug, start_epoch, model_state_dict, optimizer_state_dict,
  File "/home/ubuntu/nlp-ca/sentiment/torch_ddp_finetune_neural_classifier.py", line 1352, in fit
    self.optimizer.step()
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/optim/lr_scheduler.py", line 68, in wrapper
    return wrapped(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/optim/optimizer.py", line 373, in wrapper
    out = func(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py", line 1114, in step
    self._sync_params()
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py", line 809, in _sync_params
    handles.extend(self._broadcast_params_from_rank(rank))
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py", line 788, in _broadcast_params_from_rank
    dist.broadcast(
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/c10d_logger.py", line 47, in wrapper
    return func(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 1906, in broadcast
    work = default_pg.broadcast([tensor], opts)
RuntimeError: Tensors must be contiguous
An error occurred during training: Tensors must be contiguous
Traceback (most recent call last):
  File "/home/ubuntu/nlp-ca/sentiment/ddp_sentiment_finetune.py", line 1205, in main
    classifier.fit(X_train, X_val, y_train, y_val, rank, world_size, debug, start_epoch, model_state_dict, optimizer_state_dict,
  File "/home/ubuntu/nlp-ca/sentiment/torch_ddp_finetune_neural_classifier.py", line 1352, in fit
    self.optimizer.step()
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/optim/lr_scheduler.py", line 68, in wrapper
    return wrapped(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/optim/optimizer.py", line 373, in wrapper
    out = func(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py", line 1114, in step
    self._sync_params()
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py", line 809, in _sync_params
    handles.extend(self._broadcast_params_from_rank(rank))
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py", line 788, in _broadcast_params_from_rank
    dist.broadcast(
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/c10d_logger.py", line 47, in wrapper
    return func(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 1906, in broadcast
    work = default_pg.broadcast([tensor], opts)
RuntimeError: Tensors must be contiguous
An error occurred during training: Tensors must be contiguous
An error occurred during training: Tensors must be contiguous
An error occurred during training: Tensors must be contiguous
Traceback (most recent call last):
  File "/home/ubuntu/nlp-ca/sentiment/ddp_sentiment_finetune.py", line 1205, in main
    classifier.fit(X_train, X_val, y_train, y_val, rank, world_size, debug, start_epoch, model_state_dict, optimizer_state_dict,
  File "/home/ubuntu/nlp-ca/sentiment/torch_ddp_finetune_neural_classifier.py", line 1352, in fit
    self.optimizer.step()
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/optim/lr_scheduler.py", line 68, in wrapper
    return wrapped(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/optim/optimizer.py", line 373, in wrapper
    out = func(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py", line 1114, in step
    self._sync_params()
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py", line 809, in _sync_params
    handles.extend(self._broadcast_params_from_rank(rank))
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py", line 788, in _broadcast_params_from_rank
    dist.broadcast(
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/c10d_logger.py", line 47, in wrapper
    return func(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 1906, in broadcast
    work = default_pg.broadcast([tensor], opts)
RuntimeError: Tensors must be contiguous
An error occurred during training: Tensors must be contiguous
Traceback (most recent call last):
  File "/home/ubuntu/nlp-ca/sentiment/ddp_sentiment_finetune.py", line 1205, in main
    classifier.fit(X_train, X_val, y_train, y_val, rank, world_size, debug, start_epoch, model_state_dict, optimizer_state_dict,
  File "/home/ubuntu/nlp-ca/sentiment/torch_ddp_finetune_neural_classifier.py", line 1352, in fit
    self.optimizer.step()
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/optim/lr_scheduler.py", line 68, in wrapper
    return wrapped(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/optim/optimizer.py", line 373, in wrapper
    out = func(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py", line 1114, in step
    self._sync_params()
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py", line 809, in _sync_params
    handles.extend(self._broadcast_params_from_rank(rank))
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py", line 788, in _broadcast_params_from_rank
    dist.broadcast(
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/c10d_logger.py", line 47, in wrapper
    return func(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 1906, in broadcast
    work = default_pg.broadcast([tensor], opts)
RuntimeError: Tensors must be contiguous
Traceback (most recent call last):
  File "/home/ubuntu/nlp-ca/sentiment/ddp_sentiment_finetune.py", line 1205, in main
    classifier.fit(X_train, X_val, y_train, y_val, rank, world_size, debug, start_epoch, model_state_dict, optimizer_state_dict,
  File "/home/ubuntu/nlp-ca/sentiment/torch_ddp_finetune_neural_classifier.py", line 1352, in fit
    self.optimizer.step()
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/optim/lr_scheduler.py", line 68, in wrapper
    return wrapped(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/optim/optimizer.py", line 373, in wrapper
    out = func(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py", line 1114, in step
    self._sync_params()
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py", line 809, in _sync_params
    handles.extend(self._broadcast_params_from_rank(rank))
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py", line 788, in _broadcast_params_from_rank
    dist.broadcast(
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/c10d_logger.py", line 47, in wrapper
    return func(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 1906, in broadcast
    work = default_pg.broadcast([tensor], opts)
RuntimeError: Tensors must be contiguous
Traceback (most recent call last):
  File "/home/ubuntu/nlp-ca/sentiment/ddp_sentiment_finetune.py", line 1205, in main
    classifier.fit(X_train, X_val, y_train, y_val, rank, world_size, debug, start_epoch, model_state_dict, optimizer_state_dict,
  File "/home/ubuntu/nlp-ca/sentiment/torch_ddp_finetune_neural_classifier.py", line 1352, in fit
    self.optimizer.step()
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/optim/lr_scheduler.py", line 68, in wrapper
    return wrapped(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/optim/optimizer.py", line 373, in wrapper
    out = func(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py", line 1114, in step
    self._sync_params()
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py", line 809, in _sync_params
    handles.extend(self._broadcast_params_from_rank(rank))
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py", line 788, in _broadcast_params_from_rank
    dist.broadcast(
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/c10d_logger.py", line 47, in wrapper
    return func(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 1906, in broadcast
    work = default_pg.broadcast([tensor], opts)
RuntimeError: Tensors must be contiguous
An error occurred during training: Tensors must be contiguous
An error occurred during training: Tensors must be contiguous
Traceback (most recent call last):
  File "/home/ubuntu/nlp-ca/sentiment/ddp_sentiment_finetune.py", line 1205, in main
    classifier.fit(X_train, X_val, y_train, y_val, rank, world_size, debug, start_epoch, model_state_dict, optimizer_state_dict,
  File "/home/ubuntu/nlp-ca/sentiment/torch_ddp_finetune_neural_classifier.py", line 1352, in fit
    self.optimizer.step()
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/optim/lr_scheduler.py", line 68, in wrapper
    return wrapped(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/optim/optimizer.py", line 373, in wrapper
    out = func(*args, **kwargs)
Traceback (most recent call last):
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py", line 1114, in step
    self._sync_params()
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py", line 809, in _sync_params
    handles.extend(self._broadcast_params_from_rank(rank))
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py", line 788, in _broadcast_params_from_rank
    dist.broadcast(
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/c10d_logger.py", line 47, in wrapper
    return func(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 1906, in broadcast
    work = default_pg.broadcast([tensor], opts)
  File "/home/ubuntu/nlp-ca/sentiment/ddp_sentiment_finetune.py", line 1205, in main
    classifier.fit(X_train, X_val, y_train, y_val, rank, world_size, debug, start_epoch, model_state_dict, optimizer_state_dict,
  File "/home/ubuntu/nlp-ca/sentiment/torch_ddp_finetune_neural_classifier.py", line 1352, in fit
    self.optimizer.step()
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/optim/lr_scheduler.py", line 68, in wrapper
    return wrapped(*args, **kwargs)
RuntimeError: Tensors must be contiguous
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/optim/optimizer.py", line 373, in wrapper
    out = func(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py", line 1114, in step
    self._sync_params()
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py", line 809, in _sync_params
    handles.extend(self._broadcast_params_from_rank(rank))
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py", line 788, in _broadcast_params_from_rank
    dist.broadcast(
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/c10d_logger.py", line 47, in wrapper
    return func(*args, **kwargs)
  File "/home/ubuntu/nlp-ca/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 1906, in broadcast
    work = default_pg.broadcast([tensor], opts)
RuntimeError: Tensors must be contiguous
Epoch 1/100:   0%|                                                                                                                                              | 0/798 [00:08<?, ?it/s]
wandb: ðŸš€ View run large_ft_run_1 at: https://wandb.ai/jimbeno/Electra Large/runs/2ocuwfg3
wandb: Find logs at: wandb/run-20241023_063756-2ocuwfg3/logs
(nlp) ubuntu@192-18-129-105:~/nlp-ca/sentiment$ ls
README.md    data                   ddp_sentiment_finetune.py   requirements.txt  test_input.py                            torch_shallow_neural_classifier.py
__pycache__  data_processing.ipynb  dspy_sentiment.ipynb        saves             torch_ddp_finetune_neural_classifier.py  utils.py
colors.py    datawaza_funcs.py      dspy_sentiment_final.ipynb  sst.py            torch_ddp_neural_classifier.py           wandb
compare.py   ddp_sentiment.py       nlp                         test.ipynb        torch_model_base.py
(nlp) ubuntu@192-18-129-105:~/nlp-ca/sentiment$ mv requirements.txt requirements.lambda
(nlp) ubuntu@192-18-129-105:~/nlp-ca/sentiment$ git pull
Username for 'https://github.com': jim@jimbeno.net
Password for 'https://jim@jimbeno.net@github.com': 
Already up to date.
(nlp) ubuntu@192-18-129-105:~/nlp-ca/sentiment$ git pull
Username for 'https://github.com': jim@jimbeno.net
Password for 'https://jim@jimbeno.net@github.com': 
remote: Enumerating objects: 5, done.
remote: Counting objects: 100% (5/5), done.
remote: Compressing objects: 100% (1/1), done.
remote: Total 3 (delta 2), reused 3 (delta 2), pack-reused 0 (from 0)
Unpacking objects: 100% (3/3), 410 bytes | 6.00 KiB/s, done.
From https://github.com/jbeno/sentiment
   a1be65f..d40daeb  main       -> origin/main
Updating a1be65f..d40daeb
Fast-forward
 torch_ddp_finetune_neural_classifier.py | 5 +++++
 1 file changed, 5 insertions(+)
(nlp) ubuntu@192-18-129-105:~/nlp-ca/sentiment$ python ./ddp_sentiment_finetune.py --dataset 'merged_local' --weights_name 'google/electra-large-discriminator' --save_data --save_model --save_pickle --save_preds --lr 0.00001 --epochs 100 --pooling 'mean' --dropout_rate 0.3 --num_layers 2 --hidden_dim 1024 --hidden_activation 'swishglu' --batch_size 16 --accumulation_steps 2 --finetune_bert --finetune_layers 24 --l2_strength 0.01 --checkpoint_interval 5 --use_zero --optimizer 'adamw' --scheduler 'cosine_warmup' --scheduler_kwargs '{"T_0":5, "T_mult":1, "eta_min":1e-7}' --decimal 6 --use_val_split --eval_split 'test' --early_stop 'score' --n_iter_no_change 100 --show_progress --wandb --wandb_project 'Electra Large' --wandb_run 'large_ft_run_1'

Starting DDP PyTorch Training...
Device: cuda, Number of GPUs: 8
Spawning 8 processes...
Rank 3 - Device: cuda:3
Rank 1 - Device: cuda:1
Rank 5 - Device: cuda:5
Rank 4 - Device: cuda:4
Rank 2 - Device: cuda:2
Rank 6 - Device: cuda:6
Rank 7 - Device: cuda:7
Rank 0 - Device: cuda:0
8 process groups initialized with 'nccl' backend on localhost:12355
NCCL Timeout: 1 hr 0 min. NCCL Blocking Wait: Enabled
wandb: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: jbeno (jimbeno). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.5
wandb: Run data is saved locally in /home/ubuntu/nlp-ca/sentiment/wandb/run-20241023_064329-4hkcvrpf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run large_ft_run_1
wandb: â­ï¸ View project at https://wandb.ai/jimbeno/Electra%20Large
wandb: ðŸš€ View run at https://wandb.ai/jimbeno/Electra%20Large/runs/4hkcvrpf
Wand run initialized.

Initializing 'google/electra-large-discriminator' tokenizer and model...
Checking for local files...
Found all files in cache, skipping download
All ranks loading tokenizer from local files...
All ranks loading model from local files...
Tokenizer and model initialized (6s)

Loading data...
Using the same dataset for training and evaluation
Splits:
- Train: Using merged_local 'train' split
- Validation: Using merged_local 'validation' split
- Evaluation: Using merged_local 'test' split
Train Data: Merged DynaSent Round 1, Round 2 and SST from Local: 'data/merged'
Validation Data: Merged DynaSent Round 1, Round 2 and SST from Local: 'data/merged'
Evaluation Data: Merged DynaSent Round 1, Round 2 and SST from Local: 'data/merged'
Train size: 102097
Validation size: 5421
Evaluation size: 5421
Train label distribution:
	      Negative: 21910
	       Neutral: 49148
	      Positive: 31039
Validation label distribution:
	      Negative: 1868
	       Neutral: 1669
	      Positive: 1884
Evaluation label distribution:
	      Negative: 1868
	       Neutral: 1669
	      Positive: 1884
Data loaded (2s)

Processing data...
(Batch size: 16, Pooling: Mean, Fine Tune BERT: True, Chunk size: None)...
Extracting sentences and labels...

Data saved to: saves/data_8_gpu_20241023-064340.npz
X Train shape: [102097], X Validation shape: [5421], X Test shape: [5421]
y Train shape: [102097], y Validation shape: [5421], y Test shape: [5421]
Data processed (859ms)

Initializing DDP Neural Classifier...
Layers: 2, Hidden Dim: 1024, Hidden Act: SwishGLU, Dropout: 0.3, Optimizer: AdamW, L2 Strength: 0.01, Pooling: MEAN, Accumulation Steps: 2, Max Grad Norm: None
Batch Size: 16, Max Epochs: 100, LR: 1e-05, Early Stop: score, Fine-tune BERT: True, Fine-tune Layers: 24, Freeze BERT: False, Target Score: None, Interactive: False
Classifier initialized (27ms)

Fitting DDP Neural Classifier on training data...
Num Workers: 0, Prefetch: None
Score-based early stopping enabled (macro average F1 score against validation set). Validation fraction: 0.1
Training will stop early if the score does not improve by at least 0.00001 for 100 iterations.
Using provided validation set for early stopping.
Building dataset and dataloader...
Initializing model, graph, optimizer...
BERT's original pooler removed. Using custom pooling type: mean
BERT has 334,092,288 trainable parameters and 0 non-trainable parameters
Number of BERT layers requiring gradients: 24 out of 24
Fine-tuning the last 24 out of 24 BERT layers

Model Architecture Summary:
BERTClassifier(
  (bert): ElectraModel(
    (embeddings): ElectraEmbeddings(
      (word_embeddings): Embedding(30522, 1024, padding_idx=0)
      (position_embeddings): Embedding(512, 1024)
      (token_type_embeddings): Embedding(2, 1024)
      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): ElectraEncoder(
      (layer): ModuleList(
        (0-23): 24 x ElectraLayer(
          (attention): ElectraAttention(
            (self): ElectraSelfAttention(
              (query): Linear(in_features=1024, out_features=1024, bias=True)
              (key): Linear(in_features=1024, out_features=1024, bias=True)
              (value): Linear(in_features=1024, out_features=1024, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): ElectraSelfOutput(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): ElectraIntermediate(
            (dense): Linear(in_features=1024, out_features=4096, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): ElectraOutput(
            (dense): Linear(in_features=4096, out_features=1024, bias=True)
            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
  (custom_pooling): PoolingLayer()
  (classifier): Classifier(
    (layers): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): SwishGLU(
        (projection): Linear(in_features=1024, out_features=2048, bias=True)
        (activation): SiLU()
      )
      (2): Dropout(p=0.3, inplace=False)
      (3): Linear(in_features=1024, out_features=1024, bias=True)
      (4): SwishGLU(
        (projection): Linear(in_features=1024, out_features=2048, bias=True)
        (activation): SiLU()
      )
      (5): Dropout(p=0.3, inplace=False)
      (6): Linear(in_features=1024, out_features=3, bias=True)
    )
  )
)

Model Parameters:
  bert.embeddings.word_embeddings: 31,254,528 (trainable)
  bert.embeddings.position_embeddings: 524,288 (trainable)
  bert.embeddings.token_type_embeddings: 2,048 (trainable)
  bert.embeddings.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.0.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.0.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.0.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.0.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.0.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.0.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.0.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.0.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.1.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.1.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.1.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.1.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.1.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.1.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.1.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.1.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.2.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.2.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.2.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.2.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.2.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.2.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.2.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.2.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.3.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.3.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.3.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.3.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.3.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.3.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.3.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.3.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.4.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.4.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.4.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.4.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.4.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.4.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.4.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.4.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.5.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.5.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.5.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.5.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.5.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.5.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.5.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.5.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.6.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.6.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.6.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.6.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.6.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.6.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.6.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.6.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.7.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.7.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.7.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.7.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.7.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.7.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.7.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.7.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.8.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.8.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.8.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.8.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.8.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.8.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.8.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.8.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.9.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.9.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.9.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.9.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.9.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.9.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.9.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.9.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.10.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.10.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.10.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.10.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.10.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.10.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.10.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.10.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.11.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.11.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.11.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.11.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.11.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.11.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.11.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.11.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.12.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.12.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.12.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.12.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.12.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.12.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.12.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.12.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.13.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.13.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.13.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.13.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.13.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.13.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.13.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.13.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.14.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.14.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.14.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.14.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.14.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.14.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.14.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.14.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.15.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.15.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.15.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.15.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.15.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.15.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.15.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.15.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.16.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.16.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.16.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.16.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.16.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.16.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.16.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.16.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.17.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.17.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.17.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.17.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.17.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.17.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.17.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.17.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.18.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.18.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.18.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.18.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.18.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.18.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.18.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.18.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.19.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.19.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.19.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.19.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.19.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.19.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.19.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.19.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.20.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.20.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.20.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.20.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.20.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.20.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.20.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.20.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.21.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.21.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.21.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.21.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.21.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.21.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.21.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.21.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.22.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.22.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.22.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.22.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.22.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.22.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.22.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.22.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.23.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.23.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.23.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.23.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.23.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.23.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.23.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.23.output.LayerNorm: 2,048 (trainable)
  classifier.layers.0: 1,049,600 (trainable)
  classifier.layers.1.projection: 2,099,200 (trainable)
  classifier.layers.3: 1,049,600 (trainable)
  classifier.layers.6: 3,075 (trainable)

Total layers: 200
Trainable layers: 200
Total parameters: 338,293,763
Trainable parameters: 338,293,763
Percentage of trainable parameters: 100.00%
Using optimizer: AdamW, Use Zero: True, Learning Rate: 1e-05, L2 strength: 0.01
Using scheduler: CosineAnnealingWarmRestarts
Scheduler arguments:
- T_0: 5
- T_mult: 1
- eta_min: 1e-07

Starting training loop...
Start epoch: 1, Max Iterations: 100, Early Stop: score, Tolerance: 0.00001, Number Iterations No Change: 100
Epoch 1/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [18:49<00:00,  1.05s/it, loss=1.7345, lr=9.06e-06, grad=M:1.0565, status=Computing train metrics...]^C
Ctrl+C received. Terminating all processes...
Rank 0 - Current process: MainProcess cleaning up...
Terminating all child processes of MainProcess...
Terminated child process: SpawnProcess-6
Terminated child process: SpawnProcess-8

KeyboardInterrupt received. Terminating all processes...
Terminated child process: SpawnProcess-5
Terminated child process: SpawnProcess-4
Terminated child process: SpawnProcess-2
Terminated child process: SpawnProcess-7
Terminated child process: SpawnProcess-1
Terminated child process: SpawnProcess-3
Rank 0 - Exiting program...
/usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
(nlp) ubuntu@192-18-129-105:~/nlp-ca/sentiment$ logout
Connection to 192.18.129.105 closed.
(base) Jims-MBP:multiclass jim$ ssh ubuntu@138.2.58.218
The authenticity of host '138.2.58.218 (138.2.58.218)' can't be established.
ED25519 key fingerprint is SHA256:1ImgxEg42Dvu0iUQIqbpYC7+T1RhkIRuPWumRU29RRo.
This key is not known by any other names
Are you sure you want to continue connecting (yes/no/[fingerprint])? yes
Warning: Permanently added '138.2.58.218' (ED25519) to the list of known hosts.
Enter passphrase for key '/Users/jim/.ssh/id_rsa': 
Welcome to Ubuntu 22.04.5 LTS (GNU/Linux 6.8.0-47-generic x86_64)
 .============.
 ||   __      ||    _                    _         _
 ||   \_\     ||   | |    __ _ _ __ ___ | |__   __| | __ _
 ||    \_\    ||   | |   / _` | '_ ` _ \| '_ \ / _` |/ _` |
 ||   /_Î»_\   ||   | |__| (_| | | | | | | |_) | (_| | (_| |
 ||  /_/ \_\  ||   |_____\__,_|_| |_| |_|_.__/ \__,_|\__,_|
  .============.                                  GPU CLOUD

ubuntu@138-2-58-218:~$ cd nlp-osaka/
ubuntu@138-2-58-218:~/nlp-osaka$ ls
ubuntu@138-2-58-218:~/nlp-osaka$ git clone https://github.com/jbeno/sentiment.git
Cloning into 'sentiment'...
Username for 'https://github.com': jim@jimbeno.net
Password for 'https://jim@jimbeno.net@github.com': 
remote: Enumerating objects: 219, done.
remote: Counting objects: 100% (219/219), done.
remote: Compressing objects: 100% (130/130), done.
remote: Total 219 (delta 134), reused 169 (delta 85), pack-reused 0 (from 0)
Receiving objects: 100% (219/219), 19.23 MiB | 12.22 MiB/s, done.
Resolving deltas: 100% (134/134), done.
Updating files: 100% (38/38), done.
ubuntu@138-2-58-218:~/nlp-osaka$ cd sentiment/
ubuntu@138-2-58-218:~/nlp-osaka/sentiment$ python -m venv nlp
ubuntu@138-2-58-218:~/nlp-osaka/sentiment$ source nlp/bin/activate
(nlp) ubuntu@138-2-58-218:~/nlp-osaka/sentiment$ vi requirements.txt
(nlp) ubuntu@138-2-58-218:~/nlp-osaka/sentiment$ ls -alt
total 62411
drwxrwxr-x 5 ubuntu ubuntu       22 Oct 23 23:33 .
drwxrwxr-x 5 ubuntu ubuntu        5 Oct 23 23:33 nlp
drwxrwxr-x 8 ubuntu ubuntu       11 Oct 23 23:32 .git
-rw-rw-r-- 1 ubuntu ubuntu    29629 Oct 23 23:32 utils.py
-rw-rw-r-- 1 ubuntu ubuntu     6388 Oct 23 23:32 torch_shallow_neural_classifier.py
-rw-rw-r-- 1 ubuntu ubuntu    25766 Oct 23 23:32 torch_model_base.py
-rw-rw-r-- 1 ubuntu ubuntu    24655 Oct 23 23:32 torch_ddp_neural_classifier.py
-rw-rw-r-- 1 ubuntu ubuntu    84983 Oct 23 23:32 torch_ddp_finetune_neural_classifier.py
-rw-rw-r-- 1 ubuntu ubuntu     3923 Oct 23 23:32 test_input.py
-rw-rw-r-- 1 ubuntu ubuntu   385017 Oct 23 23:32 test.ipynb
-rw-rw-r-- 1 ubuntu ubuntu    14479 Oct 23 23:32 sst.py
-rw-rw-r-- 1 ubuntu ubuntu      486 Oct 23 23:32 requirements.txt
-rw-rw-r-- 1 ubuntu ubuntu  5355444 Oct 23 23:32 dspy_sentiment_final.ipynb
-rw-rw-r-- 1 ubuntu ubuntu 54823062 Oct 23 23:32 dspy_sentiment.ipynb
-rw-rw-r-- 1 ubuntu ubuntu    83119 Oct 23 23:32 ddp_sentiment_finetune.py
-rw-rw-r-- 1 ubuntu ubuntu    42737 Oct 23 23:32 ddp_sentiment.py
-rw-rw-r-- 1 ubuntu ubuntu    42657 Oct 23 23:32 datawaza_funcs.py
-rw-rw-r-- 1 ubuntu ubuntu   106239 Oct 23 23:32 data_processing.ipynb
drwxrwxr-x 5 ubuntu ubuntu        3 Oct 23 23:32 data
-rw-rw-r-- 1 ubuntu ubuntu     2166 Oct 23 23:32 compare.py
-rw-rw-r-- 1 ubuntu ubuntu     6706 Oct 23 23:32 colors.py
-rw-rw-r-- 1 ubuntu ubuntu       39 Oct 23 23:32 README.md
-rw-rw-r-- 1 ubuntu ubuntu       65 Oct 23 23:32 .gitignore
drwxr-xr-x 3 ubuntu ubuntu        1 Oct 23 23:32 ..
(nlp) ubuntu@138-2-58-218:~/nlp-osaka/sentiment$ more requirements.txt 
numpy>=1.20.0
scipy>=1.7.0
matplotlib>=3.7.0
scikit-learn>=1.0.2
nltk>=3.7
pytest>=7.1
jupyter>=1.0.0
pandas>=1.5
# uncomment the following line to install pytorch and torchvision
torch>=2.2.0; sys_platform != "linux" and sys_platform != "win32"
torch>=2.2.0+${DEVICE}; sys_platform == "linux" or sys_platform == "win32"
torchvision==0.16.2
torchaudio==2.1.2
transformers>=4.38.0
datasets==2.14.6
spacy==3.7.2
dspy-ai==2.3.1
# dependencies for dspy-ai
openai<=0.28.1
python-dotenv
wget
(nlp) ubuntu@138-2-58-218:~/nlp-osaka/sentiment$ vi requirements.txt 
(nlp) ubuntu@138-2-58-218:~/nlp-osaka/sentiment$ pip install -r requirements.txt
Collecting numpy>=1.20.0
  Downloading numpy-2.1.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.3 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 16.3/16.3 MB 82.7 MB/s eta 0:00:00
Collecting scipy>=1.7.0
  Downloading scipy-1.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (41.2 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 41.2/41.2 MB 46.8 MB/s eta 0:00:00
Collecting matplotlib>=3.7.0
  Downloading matplotlib-3.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 8.3/8.3 MB 108.8 MB/s eta 0:00:00
Collecting scikit-learn>=1.0.2
  Downloading scikit_learn-1.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 13.3/13.3 MB 98.0 MB/s eta 0:00:00
Collecting nltk>=3.7
  Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1.5/1.5 MB 103.6 MB/s eta 0:00:00
Collecting pytest>=7.1
  Downloading pytest-8.3.3-py3-none-any.whl (342 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 342.3/342.3 KB 69.0 MB/s eta 0:00:00
Collecting jupyter>=1.0.0
  Using cached jupyter-1.1.1-py2.py3-none-any.whl (2.7 kB)
Collecting pandas>=1.5
  Downloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 13.1/13.1 MB 114.7 MB/s eta 0:00:00
Collecting torch==2.1.2
  Downloading torch-2.1.2-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 670.2/670.2 MB 3.4 MB/s eta 0:00:00
Collecting torchvision==0.16.2
  Downloading torchvision-0.16.2-cp310-cp310-manylinux1_x86_64.whl (6.8 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 6.8/6.8 MB 31.0 MB/s eta 0:00:00
Collecting torchaudio==2.1.2
  Downloading torchaudio-2.1.2-cp310-cp310-manylinux1_x86_64.whl (3.3 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 3.3/3.3 MB 120.5 MB/s eta 0:00:00
Collecting transformers>=4.38.0
  Downloading transformers-4.45.2-py3-none-any.whl (9.9 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 9.9/9.9 MB 114.8 MB/s eta 0:00:00
Collecting datasets==2.14.6
  Downloading datasets-2.14.6-py3-none-any.whl (493 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 493.7/493.7 KB 78.0 MB/s eta 0:00:00
Collecting spacy==3.7.2
  Downloading spacy-3.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.6 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 6.6/6.6 MB 123.4 MB/s eta 0:00:00
Collecting dspy-ai==2.3.1
  Downloading dspy_ai-2.3.1-py3-none-any.whl (164 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 164.8/164.8 KB 40.9 MB/s eta 0:00:00
Collecting openai<=0.28.1
  Downloading openai-0.28.1-py3-none-any.whl (76 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 77.0/77.0 KB 24.6 MB/s eta 0:00:00
Collecting python-dotenv
  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)
Collecting wget
  Downloading wget-3.2.zip (10 kB)
  Preparing metadata (setup.py) ... done
Collecting nvidia-cusolver-cu12==11.4.5.107
  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 124.2/124.2 MB 18.7 MB/s eta 0:00:00
Collecting nvidia-nccl-cu12==2.18.1
  Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 209.8/209.8 MB 10.2 MB/s eta 0:00:00
Collecting nvidia-nvtx-cu12==12.1.105
  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 99.1/99.1 KB 24.9 MB/s eta 0:00:00
Collecting fsspec
  Downloading fsspec-2024.10.0-py3-none-any.whl (179 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 179.6/179.6 KB 44.2 MB/s eta 0:00:00
Collecting jinja2
  Using cached jinja2-3.1.4-py3-none-any.whl (133 kB)
Collecting nvidia-cuda-cupti-cu12==12.1.105
  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 14.1/14.1 MB 96.6 MB/s eta 0:00:00
Collecting nvidia-cudnn-cu12==8.9.2.26
  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 731.7/731.7 MB 3.7 MB/s eta 0:00:00
Collecting nvidia-cublas-cu12==12.1.3.1
  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 410.6/410.6 MB 6.4 MB/s eta 0:00:00
Collecting sympy
  Downloading sympy-1.13.3-py3-none-any.whl (6.2 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 6.2/6.2 MB 113.9 MB/s eta 0:00:00
Collecting typing-extensions
  Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)
Collecting nvidia-cuda-runtime-cu12==12.1.105
  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 823.6/823.6 KB 88.1 MB/s eta 0:00:00
Collecting nvidia-cufft-cu12==11.0.2.54
  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 121.6/121.6 MB 18.7 MB/s eta 0:00:00
Collecting nvidia-curand-cu12==10.3.2.106
  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 56.5/56.5 MB 37.0 MB/s eta 0:00:00
Collecting nvidia-cusparse-cu12==12.1.0.106
  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 196.0/196.0 MB 12.8 MB/s eta 0:00:00
Collecting triton==2.1.0
  Downloading triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 89.2/89.2 MB 13.9 MB/s eta 0:00:00
Collecting networkx
  Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1.7/1.7 MB 95.2 MB/s eta 0:00:00
Collecting nvidia-cuda-nvrtc-cu12==12.1.105
  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 23.7/23.7 MB 68.0 MB/s eta 0:00:00
Collecting filelock
  Downloading filelock-3.16.1-py3-none-any.whl (16 kB)
Collecting requests
  Using cached requests-2.32.3-py3-none-any.whl (64 kB)
Collecting pillow!=8.3.*,>=5.3.0
  Downloading pillow-11.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.4 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 4.4/4.4 MB 117.6 MB/s eta 0:00:00
Collecting pyyaml>=5.1
  Using cached PyYAML-6.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (751 kB)
Collecting fsspec[http]<=2023.10.0,>=2023.1.0
  Downloading fsspec-2023.10.0-py3-none-any.whl (166 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 166.4/166.4 KB 35.8 MB/s eta 0:00:00
Collecting pyarrow>=8.0.0
  Downloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (39.9 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 39.9/39.9 MB 47.6 MB/s eta 0:00:00
Collecting dill<0.3.8,>=0.3.0
  Downloading dill-0.3.7-py3-none-any.whl (115 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 115.3/115.3 KB 29.8 MB/s eta 0:00:00
Collecting packaging
  Using cached packaging-24.1-py3-none-any.whl (53 kB)
Collecting aiohttp
  Downloading aiohttp-3.10.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1.2/1.2 MB 96.6 MB/s eta 0:00:00
Collecting xxhash
  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 194.1/194.1 KB 43.6 MB/s eta 0:00:00
Collecting multiprocess
  Downloading multiprocess-0.70.17-py310-none-any.whl (134 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 134.8/134.8 KB 29.9 MB/s eta 0:00:00
Collecting huggingface-hub<1.0.0,>=0.14.0
  Downloading huggingface_hub-0.26.1-py3-none-any.whl (447 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 447.4/447.4 KB 68.8 MB/s eta 0:00:00
Collecting tqdm>=4.62.1
  Downloading tqdm-4.66.5-py3-none-any.whl (78 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 78.4/78.4 KB 21.1 MB/s eta 0:00:00
Collecting pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4
  Downloading pydantic-2.9.2-py3-none-any.whl (434 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 434.9/434.9 KB 63.5 MB/s eta 0:00:00
Collecting spacy-legacy<3.1.0,>=3.0.11
  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)
Collecting weasel<0.4.0,>=0.1.0
  Downloading weasel-0.3.4-py3-none-any.whl (50 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 50.1/50.1 KB 15.7 MB/s eta 0:00:00
Collecting catalogue<2.1.0,>=2.0.6
  Downloading catalogue-2.0.10-py3-none-any.whl (17 kB)
Collecting cymem<2.1.0,>=2.0.2
  Downloading cymem-2.0.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (46 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 46.1/46.1 KB 14.7 MB/s eta 0:00:00
Collecting murmurhash<1.1.0,>=0.28.0
  Downloading murmurhash-1.0.10-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29 kB)
Collecting spacy-loggers<2.0.0,>=1.0.0
  Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)
Requirement already satisfied: setuptools in ./nlp/lib/python3.10/site-packages (from spacy==3.7.2->-r requirements.txt (line 17)) (59.6.0)
Collecting wasabi<1.2.0,>=0.9.1
  Downloading wasabi-1.1.3-py3-none-any.whl (27 kB)
Collecting smart-open<7.0.0,>=5.2.1
  Downloading smart_open-6.4.0-py3-none-any.whl (57 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 57.0/57.0 KB 14.9 MB/s eta 0:00:00
Collecting langcodes<4.0.0,>=3.2.0
  Downloading langcodes-3.4.1-py3-none-any.whl (182 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 182.4/182.4 KB 42.0 MB/s eta 0:00:00
Collecting srsly<3.0.0,>=2.4.3
  Downloading srsly-2.4.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (493 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 493.0/493.0 KB 76.2 MB/s eta 0:00:00
Collecting thinc<8.3.0,>=8.1.8
  Downloading thinc-8.2.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (922 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 922.4/922.4 KB 34.3 MB/s eta 0:00:00
Collecting preshed<3.1.0,>=3.0.2
  Downloading preshed-3.0.9-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (156 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 156.9/156.9 KB 37.0 MB/s eta 0:00:00
Collecting typer<0.10.0,>=0.3.0
  Downloading typer-0.9.4-py3-none-any.whl (45 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 46.0/46.0 KB 13.4 MB/s eta 0:00:00
Collecting optuna
  Downloading optuna-4.0.0-py3-none-any.whl (362 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 362.8/362.8 KB 68.0 MB/s eta 0:00:00
Collecting joblib~=1.3.2
  Downloading joblib-1.3.2-py3-none-any.whl (302 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 302.2/302.2 KB 60.1 MB/s eta 0:00:00
Collecting regex
  Downloading regex-2024.9.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (782 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 782.7/782.7 KB 83.3 MB/s eta 0:00:00
Collecting ujson
  Downloading ujson-5.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 53.6/53.6 KB 14.5 MB/s eta 0:00:00
Collecting backoff~=2.2.1
  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)
Collecting nvidia-nvjitlink-cu12
  Downloading nvidia_nvjitlink_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (19.7 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 19.7/19.7 MB 88.4 MB/s eta 0:00:00
Collecting contourpy>=1.0.1
  Downloading contourpy-1.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (322 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 322.0/322.0 KB 62.2 MB/s eta 0:00:00
Collecting fonttools>=4.22.0
  Downloading fonttools-4.54.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 4.6/4.6 MB 118.5 MB/s eta 0:00:00
Collecting kiwisolver>=1.3.1
  Downloading kiwisolver-1.4.7-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1.6/1.6 MB 105.2 MB/s eta 0:00:00
Collecting python-dateutil>=2.7
  Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)
Collecting cycler>=0.10
  Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)
Collecting pyparsing>=2.3.1
  Downloading pyparsing-3.2.0-py3-none-any.whl (106 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 106.9/106.9 KB 29.3 MB/s eta 0:00:00
Collecting threadpoolctl>=3.1.0
  Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)
Collecting click
  Downloading click-8.1.7-py3-none-any.whl (97 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 97.9/97.9 KB 27.3 MB/s eta 0:00:00
Collecting iniconfig
  Downloading iniconfig-2.0.0-py3-none-any.whl (5.9 kB)
Collecting exceptiongroup>=1.0.0rc8
  Using cached exceptiongroup-1.2.2-py3-none-any.whl (16 kB)
Collecting tomli>=1
  Using cached tomli-2.0.2-py3-none-any.whl (13 kB)
Collecting pluggy<2,>=1.5
  Downloading pluggy-1.5.0-py3-none-any.whl (20 kB)
Collecting jupyterlab
  Using cached jupyterlab-4.2.5-py3-none-any.whl (11.6 MB)
Collecting ipywidgets
  Using cached ipywidgets-8.1.5-py3-none-any.whl (139 kB)
Collecting notebook
  Using cached notebook-7.2.2-py3-none-any.whl (5.0 MB)
Collecting nbconvert
  Using cached nbconvert-7.16.4-py3-none-any.whl (257 kB)
Collecting jupyter-console
  Using cached jupyter_console-6.6.3-py3-none-any.whl (24 kB)
Collecting ipykernel
  Using cached ipykernel-6.29.5-py3-none-any.whl (117 kB)
Collecting pytz>=2020.1
  Downloading pytz-2024.2-py2.py3-none-any.whl (508 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 508.0/508.0 KB 75.1 MB/s eta 0:00:00
Collecting tzdata>=2022.7
  Downloading tzdata-2024.2-py2.py3-none-any.whl (346 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 346.6/346.6 KB 60.8 MB/s eta 0:00:00
Collecting tokenizers<0.21,>=0.20
  Downloading tokenizers-0.20.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 3.0/3.0 MB 119.6 MB/s eta 0:00:00
Collecting safetensors>=0.4.1
  Downloading safetensors-0.4.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (435 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 435.0/435.0 KB 68.9 MB/s eta 0:00:00
Collecting attrs>=17.3.0
  Using cached attrs-24.2.0-py3-none-any.whl (63 kB)
Collecting async-timeout<5.0,>=4.0
  Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)
Collecting multidict<7.0,>=4.5
  Downloading multidict-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 124.6/124.6 KB 33.0 MB/s eta 0:00:00
Collecting frozenlist>=1.1.1
  Downloading frozenlist-1.5.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (241 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 241.9/241.9 KB 52.3 MB/s eta 0:00:00
Collecting yarl<2.0,>=1.12.0
  Downloading yarl-1.16.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 318.1/318.1 KB 57.4 MB/s eta 0:00:00
Collecting aiosignal>=1.1.2
  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)
Collecting aiohappyeyeballs>=2.3.0
  Downloading aiohappyeyeballs-2.4.3-py3-none-any.whl (14 kB)
Collecting language-data>=1.2
  Downloading language_data-1.2.0-py3-none-any.whl (5.4 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 5.4/5.4 MB 121.3 MB/s eta 0:00:00
Collecting annotated-types>=0.6.0
  Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)
Collecting pydantic-core==2.23.4
  Downloading pydantic_core-2.23.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2.1/2.1 MB 25.2 MB/s eta 0:00:00
Collecting six>=1.5
  Using cached six-1.16.0-py2.py3-none-any.whl (11 kB)
Collecting urllib3<3,>=1.21.1
  Using cached urllib3-2.2.3-py3-none-any.whl (126 kB)
Collecting idna<4,>=2.5
  Using cached idna-3.10-py3-none-any.whl (70 kB)
Collecting charset-normalizer<4,>=2
  Using cached charset_normalizer-3.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)
Collecting certifi>=2017.4.17
  Using cached certifi-2024.8.30-py3-none-any.whl (167 kB)
Collecting confection<1.0.0,>=0.0.1
  Downloading confection-0.1.5-py3-none-any.whl (35 kB)
Collecting blis<0.8.0,>=0.7.8
  Downloading blis-0.7.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.2 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 10.2/10.2 MB 24.9 MB/s eta 0:00:00
Collecting numpy>=1.20.0
  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 18.2/18.2 MB 91.4 MB/s eta 0:00:00
Collecting cloudpathlib<0.17.0,>=0.7.0
  Downloading cloudpathlib-0.16.0-py3-none-any.whl (45 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 45.0/45.0 KB 14.5 MB/s eta 0:00:00
Collecting ipython>=7.23.1
  Using cached ipython-8.28.0-py3-none-any.whl (819 kB)
Collecting jupyter-core!=5.0.*,>=4.12
  Using cached jupyter_core-5.7.2-py3-none-any.whl (28 kB)
Collecting psutil
  Downloading psutil-6.1.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (287 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 287.3/287.3 KB 53.2 MB/s eta 0:00:00
Collecting traitlets>=5.4.0
  Using cached traitlets-5.14.3-py3-none-any.whl (85 kB)
Collecting matplotlib-inline>=0.1
  Using cached matplotlib_inline-0.1.7-py3-none-any.whl (9.9 kB)
Collecting nest-asyncio
  Using cached nest_asyncio-1.6.0-py3-none-any.whl (5.2 kB)
Collecting jupyter-client>=6.1.12
  Using cached jupyter_client-8.6.3-py3-none-any.whl (106 kB)
Collecting tornado>=6.1
  Using cached tornado-6.4.1-cp38-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (436 kB)
Collecting comm>=0.1.1
  Using cached comm-0.2.2-py3-none-any.whl (7.2 kB)
Collecting pyzmq>=24
  Using cached pyzmq-26.2.0-cp310-cp310-manylinux_2_28_x86_64.whl (868 kB)
Collecting debugpy>=1.6.5
  Using cached debugpy-1.8.7-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.5 MB)
Collecting jupyterlab-widgets~=3.0.12
  Using cached jupyterlab_widgets-3.0.13-py3-none-any.whl (214 kB)
Collecting widgetsnbextension~=4.0.12
  Using cached widgetsnbextension-4.0.13-py3-none-any.whl (2.3 MB)
Collecting MarkupSafe>=2.0
  Downloading MarkupSafe-3.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20 kB)
Collecting pygments
  Using cached pygments-2.18.0-py3-none-any.whl (1.2 MB)
Collecting prompt-toolkit>=3.0.30
  Using cached prompt_toolkit-3.0.48-py3-none-any.whl (386 kB)
Collecting async-lru>=1.0.0
  Using cached async_lru-2.0.4-py3-none-any.whl (6.1 kB)
Collecting jupyter-lsp>=2.0.0
  Using cached jupyter_lsp-2.2.5-py3-none-any.whl (69 kB)
Collecting jupyterlab-server<3,>=2.27.1
  Using cached jupyterlab_server-2.27.3-py3-none-any.whl (59 kB)
Collecting jupyter-server<3,>=2.4.0
  Using cached jupyter_server-2.14.2-py3-none-any.whl (383 kB)
Collecting notebook-shim>=0.2
  Using cached notebook_shim-0.2.4-py3-none-any.whl (13 kB)
Collecting httpx>=0.25.0
  Using cached httpx-0.27.2-py3-none-any.whl (76 kB)
Collecting multiprocess
  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 134.8/134.8 KB 29.6 MB/s eta 0:00:00
  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 134.8/134.8 KB 31.7 MB/s eta 0:00:00
Collecting jupyterlab-pygments
  Using cached jupyterlab_pygments-0.3.0-py3-none-any.whl (15 kB)
Collecting pandocfilters>=1.4.1
  Using cached pandocfilters-1.5.1-py2.py3-none-any.whl (8.7 kB)
Collecting bleach!=5.0.0
  Using cached bleach-6.1.0-py3-none-any.whl (162 kB)
Collecting nbformat>=5.7
  Using cached nbformat-5.10.4-py3-none-any.whl (78 kB)
Collecting defusedxml
  Using cached defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)
Collecting beautifulsoup4
  Using cached beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)
Collecting tinycss2
  Using cached tinycss2-1.3.0-py3-none-any.whl (22 kB)
Collecting nbclient>=0.5.0
  Using cached nbclient-0.10.0-py3-none-any.whl (25 kB)
Collecting mistune<4,>=2.0.3
  Using cached mistune-3.0.2-py3-none-any.whl (47 kB)
Collecting colorlog
  Downloading colorlog-6.8.2-py3-none-any.whl (11 kB)
Collecting alembic>=1.5.0
  Downloading alembic-1.13.3-py3-none-any.whl (233 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 233.2/233.2 KB 50.2 MB/s eta 0:00:00
Collecting sqlalchemy>=1.3.0
  Downloading SQLAlchemy-2.0.36-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 3.1/3.1 MB 109.8 MB/s eta 0:00:00
Collecting mpmath<1.4,>=1.1.0
  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 536.2/536.2 KB 70.8 MB/s eta 0:00:00
Collecting Mako
  Downloading Mako-1.3.6-py3-none-any.whl (78 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 78.6/78.6 KB 20.0 MB/s eta 0:00:00
Collecting webencodings
  Using cached webencodings-0.5.1-py2.py3-none-any.whl (11 kB)
Collecting httpcore==1.*
  Using cached httpcore-1.0.6-py3-none-any.whl (78 kB)
Collecting sniffio
  Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)
Collecting anyio
  Using cached anyio-4.6.2.post1-py3-none-any.whl (90 kB)
Collecting h11<0.15,>=0.13
  Using cached h11-0.14.0-py3-none-any.whl (58 kB)
Collecting pexpect>4.3
  Using cached pexpect-4.9.0-py2.py3-none-any.whl (63 kB)
Collecting stack-data
  Using cached stack_data-0.6.3-py3-none-any.whl (24 kB)
Collecting decorator
  Using cached decorator-5.1.1-py3-none-any.whl (9.1 kB)
Collecting jedi>=0.16
  Using cached jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)
Collecting platformdirs>=2.5
  Using cached platformdirs-4.3.6-py3-none-any.whl (18 kB)
Collecting send2trash>=1.8.2
  Using cached Send2Trash-1.8.3-py3-none-any.whl (18 kB)
Collecting overrides>=5.0
  Using cached overrides-7.7.0-py3-none-any.whl (17 kB)
Collecting jupyter-events>=0.9.0
  Using cached jupyter_events-0.10.0-py3-none-any.whl (18 kB)
Collecting argon2-cffi>=21.1
  Using cached argon2_cffi-23.1.0-py3-none-any.whl (15 kB)
Collecting jupyter-server-terminals>=0.4.4
  Using cached jupyter_server_terminals-0.5.3-py3-none-any.whl (13 kB)
Collecting terminado>=0.8.3
  Using cached terminado-0.18.1-py3-none-any.whl (14 kB)
Collecting websocket-client>=1.7
  Using cached websocket_client-1.8.0-py3-none-any.whl (58 kB)
Collecting prometheus-client>=0.9
  Using cached prometheus_client-0.21.0-py3-none-any.whl (54 kB)
Collecting jsonschema>=4.18.0
  Using cached jsonschema-4.23.0-py3-none-any.whl (88 kB)
Collecting json5>=0.9.0
  Using cached json5-0.9.25-py3-none-any.whl (30 kB)
Collecting babel>=2.10
  Using cached babel-2.16.0-py3-none-any.whl (9.6 MB)
Collecting marisa-trie>=0.7.7
  Downloading marisa_trie-1.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1.3/1.3 MB 44.6 MB/s eta 0:00:00
Collecting fastjsonschema>=2.15
  Using cached fastjsonschema-2.20.0-py3-none-any.whl (23 kB)
Collecting wcwidth
  Using cached wcwidth-0.2.13-py2.py3-none-any.whl (34 kB)
Collecting greenlet!=0.4.17
  Downloading greenlet-3.1.1-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (599 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 599.5/599.5 KB 77.8 MB/s eta 0:00:00
Collecting propcache>=0.2.0
  Downloading propcache-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (208 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 208.9/208.9 KB 49.9 MB/s eta 0:00:00
Collecting soupsieve>1.2
  Using cached soupsieve-2.6-py3-none-any.whl (36 kB)
Collecting argon2-cffi-bindings
  Using cached argon2_cffi_bindings-21.2.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (86 kB)
Collecting parso<0.9.0,>=0.8.3
  Using cached parso-0.8.4-py2.py3-none-any.whl (103 kB)
Collecting referencing>=0.28.4
  Using cached referencing-0.35.1-py3-none-any.whl (26 kB)
Collecting jsonschema-specifications>=2023.03.6
  Using cached jsonschema_specifications-2024.10.1-py3-none-any.whl (18 kB)
Collecting rpds-py>=0.7.1
  Using cached rpds_py-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (354 kB)
Collecting python-json-logger>=2.0.4
  Using cached python_json_logger-2.0.7-py3-none-any.whl (8.1 kB)
Collecting rfc3339-validator
  Using cached rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)
Collecting rfc3986-validator>=0.1.1
  Using cached rfc3986_validator-0.1.1-py2.py3-none-any.whl (4.2 kB)
Collecting ptyprocess>=0.5
  Using cached ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB)
Collecting pure-eval
  Using cached pure_eval-0.2.3-py3-none-any.whl (11 kB)
Collecting executing>=1.2.0
  Using cached executing-2.1.0-py2.py3-none-any.whl (25 kB)
Collecting asttokens>=2.1.0
  Using cached asttokens-2.4.1-py2.py3-none-any.whl (27 kB)
Collecting uri-template
  Using cached uri_template-1.3.0-py3-none-any.whl (11 kB)
Collecting fqdn
  Using cached fqdn-1.5.1-py3-none-any.whl (9.1 kB)
Collecting isoduration
  Using cached isoduration-20.11.0-py3-none-any.whl (11 kB)
Collecting webcolors>=24.6.0
  Using cached webcolors-24.8.0-py3-none-any.whl (15 kB)
Collecting jsonpointer>1.13
  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)
Collecting cffi>=1.0.1
  Using cached cffi-1.17.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (446 kB)
Collecting pycparser
  Using cached pycparser-2.22-py3-none-any.whl (117 kB)
Collecting arrow>=0.15.0
  Using cached arrow-1.3.0-py3-none-any.whl (66 kB)
Collecting types-python-dateutil>=2.8.10
  Using cached types_python_dateutil-2.9.0.20241003-py3-none-any.whl (9.7 kB)
Using legacy 'setup.py install' for wget, since package 'wheel' is not installed.
Installing collected packages: wget, webencodings, wcwidth, pytz, pure-eval, ptyprocess, mpmath, fastjsonschema, cymem, xxhash, widgetsnbextension, websocket-client, webcolors, wasabi, urllib3, uri-template, ujson, tzdata, typing-extensions, types-python-dateutil, traitlets, tqdm, tornado, tomli, tinycss2, threadpoolctl, sympy, spacy-loggers, spacy-legacy, soupsieve, sniffio, smart-open, six, send2trash, safetensors, rpds-py, rfc3986-validator, regex, pyzmq, pyyaml, python-json-logger, python-dotenv, pyparsing, pygments, pycparser, psutil, propcache, prompt-toolkit, prometheus-client, pluggy, platformdirs, pillow, pexpect, parso, pandocfilters, packaging, overrides, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, nest-asyncio, murmurhash, mistune, MarkupSafe, marisa-trie, kiwisolver, jupyterlab-widgets, jupyterlab-pygments, jsonpointer, json5, joblib, iniconfig, idna, h11, greenlet, fsspec, frozenlist, fqdn, fonttools, filelock, executing, exceptiongroup, dill, defusedxml, decorator, debugpy, cycler, colorlog, click, charset-normalizer, certifi, catalogue, backoff, babel, attrs, async-timeout, annotated-types, aiohappyeyeballs, typer, triton, terminado, srsly, sqlalchemy, scipy, rfc3339-validator, requests, referencing, python-dateutil, pytest, pydantic-core, pyarrow, preshed, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nltk, multiprocess, multidict, matplotlib-inline, Mako, language-data, jupyter-core, jinja2, jedi, httpcore, contourpy, comm, cloudpathlib, cffi, blis, bleach, beautifulsoup4, async-lru, asttokens, anyio, aiosignal, yarl, stack-data, scikit-learn, pydantic, pandas, nvidia-cusolver-cu12, matplotlib, langcodes, jupyter-server-terminals, jupyter-client, jsonschema-specifications, huggingface-hub, httpx, arrow, argon2-cffi-bindings, alembic, torch, tokenizers, optuna, jsonschema, isoduration, ipython, confection, argon2-cffi, aiohttp, weasel, transformers, torchvision, torchaudio, thinc, openai, nbformat, ipywidgets, ipykernel, spacy, nbclient, jupyter-events, jupyter-console, datasets, nbconvert, dspy-ai, jupyter-server, notebook-shim, jupyterlab-server, jupyter-lsp, jupyterlab, notebook, jupyter
  Running setup.py install for wget ... done





Successfully installed Mako-1.3.6 MarkupSafe-3.0.2 aiohappyeyeballs-2.4.3 aiohttp-3.10.10 aiosignal-1.3.1 alembic-1.13.3 annotated-types-0.7.0 anyio-4.6.2.post1 argon2-cffi-23.1.0 argon2-cffi-bindings-21.2.0 arrow-1.3.0 asttokens-2.4.1 async-lru-2.0.4 async-timeout-4.0.3 attrs-24.2.0 babel-2.16.0 backoff-2.2.1 beautifulsoup4-4.12.3 bleach-6.1.0 blis-0.7.11 catalogue-2.0.10 certifi-2024.8.30 cffi-1.17.1 charset-normalizer-3.4.0 click-8.1.7 cloudpathlib-0.16.0 colorlog-6.8.2 comm-0.2.2 confection-0.1.5 contourpy-1.3.0 cycler-0.12.1 cymem-2.0.8 datasets-2.14.6 debugpy-1.8.7 decorator-5.1.1 defusedxml-0.7.1 dill-0.3.7 dspy-ai-2.3.1 exceptiongroup-1.2.2 executing-2.1.0 fastjsonschema-2.20.0 filelock-3.16.1 fonttools-4.54.1 fqdn-1.5.1 frozenlist-1.5.0 fsspec-2023.10.0 greenlet-3.1.1 h11-0.14.0 httpcore-1.0.6 httpx-0.27.2 huggingface-hub-0.26.1 idna-3.10 iniconfig-2.0.0 ipykernel-6.29.5 ipython-8.28.0 ipywidgets-8.1.5 isoduration-20.11.0 jedi-0.19.1 jinja2-3.1.4 joblib-1.3.2 json5-0.9.25 jsonpointer-3.0.0 jsonschema-4.23.0 jsonschema-specifications-2024.10.1 jupyter-1.1.1 jupyter-client-8.6.3 jupyter-console-6.6.3 jupyter-core-5.7.2 jupyter-events-0.10.0 jupyter-lsp-2.2.5 jupyter-server-2.14.2 jupyter-server-terminals-0.5.3 jupyterlab-4.2.5 jupyterlab-pygments-0.3.0 jupyterlab-server-2.27.3 jupyterlab-widgets-3.0.13 kiwisolver-1.4.7 langcodes-3.4.1 language-data-1.2.0 marisa-trie-1.2.1 matplotlib-3.9.2 matplotlib-inline-0.1.7 mistune-3.0.2 mpmath-1.3.0 multidict-6.1.0 multiprocess-0.70.15 murmurhash-1.0.10 nbclient-0.10.0 nbconvert-7.16.4 nbformat-5.10.4 nest-asyncio-1.6.0 networkx-3.4.2 nltk-3.9.1 notebook-7.2.2 notebook-shim-0.2.4 numpy-1.26.4 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvjitlink-cu12-12.6.77 nvidia-nvtx-cu12-12.1.105 openai-0.28.1 optuna-4.0.0 overrides-7.7.0 packaging-24.1 pandas-2.2.3 pandocfilters-1.5.1 parso-0.8.4 pexpect-4.9.0 pillow-11.0.0 platformdirs-4.3.6 pluggy-1.5.0 preshed-3.0.9 prometheus-client-0.21.0 prompt-toolkit-3.0.48 propcache-0.2.0 psutil-6.1.0 ptyprocess-0.7.0 pure-eval-0.2.3 pyarrow-17.0.0 pycparser-2.22 pydantic-2.9.2 pydantic-core-2.23.4 pygments-2.18.0 pyparsing-3.2.0 pytest-8.3.3 python-dateutil-2.9.0.post0 python-dotenv-1.0.1 python-json-logger-2.0.7 pytz-2024.2 pyyaml-6.0.2 pyzmq-26.2.0 referencing-0.35.1 regex-2024.9.11 requests-2.32.3 rfc3339-validator-0.1.4 rfc3986-validator-0.1.1 rpds-py-0.20.0 safetensors-0.4.5 scikit-learn-1.5.2 scipy-1.14.1 send2trash-1.8.3 six-1.16.0 smart-open-6.4.0 sniffio-1.3.1 soupsieve-2.6 spacy-3.7.2 spacy-legacy-3.0.12 spacy-loggers-1.0.5 sqlalchemy-2.0.36 srsly-2.4.8 stack-data-0.6.3 sympy-1.13.3 terminado-0.18.1 thinc-8.2.5 threadpoolctl-3.5.0 tinycss2-1.3.0 tokenizers-0.20.1 tomli-2.0.2 torch-2.1.2 torchaudio-2.1.2 torchvision-0.16.2 tornado-6.4.1 tqdm-4.66.5 traitlets-5.14.3 transformers-4.45.2 triton-2.1.0 typer-0.9.4 types-python-dateutil-2.9.0.20241003 typing-extensions-4.12.2 tzdata-2024.2 ujson-5.10.0 uri-template-1.3.0 urllib3-2.2.3 wasabi-1.1.3 wcwidth-0.2.13 weasel-0.3.4 webcolors-24.8.0 webencodings-0.5.1 websocket-client-1.8.0 wget-3.2 widgetsnbextension-4.0.13 xxhash-3.5.0 yarl-1.16.0
(nlp) ubuntu@138-2-58-218:~/nlp-osaka/sentiment$ 
(nlp) ubuntu@138-2-58-218:~/nlp-osaka/sentiment$ 
(nlp) ubuntu@138-2-58-218:~/nlp-osaka/sentiment$ 
(nlp) ubuntu@138-2-58-218:~/nlp-osaka/sentiment$ 
(nlp) ubuntu@138-2-58-218:~/nlp-osaka/sentiment$ 
(nlp) ubuntu@138-2-58-218:~/nlp-osaka/sentiment$ python ./ddp_sentiment_finetune.py --dataset 'merged_local' --weights_name 'google/electra-large-discriminator' --save_data --save_model --save_pickle --save_preds --lr 0.0002 --lr_decay 0.95 --epochs 50 --pooling 'mean' --dropout_rate 0.3 --num_layers 2 --hidden_dim 1024 --hidden_activation 'swishglu' --batch_size 16 --accumulation_steps 2 --l2_strength 0.0001 --checkpoint_interval 5 --use_zero --optimizer 'adamw' --scheduler 'cosine_warmup' --scheduler_kwargs '{"T_0":5, "T_mult":1, "eta_min":1e-7}' --decimal 6 --use_val_split --eval_split 'test' --early_stop 'score' --n_iter_no_change 50 --show_progress --wandb --wandb_project 'Electra Large' --wandb_run 'run_1_merged_class'
usage: ddp_sentiment_finetune.py [-h] [--dataset DATASET] [--eval_dataset EVAL_DATASET] [--eval_split {validation,test}] [--sample_percent SAMPLE_PERCENT] [--chunk_size CHUNK_SIZE]
                                 [--label_dict LABEL_DICT] [--numeric_dict NUMERIC_DICT] [--label_template LABEL_TEMPLATE] [--pos_label POS_LABEL] [--weights_name WEIGHTS_NAME]
                                 [--pooling POOLING] [--finetune_bert] [--finetune_layers FINETUNE_LAYERS] [--freeze_bert] [--num_layers NUM_LAYERS] [--hidden_dim HIDDEN_DIM]
                                 [--hidden_activation HIDDEN_ACTIVATION] [--dropout_rate DROPOUT_RATE] [--batch_size BATCH_SIZE] [--accumulation_steps ACCUMULATION_STEPS]
                                 [--epochs EPOCHS] [--lr LR] [--optimizer OPTIMIZER] [--use_zero] [--l2_strength L2_STRENGTH] [--optimizer_kwargs OPTIMIZER_KWARGS]
                                 [--scheduler SCHEDULER] [--scheduler_kwargs SCHEDULER_KWARGS] [--max_grad_norm MAX_GRAD_NORM] [--random_seed RANDOM_SEED] [--interactive]
                                 [--show_progress] [--checkpoint_dir CHECKPOINT_DIR] [--checkpoint_interval CHECKPOINT_INTERVAL] [--resume_from_checkpoint] [--early_stop EARLY_STOP]
                                 [--n_iter_no_change N_ITER_NO_CHANGE] [--tol TOL] [--target_score TARGET_SCORE] [--val_percent VAL_PERCENT] [--use_val_split] [--wandb]
                                 [--wandb_project WANDB_PROJECT] [--wandb_run WANDB_RUN] [--threshold THRESHOLD] [--model_name MODEL_NAME] [--save_data] [--save_model]
                                 [--save_pickle] [--save_preds] [--save_plots] [--save_dir SAVE_DIR] [--data_file DATA_FILE] [--model_file MODEL_FILE] [--use_saved_params]
                                 [--predict] [--predict_file PREDICT_FILE] [--device DEVICE] [--gpus GPUS] [--num_threads NUM_THREADS] [--num_workers NUM_WORKERS]
                                 [--prefetch PREFETCH] [--empty_cache] [--port PORT] [--debug] [--mem_interval MEM_INTERVAL] [--decimal DECIMAL] [--color_theme COLOR_THEME]
ddp_sentiment_finetune.py: error: unrecognized arguments: --lr_decay 0.95
(nlp) ubuntu@138-2-58-218:~/nlp-osaka/sentiment$ mv requirements.txt requirements.lambda
(nlp) ubuntu@138-2-58-218:~/nlp-osaka/sentiment$ git pull
Username for 'https://github.com': jim@jimbeno.net
Password for 'https://jim@jimbeno.net@github.com': 
remote: Enumerating objects: 7, done.
remote: Counting objects: 100% (7/7), done.
remote: Compressing objects: 100% (1/1), done.
remote: Total 4 (delta 3), reused 4 (delta 3), pack-reused 0 (from 0)
Unpacking objects: 100% (4/4), 1.34 KiB | 26.00 KiB/s, done.
From https://github.com/jbeno/sentiment
   d40daeb..608f193  main       -> origin/main
Updating d40daeb..608f193
Fast-forward
 ddp_sentiment_finetune.py               |  9 ++++++---
 torch_ddp_finetune_neural_classifier.py | 83 +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++------------------
 2 files changed, 71 insertions(+), 21 deletions(-)
(nlp) ubuntu@138-2-58-218:~/nlp-osaka/sentiment$ python ./ddp_sentiment_finetune.py --dataset 'merged_local' --weights_name 'google/electra-large-discriminator' --save_data --save_model --save_pickle --save_preds --lr 0.0002 --lr_decay 0.95 --epochs 50 --pooling 'mean' --dropout_rate 0.3 --num_layers 2 --hidden_dim 1024 --hidden_activation 'swishglu' --batch_size 16 --accumulation_steps 2 --l2_strength 0.0001 --checkpoint_interval 5 --use_zero --optimizer 'adamw' --scheduler 'cosine_warmup' --scheduler_kwargs '{"T_0":5, "T_mult":1, "eta_min":1e-7}' --decimal 6 --use_val_split --eval_split 'test' --early_stop 'score' --n_iter_no_change 50 --show_progress --wandb --wandb_project 'Electra Large' --wandb_run 'run_1_merged_class'

Starting DDP PyTorch Training...
Device: cuda, Number of GPUs: 8
Spawning 8 processes...
Rank 6 - Device: cuda:6
Rank 5 - Device: cuda:5
Rank 3 - Device: cuda:3
Rank 4 - Device: cuda:4
Rank 1 - Device: cuda:1
Rank 7 - Device: cuda:7
Rank 2 - Device: cuda:2
Rank 0 - Device: cuda:0
8 process groups initialized with 'nccl' backend on localhost:12355
NCCL Timeout: 1 hr 0 min. NCCL Blocking Wait: Enabled
wandb: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: jbeno (jimbeno). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.5
wandb: Run data is saved locally in /home/ubuntu/nlp-osaka/sentiment/wandb/run-20241023_234817-048fns5m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run run_1_merged_class
wandb: â­ï¸ View project at https://wandb.ai/jimbeno/Electra%20Large
wandb: ðŸš€ View run at https://wandb.ai/jimbeno/Electra%20Large/runs/048fns5m
Wand run initialized.

Initializing 'google/electra-large-discriminator' tokenizer and model...
Checking for local files...
Some files not found locally, downloading...
tokenizer_config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48.0/48.0 [00:00<00:00, 386kB/s]
config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 668/668 [00:00<00:00, 3.43MB/s]
vocab.txt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 232k/232k [00:00<00:00, 791kB/s]
tokenizer.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 466k/466k [00:00<00:00, 3.11MB/s]
pytorch_model.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.34G/1.34G [00:04<00:00, 290MB/s]
Download complete
All ranks loading tokenizer from local files...
All ranks loading model from local files...
Tokenizer and model initialized (13s)

Loading data...
Using the same dataset for training and evaluation
Splits:
- Train: Using merged_local 'train' split
- Validation: Using merged_local 'validation' split
- Evaluation: Using merged_local 'test' split
Train Data: Merged DynaSent Round 1, Round 2 and SST from Local: 'data/merged'
Validation Data: Merged DynaSent Round 1, Round 2 and SST from Local: 'data/merged'
Evaluation Data: Merged DynaSent Round 1, Round 2 and SST from Local: 'data/merged'
Train size: 102097
Validation size: 5421
Evaluation size: 5421
Train label distribution:
	      Negative: 21910
	       Neutral: 49148
	      Positive: 31039
Validation label distribution:
	      Negative: 1868
	       Neutral: 1669
	      Positive: 1884
Evaluation label distribution:
	      Negative: 1868
	       Neutral: 1669
	      Positive: 1884
Data loaded (1s)

Processing data...
(Batch size: 16, Pooling: Mean, Fine Tune BERT: False, Chunk size: None)...
Extracting sentences and labels...

Displaying samples from Train data:
Train[84457]: she blurted. - NEUTRAL
Tokens: ['she', 'blurted', '.']
Embedding: [ 0.08256386  0.14963749  0.19717517 -0.26130205  0.08827331  0.6304889 ] ...

Train[33315]: $10 is the minimum tip they ask for. - NEUTRAL
Tokens: ['$', '10', 'is', 'the', 'minimum', 'tip', 'they', 'ask', 'for', '.']
Embedding: [ 0.07732821  0.05567317  0.10109115 -0.03255092  0.05662063  0.3636926 ] ...

Train[95755]: Once arriving home, we opened our food. - NEUTRAL
Tokens: ['once', 'arriving', 'home', ',', 'we', 'opened', 'our', 'food', '.']
Embedding: [0.0316001  0.03178836 0.12717418 0.09764466 0.00259186 0.3355862 ] ...


Encoding Train data of 102097 texts distributed across 8 GPUs...
Batch Size: 16, Pooling: Mean, Empty Cache: False
Padding Train data to 102104 texts for even distribution across 8 ranks...
Texts per rank: 12763, Total batches: 6382
Rank 6: Processing 12763 texts (indices 76578 to 89340) in 798 batches...
Rank 2: Processing 12763 texts (indices 25526 to 38288) in 798 batches...
Rank 4: Processing 12763 texts (indices 51052 to 63814) in 798 batches...
Rank 0: Processing 12763 texts (indices 0 to 12762) in 798 batches...
Rank 1: Processing 12763 texts (indices 12763 to 25525) in 798 batches...
Rank 5: Processing 12763 texts (indices 63815 to 76577) in 798 batches...
Rank 7: Processing 12763 texts (indices 89341 to 102103) in 798 batches...
Rank 3: Processing 12763 texts (indices 38289 to 51051) in 798 batches...
Rank 0: Batch  1 / 798, Shape: [16, 1024], Time: 24ms
Rank 7: Batch  1 / 798, Shape: [16, 1024], Time: 369ms
Rank 6: Batch  1 / 798, Shape: [16, 1024], Time: 387ms
Rank 2: Batch  1 / 798, Shape: [16, 1024], Time: 387ms
Rank 4: Batch  1 / 798, Shape: [16, 1024], Time: 399ms
Rank 1: Batch  1 / 798, Shape: [16, 1024], Time: 487ms
Rank 3: Batch  1 / 798, Shape: [16, 1024], Time: 487ms
Rank 5: Batch  1 / 798, Shape: [16, 1024], Time: 499ms
Rank 2: Batch  2 / 798, Shape: [16, 1024], Time: 373ms
Rank 6: Batch  2 / 798, Shape: [16, 1024], Time: 374ms
Rank 7: Batch  2 / 798, Shape: [16, 1024], Time: 391ms
Rank 4: Batch  2 / 798, Shape: [16, 1024], Time: 362ms
Rank 3: Batch  2 / 798, Shape: [16, 1024], Time: 344ms
Rank 6: Batch  3 / 798, Shape: [16, 1024], Time: 339ms
Rank 4: Batch  3 / 798, Shape: [16, 1024], Time: 339ms
Rank 7: Batch  3 / 798, Shape: [16, 1024], Time: 340ms
Rank 2: Batch  3 / 798, Shape: [16, 1024], Time: 340ms
Rank 3: Batch  3 / 798, Shape: [16, 1024], Time: 354ms
Rank 1: Batch  2 / 798, Shape: [16, 1024], Time: 820ms
Rank 5: Batch  2 / 798, Shape: [16, 1024], Time: 809ms
Rank 6: Batch  4 / 798, Shape: [16, 1024], Time: 358ms
Rank 7: Batch  4 / 798, Shape: [16, 1024], Time: 358ms
Rank 4: Batch  4 / 798, Shape: [16, 1024], Time: 358ms
Rank 2: Batch  4 / 798, Shape: [16, 1024], Time: 359ms
Rank 3: Batch  4 / 798, Shape: [16, 1024], Time: 358ms
Rank 5: Batch  3 / 798, Shape: [16, 1024], Time: 338ms
Rank 1: Batch  3 / 798, Shape: [16, 1024], Time: 339ms
Rank 6: Batch  5 / 798, Shape: [16, 1024], Time: 358ms
Rank 7: Batch  5 / 798, Shape: [16, 1024], Time: 360ms
Rank 4: Batch  5 / 798, Shape: [16, 1024], Time: 361ms
Rank 2: Batch  5 / 798, Shape: [16, 1024], Time: 360ms
Rank 3: Batch  5 / 798, Shape: [16, 1024], Time: 358ms
Rank 1: Batch  4 / 798, Shape: [16, 1024], Time: 359ms
Rank 5: Batch  4 / 798, Shape: [16, 1024], Time: 360ms
Rank 6: Batch  6 / 798, Shape: [16, 1024], Time: 358ms
Rank 7: Batch  6 / 798, Shape: [16, 1024], Time: 357ms
Rank 4: Batch  6 / 798, Shape: [16, 1024], Time: 357ms
Rank 2: Batch  6 / 798, Shape: [16, 1024], Time: 359ms
Rank 3: Batch  6 / 798, Shape: [16, 1024], Time: 361ms
Rank 5: Batch  5 / 798, Shape: [16, 1024], Time: 356ms
Rank 1: Batch  5 / 798, Shape: [16, 1024], Time: 357ms
Rank 6: Batch  7 / 798, Shape: [16, 1024], Time: 359ms
Rank 7: Batch  7 / 798, Shape: [16, 1024], Time: 358ms
Rank 4: Batch  7 / 798, Shape: [16, 1024], Time: 359ms
Rank 2: Batch  7 / 798, Shape: [16, 1024], Time: 360ms
Rank 3: Batch  7 / 798, Shape: [16, 1024], Time: 357ms
Rank 5: Batch  6 / 798, Shape: [16, 1024], Time: 360ms
Rank 1: Batch  6 / 798, Shape: [16, 1024], Time: 359ms
Rank 6: Batch  8 / 798, Shape: [16, 1024], Time: 358ms
Rank 7: Batch  8 / 798, Shape: [16, 1024], Time: 358ms
Rank 4: Batch  8 / 798, Shape: [16, 1024], Time: 358ms
Rank 2: Batch  8 / 798, Shape: [16, 1024], Time: 359ms
Rank 3: Batch  8 / 798, Shape: [16, 1024], Time: 358ms
Rank 5: Batch  7 / 798, Shape: [16, 1024], Time: 357ms
Rank 1: Batch  7 / 798, Shape: [16, 1024], Time: 358ms
Rank 6: Batch  9 / 798, Shape: [16, 1024], Time: 358ms
Rank 7: Batch  9 / 798, Shape: [16, 1024], Time: 358ms
Rank 4: Batch  9 / 798, Shape: [16, 1024], Time: 358ms
Rank 2: Batch  9 / 798, Shape: [16, 1024], Time: 359ms
Rank 3: Batch  9 / 798, Shape: [16, 1024], Time: 358ms
Rank 5: Batch  8 / 798, Shape: [16, 1024], Time: 359ms
Rank 1: Batch  8 / 798, Shape: [16, 1024], Time: 359ms
Rank 6: Batch 10 / 798, Shape: [16, 1024], Time: 359ms
Rank 4: Batch 10 / 798, Shape: [16, 1024], Time: 359ms
Rank 7: Batch 10 / 798, Shape: [16, 1024], Time: 361ms
Rank 2: Batch 10 / 798, Shape: [16, 1024], Time: 361ms
Rank 3: Batch 10 / 798, Shape: [16, 1024], Time: 359ms
Rank 1: Batch  9 / 798, Shape: [16, 1024], Time: 358ms
Rank 5: Batch  9 / 798, Shape: [16, 1024], Time: 359ms
Rank 6: Batch 11 / 798, Shape: [16, 1024], Time: 359ms
Rank 7: Batch 11 / 798, Shape: [16, 1024], Time: 357ms
Rank 4: Batch 11 / 798, Shape: [16, 1024], Time: 358ms
Rank 2: Batch 11 / 798, Shape: [16, 1024], Time: 382ms
Rank 3: Batch 11 / 798, Shape: [16, 1024], Time: 360ms
Rank 5: Batch 10 / 798, Shape: [16, 1024], Time: 357ms
Rank 1: Batch 10 / 798, Shape: [16, 1024], Time: 358ms
Rank 6: Batch 12 / 798, Shape: [16, 1024], Time: 358ms
Rank 7: Batch 12 / 798, Shape: [16, 1024], Time: 358ms
Rank 4: Batch 12 / 798, Shape: [16, 1024], Time: 358ms
Rank 2: Batch 12 / 798, Shape: [16, 1024], Time: 360ms
Rank 3: Batch 12 / 798, Shape: [16, 1024], Time: 359ms
Rank 1: Batch 11 / 798, Shape: [16, 1024], Time: 358ms
Rank 5: Batch 11 / 798, Shape: [16, 1024], Time: 360ms
Rank 6: Batch 13 / 798, Shape: [16, 1024], Time: 358ms
Rank 7: Batch 13 / 798, Shape: [16, 1024], Time: 358ms
Rank 4: Batch 13 / 798, Shape: [16, 1024], Time: 358ms
Rank 2: Batch 13 / 798, Shape: [16, 1024], Time: 359ms
Rank 3: Batch 13 / 798, Shape: [16, 1024], Time: 358ms
Rank 1: Batch 12 / 798, Shape: [16, 1024], Time: 358ms
Rank 5: Batch 12 / 798, Shape: [16, 1024], Time: 357ms
Rank 6: Batch 14 / 798, Shape: [16, 1024], Time: 358ms
Rank 7: Batch 14 / 798, Shape: [16, 1024], Time: 358ms
Rank 4: Batch 14 / 798, Shape: [16, 1024], Time: 358ms
Rank 2: Batch 14 / 798, Shape: [16, 1024], Time: 360ms
Rank 3: Batch 14 / 798, Shape: [16, 1024], Time: 358ms
Rank 1: Batch 13 / 798, Shape: [16, 1024], Time: 358ms
Rank 5: Batch 13 / 798, Shape: [16, 1024], Time: 358ms
Rank 6: Batch 15 / 798, Shape: [16, 1024], Time: 358ms
Rank 7: Batch 15 / 798, Shape: [16, 1024], Time: 358ms
Rank 4: Batch 15 / 798, Shape: [16, 1024], Time: 360ms
Rank 2: Batch 15 / 798, Shape: [16, 1024], Time: 360ms
Rank 3: Batch 15 / 798, Shape: [16, 1024], Time: 359ms
Rank 1: Batch 14 / 798, Shape: [16, 1024], Time: 358ms
Rank 5: Batch 14 / 798, Shape: [16, 1024], Time: 358ms
Rank 6: Batch 16 / 798, Shape: [16, 1024], Time: 358ms
Rank 7: Batch 16 / 798, Shape: [16, 1024], Time: 358ms
Rank 4: Batch 16 / 798, Shape: [16, 1024], Time: 360ms
Rank 2: Batch 16 / 798, Shape: [16, 1024], Time: 359ms
Rank 3: Batch 16 / 798, Shape: [16, 1024], Time: 357ms
Rank 1: Batch 15 / 798, Shape: [16, 1024], Time: 358ms
Rank 5: Batch 15 / 798, Shape: [16, 1024], Time: 359ms
Rank 6: Batch 17 / 798, Shape: [16, 1024], Time: 359ms
Rank 7: Batch 17 / 798, Shape: [16, 1024], Time: 358ms
Rank 4: Batch 17 / 798, Shape: [16, 1024], Time: 358ms
Rank 2: Batch 17 / 798, Shape: [16, 1024], Time: 359ms
Rank 3: Batch 17 / 798, Shape: [16, 1024], Time: 358ms
Rank 1: Batch 16 / 798, Shape: [16, 1024], Time: 358ms
Rank 5: Batch 16 / 798, Shape: [16, 1024], Time: 358ms
Rank 6: Batch 18 / 798, Shape: [16, 1024], Time: 357ms
Rank 7: Batch 18 / 798, Shape: [16, 1024], Time: 358ms
Rank 4: Batch 18 / 798, Shape: [16, 1024], Time: 358ms
Rank 2: Batch 18 / 798, Shape: [16, 1024], Time: 359ms
Rank 3: Batch 18 / 798, Shape: [16, 1024], Time: 358ms
Rank 1: Batch 17 / 798, Shape: [16, 1024], Time: 358ms
Rank 5: Batch 17 / 798, Shape: [16, 1024], Time: 358ms
Rank 6: Batch 19 / 798, Shape: [16, 1024], Time: 358ms
Rank 7: Batch 19 / 798, Shape: [16, 1024], Time: 358ms
Rank 4: Batch 19 / 798, Shape: [16, 1024], Time: 359ms
Rank 2: Batch 19 / 798, Shape: [16, 1024], Time: 360ms
Rank 3: Batch 19 / 798, Shape: [16, 1024], Time: 382ms
Rank 5: Batch 18 / 798, Shape: [16, 1024], Time: 363ms
Rank 1: Batch 18 / 798, Shape: [16, 1024], Time: 363ms
Rank 6: Batch 20 / 798, Shape: [16, 1024], Time: 358ms
Rank 7: Batch 20 / 798, Shape: [16, 1024], Time: 358ms
Rank 4: Batch 20 / 798, Shape: [16, 1024], Time: 359ms
Rank 2: Batch 20 / 798, Shape: [16, 1024], Time: 360ms
Rank 3: Batch 20 / 798, Shape: [16, 1024], Time: 360ms
Rank 1: Batch 19 / 798, Shape: [16, 1024], Time: 355ms
Rank 5: Batch 19 / 798, Shape: [16, 1024], Time: 356ms
Rank 6: Batch 21 / 798, Shape: [16, 1024], Time: 358ms
Rank 7: Batch 21 / 798, Shape: [16, 1024], Time: 358ms
Rank 4: Batch 21 / 798, Shape: [16, 1024], Time: 366ms
Rank 2: Batch 21 / 798, Shape: [16, 1024], Time: 359ms
Rank 3: Batch 21 / 798, Shape: [16, 1024], Time: 358ms
Rank 1: Batch 20 / 798, Shape: [16, 1024], Time: 358ms
Rank 5: Batch 20 / 798, Shape: [16, 1024], Time: 357ms
Rank 6: Batch 22 / 798, Shape: [16, 1024], Time: 358ms
Rank 7: Batch 22 / 798, Shape: [16, 1024], Time: 358ms
Rank 4: Batch 22 / 798, Shape: [16, 1024], Time: 355ms
Rank 2: Batch 22 / 798, Shape: [16, 1024], Time: 359ms
Rank 3: Batch 22 / 798, Shape: [16, 1024], Time: 358ms
Rank 1: Batch 21 / 798, Shape: [16, 1024], Time: 358ms
Rank 5: Batch 21 / 798, Shape: [16, 1024], Time: 359ms
Rank 6: Batch 23 / 798, Shape: [16, 1024], Time: 358ms
Rank 7: Batch 23 / 798, Shape: [16, 1024], Time: 359ms
Rank 4: Batch 23 / 798, Shape: [16, 1024], Time: 359ms
Rank 2: Batch 23 / 798, Shape: [16, 1024], Time: 359ms
Rank 3: Batch 23 / 798, Shape: [16, 1024], Time: 361ms
Rank 1: Batch 22 / 798, Shape: [16, 1024], Time: 358ms
Rank 5: Batch 22 / 798, Shape: [16, 1024], Time: 359ms
Rank 6: Batch 24 / 798, Shape: [16, 1024], Time: 358ms
Rank 7: Batch 24 / 798, Shape: [16, 1024], Time: 358ms
Rank 4: Batch 24 / 798, Shape: [16, 1024], Time: 358ms
Rank 2: Batch 24 / 798, Shape: [16, 1024], Time: 360ms
Rank 3: Batch 24 / 798, Shape: [16, 1024], Time: 357ms
Rank 1: Batch 23 / 798, Shape: [16, 1024], Time: 358ms
Rank 5: Batch 23 / 798, Shape: [16, 1024], Time: 357ms
Rank 6: Batch 25 / 798, Shape: [16, 1024], Time: 358ms
Rank 7: Batch 25 / 798, Shape: [16, 1024], Time: 358ms
Rank 4: Batch 25 / 798, Shape: [16, 1024], Time: 359ms
Rank 2: Batch 25 / 798, Shape: [16, 1024], Time: 361ms
Rank 3: Batch 25 / 798, Shape: [16, 1024], Time: 358ms
Rank 1: Batch 24 / 798, Shape: [16, 1024], Time: 358ms
Rank 5: Batch 24 / 798, Shape: [16, 1024], Time: 358ms
Rank 1: Batch 25 / 798, Shape: [16, 1024], Time: 359ms
Rank 5: Batch 25 / 798, Shape: [16, 1024], Time: 359ms
Rank 6: Batch 26 / 798, Shape: [16, 1024], Time: 627ms
Rank 7: Batch 26 / 798, Shape: [16, 1024], Time: 625ms
Rank 4: Batch 26 / 798, Shape: [16, 1024], Time: 617ms
Rank 6: Batch 27 / 798, Shape: [16, 1024], Time: 358ms
Rank 7: Batch 27 / 798, Shape: [16, 1024], Time: 358ms
Rank 4: Batch 27 / 798, Shape: [16, 1024], Time: 360ms
Rank 2: Batch 26 / 798, Shape: [16, 1024], Time: 950ms
Rank 3: Batch 26 / 798, Shape: [16, 1024], Time: 888ms
Rank 1: Batch 26 / 798, Shape: [16, 1024], Time: 455ms
Rank 5: Batch 26 / 798, Shape: [16, 1024], Time: 457ms
Rank 6: Batch 28 / 798, Shape: [16, 1024], Time: 358ms
Rank 7: Batch 28 / 798, Shape: [16, 1024], Time: 358ms
Rank 3: Batch 27 / 798, Shape: [16, 1024], Time: 358ms
Rank 4: Batch 28 / 798, Shape: [16, 1024], Time: 373ms
Rank 2: Batch 27 / 798, Shape: [16, 1024], Time: 359ms
Rank 1: Batch 27 / 798, Shape: [16, 1024], Time: 358ms
Rank 5: Batch 27 / 798, Shape: [16, 1024], Time: 358ms
Rank 6: Batch 29 / 798, Shape: [16, 1024], Time: 358ms
Rank 7: Batch 29 / 798, Shape: [16, 1024], Time: 358ms
Rank 4: Batch 29 / 798, Shape: [16, 1024], Time: 357ms
Rank 3: Batch 28 / 798, Shape: [16, 1024], Time: 358ms
Rank 1: Batch 28 / 798, Shape: [16, 1024], Time: 358ms
Rank 2: Batch 28 / 798, Shape: [16, 1024], Time: 361ms
Rank 5: Batch 28 / 798, Shape: [16, 1024], Time: 372ms
Rank 6: Batch 30 / 798, Shape: [16, 1024], Time: 358ms
Rank 7: Batch 30 / 798, Shape: [16, 1024], Time: 358ms
Rank 4: Batch 30 / 798, Shape: [16, 1024], Time: 358ms
Rank 3: Batch 29 / 798, Shape: [16, 1024], Time: 359ms
Rank 1: Batch 29 / 798, Shape: [16, 1024], Time: 358ms
Rank 2: Batch 29 / 798, Shape: [16, 1024], Time: 358ms
Rank 5: Batch 29 / 798, Shape: [16, 1024], Time: 361ms
Rank 6: Batch 31 / 798, Shape: [16, 1024], Time: 359ms
Rank 7: Batch 31 / 798, Shape: [16, 1024], Time: 359ms
Rank 3: Batch 30 / 798, Shape: [16, 1024], Time: 358ms
Rank 4: Batch 31 / 798, Shape: [16, 1024], Time: 359ms
Rank 1: Batch 30 / 798, Shape: [16, 1024], Time: 358ms
Rank 2: Batch 30 / 798, Shape: [16, 1024], Time: 359ms
Rank 5: Batch 30 / 798, Shape: [16, 1024], Time: 356ms
Rank 6: Batch 32 / 798, Shape: [16, 1024], Time: 358ms
Rank 7: Batch 32 / 798, Shape: [16, 1024], Time: 358ms
Rank 4: Batch 32 / 798, Shape: [16, 1024], Time: 358ms
Rank 3: Batch 31 / 798, Shape: [16, 1024], Time: 359ms
Rank 1: Batch 31 / 798, Shape: [16, 1024], Time: 361ms
Rank 2: Batch 31 / 798, Shape: [16, 1024], Time: 361ms
Rank 5: Batch 31 / 798, Shape: [16, 1024], Time: 358ms
Rank 7: Batch 33 / 798, Shape: [16, 1024], Time: 358ms
Rank 6: Batch 33 / 798, Shape: [16, 1024], Time: 360ms
Rank 3: Batch 32 / 798, Shape: [16, 1024], Time: 358ms
Rank 4: Batch 33 / 798, Shape: [16, 1024], Time: 359ms
Rank 1: Batch 32 / 798, Shape: [16, 1024], Time: 356ms
Rank 2: Batch 32 / 798, Shape: [16, 1024], Time: 357ms
Rank 5: Batch 32 / 798, Shape: [16, 1024], Time: 358ms
Rank 6: Batch 34 / 798, Shape: [16, 1024], Time: 357ms
Rank 7: Batch 34 / 798, Shape: [16, 1024], Time: 358ms
Rank 3: Batch 33 / 798, Shape: [16, 1024], Time: 358ms
Rank 4: Batch 34 / 798, Shape: [16, 1024], Time: 359ms
Rank 1: Batch 33 / 798, Shape: [16, 1024], Time: 358ms
Rank 2: Batch 33 / 798, Shape: [16, 1024], Time: 359ms
Rank 5: Batch 33 / 798, Shape: [16, 1024], Time: 358ms
Rank 6: Batch 35 / 798, Shape: [16, 1024], Time: 358ms
Rank 7: Batch 35 / 798, Shape: [16, 1024], Time: 358ms
Rank 3: Batch 34 / 798, Shape: [16, 1024], Time: 358ms
Rank 4: Batch 35 / 798, Shape: [16, 1024], Time: 359ms
Rank 1: Batch 34 / 798, Shape: [16, 1024], Time: 358ms
Rank 2: Batch 34 / 798, Shape: [16, 1024], Time: 359ms
Rank 5: Batch 34 / 798, Shape: [16, 1024], Time: 358ms
Rank 6: Batch 36 / 798, Shape: [16, 1024], Time: 358ms
Rank 7: Batch 36 / 798, Shape: [16, 1024], Time: 358ms
Rank 3: Batch 35 / 798, Shape: [16, 1024], Time: 359ms
Rank 4: Batch 36 / 798, Shape: [16, 1024], Time: 359ms
Rank 1: Batch 35 / 798, Shape: [16, 1024], Time: 358ms
Rank 2: Batch 35 / 798, Shape: [16, 1024], Time: 360ms
Rank 5: Batch 35 / 798, Shape: [16, 1024], Time: 359ms
Rank 7: Batch 37 / 798, Shape: [16, 1024], Time: 358ms
Rank 6: Batch 37 / 798, Shape: [16, 1024], Time: 371ms
Rank 3: Batch 36 / 798, Shape: [16, 1024], Time: 358ms
Rank 4: Batch 37 / 798, Shape: [16, 1024], Time: 359ms
Rank 1: Batch 36 / 798, Shape: [16, 1024], Time: 358ms
Rank 2: Batch 36 / 798, Shape: [16, 1024], Time: 359ms
Rank 5: Batch 36 / 798, Shape: [16, 1024], Time: 358ms
Rank 7: Batch 38 / 798, Shape: [16, 1024], Time: 361ms
Rank 6: Batch 38 / 798, Shape: [16, 1024], Time: 361ms
Rank 3: Batch 37 / 798, Shape: [16, 1024], Time: 359ms
Rank 4: Batch 38 / 798, Shape: [16, 1024], Time: 359ms
Rank 1: Batch 37 / 798, Shape: [16, 1024], Time: 359ms
Rank 2: Batch 37 / 798, Shape: [16, 1024], Time: 359ms
Rank 5: Batch 37 / 798, Shape: [16, 1024], Time: 359ms
Rank 7: Batch 39 / 798, Shape: [16, 1024], Time: 356ms
Rank 6: Batch 39 / 798, Shape: [16, 1024], Time: 358ms
Rank 3: Batch 38 / 798, Shape: [16, 1024], Time: 357ms
Rank 4: Batch 39 / 798, Shape: [16, 1024], Time: 358ms
Rank 1: Batch 38 / 798, Shape: [16, 1024], Time: 358ms
Rank 2: Batch 38 / 798, Shape: [16, 1024], Time: 358ms
Rank 5: Batch 38 / 798, Shape: [16, 1024], Time: 358ms
Rank 7: Batch 40 / 798, Shape: [16, 1024], Time: 358ms
Rank 6: Batch 40 / 798, Shape: [16, 1024], Time: 360ms
Rank 3: Batch 39 / 798, Shape: [16, 1024], Time: 359ms
Rank 1: Batch 39 / 798, Shape: [16, 1024], Time: 358ms
Rank 4: Batch 40 / 798, Shape: [16, 1024], Time: 358ms
Rank 2: Batch 39 / 798, Shape: [16, 1024], Time: 359ms
Rank 5: Batch 39 / 798, Shape: [16, 1024], Time: 358ms
Rank 7: Batch 41 / 798, Shape: [16, 1024], Time: 358ms
Rank 6: Batch 41 / 798, Shape: [16, 1024], Time: 356ms
Rank 3: Batch 40 / 798, Shape: [16, 1024], Time: 357ms
Rank 4: Batch 41 / 798, Shape: [16, 1024], Time: 358ms
Rank 1: Batch 40 / 798, Shape: [16, 1024], Time: 358ms
Rank 2: Batch 40 / 798, Shape: [16, 1024], Time: 359ms
Rank 5: Batch 40 / 798, Shape: [16, 1024], Time: 358ms
Rank 7: Batch 42 / 798, Shape: [16, 1024], Time: 358ms
Rank 6: Batch 42 / 798, Shape: [16, 1024], Time: 358ms
Rank 3: Batch 41 / 798, Shape: [16, 1024], Time: 358ms
Rank 1: Batch 41 / 798, Shape: [16, 1024], Time: 358ms
Rank 4: Batch 42 / 798, Shape: [16, 1024], Time: 359ms
Rank 2: Batch 41 / 798, Shape: [16, 1024], Time: 359ms
Rank 5: Batch 41 / 798, Shape: [16, 1024], Time: 360ms
Rank 7: Batch 43 / 798, Shape: [16, 1024], Time: 358ms
Rank 6: Batch 43 / 798, Shape: [16, 1024], Time: 358ms
Rank 3: Batch 42 / 798, Shape: [16, 1024], Time: 358ms
Rank 1: Batch 42 / 798, Shape: [16, 1024], Time: 358ms
Rank 4: Batch 43 / 798, Shape: [16, 1024], Time: 359ms
Rank 2: Batch 42 / 798, Shape: [16, 1024], Time: 359ms
Rank 5: Batch 42 / 798, Shape: [16, 1024], Time: 357ms
Rank 7: Batch 44 / 798, Shape: [16, 1024], Time: 358ms
Rank 6: Batch 44 / 798, Shape: [16, 1024], Time: 358ms
Rank 3: Batch 43 / 798, Shape: [16, 1024], Time: 358ms
Rank 1: Batch 43 / 798, Shape: [16, 1024], Time: 358ms
Rank 4: Batch 44 / 798, Shape: [16, 1024], Time: 358ms
Rank 2: Batch 43 / 798, Shape: [16, 1024], Time: 361ms
Rank 5: Batch 43 / 798, Shape: [16, 1024], Time: 358ms
Rank 7: Batch 45 / 798, Shape: [16, 1024], Time: 358ms
Rank 6: Batch 45 / 798, Shape: [16, 1024], Time: 371ms
Rank 1: Batch 44 / 798, Shape: [16, 1024], Time: 367ms
Rank 4: Batch 45 / 798, Shape: [16, 1024], Time: 367ms
Rank 3: Batch 44 / 798, Shape: [16, 1024], Time: 373ms
Rank 5: Batch 44 / 798, Shape: [16, 1024], Time: 363ms
Rank 2: Batch 44 / 798, Shape: [16, 1024], Time: 369ms
Rank 7: Batch 46 / 798, Shape: [16, 1024], Time: 374ms
Rank 6: Batch 46 / 798, Shape: [16, 1024], Time: 346ms
Rank 3: Batch 45 / 798, Shape: [16, 1024], Time: 344ms
Rank 1: Batch 45 / 798, Shape: [16, 1024], Time: 350ms
Rank 4: Batch 46 / 798, Shape: [16, 1024], Time: 350ms
Rank 2: Batch 45 / 798, Shape: [16, 1024], Time: 351ms
Rank 5: Batch 45 / 798, Shape: [16, 1024], Time: 354ms
Memory: Rank 0: 3.50 GB | Rank 1: 4.07 GB | Rank 2: 4.10 GB | Rank 3: 4.10 GB | Rank 4: 4.10 GB | Rank 5: 4.10 GB | Rank 6: 4.10 GB | Rank 7: 3.95 GB (Max: 42.29 GB, Total: 338.28 GB)
Rank 0: Batch  2 / 798, Shape: [16, 1024], Time: 25ms
Rank 6: Batch 47 / 798, Shape: [16, 1024], Time: 358ms
Rank 7: Batch 47 / 798, Shape: [16, 1024], Time: 359ms
Rank 3: Batch 46 / 798, Shape: [16, 1024], Time: 359ms
Rank 1: Batch 46 / 798, Shape: [16, 1024], Time: 359ms
Rank 4: Batch 47 / 798, Shape: [16, 1024], Time: 359ms
Rank 5: Batch 46 / 798, Shape: [16, 1024], Time: 358ms
Rank 2: Batch 46 / 798, Shape: [16, 1024], Time: 359ms
Rank 0: Batch  3 / 798, Shape: [16, 1024], Time: 402ms
Rank 7: Batch 48 / 798, Shape: [16, 1024], Time: 357ms
Rank 6: Batch 48 / 798, Shape: [16, 1024], Time: 358ms
Rank 3: Batch 47 / 798, Shape: [16, 1024], Time: 358ms
Rank 1: Batch 47 / 798, Shape: [16, 1024], Time: 359ms
Rank 4: Batch 48 / 798, Shape: [16, 1024], Time: 359ms
Rank 5: Batch 47 / 798, Shape: [16, 1024], Time: 358ms
Rank 2: Batch 47 / 798, Shape: [16, 1024], Time: 360ms
Rank 0: Batch  4 / 798, Shape: [16, 1024], Time: 354ms
Rank 7: Batch 49 / 798, Shape: [16, 1024], Time: 358ms
Rank 6: Batch 49 / 798, Shape: [16, 1024], Time: 358ms
Rank 3: Batch 48 / 798, Shape: [16, 1024], Time: 358ms
Rank 1: Batch 48 / 798, Shape: [16, 1024], Time: 358ms
Rank 4: Batch 49 / 798, Shape: [16, 1024], Time: 359ms
Rank 5: Batch 48 / 798, Shape: [16, 1024], Time: 359ms
Rank 2: Batch 48 / 798, Shape: [16, 1024], Time: 360ms
Rank 0: Batch  5 / 798, Shape: [16, 1024], Time: 357ms
Rank 7: Batch 50 / 798, Shape: [16, 1024], Time: 358ms
Rank 6: Batch 50 / 798, Shape: [16, 1024], Time: 358ms
Rank 3: Batch 49 / 798, Shape: [16, 1024], Time: 358ms
Rank 1: Batch 49 / 798, Shape: [16, 1024], Time: 358ms
Rank 4: Batch 50 / 798, Shape: [16, 1024], Time: 358ms
Rank 5: Batch 49 / 798, Shape: [16, 1024], Time: 358ms
Rank 2: Batch 49 / 798, Shape: [16, 1024], Time: 358ms
Rank 0: Batch  6 / 798, Shape: [16, 1024], Time: 358ms
Rank 7: Batch 51 / 798, Shape: [16, 1024], Time: 359ms
Rank 6: Batch 51 / 798, Shape: [16, 1024], Time: 358ms
Rank 3: Batch 50 / 798, Shape: [16, 1024], Time: 358ms
Rank 1: Batch 50 / 798, Shape: [16, 1024], Time: 359ms
Rank 4: Batch 51 / 798, Shape: [16, 1024], Time: 359ms
Rank 5: Batch 50 / 798, Shape: [16, 1024], Time: 358ms
Rank 2: Batch 50 / 798, Shape: [16, 1024], Time: 360ms
Rank 7: Batch 52 / 798, Shape: [16, 1024], Time: 358ms
Rank 6: Batch 52 / 798, Shape: [16, 1024], Time: 358ms
Rank 3: Batch 51 / 798, Shape: [16, 1024], Time: 358ms
Rank 1: Batch 51 / 798, Shape: [16, 1024], Time: 358ms
Rank 4: Batch 52 / 798, Shape: [16, 1024], Time: 358ms
Rank 5: Batch 51 / 798, Shape: [16, 1024], Time: 358ms
Rank 2: Batch 51 / 798, Shape: [16, 1024], Time: 360ms
Rank 7: Batch 53 / 798, Shape: [16, 1024], Time: 358ms
Rank 6: Batch 53 / 798, Shape: [16, 1024], Time: 359ms
Rank 3: Batch 52 / 798, Shape: [16, 1024], Time: 358ms
Rank 1: Batch 52 / 798, Shape: [16, 1024], Time: 358ms
Rank 4: Batch 53 / 798, Shape: [16, 1024], Time: 359ms
Rank 5: Batch 52 / 798, Shape: [16, 1024], Time: 359ms
Rank 2: Batch 52 / 798, Shape: [16, 1024], Time: 358ms
Rank 7: Batch 54 / 798, Shape: [16, 1024], Time: 358ms
Rank 6: Batch 54 / 798, Shape: [16, 1024], Time: 358ms
Rank 3: Batch 53 / 798, Shape: [16, 1024], Time: 358ms
Rank 1: Batch 53 / 798, Shape: [16, 1024], Time: 358ms
Rank 4: Batch 54 / 798, Shape: [16, 1024], Time: 359ms
Rank 5: Batch 53 / 798, Shape: [16, 1024], Time: 358ms
Rank 2: Batch 53 / 798, Shape: [16, 1024], Time: 360ms
Memory: Rank 0: 3.53 GB | Rank 1: 4.10 GB | Rank 2: 4.10 GB | Rank 3: 4.10 GB | Rank 4: 4.10 GB | Rank 5: 4.10 GB | Rank 6: 4.10 GB | Rank 7: 3.95 GB (Max: 42.29 GB, Total: 338.28 GB)
Rank 0: Batch  7 / 798, Shape: [16, 1024], Time: 21ms
Rank 7: Batch 55 / 798, Shape: [16, 1024], Time: 358ms
Rank 6: Batch 55 / 798, Shape: [16, 1024], Time: 358ms
Rank 3: Batch 54 / 798, Shape: [16, 1024], Time: 358ms
Rank 1: Batch 54 / 798, Shape: [16, 1024], Time: 358ms
Rank 4: Batch 55 / 798, Shape: [16, 1024], Time: 358ms
Rank 5: Batch 54 / 798, Shape: [16, 1024], Time: 358ms
Rank 2: Batch 54 / 798, Shape: [16, 1024], Time: 358ms
Rank 0: Batch  8 / 798, Shape: [16, 1024], Time: 360ms
Rank 7: Batch 56 / 798, Shape: [16, 1024], Time: 358ms
Rank 6: Batch 56 / 798, Shape: [16, 1024], Time: 358ms
Rank 3: Batch 55 / 798, Shape: [16, 1024], Time: 358ms
Rank 1: Batch 55 / 798, Shape: [16, 1024], Time: 358ms
Rank 4: Batch 56 / 798, Shape: [16, 1024], Time: 358ms
Rank 5: Batch 55 / 798, Shape: [16, 1024], Time: 358ms
Rank 2: Batch 55 / 798, Shape: [16, 1024], Time: 361ms
Rank 0: Batch  9 / 798, Shape: [16, 1024], Time: 359ms
Rank 7: Batch 57 / 798, Shape: [16, 1024], Time: 358ms
Rank 6: Batch 57 / 798, Shape: [16, 1024], Time: 358ms
Rank 3: Batch 56 / 798, Shape: [16, 1024], Time: 359ms
Rank 1: Batch 56 / 798, Shape: [16, 1024], Time: 358ms
Rank 4: Batch 57 / 798, Shape: [16, 1024], Time: 358ms
Rank 5: Batch 56 / 798, Shape: [16, 1024], Time: 358ms
Rank 2: Batch 56 / 798, Shape: [16, 1024], Time: 358ms
Rank 0: Batch 10 / 798, Shape: [16, 1024], Time: 361ms
Rank 3: Batch 57 / 798, Shape: [16, 1024], Time: 357ms
Rank 1: Batch 57 / 798, Shape: [16, 1024], Time: 358ms
Rank 5: Batch 57 / 798, Shape: [16, 1024], Time: 358ms
Rank 2: Batch 57 / 798, Shape: [16, 1024], Time: 360ms
Rank 0: Batch 11 / 798, Shape: [16, 1024], Time: 359ms
Rank 6: Batch 58 / 798, Shape: [16, 1024], Time: 730ms
Rank 7: Batch 58 / 798, Shape: [16, 1024], Time: 732ms
Rank 4: Batch 58 / 798, Shape: [16, 1024], Time: 720ms
Rank 6: Batch 59 / 798, Shape: [16, 1024], Time: 359ms
Rank 7: Batch 59 / 798, Shape: [16, 1024], Time: 358ms
Rank 4: Batch 59 / 798, Shape: [16, 1024], Time: 358ms
Rank 3: Batch 58 / 798, Shape: [16, 1024], Time: 859ms
Rank 6: Batch 60 / 798, Shape: [16, 1024], Time: 358ms
Rank 7: Batch 60 / 798, Shape: [16, 1024], Time: 359ms
Rank 4: Batch 60 / 798, Shape: [16, 1024], Time: 358ms
Rank 3: Batch 59 / 798, Shape: [16, 1024], Time: 358ms
Rank 5: Batch 58 / 798, Shape: [16, 1024], Time: 1s
Rank 1: Batch 58 / 798, Shape: [16, 1024], Time: 1s
Rank 6: Batch 61 / 798, Shape: [16, 1024], Time: 358ms
Rank 7: Batch 61 / 798, Shape: [16, 1024], Time: 359ms
Rank 4: Batch 61 / 798, Shape: [16, 1024], Time: 359ms
Rank 3: Batch 60 / 798, Shape: [16, 1024], Time: 358ms
Rank 2: Batch 58 / 798, Shape: [16, 1024], Time: 1s
Rank 5: Batch 59 / 798, Shape: [16, 1024], Time: 358ms
Rank 1: Batch 59 / 798, Shape: [16, 1024], Time: 359ms
Rank 6: Batch 62 / 798, Shape: [16, 1024], Time: 358ms
Rank 7: Batch 62 / 798, Shape: [16, 1024], Time: 357ms
Rank 4: Batch 62 / 798, Shape: [16, 1024], Time: 358ms
Rank 3: Batch 61 / 798, Shape: [16, 1024], Time: 358ms
Rank 2: Batch 59 / 798, Shape: [16, 1024], Time: 358ms
Rank 5: Batch 60 / 798, Shape: [16, 1024], Time: 359ms
Rank 1: Batch 60 / 798, Shape: [16, 1024], Time: 357ms
Rank 6: Batch 63 / 798, Shape: [16, 1024], Time: 358ms
Rank 7: Batch 63 / 798, Shape: [16, 1024], Time: 358ms
Rank 4: Batch 63 / 798, Shape: [16, 1024], Time: 359ms
Rank 3: Batch 62 / 798, Shape: [16, 1024], Time: 358ms
Rank 5: Batch 61 / 798, Shape: [16, 1024], Time: 358ms
Rank 2: Batch 60 / 798, Shape: [16, 1024], Time: 361ms
Rank 1: Batch 61 / 798, Shape: [16, 1024], Time: 359ms
Memory: Rank 0: 3.53 GB | Rank 1: 4.10 GB | Rank 2: 4.10 GB | Rank 3: 4.10 GB | Rank 4: 4.10 GB | Rank 5: 4.10 GB | Rank 6: 4.10 GB | Rank 7: 3.95 GB (Max: 42.29 GB, Total: 338.28 GB)
Rank 0: Batch 12 / 798, Shape: [16, 1024], Time: 22ms
Rank 6: Batch 64 / 798, Shape: [16, 1024], Time: 358ms
Rank 7: Batch 64 / 798, Shape: [16, 1024], Time: 359ms
Rank 4: Batch 64 / 798, Shape: [16, 1024], Time: 358ms
Rank 3: Batch 63 / 798, Shape: [16, 1024], Time: 358ms
Rank 5: Batch 62 / 798, Shape: [16, 1024], Time: 358ms
Rank 2: Batch 61 / 798, Shape: [16, 1024], Time: 358ms
Rank 1: Batch 62 / 798, Shape: [16, 1024], Time: 359ms
Rank 0: Batch 13 / 798, Shape: [16, 1024], Time: 361ms
Rank 6: Batch 65 / 798, Shape: [16, 1024], Time: 358ms
Rank 7: Batch 65 / 798, Shape: [16, 1024], Time: 358ms
Rank 4: Batch 65 / 798, Shape: [16, 1024], Time: 358ms
Rank 3: Batch 64 / 798, Shape: [16, 1024], Time: 358ms
Rank 5: Batch 63 / 798, Shape: [16, 1024], Time: 358ms
Rank 2: Batch 62 / 798, Shape: [16, 1024], Time: 361ms
Rank 1: Batch 63 / 798, Shape: [16, 1024], Time: 359ms
Rank 0: Batch 14 / 798, Shape: [16, 1024], Time: 359ms
Rank 6: Batch 66 / 798, Shape: [16, 1024], Time: 358ms
Rank 7: Batch 66 / 798, Shape: [16, 1024], Time: 358ms
Rank 4: Batch 66 / 798, Shape: [16, 1024], Time: 358ms
Rank 3: Batch 65 / 798, Shape: [16, 1024], Time: 358ms
Rank 5: Batch 64 / 798, Shape: [16, 1024], Time: 359ms
Rank 2: Batch 63 / 798, Shape: [16, 1024], Time: 358ms
Rank 1: Batch 64 / 798, Shape: [16, 1024], Time: 359ms
Rank 0: Batch 15 / 798, Shape: [16, 1024], Time: 357ms
Rank 6: Batch 67 / 798, Shape: [16, 1024], Time: 358ms
Rank 7: Batch 67 / 798, Shape: [16, 1024], Time: 358ms
Rank 4: Batch 67 / 798, Shape: [16, 1024], Time: 358ms
Rank 3: Batch 66 / 798, Shape: [16, 1024], Time: 358ms
Rank 5: Batch 65 / 798, Shape: [16, 1024], Time: 357ms
Rank 2: Batch 64 / 798, Shape: [16, 1024], Time: 359ms
Rank 1: Batch 65 / 798, Shape: [16, 1024], Time: 357ms
Rank 0: Batch 16 / 798, Shape: [16, 1024], Time: 357ms
Rank 6: Batch 68 / 798, Shape: [16, 1024], Time: 358ms
Rank 7: Batch 68 / 798, Shape: [16, 1024], Time: 358ms
Rank 4: Batch 68 / 798, Shape: [16, 1024], Time: 358ms
Rank 3: Batch 67 / 798, Shape: [16, 1024], Time: 358ms
Rank 5: Batch 66 / 798, Shape: [16, 1024], Time: 358ms
Rank 1: Batch 66 / 798, Shape: [16, 1024], Time: 359ms
Rank 2: Batch 65 / 798, Shape: [16, 1024], Time: 361ms
^C
Ctrl+C received. Terminating all processes...
Rank 0 - Current process: MainProcess cleaning up...
Terminating all child processes of MainProcess...
Terminated child process: SpawnProcess-4
Terminated child process: SpawnProcess-5
Terminated child process: SpawnProcess-6
Terminated child process: SpawnProcess-8
Terminated child process: SpawnProcess-3
Terminated child process: SpawnProcess-1
Terminated child process: SpawnProcess-7
Terminated child process: SpawnProcess-2
Rank 0 - Exiting program...
/usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
(nlp) ubuntu@138-2-58-218:~/nlp-osaka/sentiment$ python ./ddp_sentiment_finetune.py --dataset 'merged_local' --weights_name 'google/electra-large-discriminator' --save_data --save_model --save_pickle --save_preds --lr 0.0002 --lr_decay 0.95 --epochs 50 --pooling 'mean' --dropout_rate 0.3 --num_layers 2 --hidden_dim 1024 --hidden_activation 'swishglu' --batch_size 128 --l2_strength 0.0001 --checkpoint_interval 5 --use_zero --optimizer 'adamw' --scheduler 'cosine_warmup' --scheduler_kwargs '{"T_0":5, "T_mult":1, "eta_min":1e-7}' --decimal 6 --use_val_split --eval_split 'test' --early_stop 'score' --n_iter_no_change 50 --show_progress --wandb --wandb_project 'Electra Large' --wandb_run 'run_1_merged_class'

Starting DDP PyTorch Training...
Device: cuda, Number of GPUs: 8
Spawning 8 processes...
Rank 6 - Device: cuda:6
Rank 1 - Device: cuda:1
Rank 2 - Device: cuda:2
Rank 5 - Device: cuda:5
Rank 4 - Device: cuda:4
Rank 7 - Device: cuda:7
Rank 3 - Device: cuda:3
Rank 0 - Device: cuda:0
8 process groups initialized with 'nccl' backend on localhost:12355
NCCL Timeout: 1 hr 0 min. NCCL Blocking Wait: Enabled
wandb: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: jbeno (jimbeno). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.5
wandb: Run data is saved locally in /home/ubuntu/nlp-osaka/sentiment/wandb/run-20241023_235121-7n2enn4e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run run_1_merged_class
wandb: â­ï¸ View project at https://wandb.ai/jimbeno/Electra%20Large
wandb: ðŸš€ View run at https://wandb.ai/jimbeno/Electra%20Large/runs/7n2enn4e
Wand run initialized.

Initializing 'google/electra-large-discriminator' tokenizer and model...
Checking for local files...
Found all files in cache, skipping download
All ranks loading tokenizer from local files...
All ranks loading model from local files...
Tokenizer and model initialized (6s)

Loading data...
Using the same dataset for training and evaluation
Splits:
- Train: Using merged_local 'train' split
- Validation: Using merged_local 'validation' split
- Evaluation: Using merged_local 'test' split
Train Data: Merged DynaSent Round 1, Round 2 and SST from Local: 'data/merged'
Validation Data: Merged DynaSent Round 1, Round 2 and SST from Local: 'data/merged'
Evaluation Data: Merged DynaSent Round 1, Round 2 and SST from Local: 'data/merged'
Train size: 102097
Validation size: 5421
Evaluation size: 5421
Train label distribution:
	      Negative: 21910
	       Neutral: 49148
	      Positive: 31039
Validation label distribution:
	      Negative: 1868
	       Neutral: 1669
	      Positive: 1884
Evaluation label distribution:
	      Negative: 1868
	       Neutral: 1669
	      Positive: 1884
Data loaded (2s)

Processing data...
(Batch size: 128, Pooling: Mean, Fine Tune BERT: False, Chunk size: None)...
Extracting sentences and labels...

Displaying samples from Train data:
Train[84457]: she blurted. - NEUTRAL
Tokens: ['she', 'blurted', '.']
Embedding: [ 0.08256386  0.14963749  0.19717517 -0.26130205  0.08827331  0.6304889 ] ...

Train[33315]: $10 is the minimum tip they ask for. - NEUTRAL
Tokens: ['$', '10', 'is', 'the', 'minimum', 'tip', 'they', 'ask', 'for', '.']
Embedding: [ 0.07732821  0.05567317  0.10109115 -0.03255092  0.05662063  0.3636926 ] ...

Train[95755]: Once arriving home, we opened our food. - NEUTRAL
Tokens: ['once', 'arriving', 'home', ',', 'we', 'opened', 'our', 'food', '.']
Embedding: [0.0316001  0.03178836 0.12717418 0.09764466 0.00259186 0.3355862 ] ...


Encoding Train data of 102097 texts distributed across 8 GPUs...
Batch Size: 128, Pooling: Mean, Empty Cache: False
Padding Train data to 102104 texts for even distribution across 8 ranks...
Texts per rank: 12763, Total batches: 798
Rank 5: Processing 12763 texts (indices 63815 to 76577) in 100 batches...
Rank 6: Processing 12763 texts (indices 76578 to 89340) in 100 batches...
Rank 2: Processing 12763 texts (indices 25526 to 38288) in 100 batches...
Rank 3: Processing 12763 texts (indices 38289 to 51051) in 100 batches...
Rank 7: Processing 12763 texts (indices 89341 to 102103) in 100 batches...
Rank 4: Processing 12763 texts (indices 51052 to 63814) in 100 batches...
Rank 0: Processing 12763 texts (indices 0 to 12762) in 100 batches...
Rank 1: Processing 12763 texts (indices 12763 to 25525) in 100 batches...
Rank 0: Batch  1 / 100, Shape: [128, 1024], Time: 1s
Rank 2: Batch  1 / 100, Shape: [128, 1024], Time: 2s
Rank 3: Batch  1 / 100, Shape: [128, 1024], Time: 2s
Rank 4: Batch  1 / 100, Shape: [128, 1024], Time: 2s
Rank 6: Batch  1 / 100, Shape: [128, 1024], Time: 2s
Rank 7: Batch  1 / 100, Shape: [128, 1024], Time: 2s
Rank 5: Batch  1 / 100, Shape: [128, 1024], Time: 2s
Rank 1: Batch  1 / 100, Shape: [128, 1024], Time: 2s
Rank 3: Batch  2 / 100, Shape: [128, 1024], Time: 3s
Rank 2: Batch  2 / 100, Shape: [128, 1024], Time: 3s
Rank 4: Batch  2 / 100, Shape: [128, 1024], Time: 3s
Rank 5: Batch  2 / 100, Shape: [128, 1024], Time: 2s
Rank 6: Batch  2 / 100, Shape: [128, 1024], Time: 2s
Rank 7: Batch  2 / 100, Shape: [128, 1024], Time: 2s
Rank 1: Batch  2 / 100, Shape: [128, 1024], Time: 2s
Rank 3: Batch  3 / 100, Shape: [128, 1024], Time: 2s
Rank 7: Batch  3 / 100, Shape: [128, 1024], Time: 2s
Rank 1: Batch  3 / 100, Shape: [128, 1024], Time: 2s
Rank 4: Batch  3 / 100, Shape: [128, 1024], Time: 2s
Rank 6: Batch  3 / 100, Shape: [128, 1024], Time: 2s
Rank 5: Batch  3 / 100, Shape: [128, 1024], Time: 2s
Rank 2: Batch  3 / 100, Shape: [128, 1024], Time: 2s
Rank 1: Batch  4 / 100, Shape: [128, 1024], Time: 2s
Rank 7: Batch  4 / 100, Shape: [128, 1024], Time: 2s
Rank 3: Batch  4 / 100, Shape: [128, 1024], Time: 2s
Rank 4: Batch  4 / 100, Shape: [128, 1024], Time: 2s
Rank 6: Batch  4 / 100, Shape: [128, 1024], Time: 2s
Rank 5: Batch  4 / 100, Shape: [128, 1024], Time: 2s
Rank 2: Batch  4 / 100, Shape: [128, 1024], Time: 2s
Rank 1: Batch  5 / 100, Shape: [128, 1024], Time: 2s
Rank 3: Batch  5 / 100, Shape: [128, 1024], Time: 2s
Rank 7: Batch  5 / 100, Shape: [128, 1024], Time: 2s
Rank 6: Batch  5 / 100, Shape: [128, 1024], Time: 3s
Rank 5: Batch  5 / 100, Shape: [128, 1024], Time: 3s
Rank 4: Batch  5 / 100, Shape: [128, 1024], Time: 3s
Rank 2: Batch  5 / 100, Shape: [128, 1024], Time: 3s
^C
Ctrl+C received. Terminating all processes...
Rank 0 - Current process: MainProcess cleaning up...
Terminating all child processes of MainProcess...
Terminated child process: SpawnProcess-3
Terminated child process: SpawnProcess-7
Terminated child process: SpawnProcess-2
Terminated child process: SpawnProcess-6
Terminated child process: SpawnProcess-5
Terminated child process: SpawnProcess-1
Terminated child process: SpawnProcess-4
Terminated child process: SpawnProcess-8
Rank 0 - Exiting program...
(nlp) ubuntu@138-2-58-218:~/nlp-osaka/sentiment$ python ./ddp_sentiment_finetune.py --dataset 'merged_local' --weights_name 'google/electra-large-discriminator' --save_data --save_model --save_pickle --save_preds --lr 0.0002 --lr_decay 0.95 --epochs 50 --pooling 'mean' --dropout_rate 0.3 --num_layers 2 --hidden_dim 1024 --hidden_activation 'swishglu' --batch_size 512 --l2_strength 0.0001 --checkpoint_interval 5 --use_zero --optimizer 'adamw' --scheduler 'cosine_warmup' --scheduler_kwargs '{"T_0":5, "T_mult":1, "eta_min":1e-7}' --decimal 6 --use_val_split --eval_split 'test' --early_stop 'score' --n_iter_no_change 50 --show_progress --wandb --wandb_project 'Electra Large' --wandb_run 'run_1_merged_class' --interactive

Starting DDP PyTorch Training...
^C
Ctrl+C received. Terminating all processes...
Rank 0 - Current process: MainProcess cleaning up...
No active child processes to terminate
Rank 0 - Exiting program...
(nlp) ubuntu@138-2-58-218:~/nlp-osaka/sentiment$ python ./ddp_sentiment_finetune.py --dataset 'merged_local' --weights_name 'google/electra-large-discriminator' --save_data --save_model --save_pickle --save_preds --lr 0.0002 --lr_decay 0.95 --epochs 50 --pooling 'mean' --dropout_rate 0.3 --num_layers 2 --hidden_dim 1024 --hidden_activation 'swishglu' --batch_size 512 --l2_strength 0.0001 --checkpoint_interval 5 --use_zero --optimizer 'adamw' --scheduler 'cosine_warmup' --scheduler_kwargs '{"T_0":5, "T_mult":1, "eta_min":1e-7}' --decimal 6 --use_val_split --eval_split 'test' --early_stop 'score' --n_iter_no_change 50 --show_progress --wandb --wandb_project 'Electra Large' --wandb_run 'run_0_merged_data' --interactive

Starting DDP PyTorch Training...
Device: cuda, Number of GPUs: 8
Spawning 8 processes...
Rank 7 - Device: cuda:7
Rank 2 - Device: cuda:2
Rank 1 - Device: cuda:1
Rank 6 - Device: cuda:6
Rank 3 - Device: cuda:3
Rank 4 - Device: cuda:4
Rank 5 - Device: cuda:5
Rank 0 - Device: cuda:0
8 process groups initialized with 'nccl' backend on localhost:12355
NCCL Timeout: 1 hr 0 min. NCCL Blocking Wait: Enabled
wandb: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: jbeno (jimbeno). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.5
wandb: Run data is saved locally in /home/ubuntu/nlp-osaka/sentiment/wandb/run-20241023_235543-735c5n7t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run run_0_merged_data
wandb: â­ï¸ View project at https://wandb.ai/jimbeno/Electra%20Large
wandb: ðŸš€ View run at https://wandb.ai/jimbeno/Electra%20Large/runs/735c5n7t
Wand run initialized.

Initializing 'google/electra-large-discriminator' tokenizer and model...
Checking for local files...
Found all files in cache, skipping download
All ranks loading tokenizer from local files...
All ranks loading model from local files...
Tokenizer and model initialized (6s)

Loading data...
Using the same dataset for training and evaluation
Splits:
- Train: Using merged_local 'train' split
- Validation: Using merged_local 'validation' split
- Evaluation: Using merged_local 'test' split
Train Data: Merged DynaSent Round 1, Round 2 and SST from Local: 'data/merged'
Validation Data: Merged DynaSent Round 1, Round 2 and SST from Local: 'data/merged'
Evaluation Data: Merged DynaSent Round 1, Round 2 and SST from Local: 'data/merged'
Train size: 102097
Validation size: 5421
Evaluation size: 5421
Train label distribution:
	      Negative: 21910
	       Neutral: 49148
	      Positive: 31039
Validation label distribution:
	      Negative: 1868
	       Neutral: 1669
	      Positive: 1884
Evaluation label distribution:
	      Negative: 1868
	       Neutral: 1669
	      Positive: 1884
Data loaded (978ms)

Processing data...
(Batch size: 512, Pooling: Mean, Fine Tune BERT: False, Chunk size: None)...
Extracting sentences and labels...

Displaying samples from Train data:
Train[84457]: she blurted. - NEUTRAL
Tokens: ['she', 'blurted', '.']
Embedding: [ 0.08256386  0.14963749  0.19717517 -0.26130205  0.08827331  0.6304889 ] ...

Train[33315]: $10 is the minimum tip they ask for. - NEUTRAL
Tokens: ['$', '10', 'is', 'the', 'minimum', 'tip', 'they', 'ask', 'for', '.']
Embedding: [ 0.07732821  0.05567317  0.10109115 -0.03255092  0.05662063  0.3636926 ] ...

Train[95755]: Once arriving home, we opened our food. - NEUTRAL
Tokens: ['once', 'arriving', 'home', ',', 'we', 'opened', 'our', 'food', '.']
Embedding: [0.0316001  0.03178836 0.12717418 0.09764466 0.00259186 0.3355862 ] ...


Encoding Train data of 102097 texts distributed across 8 GPUs...
Batch Size: 512, Pooling: Mean, Empty Cache: False
Padding Train data to 102104 texts for even distribution across 8 ranks...
Texts per rank: 12763, Total batches: 200
Rank 5: Processing 12763 texts (indices 63815 to 76577) in 25 batches...
Rank 2: Processing 12763 texts (indices 25526 to 38288) in 25 batches...
Rank 0: Processing 12763 texts (indices 0 to 12762) in 25 batches...
Rank 4: Processing 12763 texts (indices 51052 to 63814) in 25 batches...
Rank 1: Processing 12763 texts (indices 12763 to 25525) in 25 batches...
Rank 6: Processing 12763 texts (indices 76578 to 89340) in 25 batches...
Rank 7: Processing 12763 texts (indices 89341 to 102103) in 25 batches...
Rank 3: Processing 12763 texts (indices 38289 to 51051) in 25 batches...
Rank 0: Batch  1 / 25, Shape: [512, 1024], Time: 2s
Rank 7: Batch  1 / 25, Shape: [512, 1024], Time: 2s
Rank 1: Batch  1 / 25, Shape: [512, 1024], Time: 2s
Rank 4: Batch  1 / 25, Shape: [512, 1024], Time: 2s
Rank 6: Batch  1 / 25, Shape: [512, 1024], Time: 2s
Rank 5: Batch  1 / 25, Shape: [512, 1024], Time: 3s
Rank 3: Batch  1 / 25, Shape: [512, 1024], Time: 3s
Rank 2: Batch  1 / 25, Shape: [512, 1024], Time: 4s
Rank 7: Batch  2 / 25, Shape: [512, 1024], Time: 11s
Rank 1: Batch  2 / 25, Shape: [512, 1024], Time: 12s
Rank 4: Batch  2 / 25, Shape: [512, 1024], Time: 12s
Rank 5: Batch  2 / 25, Shape: [512, 1024], Time: 11s
Rank 6: Batch  2 / 25, Shape: [512, 1024], Time: 12s
Rank 3: Batch  2 / 25, Shape: [512, 1024], Time: 11s
Rank 2: Batch  2 / 25, Shape: [512, 1024], Time: 10s
Memory: Rank 0: 27.42 GB | Rank 1: 27.99 GB | Rank 2: 27.99 GB | Rank 3: 27.99 GB | Rank 4: 27.99 GB | Rank 5: 30.14 GB | Rank 6: 30.14 GB | Rank 7: 29.99 GB (Max: 42.29 GB, Total: 338.28 GB)
Rank 0: Batch  2 / 25, Shape: [512, 1024], Time: 182ms
Rank 7: Batch  3 / 25, Shape: [512, 1024], Time: 10s
Rank 1: Batch  3 / 25, Shape: [512, 1024], Time: 10s
Rank 4: Batch  3 / 25, Shape: [512, 1024], Time: 10s
Rank 6: Batch  3 / 25, Shape: [512, 1024], Time: 10s
Rank 5: Batch  3 / 25, Shape: [512, 1024], Time: 10s
Rank 3: Batch  3 / 25, Shape: [512, 1024], Time: 10s
Rank 2: Batch  3 / 25, Shape: [512, 1024], Time: 10s
Rank 0: Batch  3 / 25, Shape: [512, 1024], Time: 10s
Rank 7: Batch  4 / 25, Shape: [512, 1024], Time: 10s
Rank 1: Batch  4 / 25, Shape: [512, 1024], Time: 10s
Rank 4: Batch  4 / 25, Shape: [512, 1024], Time: 10s
Rank 6: Batch  4 / 25, Shape: [512, 1024], Time: 10s
Rank 5: Batch  4 / 25, Shape: [512, 1024], Time: 10s
Rank 3: Batch  4 / 25, Shape: [512, 1024], Time: 10s
Rank 2: Batch  4 / 25, Shape: [512, 1024], Time: 10s
Rank 0: Batch  4 / 25, Shape: [512, 1024], Time: 10s
Rank 7: Batch  5 / 25, Shape: [512, 1024], Time: 10s
Rank 1: Batch  5 / 25, Shape: [512, 1024], Time: 10s
Rank 4: Batch  5 / 25, Shape: [512, 1024], Time: 10s
Rank 6: Batch  5 / 25, Shape: [512, 1024], Time: 10s
Rank 5: Batch  5 / 25, Shape: [512, 1024], Time: 10s
Rank 3: Batch  5 / 25, Shape: [512, 1024], Time: 10s
Rank 2: Batch  5 / 25, Shape: [512, 1024], Time: 10s
Rank 0: Batch  5 / 25, Shape: [512, 1024], Time: 10s
Rank 7: Batch  6 / 25, Shape: [512, 1024], Time: 10s
Rank 1: Batch  6 / 25, Shape: [512, 1024], Time: 10s
Rank 4: Batch  6 / 25, Shape: [512, 1024], Time: 10s
Rank 6: Batch  6 / 25, Shape: [512, 1024], Time: 10s
Rank 5: Batch  6 / 25, Shape: [512, 1024], Time: 10s
Rank 3: Batch  6 / 25, Shape: [512, 1024], Time: 10s
Rank 2: Batch  6 / 25, Shape: [512, 1024], Time: 10s
Rank 0: Batch  6 / 25, Shape: [512, 1024], Time: 10s
Memory: Rank 0: 28.50 GB | Rank 1: 30.14 GB | Rank 2: 30.14 GB | Rank 3: 30.14 GB | Rank 4: 30.14 GB | Rank 5: 30.14 GB | Rank 6: 30.14 GB | Rank 7: 29.99 GB (Max: 42.29 GB, Total: 338.28 GB)
Rank 7: Batch  7 / 25, Shape: [512, 1024], Time: 10s
Rank 1: Batch  7 / 25, Shape: [512, 1024], Time: 10s
Rank 6: Batch  7 / 25, Shape: [512, 1024], Time: 10s
Rank 4: Batch  7 / 25, Shape: [512, 1024], Time: 10s
Rank 5: Batch  7 / 25, Shape: [512, 1024], Time: 10s
Rank 3: Batch  7 / 25, Shape: [512, 1024], Time: 10s
Rank 2: Batch  7 / 25, Shape: [512, 1024], Time: 10s
Rank 0: Batch  7 / 25, Shape: [512, 1024], Time: 9s
Rank 7: Batch  8 / 25, Shape: [512, 1024], Time: 10s
Rank 1: Batch  8 / 25, Shape: [512, 1024], Time: 10s
Rank 6: Batch  8 / 25, Shape: [512, 1024], Time: 10s
Rank 4: Batch  8 / 25, Shape: [512, 1024], Time: 10s
Rank 5: Batch  8 / 25, Shape: [512, 1024], Time: 10s
Rank 3: Batch  8 / 25, Shape: [512, 1024], Time: 10s
Rank 2: Batch  8 / 25, Shape: [512, 1024], Time: 10s
Rank 0: Batch  8 / 25, Shape: [512, 1024], Time: 10s
Rank 7: Batch  9 / 25, Shape: [512, 1024], Time: 10s
Rank 1: Batch  9 / 25, Shape: [512, 1024], Time: 10s
Rank 6: Batch  9 / 25, Shape: [512, 1024], Time: 10s
Rank 4: Batch  9 / 25, Shape: [512, 1024], Time: 10s
Rank 5: Batch  9 / 25, Shape: [512, 1024], Time: 10s
Rank 3: Batch  9 / 25, Shape: [512, 1024], Time: 10s
Rank 2: Batch  9 / 25, Shape: [512, 1024], Time: 10s
Rank 0: Batch  9 / 25, Shape: [512, 1024], Time: 10s
Rank 7: Batch 10 / 25, Shape: [512, 1024], Time: 10s
Rank 1: Batch 10 / 25, Shape: [512, 1024], Time: 10s
Rank 6: Batch 10 / 25, Shape: [512, 1024], Time: 10s
Rank 4: Batch 10 / 25, Shape: [512, 1024], Time: 10s
Rank 5: Batch 10 / 25, Shape: [512, 1024], Time: 10s
Rank 3: Batch 10 / 25, Shape: [512, 1024], Time: 10s
Rank 2: Batch 10 / 25, Shape: [512, 1024], Time: 10s
Rank 0: Batch 10 / 25, Shape: [512, 1024], Time: 11s
Rank 7: Batch 11 / 25, Shape: [512, 1024], Time: 10s
Rank 1: Batch 11 / 25, Shape: [512, 1024], Time: 10s
Rank 4: Batch 11 / 25, Shape: [512, 1024], Time: 10s
Rank 6: Batch 11 / 25, Shape: [512, 1024], Time: 10s
Rank 5: Batch 11 / 25, Shape: [512, 1024], Time: 10s
Rank 3: Batch 11 / 25, Shape: [512, 1024], Time: 10s
Rank 2: Batch 11 / 25, Shape: [512, 1024], Time: 10s
Rank 0: Batch 11 / 25, Shape: [512, 1024], Time: 10s
Memory: Rank 0: 29.57 GB | Rank 1: 30.14 GB | Rank 2: 30.14 GB | Rank 3: 30.14 GB | Rank 4: 30.14 GB | Rank 5: 30.14 GB | Rank 6: 30.14 GB | Rank 7: 29.99 GB (Max: 42.29 GB, Total: 338.28 GB)
Rank 7: Batch 12 / 25, Shape: [512, 1024], Time: 10s
Rank 1: Batch 12 / 25, Shape: [512, 1024], Time: 10s
Rank 4: Batch 12 / 25, Shape: [512, 1024], Time: 10s
Rank 6: Batch 12 / 25, Shape: [512, 1024], Time: 10s
Rank 5: Batch 12 / 25, Shape: [512, 1024], Time: 10s
Rank 3: Batch 12 / 25, Shape: [512, 1024], Time: 10s
Rank 2: Batch 12 / 25, Shape: [512, 1024], Time: 10s
Rank 0: Batch 12 / 25, Shape: [512, 1024], Time: 10s
Rank 7: Batch 13 / 25, Shape: [512, 1024], Time: 10s
Rank 1: Batch 13 / 25, Shape: [512, 1024], Time: 10s
Rank 4: Batch 13 / 25, Shape: [512, 1024], Time: 10s
Rank 6: Batch 13 / 25, Shape: [512, 1024], Time: 10s
Rank 5: Batch 13 / 25, Shape: [512, 1024], Time: 10s
Rank 3: Batch 13 / 25, Shape: [512, 1024], Time: 10s
Rank 2: Batch 13 / 25, Shape: [512, 1024], Time: 10s
Rank 0: Batch 13 / 25, Shape: [512, 1024], Time: 10s
Rank 7: Batch 14 / 25, Shape: [512, 1024], Time: 10s
Rank 1: Batch 14 / 25, Shape: [512, 1024], Time: 10s
Rank 4: Batch 14 / 25, Shape: [512, 1024], Time: 10s
Rank 6: Batch 14 / 25, Shape: [512, 1024], Time: 10s
Rank 5: Batch 14 / 25, Shape: [512, 1024], Time: 10s
Rank 3: Batch 14 / 25, Shape: [512, 1024], Time: 10s
Rank 2: Batch 14 / 25, Shape: [512, 1024], Time: 10s
Rank 0: Batch 14 / 25, Shape: [512, 1024], Time: 10s
Rank 7: Batch 15 / 25, Shape: [512, 1024], Time: 10s
Rank 1: Batch 15 / 25, Shape: [512, 1024], Time: 10s
Rank 6: Batch 15 / 25, Shape: [512, 1024], Time: 10s
Rank 4: Batch 15 / 25, Shape: [512, 1024], Time: 10s
Rank 5: Batch 15 / 25, Shape: [512, 1024], Time: 10s
Rank 3: Batch 15 / 25, Shape: [512, 1024], Time: 10s
Rank 2: Batch 15 / 25, Shape: [512, 1024], Time: 10s
Rank 0: Batch 15 / 25, Shape: [512, 1024], Time: 10s
Rank 7: Batch 16 / 25, Shape: [512, 1024], Time: 10s
Rank 1: Batch 16 / 25, Shape: [512, 1024], Time: 10s
Rank 6: Batch 16 / 25, Shape: [512, 1024], Time: 10s
Rank 4: Batch 16 / 25, Shape: [512, 1024], Time: 10s
Rank 5: Batch 16 / 25, Shape: [512, 1024], Time: 10s
Rank 3: Batch 16 / 25, Shape: [512, 1024], Time: 10s
Rank 2: Batch 16 / 25, Shape: [512, 1024], Time: 10s
Rank 0: Batch 16 / 25, Shape: [512, 1024], Time: 10s
Memory: Rank 0: 29.57 GB | Rank 1: 30.14 GB | Rank 2: 30.14 GB | Rank 3: 30.14 GB | Rank 4: 30.14 GB | Rank 5: 30.14 GB | Rank 6: 30.14 GB | Rank 7: 29.99 GB (Max: 42.29 GB, Total: 338.28 GB)
Rank 7: Batch 17 / 25, Shape: [512, 1024], Time: 10s
Rank 1: Batch 17 / 25, Shape: [512, 1024], Time: 10s
Rank 6: Batch 17 / 25, Shape: [512, 1024], Time: 10s
Rank 4: Batch 17 / 25, Shape: [512, 1024], Time: 10s
Rank 5: Batch 17 / 25, Shape: [512, 1024], Time: 10s
Rank 3: Batch 17 / 25, Shape: [512, 1024], Time: 10s
Rank 2: Batch 17 / 25, Shape: [512, 1024], Time: 10s
Rank 0: Batch 17 / 25, Shape: [512, 1024], Time: 9s
Rank 7: Batch 18 / 25, Shape: [512, 1024], Time: 10s
Rank 1: Batch 18 / 25, Shape: [512, 1024], Time: 10s
Rank 6: Batch 18 / 25, Shape: [512, 1024], Time: 10s
Rank 4: Batch 18 / 25, Shape: [512, 1024], Time: 10s
Rank 5: Batch 18 / 25, Shape: [512, 1024], Time: 10s
Rank 3: Batch 18 / 25, Shape: [512, 1024], Time: 10s
Rank 2: Batch 18 / 25, Shape: [512, 1024], Time: 10s
Rank 0: Batch 18 / 25, Shape: [512, 1024], Time: 10s
Rank 7: Batch 19 / 25, Shape: [512, 1024], Time: 10s
Rank 1: Batch 19 / 25, Shape: [512, 1024], Time: 10s
Rank 6: Batch 19 / 25, Shape: [512, 1024], Time: 10s
Rank 4: Batch 19 / 25, Shape: [512, 1024], Time: 10s
Rank 5: Batch 19 / 25, Shape: [512, 1024], Time: 10s
Rank 3: Batch 19 / 25, Shape: [512, 1024], Time: 10s
Rank 2: Batch 19 / 25, Shape: [512, 1024], Time: 10s
Rank 0: Batch 19 / 25, Shape: [512, 1024], Time: 10s
Rank 7: Batch 20 / 25, Shape: [512, 1024], Time: 10s
Rank 1: Batch 20 / 25, Shape: [512, 1024], Time: 10s
Rank 6: Batch 20 / 25, Shape: [512, 1024], Time: 10s
Rank 4: Batch 20 / 25, Shape: [512, 1024], Time: 10s
Rank 5: Batch 20 / 25, Shape: [512, 1024], Time: 10s
Rank 3: Batch 20 / 25, Shape: [512, 1024], Time: 10s
Rank 2: Batch 20 / 25, Shape: [512, 1024], Time: 10s
Rank 0: Batch 20 / 25, Shape: [512, 1024], Time: 10s
Rank 7: Batch 21 / 25, Shape: [512, 1024], Time: 10s
Rank 1: Batch 21 / 25, Shape: [512, 1024], Time: 10s
Rank 6: Batch 21 / 25, Shape: [512, 1024], Time: 10s
Rank 4: Batch 21 / 25, Shape: [512, 1024], Time: 10s
Rank 5: Batch 21 / 25, Shape: [512, 1024], Time: 10s
Rank 3: Batch 21 / 25, Shape: [512, 1024], Time: 10s
Rank 2: Batch 21 / 25, Shape: [512, 1024], Time: 10s
Rank 0: Batch 21 / 25, Shape: [512, 1024], Time: 10s
Memory: Rank 0: 29.57 GB | Rank 1: 30.14 GB | Rank 2: 30.14 GB | Rank 3: 30.14 GB | Rank 4: 30.14 GB | Rank 5: 30.14 GB | Rank 6: 30.14 GB | Rank 7: 29.99 GB (Max: 42.29 GB, Total: 338.28 GB)
Rank 7: Batch 22 / 25, Shape: [512, 1024], Time: 10s
Rank 1: Batch 22 / 25, Shape: [512, 1024], Time: 10s
Rank 6: Batch 22 / 25, Shape: [512, 1024], Time: 10s
Rank 4: Batch 22 / 25, Shape: [512, 1024], Time: 10s
Rank 5: Batch 22 / 25, Shape: [512, 1024], Time: 10s
Rank 3: Batch 22 / 25, Shape: [512, 1024], Time: 10s
Rank 2: Batch 22 / 25, Shape: [512, 1024], Time: 10s
Rank 0: Batch 22 / 25, Shape: [512, 1024], Time: 10s
Rank 7: Batch 23 / 25, Shape: [512, 1024], Time: 10s
Rank 1: Batch 23 / 25, Shape: [512, 1024], Time: 10s
Rank 6: Batch 23 / 25, Shape: [512, 1024], Time: 10s
Rank 4: Batch 23 / 25, Shape: [512, 1024], Time: 10s
Rank 5: Batch 23 / 25, Shape: [512, 1024], Time: 10s
Rank 3: Batch 23 / 25, Shape: [512, 1024], Time: 10s
Rank 2: Batch 23 / 25, Shape: [512, 1024], Time: 10s
Rank 0: Batch 23 / 25, Shape: [512, 1024], Time: 10s
Rank 7: Batch 24 / 25, Shape: [512, 1024], Time: 10s
Rank 1: Batch 24 / 25, Shape: [512, 1024], Time: 10s
Rank 6: Batch 24 / 25, Shape: [512, 1024], Time: 10s
Rank 4: Batch 24 / 25, Shape: [512, 1024], Time: 10s
Rank 5: Batch 24 / 25, Shape: [512, 1024], Time: 10s
Rank 3: Batch 24 / 25, Shape: [512, 1024], Time: 10s
Rank 2: Batch 24 / 25, Shape: [512, 1024], Time: 10s
Rank 0: Batch 24 / 25, Shape: [512, 1024], Time: 10s
Rank 7: Batch 25 / 25, Shape: [475, 1024], Time: 10s
Rank 1: Batch 25 / 25, Shape: [475, 1024], Time: 10s
Rank 6: Batch 25 / 25, Shape: [475, 1024], Time: 10s
Rank 4: Batch 25 / 25, Shape: [475, 1024], Time: 10s
Rank 5: Batch 25 / 25, Shape: [475, 1024], Time: 10s
Rank 3: Batch 25 / 25, Shape: [475, 1024], Time: 10s
Rank 2: Batch 25 / 25, Shape: [475, 1024], Time: 10s
Rank 0: Batch 25 / 25, Shape: [475, 1024], Time: 10s
Total embeddings: 102104
Original texts: 102097
Expected padding: 7
Actual padding: 7
Maximum difference between padding embeddings: 0.0
Padding embeddings verified as very similar.
Encoding completed (4m 40s)

Displaying samples from Validation data:
Validation[1381]: My primary care doctor left and unfortunately his new office is taking new patients so I stuck with Forte until I find someone new. - NEGATIVE
Tokens: ['my', 'primary', 'care', 'doctor', 'left', 'and', 'unfortunately', 'his', 'new', 'office', 'is', 'taking', 'new', 'patients', 'so', 'i', 'stuck', 'with', 'forte', 'until', 'i', 'find', 'someone', 'new', '.']
Embedding: [ 0.01366349  0.04574399 -0.04796911  0.10655529 -0.01691415  0.19390202] ...

Validation[2337]: He didn't even back off when we made it clear we were a couple. - NEGATIVE
Tokens: ['he', 'didn', "'", 't', 'even', 'back', 'off', 'when', 'we', 'made', 'it', 'clear', 'we', 'were', 'a', 'couple', '.']
Embedding: [ 0.12637253  0.00845566  0.06000464 -0.06163526  0.08394092  0.19549723] ...

Validation[5213]: The food was fantastic if you love cold greasy food. - NEGATIVE
Tokens: ['the', 'food', 'was', 'fantastic', 'if', 'you', 'love', 'cold', 'greasy', 'food', '.']
Embedding: [ 0.01308539  0.121415    0.06353684 -0.0267145   0.00121865  0.26498944] ...


Encoding Validation data of 5421 texts distributed across 8 GPUs...
Batch Size: 512, Pooling: Mean, Empty Cache: False
Padding Validation data to 5424 texts for even distribution across 8 ranks...
Texts per rank: 678, Total batches: 11
Rank 1: Processing 678 texts (indices 678 to 1355) in 2 batches...
Rank 2: Processing 678 texts (indices 1356 to 2033) in 2 batches...
Rank 7: Processing 678 texts (indices 4746 to 5423) in 2 batches...
Rank 5: Processing 678 texts (indices 3390 to 4067) in 2 batches...
Rank 3: Processing 678 texts (indices 2034 to 2711) in 2 batches...
Rank 4: Processing 678 texts (indices 2712 to 3389) in 2 batches...
Rank 6: Processing 678 texts (indices 4068 to 4745) in 2 batches...
Rank 0: Processing 678 texts (indices 0 to 677) in 2 batches...
Rank 1: Batch  1 / 2, Shape: [512, 1024], Time: 183ms
Rank 5: Batch  1 / 2, Shape: [512, 1024], Time: 187ms
Rank 7: Batch  1 / 2, Shape: [512, 1024], Time: 188ms
Rank 3: Batch  1 / 2, Shape: [512, 1024], Time: 192ms
Rank 4: Batch  1 / 2, Shape: [512, 1024], Time: 194ms
Rank 2: Batch  1 / 2, Shape: [512, 1024], Time: 197ms
Rank 6: Batch  1 / 2, Shape: [512, 1024], Time: 205ms
Rank 0: Batch  1 / 2, Shape: [512, 1024], Time: 601ms
Memory: Rank 0: 28.50 GB | Rank 1: 30.14 GB | Rank 2: 30.14 GB | Rank 3: 30.14 GB | Rank 4: 30.14 GB | Rank 5: 30.14 GB | Rank 6: 30.14 GB | Rank 7: 29.99 GB (Max: 42.29 GB, Total: 338.28 GB)
Rank 1: Batch  2 / 2, Shape: [166, 1024], Time: 10s
Rank 5: Batch  2 / 2, Shape: [166, 1024], Time: 10s
Rank 7: Batch  2 / 2, Shape: [166, 1024], Time: 10s
Rank 3: Batch  2 / 2, Shape: [166, 1024], Time: 10s
Rank 6: Batch  2 / 2, Shape: [166, 1024], Time: 10s
Rank 4: Batch  2 / 2, Shape: [166, 1024], Time: 10s
Rank 2: Batch  2 / 2, Shape: [166, 1024], Time: 10s
Rank 0: Batch  2 / 2, Shape: [166, 1024], Time: 10s
Total embeddings: 5424
Original texts: 5421
Expected padding: 3
Actual padding: 3
Maximum difference between padding embeddings: 0.0
Padding embeddings verified as very similar.
Encoding completed (14s)

Displaying samples from Evaluation data:
Evaluation[1914]: Some pieces could be replaced by other pieces moving forward as they were less interesting. - NEGATIVE
Tokens: ['some', 'pieces', 'could', 'be', 'replaced', 'by', 'other', 'pieces', 'moving', 'forward', 'as', 'they', 'were', 'less', 'interesting', '.']
Embedding: [0.01328443 0.0649268  0.04166172 0.0843638  0.03973192 0.32150322] ...

Evaluation[1691]: Now i regret the decision of going here very much, since I am addicted to the great food. - POSITIVE
Tokens: ['now', 'i', 'regret', 'the', 'decision', 'of', 'going', 'here', 'very', 'much', ',', 'since', 'i', 'am', 'addicted', 'to', 'the', 'great', 'food', '.']
Embedding: [-0.04003622  0.07194331  0.01292203  0.17146584 -0.06550248  0.21607018] ...

Evaluation[5340]: Really deserves NEGATIVE 5 stars. - NEGATIVE
Tokens: ['really', 'deserves', 'negative', '5', 'stars', '.']
Embedding: [0.09070589 0.07491362 0.16970977 0.00959208 0.03639592 0.4348669 ] ...


Encoding Evaluation data of 5421 texts distributed across 8 GPUs...
Batch Size: 512, Pooling: Mean, Empty Cache: False
Padding Evaluation data to 5424 texts for even distribution across 8 ranks...
Texts per rank: 678, Total batches: 11
Rank 3: Processing 678 texts (indices 2034 to 2711) in 2 batches...
Rank 4: Processing 678 texts (indices 2712 to 3389) in 2 batches...
Rank 5: Processing 678 texts (indices 3390 to 4067) in 2 batches...
Rank 7: Processing 678 texts (indices 4746 to 5423) in 2 batches...
Rank 6: Processing 678 texts (indices 4068 to 4745) in 2 batches...
Rank 1: Processing 678 texts (indices 678 to 1355) in 2 batches...
Rank 2: Processing 678 texts (indices 1356 to 2033) in 2 batches...
Rank 0: Processing 678 texts (indices 0 to 677) in 2 batches...
Rank 1: Batch  1 / 2, Shape: [512, 1024], Time: 189ms
Rank 7: Batch  1 / 2, Shape: [512, 1024], Time: 191ms
Rank 6: Batch  1 / 2, Shape: [512, 1024], Time: 193ms
Rank 2: Batch  1 / 2, Shape: [512, 1024], Time: 194ms
Rank 4: Batch  1 / 2, Shape: [512, 1024], Time: 195ms
Rank 5: Batch  1 / 2, Shape: [512, 1024], Time: 196ms
Rank 3: Batch  1 / 2, Shape: [512, 1024], Time: 198ms
Rank 0: Batch  1 / 2, Shape: [512, 1024], Time: 498ms
Memory: Rank 0: 28.50 GB | Rank 1: 30.14 GB | Rank 2: 30.14 GB | Rank 3: 30.14 GB | Rank 4: 30.14 GB | Rank 5: 30.14 GB | Rank 6: 30.14 GB | Rank 7: 29.99 GB (Max: 42.29 GB, Total: 338.28 GB)
Rank 7: Batch  2 / 2, Shape: [166, 1024], Time: 10s
Rank 1: Batch  2 / 2, Shape: [166, 1024], Time: 10s
Rank 6: Batch  2 / 2, Shape: [166, 1024], Time: 10s
Rank 5: Batch  2 / 2, Shape: [166, 1024], Time: 10s
Rank 4: Batch  2 / 2, Shape: [166, 1024], Time: 10s
Rank 3: Batch  2 / 2, Shape: [166, 1024], Time: 10s
Rank 2: Batch  2 / 2, Shape: [166, 1024], Time: 10s
Rank 0: Batch  2 / 2, Shape: [166, 1024], Time: 10s
Total embeddings: 5424
Original texts: 5421
Expected padding: 3
Actual padding: 3
Maximum difference between padding embeddings: 0.0
Padding embeddings verified as very similar.
Encoding completed (15s)

Data saved to: saves/data_8_gpu_20241024-000103.npz
X Train shape: [102097, 1024], X Validation shape: [5421, 1024], X Test shape: [5421, 1024]
y Train shape: [102097], y Validation shape: [5421], y Test shape: [5421]
Data processed (5m 36s)

Initializing DDP Neural Classifier...
Layers: 2, Hidden Dim: 1024, Hidden Act: SwishGLU, Dropout: 0.3, Optimizer: AdamW, L2 Strength: 0.0001, Pooling: MEAN, Accumulation Steps: 1, Max Grad Norm: None
Batch Size: 512, Max Epochs: 50, LR: 0.0002, Early Stop: score, Fine-tune BERT: False, Fine-tune Layers: 1, Freeze BERT: False, Target Score: None, Interactive: True
Classifier initialized (21ms)

Fitting DDP Neural Classifier on training data...
Num Workers: 0, Prefetch: None
Score-based early stopping enabled (macro average F1 score against validation set). Validation fraction: 0.1
Training will stop early if the score does not improve by at least 0.00001 for 50 iterations.
Using provided validation set for early stopping.
Building dataset and dataloader...
Classes: ['negative', 'neutral', 'positive'], Number of classes: 3
Initializing model, graph, optimizer...

Model Architecture Summary:
Classifier(
  (layers): Sequential(
    (0): Linear(in_features=1024, out_features=1024, bias=True)
    (1): SwishGLU(
      (projection): Linear(in_features=1024, out_features=2048, bias=True)
      (activation): SiLU()
    )
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=1024, out_features=1024, bias=True)
    (4): SwishGLU(
      (projection): Linear(in_features=1024, out_features=2048, bias=True)
      (activation): SiLU()
    )
    (5): Dropout(p=0.3, inplace=False)
    (6): Linear(in_features=1024, out_features=3, bias=True)
  )
)

Model Parameters:
  layers.0: 1,049,600 (trainable)
  layers.1.projection: 2,099,200 (trainable)
  layers.3: 1,049,600 (trainable)
  layers.6: 3,075 (trainable)

Total layers: 4
Trainable layers: 4
Total parameters: 4,201,475
Trainable parameters: 4,201,475
Percentage of trainable parameters: 100.00%
An error occurred during training: list index out of range
Traceback (most recent call last):
  File "/home/ubuntu/nlp-osaka/sentiment/ddp_sentiment_finetune.py", line 1206, in main
    classifier.fit(X_train, X_val, y_train, y_val, rank, world_size, debug, start_epoch, model_state_dict, optimizer_state_dict,
  File "/home/ubuntu/nlp-osaka/sentiment/torch_ddp_finetune_neural_classifier.py", line 1052, in fit
    self.initialize()
  File "/home/ubuntu/nlp-osaka/sentiment/torch_model_base.py", line 426, in initialize
    self.optimizer = self.build_optimizer()
  File "/home/ubuntu/nlp-osaka/sentiment/torch_ddp_finetune_neural_classifier.py", line 511, in build_optimizer
    optimizer = ZeroRedundancyOptimizer(
  File "/home/ubuntu/nlp-osaka/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py", line 374, in __init__
    self._verify_same_dense_param_type()
  File "/home/ubuntu/nlp-osaka/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py", line 1447, in _verify_same_dense_param_type
    typename = torch.typename(self._all_params[0])
IndexError: list index out of range
An error occurred during training: list index out of range
Traceback (most recent call last):
  File "/home/ubuntu/nlp-osaka/sentiment/ddp_sentiment_finetune.py", line 1206, in main
    classifier.fit(X_train, X_val, y_train, y_val, rank, world_size, debug, start_epoch, model_state_dict, optimizer_state_dict,
  File "/home/ubuntu/nlp-osaka/sentiment/torch_ddp_finetune_neural_classifier.py", line 1052, in fit
    self.initialize()
  File "/home/ubuntu/nlp-osaka/sentiment/torch_model_base.py", line 426, in initialize
    self.optimizer = self.build_optimizer()
  File "/home/ubuntu/nlp-osaka/sentiment/torch_ddp_finetune_neural_classifier.py", line 511, in build_optimizer
    optimizer = ZeroRedundancyOptimizer(
  File "/home/ubuntu/nlp-osaka/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py", line 374, in __init__
    self._verify_same_dense_param_type()
  File "/home/ubuntu/nlp-osaka/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py", line 1447, in _verify_same_dense_param_type
    typename = torch.typename(self._all_params[0])
IndexError: list index out of range
An error occurred during training: list index out of range
An error occurred during training: list index out of range
Traceback (most recent call last):
Traceback (most recent call last):
  File "/home/ubuntu/nlp-osaka/sentiment/ddp_sentiment_finetune.py", line 1206, in main
    classifier.fit(X_train, X_val, y_train, y_val, rank, world_size, debug, start_epoch, model_state_dict, optimizer_state_dict,
  File "/home/ubuntu/nlp-osaka/sentiment/torch_ddp_finetune_neural_classifier.py", line 1052, in fit
    self.initialize()
  File "/home/ubuntu/nlp-osaka/sentiment/ddp_sentiment_finetune.py", line 1206, in main
    classifier.fit(X_train, X_val, y_train, y_val, rank, world_size, debug, start_epoch, model_state_dict, optimizer_state_dict,
  File "/home/ubuntu/nlp-osaka/sentiment/torch_ddp_finetune_neural_classifier.py", line 1052, in fit
    self.initialize()
  File "/home/ubuntu/nlp-osaka/sentiment/torch_model_base.py", line 426, in initialize
    self.optimizer = self.build_optimizer()
  File "/home/ubuntu/nlp-osaka/sentiment/torch_model_base.py", line 426, in initialize
    self.optimizer = self.build_optimizer()
  File "/home/ubuntu/nlp-osaka/sentiment/torch_ddp_finetune_neural_classifier.py", line 511, in build_optimizer
    optimizer = ZeroRedundancyOptimizer(
  File "/home/ubuntu/nlp-osaka/sentiment/torch_ddp_finetune_neural_classifier.py", line 511, in build_optimizer
    optimizer = ZeroRedundancyOptimizer(
  File "/home/ubuntu/nlp-osaka/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py", line 374, in __init__
    self._verify_same_dense_param_type()
  File "/home/ubuntu/nlp-osaka/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py", line 374, in __init__
    self._verify_same_dense_param_type()
  File "/home/ubuntu/nlp-osaka/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py", line 1447, in _verify_same_dense_param_type
    typename = torch.typename(self._all_params[0])
  File "/home/ubuntu/nlp-osaka/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py", line 1447, in _verify_same_dense_param_type
    typename = torch.typename(self._all_params[0])
IndexError: list index out of range
IndexError: list index out of range
An error occurred during training: list index out of range
Traceback (most recent call last):
  File "/home/ubuntu/nlp-osaka/sentiment/ddp_sentiment_finetune.py", line 1206, in main
    classifier.fit(X_train, X_val, y_train, y_val, rank, world_size, debug, start_epoch, model_state_dict, optimizer_state_dict,
  File "/home/ubuntu/nlp-osaka/sentiment/torch_ddp_finetune_neural_classifier.py", line 1052, in fit
    self.initialize()
  File "/home/ubuntu/nlp-osaka/sentiment/torch_model_base.py", line 426, in initialize
    self.optimizer = self.build_optimizer()
  File "/home/ubuntu/nlp-osaka/sentiment/torch_ddp_finetune_neural_classifier.py", line 511, in build_optimizer
    optimizer = ZeroRedundancyOptimizer(
  File "/home/ubuntu/nlp-osaka/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py", line 374, in __init__
    self._verify_same_dense_param_type()
  File "/home/ubuntu/nlp-osaka/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py", line 1447, in _verify_same_dense_param_type
    typename = torch.typename(self._all_params[0])
IndexError: list index out of range
An error occurred during training: list index out of range
Traceback (most recent call last):
  File "/home/ubuntu/nlp-osaka/sentiment/ddp_sentiment_finetune.py", line 1206, in main
    classifier.fit(X_train, X_val, y_train, y_val, rank, world_size, debug, start_epoch, model_state_dict, optimizer_state_dict,
  File "/home/ubuntu/nlp-osaka/sentiment/torch_ddp_finetune_neural_classifier.py", line 1052, in fit
    self.initialize()
  File "/home/ubuntu/nlp-osaka/sentiment/torch_model_base.py", line 426, in initialize
    self.optimizer = self.build_optimizer()
  File "/home/ubuntu/nlp-osaka/sentiment/torch_ddp_finetune_neural_classifier.py", line 511, in build_optimizer
    optimizer = ZeroRedundancyOptimizer(
  File "/home/ubuntu/nlp-osaka/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py", line 374, in __init__
    self._verify_same_dense_param_type()
  File "/home/ubuntu/nlp-osaka/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py", line 1447, in _verify_same_dense_param_type
    typename = torch.typename(self._all_params[0])
IndexError: list index out of range
An error occurred during training: list index out of range
Traceback (most recent call last):
  File "/home/ubuntu/nlp-osaka/sentiment/ddp_sentiment_finetune.py", line 1206, in main
    classifier.fit(X_train, X_val, y_train, y_val, rank, world_size, debug, start_epoch, model_state_dict, optimizer_state_dict,
  File "/home/ubuntu/nlp-osaka/sentiment/torch_ddp_finetune_neural_classifier.py", line 1052, in fit
    self.initialize()
  File "/home/ubuntu/nlp-osaka/sentiment/torch_model_base.py", line 426, in initialize
    self.optimizer = self.build_optimizer()
  File "/home/ubuntu/nlp-osaka/sentiment/torch_ddp_finetune_neural_classifier.py", line 511, in build_optimizer
    optimizer = ZeroRedundancyOptimizer(
  File "/home/ubuntu/nlp-osaka/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py", line 374, in __init__
    self._verify_same_dense_param_type()
  File "/home/ubuntu/nlp-osaka/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py", line 1447, in _verify_same_dense_param_type
    typename = torch.typename(self._all_params[0])
IndexError: list index out of range
An error occurred during training: list index out of range
Traceback (most recent call last):
  File "/home/ubuntu/nlp-osaka/sentiment/ddp_sentiment_finetune.py", line 1206, in main
    classifier.fit(X_train, X_val, y_train, y_val, rank, world_size, debug, start_epoch, model_state_dict, optimizer_state_dict,
  File "/home/ubuntu/nlp-osaka/sentiment/torch_ddp_finetune_neural_classifier.py", line 1052, in fit
    self.initialize()
  File "/home/ubuntu/nlp-osaka/sentiment/torch_model_base.py", line 426, in initialize
    self.optimizer = self.build_optimizer()
  File "/home/ubuntu/nlp-osaka/sentiment/torch_ddp_finetune_neural_classifier.py", line 511, in build_optimizer
    optimizer = ZeroRedundancyOptimizer(
  File "/home/ubuntu/nlp-osaka/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py", line 374, in __init__
    self._verify_same_dense_param_type()
  File "/home/ubuntu/nlp-osaka/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py", line 1447, in _verify_same_dense_param_type
    typename = torch.typename(self._all_params[0])
IndexError: list index out of range
(nlp) ubuntu@138-2-58-218:~/nlp-osaka/sentiment$ python ./ddp_sentiment_finetune.py --dataset 'merged_local' --weights_name 'google/electra-large-discriminator' --save_data --save_model --save_pickle --save_preds --lr 0.0002 --lr_decay 0.95 --epochs 50 --pooling 'mean' --dropout_rate 0.3 --num_layers 2 --hidden_dim 1024 --hidden_activation 'swishglu' --batch_size 128 --l2_strength 0.0001 --checkpoint_interval 5 --use_zero --optimizer 'adamw' --scheduler 'cosine_warmup' --scheduler_kwargs '{"T_0":5, "T_mult":1, "eta_min":1e-7}' --decimal 6 --use_val_split --eval_split 'test' --early_stop 'score' --n_iter_no_change 50 --show_progress --wandb --wandb_project 'Electra Large' --wandb_run 'run_1_merged_class' --data_file 'saves/data_8_gpu_20241024-000103.npz'

Starting DDP PyTorch Training...
Device: cuda, Number of GPUs: 8
Spawning 8 processes...
Rank 2 - Device: cuda:2
Rank 7 - Device: cuda:7
Rank 1 - Device: cuda:1
Rank 6 - Device: cuda:6
Rank 4 - Device: cuda:4
Rank 5 - Device: cuda:5
Rank 3 - Device: cuda:3
Rank 0 - Device: cuda:0
8 process groups initialized with 'nccl' backend on localhost:12355
NCCL Timeout: 1 hr 0 min. NCCL Blocking Wait: Enabled
wandb: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: jbeno (jimbeno). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.5
wandb: Run data is saved locally in /home/ubuntu/nlp-osaka/sentiment/wandb/run-20241024_000501-o3osao4d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run run_1_merged_class
wandb: â­ï¸ View project at https://wandb.ai/jimbeno/Electra%20Large
wandb: ðŸš€ View run at https://wandb.ai/jimbeno/Electra%20Large/runs/o3osao4d
Wand run initialized.

Initializing 'google/electra-large-discriminator' tokenizer and model...
Checking for local files...
Found all files in cache, skipping download
All ranks loading tokenizer from local files...
All ranks loading model from local files...
Tokenizer and model initialized (6s)

Loading archived data from: saves/data_8_gpu_20241024-000103.npz...
X Train shape: [102097, 1024], y Train shape: [102097]
X Validation shape: [5421, 1024], y Validation shape: [5421]
X Test shape: [5421, 1024], y Dev shape: [5421]
X Test Sentences shape: [5421]
Train label distribution:
	      Negative: 21910
	       Neutral: 49148
	      Positive: 31039
Validation label distribution:
	      Negative: 1868
	       Neutral: 1669
	      Positive: 1884
Test label distribution:
	      Negative: 1868
	       Neutral: 1669
	      Positive: 1884
Archived data loaded (6.00s)

Initializing DDP Neural Classifier...
Layers: 2, Hidden Dim: 1024, Hidden Act: SwishGLU, Dropout: 0.3, Optimizer: AdamW, L2 Strength: 0.0001, Pooling: MEAN, Accumulation Steps: 1, Max Grad Norm: None
Batch Size: 128, Max Epochs: 50, LR: 0.0002, Early Stop: score, Fine-tune BERT: False, Fine-tune Layers: 1, Freeze BERT: False, Target Score: None, Interactive: False
Classifier initialized (14ms)

Fitting DDP Neural Classifier on training data...
Num Workers: 0, Prefetch: None
Score-based early stopping enabled (macro average F1 score against validation set). Validation fraction: 0.1
Training will stop early if the score does not improve by at least 0.00001 for 50 iterations.
Using provided validation set for early stopping.
Building dataset and dataloader...
Classes: ['negative', 'neutral', 'positive'], Number of classes: 3
Initializing model, graph, optimizer...

Model Architecture Summary:
Classifier(
  (layers): Sequential(
    (0): Linear(in_features=1024, out_features=1024, bias=True)
    (1): SwishGLU(
      (projection): Linear(in_features=1024, out_features=2048, bias=True)
      (activation): SiLU()
    )
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=1024, out_features=1024, bias=True)
    (4): SwishGLU(
      (projection): Linear(in_features=1024, out_features=2048, bias=True)
      (activation): SiLU()
    )
    (5): Dropout(p=0.3, inplace=False)
    (6): Linear(in_features=1024, out_features=3, bias=True)
  )
)

Model Parameters:
  layers.0: 1,049,600 (trainable)
  layers.1.projection: 2,099,200 (trainable)
  layers.3: 1,049,600 (trainable)
  layers.6: 3,075 (trainable)

Total layers: 4
Trainable layers: 4
Total parameters: 4,201,475
Trainable parameters: 4,201,475
Percentage of trainable parameters: 100.00%
An error occurred during training: list index out of range
Traceback (most recent call last):
  File "/home/ubuntu/nlp-osaka/sentiment/ddp_sentiment_finetune.py", line 1206, in main
    classifier.fit(X_train, X_val, y_train, y_val, rank, world_size, debug, start_epoch, model_state_dict, optimizer_state_dict,
  File "/home/ubuntu/nlp-osaka/sentiment/torch_ddp_finetune_neural_classifier.py", line 1052, in fit
    self.initialize()
  File "/home/ubuntu/nlp-osaka/sentiment/torch_model_base.py", line 426, in initialize
    self.optimizer = self.build_optimizer()
  File "/home/ubuntu/nlp-osaka/sentiment/torch_ddp_finetune_neural_classifier.py", line 511, in build_optimizer
    optimizer = ZeroRedundancyOptimizer(
  File "/home/ubuntu/nlp-osaka/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py", line 374, in __init__
    self._verify_same_dense_param_type()
  File "/home/ubuntu/nlp-osaka/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py", line 1447, in _verify_same_dense_param_type
    typename = torch.typename(self._all_params[0])
IndexError: list index out of range
An error occurred during training: list index out of range
Traceback (most recent call last):
  File "/home/ubuntu/nlp-osaka/sentiment/ddp_sentiment_finetune.py", line 1206, in main
    classifier.fit(X_train, X_val, y_train, y_val, rank, world_size, debug, start_epoch, model_state_dict, optimizer_state_dict,
  File "/home/ubuntu/nlp-osaka/sentiment/torch_ddp_finetune_neural_classifier.py", line 1052, in fit
    self.initialize()
  File "/home/ubuntu/nlp-osaka/sentiment/torch_model_base.py", line 426, in initialize
    self.optimizer = self.build_optimizer()
  File "/home/ubuntu/nlp-osaka/sentiment/torch_ddp_finetune_neural_classifier.py", line 511, in build_optimizer
    optimizer = ZeroRedundancyOptimizer(
  File "/home/ubuntu/nlp-osaka/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py", line 374, in __init__
    self._verify_same_dense_param_type()
  File "/home/ubuntu/nlp-osaka/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py", line 1447, in _verify_same_dense_param_type
    typename = torch.typename(self._all_params[0])
IndexError: list index out of range
An error occurred during training: list index out of range
Traceback (most recent call last):
  File "/home/ubuntu/nlp-osaka/sentiment/ddp_sentiment_finetune.py", line 1206, in main
    classifier.fit(X_train, X_val, y_train, y_val, rank, world_size, debug, start_epoch, model_state_dict, optimizer_state_dict,
  File "/home/ubuntu/nlp-osaka/sentiment/torch_ddp_finetune_neural_classifier.py", line 1052, in fit
    self.initialize()
  File "/home/ubuntu/nlp-osaka/sentiment/torch_model_base.py", line 426, in initialize
    self.optimizer = self.build_optimizer()
  File "/home/ubuntu/nlp-osaka/sentiment/torch_ddp_finetune_neural_classifier.py", line 511, in build_optimizer
    optimizer = ZeroRedundancyOptimizer(
  File "/home/ubuntu/nlp-osaka/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py", line 374, in __init__
    self._verify_same_dense_param_type()
  File "/home/ubuntu/nlp-osaka/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py", line 1447, in _verify_same_dense_param_type
    typename = torch.typename(self._all_params[0])
IndexError: list index out of range
An error occurred during training: list index out of range
Traceback (most recent call last):
  File "/home/ubuntu/nlp-osaka/sentiment/ddp_sentiment_finetune.py", line 1206, in main
    classifier.fit(X_train, X_val, y_train, y_val, rank, world_size, debug, start_epoch, model_state_dict, optimizer_state_dict,
  File "/home/ubuntu/nlp-osaka/sentiment/torch_ddp_finetune_neural_classifier.py", line 1052, in fit
    self.initialize()
  File "/home/ubuntu/nlp-osaka/sentiment/torch_model_base.py", line 426, in initialize
    self.optimizer = self.build_optimizer()
  File "/home/ubuntu/nlp-osaka/sentiment/torch_ddp_finetune_neural_classifier.py", line 511, in build_optimizer
    optimizer = ZeroRedundancyOptimizer(
  File "/home/ubuntu/nlp-osaka/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py", line 374, in __init__
    self._verify_same_dense_param_type()
  File "/home/ubuntu/nlp-osaka/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py", line 1447, in _verify_same_dense_param_type
    typename = torch.typename(self._all_params[0])
IndexError: list index out of range
An error occurred during training: list index out of range
An error occurred during training: list index out of range
Traceback (most recent call last):
  File "/home/ubuntu/nlp-osaka/sentiment/ddp_sentiment_finetune.py", line 1206, in main
    classifier.fit(X_train, X_val, y_train, y_val, rank, world_size, debug, start_epoch, model_state_dict, optimizer_state_dict,
  File "/home/ubuntu/nlp-osaka/sentiment/torch_ddp_finetune_neural_classifier.py", line 1052, in fit
    self.initialize()
  File "/home/ubuntu/nlp-osaka/sentiment/torch_model_base.py", line 426, in initialize
    self.optimizer = self.build_optimizer()
  File "/home/ubuntu/nlp-osaka/sentiment/torch_ddp_finetune_neural_classifier.py", line 511, in build_optimizer
    optimizer = ZeroRedundancyOptimizer(
  File "/home/ubuntu/nlp-osaka/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py", line 374, in __init__
    self._verify_same_dense_param_type()
  File "/home/ubuntu/nlp-osaka/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py", line 1447, in _verify_same_dense_param_type
    typename = torch.typename(self._all_params[0])
IndexError: list index out of range
Traceback (most recent call last):
  File "/home/ubuntu/nlp-osaka/sentiment/ddp_sentiment_finetune.py", line 1206, in main
    classifier.fit(X_train, X_val, y_train, y_val, rank, world_size, debug, start_epoch, model_state_dict, optimizer_state_dict,
  File "/home/ubuntu/nlp-osaka/sentiment/torch_ddp_finetune_neural_classifier.py", line 1052, in fit
    self.initialize()
  File "/home/ubuntu/nlp-osaka/sentiment/torch_model_base.py", line 426, in initialize
    self.optimizer = self.build_optimizer()
  File "/home/ubuntu/nlp-osaka/sentiment/torch_ddp_finetune_neural_classifier.py", line 511, in build_optimizer
    optimizer = ZeroRedundancyOptimizer(
  File "/home/ubuntu/nlp-osaka/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py", line 374, in __init__
    self._verify_same_dense_param_type()
  File "/home/ubuntu/nlp-osaka/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py", line 1447, in _verify_same_dense_param_type
    typename = torch.typename(self._all_params[0])
IndexError: list index out of range
An error occurred during training: list index out of range
Traceback (most recent call last):
  File "/home/ubuntu/nlp-osaka/sentiment/ddp_sentiment_finetune.py", line 1206, in main
    classifier.fit(X_train, X_val, y_train, y_val, rank, world_size, debug, start_epoch, model_state_dict, optimizer_state_dict,
  File "/home/ubuntu/nlp-osaka/sentiment/torch_ddp_finetune_neural_classifier.py", line 1052, in fit
    self.initialize()
  File "/home/ubuntu/nlp-osaka/sentiment/torch_model_base.py", line 426, in initialize
    self.optimizer = self.build_optimizer()
  File "/home/ubuntu/nlp-osaka/sentiment/torch_ddp_finetune_neural_classifier.py", line 511, in build_optimizer
    optimizer = ZeroRedundancyOptimizer(
  File "/home/ubuntu/nlp-osaka/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py", line 374, in __init__
    self._verify_same_dense_param_type()
  File "/home/ubuntu/nlp-osaka/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py", line 1447, in _verify_same_dense_param_type
    typename = torch.typename(self._all_params[0])
IndexError: list index out of range
An error occurred during training: list index out of range
Traceback (most recent call last):
  File "/home/ubuntu/nlp-osaka/sentiment/ddp_sentiment_finetune.py", line 1206, in main
    classifier.fit(X_train, X_val, y_train, y_val, rank, world_size, debug, start_epoch, model_state_dict, optimizer_state_dict,
  File "/home/ubuntu/nlp-osaka/sentiment/torch_ddp_finetune_neural_classifier.py", line 1052, in fit
    self.initialize()
  File "/home/ubuntu/nlp-osaka/sentiment/torch_model_base.py", line 426, in initialize
    self.optimizer = self.build_optimizer()
  File "/home/ubuntu/nlp-osaka/sentiment/torch_ddp_finetune_neural_classifier.py", line 511, in build_optimizer
    optimizer = ZeroRedundancyOptimizer(
  File "/home/ubuntu/nlp-osaka/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py", line 374, in __init__
    self._verify_same_dense_param_type()
  File "/home/ubuntu/nlp-osaka/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py", line 1447, in _verify_same_dense_param_type
    typename = torch.typename(self._all_params[0])
IndexError: list index out of range
wandb: ðŸš€ View run run_1_merged_class at: https://wandb.ai/jimbeno/Electra Large/runs/o3osao4d
wandb: Find logs at: wandb/run-20241024_000501-o3osao4d/logs
(nlp) ubuntu@138-2-58-218:~/nlp-osaka/sentiment$ git pull
Username for 'https://github.com': jim@jimbeno.net
Password for 'https://jim@jimbeno.net@github.com': 
remote: Enumerating objects: 5, done.
remote: Counting objects: 100% (5/5), done.
remote: Compressing objects: 100% (1/1), done.
remote: Total 3 (delta 2), reused 3 (delta 2), pack-reused 0 (from 0)
Unpacking objects: 100% (3/3), 723 bytes | 16.00 KiB/s, done.
From https://github.com/jbeno/sentiment
   608f193..e962be3  main       -> origin/main
Updating 608f193..e962be3
Fast-forward
 torch_ddp_finetune_neural_classifier.py | 54 ++++++++++++++++++++++++++++++++----------------------
 1 file changed, 32 insertions(+), 22 deletions(-)
(nlp) ubuntu@138-2-58-218:~/nlp-osaka/sentiment$ python ./ddp_sentiment_finetune.py --dataset 'merged_local' --weights_name 'google/electra-large-discriminator' --save_data --save_model --save_pickle --save_preds --lr 0.0002 --lr_decay 0.95 --epochs 50 --pooling 'mean' --dropout_rate 0.3 --num_layers 2 --hidden_dim 1024 --hidden_activation 'swishglu' --batch_size 128 --l2_strength 0.0001 --checkpoint_interval 5 --use_zero --optimizer 'adamw' --scheduler 'cosine_warmup' --scheduler_kwargs '{"T_0":5, "T_mult":1, "eta_min":1e-7}' --decimal 6 --use_val_split --eval_split 'test' --early_stop 'score' --n_iter_no_change 50 --show_progress --wandb --wandb_project 'Electra Large' --wandb_run 'run_1_merged_class' --data_file 'saves/data_8_gpu_20241024-000103.npz'

Starting DDP PyTorch Training...
Device: cuda, Number of GPUs: 8
Spawning 8 processes...
Rank 4 - Device: cuda:4
Rank 1 - Device: cuda:1
Rank 5 - Device: cuda:5
Rank 3 - Device: cuda:3
Rank 2 - Device: cuda:2
Rank 6 - Device: cuda:6
Rank 7 - Device: cuda:7
Rank 0 - Device: cuda:0
8 process groups initialized with 'nccl' backend on localhost:12355
NCCL Timeout: 1 hr 0 min. NCCL Blocking Wait: Enabled
wandb: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: jbeno (jimbeno). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.5
wandb: Run data is saved locally in /home/ubuntu/nlp-osaka/sentiment/wandb/run-20241024_001109-lzj85wwk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run run_1_merged_class
wandb: â­ï¸ View project at https://wandb.ai/jimbeno/Electra%20Large
wandb: ðŸš€ View run at https://wandb.ai/jimbeno/Electra%20Large/runs/lzj85wwk
Wand run initialized.

Initializing 'google/electra-large-discriminator' tokenizer and model...
Checking for local files...
Found all files in cache, skipping download
All ranks loading tokenizer from local files...
All ranks loading model from local files...
Tokenizer and model initialized (6s)

Loading archived data from: saves/data_8_gpu_20241024-000103.npz...
X Train shape: [102097, 1024], y Train shape: [102097]
X Validation shape: [5421, 1024], y Validation shape: [5421]
X Test shape: [5421, 1024], y Dev shape: [5421]
X Test Sentences shape: [5421]
Train label distribution:
	      Negative: 21910
	       Neutral: 49148
	      Positive: 31039
Validation label distribution:
	      Negative: 1868
	       Neutral: 1669
	      Positive: 1884
Test label distribution:
	      Negative: 1868
	       Neutral: 1669
	      Positive: 1884
Archived data loaded (3.64s)

Initializing DDP Neural Classifier...
Layers: 2, Hidden Dim: 1024, Hidden Act: SwishGLU, Dropout: 0.3, Optimizer: AdamW, L2 Strength: 0.0001, Pooling: MEAN, Accumulation Steps: 1, Max Grad Norm: None
Batch Size: 128, Max Epochs: 50, LR: 0.0002, Early Stop: score, Fine-tune BERT: False, Fine-tune Layers: 1, Freeze BERT: False, Target Score: None, Interactive: False
Classifier initialized (14ms)

Fitting DDP Neural Classifier on training data...
Num Workers: 0, Prefetch: None
Score-based early stopping enabled (macro average F1 score against validation set). Validation fraction: 0.1
Training will stop early if the score does not improve by at least 0.00001 for 50 iterations.
Using provided validation set for early stopping.
Building dataset and dataloader...
Classes: ['negative', 'neutral', 'positive'], Number of classes: 3
Initializing model, graph, optimizer...

Model Architecture Summary:
Classifier(
  (layers): Sequential(
    (0): Linear(in_features=1024, out_features=1024, bias=True)
    (1): SwishGLU(
      (projection): Linear(in_features=1024, out_features=2048, bias=True)
      (activation): SiLU()
    )
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=1024, out_features=1024, bias=True)
    (4): SwishGLU(
      (projection): Linear(in_features=1024, out_features=2048, bias=True)
      (activation): SiLU()
    )
    (5): Dropout(p=0.3, inplace=False)
    (6): Linear(in_features=1024, out_features=3, bias=True)
  )
)

Model Parameters:
  layers.0: 1,049,600 (trainable)
  layers.1.projection: 2,099,200 (trainable)
  layers.3: 1,049,600 (trainable)
  layers.6: 3,075 (trainable)

Total layers: 4
Trainable layers: 4
Total parameters: 4,201,475
Trainable parameters: 4,201,475
Percentage of trainable parameters: 100.00%
Using optimizer: AdamW, Use Zero: True, Base Learning Rate: 0.0002, L2 strength: 0.0001
Using scheduler: CosineAnnealingWarmRestarts
Scheduler arguments:
- T_0: 5
- T_mult: 1
- eta_min: 1e-07

Starting training loop...
Start epoch: 1, Max Iterations: 50, Early Stop: score, Tolerance: 0.00001, Number Iterations No Change: 50
Epoch 1/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:03<00:00, 26.39it/s, loss=0.9904, lr=1.81e-04, grad=M:0.1467, status=Epoch complete]
â–ˆ Epoch  1: Loss T 0.990373 V 1.027838 | F1 T 0.377481 V 0.323147 B 0.323147 SC 0/50 | Acc T 0.553632 V 0.408923 | LR 1.81e-04 | Grad â†“ 0.012609 â†‘ 0.742544 M 0.146727 | 3s
Epoch 2/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:02<00:00, 38.59it/s, loss=0.8782, lr=1.32e-04, grad=M:0.1070, status=Epoch complete]
â–ˆ Epoch  2: Loss T 0.878233 V 0.963687 | F1 T 0.442238 V 0.396236 B 0.396236 SC 0/50 | Acc T 0.606881 V 0.490413 | LR 1.32e-04 | Grad â†“ 0.010234 â†‘ 0.420161 M 0.106973 | 2s
Epoch 3/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:02<00:00, 39.26it/s, loss=0.7998, lr=6.98e-05, grad=M:0.2968, status=Epoch complete]
â–ˆ Epoch  3: Loss T 0.799815 V 0.895710 | F1 T 0.615001 V 0.577111 B 0.577111 SC 0/50 | Acc T 0.667349 V 0.584993 | LR 6.98e-05 | Grad â†“ 0.016612 â†‘ 1.429755 M 0.296809 | 2s
Epoch 4/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:02<00:00, 40.13it/s, loss=0.7414, lr=1.96e-05, grad=M:0.4399, status=Epoch complete]
â–ˆ Epoch  4: Loss T 0.741449 V 0.849278 | F1 T 0.651284 V 0.617608 B 0.617608 SC 0/50 | Acc T 0.684655 V 0.618547 | LR 1.96e-05 | Grad â†“ 0.025729 â†‘ 2.019551 M 0.439881 | 2s
Epoch 5/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:02<00:00, 39.39it/s, loss=0.7264, lr=1.02e-07, grad=M:0.2582, status=Epoch complete]
â–ˆ Epoch  5: Loss T 0.726448 V 0.845595 | F1 T 0.654305 V 0.622575 B 0.622575 SC 0/50 | Acc T 0.686996 V 0.623341 | LR 1.02e-07 | Grad â†“ 0.006957 â†‘ 1.303354 M 0.258217 | 2s
Saved model state: checkpoints/checkpoint_epoch_5_20241024-001138.pth
Epoch 6/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:02<00:00, 39.08it/s, loss=0.7388, lr=1.81e-04, grad=M:0.6402, status=Epoch complete]
â–ˆ Epoch  6: Loss T 0.738808 V 0.888817 | F1 T 0.640378 V 0.585487 B 0.622575 SC 1/50 | Acc T 0.688886 V 0.595686 | LR 1.81e-04 | Grad â†“ 0.028086 â†‘ 3.432983 M 0.640187 | 2s
Epoch 7/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:02<00:00, 40.62it/s, loss=0.7047, lr=1.32e-04, grad=M:0.4370, status=Epoch complete]
â–ˆ Epoch  7: Loss T 0.704724 V 0.814153 | F1 T 0.676525 V 0.642730 B 0.642730 SC 0/50 | Acc T 0.704703 V 0.642883 | LR 1.32e-04 | Grad â†“ 0.018768 â†‘ 2.237853 M 0.437023 | 2s
Epoch 8/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:02<00:00, 154.27it/s, loss=0.6893, lr=6.98e-05, grad=M:0.6102, status=Computing train metrics...]^C
Ctrl+C received. Terminating all processes...
Rank 0 - Current process: MainProcess cleaning up...
Terminating all child processes of MainProcess...

KeyboardInterrupt received. Terminating all processes...

KeyboardInterrupt received. Terminating all processes...

KeyboardInterrupt received. Terminating all processes...
KeyboardInterrupt received. Terminating all processes...

KeyboardInterrupt received. Terminating all processes...

KeyboardInterrupt received. Terminating all processes...

Terminated child process: SpawnProcess-4
Terminated child process: SpawnProcess-5

KeyboardInterrupt received. Terminating all processes...
Terminated child process: SpawnProcess-6
Terminated child process: SpawnProcess-7
Terminated child process: SpawnProcess-8
Terminated child process: SpawnProcess-3
Terminated child process: SpawnProcess-1
Terminated child process: SpawnProcess-2
Rank 0 - Exiting program...
/usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
(nlp) ubuntu@138-2-58-218:~/nlp-osaka/sentiment$ python ./ddp_sentiment_finetune.py --dataset 'merged_local' --weights_name 'google/electra-large-discriminator' --save_data --save_model --save_pickle --save_preds --lr 0.0002 --lr_decay 0.95 --epochs 100 --pooling 'mean' --dropout_rate 0.3 --num_layers 2 --hidden_dim 1024 --hidden_activation 'swishglu' --batch_size 512 --l2_strength 0.0001 --checkpoint_interval 5 --use_zero --optimizer 'adamw' --scheduler 'cosine_warmup' --scheduler_kwargs '{"T_0":5, "T_mult":1, "eta_min":1e-7}' --decimal 6 --use_val_split --eval_split 'test' --early_stop 'score' --n_iter_no_change 20 --show_progress --wandb --wandb_project 'Electra Large' --wandb_run 'run_1_merged_class' --data_file 'saves/data_8_gpu_20241024-000103.npz'

Starting DDP PyTorch Training...
Device: cuda, Number of GPUs: 8
Spawning 8 processes...
Rank 4 - Device: cuda:4
Rank 6 - Device: cuda:6
Rank 1 - Device: cuda:1
Rank 5 - Device: cuda:5
Rank 2 - Device: cuda:2
Rank 7 - Device: cuda:7
Rank 0 - Device: cuda:0
Rank 3 - Device: cuda:3
8 process groups initialized with 'nccl' backend on localhost:12355
NCCL Timeout: 1 hr 0 min. NCCL Blocking Wait: Enabled
wandb: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: jbeno (jimbeno). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.5
wandb: Run data is saved locally in /home/ubuntu/nlp-osaka/sentiment/wandb/run-20241024_001423-u8ze04kp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run run_1_merged_class
wandb: â­ï¸ View project at https://wandb.ai/jimbeno/Electra%20Large
wandb: ðŸš€ View run at https://wandb.ai/jimbeno/Electra%20Large/runs/u8ze04kp
Wand run initialized.

Initializing 'google/electra-large-discriminator' tokenizer and model...
Checking for local files...
Found all files in cache, skipping download
All ranks loading tokenizer from local files...
All ranks loading model from local files...
Tokenizer and model initialized (6s)

Loading archived data from: saves/data_8_gpu_20241024-000103.npz...
X Train shape: [102097, 1024], y Train shape: [102097]
X Validation shape: [5421, 1024], y Validation shape: [5421]
X Test shape: [5421, 1024], y Dev shape: [5421]
X Test Sentences shape: [5421]
Train label distribution:
	      Negative: 21910
	       Neutral: 49148
	      Positive: 31039
Validation label distribution:
	      Negative: 1868
	       Neutral: 1669
	      Positive: 1884
Test label distribution:
	      Negative: 1868
	       Neutral: 1669
	      Positive: 1884
Archived data loaded (3.41s)

Initializing DDP Neural Classifier...
Layers: 2, Hidden Dim: 1024, Hidden Act: SwishGLU, Dropout: 0.3, Optimizer: AdamW, L2 Strength: 0.0001, Pooling: MEAN, Accumulation Steps: 1, Max Grad Norm: None
Batch Size: 512, Max Epochs: 100, LR: 0.0002, Early Stop: score, Fine-tune BERT: False, Fine-tune Layers: 1, Freeze BERT: False, Target Score: None, Interactive: False
Classifier initialized (14ms)

Fitting DDP Neural Classifier on training data...
Num Workers: 0, Prefetch: None
Score-based early stopping enabled (macro average F1 score against validation set). Validation fraction: 0.1
Training will stop early if the score does not improve by at least 0.00001 for 20 iterations.
Using provided validation set for early stopping.
Building dataset and dataloader...
Classes: ['negative', 'neutral', 'positive'], Number of classes: 3
Initializing model, graph, optimizer...

Model Architecture Summary:
Classifier(
  (layers): Sequential(
    (0): Linear(in_features=1024, out_features=1024, bias=True)
    (1): SwishGLU(
      (projection): Linear(in_features=1024, out_features=2048, bias=True)
      (activation): SiLU()
    )
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=1024, out_features=1024, bias=True)
    (4): SwishGLU(
      (projection): Linear(in_features=1024, out_features=2048, bias=True)
      (activation): SiLU()
    )
    (5): Dropout(p=0.3, inplace=False)
    (6): Linear(in_features=1024, out_features=3, bias=True)
  )
)

Model Parameters:
  layers.0: 1,049,600 (trainable)
  layers.1.projection: 2,099,200 (trainable)
  layers.3: 1,049,600 (trainable)
  layers.6: 3,075 (trainable)

Total layers: 4
Trainable layers: 4
Total parameters: 4,201,475
Trainable parameters: 4,201,475
Percentage of trainable parameters: 100.00%
Using optimizer: AdamW, Use Zero: True, Base Learning Rate: 0.0002, L2 strength: 0.0001
Using scheduler: CosineAnnealingWarmRestarts
Scheduler arguments:
- T_0: 5
- T_mult: 1
- eta_min: 1e-07

Starting training loop...
Start epoch: 1, Max Iterations: 100, Early Stop: score, Tolerance: 0.00001, Number Iterations No Change: 20
Epoch 1/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:03<00:00,  7.35it/s, loss=1.0580, lr=1.82e-04, grad=M:0.0513, status=Epoch complete]
â–ˆ Epoch   1: Loss T 1.058017 V 1.131716 | F1 T 0.220246 V 0.156909 B 0.156909 SC 0/20 | Acc T 0.480608 V 0.306047 | LR 1.82e-04 | Grad â†“ 0.007653 â†‘ 0.142788 M 0.051265 | 3s
Epoch 2/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 11.84it/s, loss=1.0004, lr=1.33e-04, grad=M:0.0356, status=Epoch complete]
â–ˆ Epoch   2: Loss T 1.000388 V 1.088899 | F1 T 0.225029 V 0.164479 B 0.164479 SC 0/20 | Acc T 0.480206 V 0.307891 | LR 1.33e-04 | Grad â†“ 0.001269 â†‘ 0.082067 M 0.035585 | 2s
Epoch 3/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00,  9.40it/s, loss=0.9375, lr=7.16e-05, grad=M:0.0796, status=Epoch complete]
â–ˆ Epoch   3: Loss T 0.937542 V 1.059300 | F1 T 0.352938 V 0.299568 B 0.299568 SC 0/20 | Acc T 0.539264 V 0.387168 | LR 7.16e-05 | Grad â†“ 0.004494 â†‘ 0.309561 M 0.079576 | 2s
Epoch 4/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 11.82it/s, loss=0.9170, lr=2.07e-05, grad=M:0.0672, status=Epoch complete]
â–ˆ Epoch   4: Loss T 0.917026 V 1.041941 | F1 T 0.388332 V 0.336051 B 0.336051 SC 0/20 | Acc T 0.561633 V 0.422198 | LR 2.07e-05 | Grad â†“ 0.004164 â†‘ 0.276879 M 0.067226 | 2s
Epoch 5/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 11.71it/s, loss=0.9111, lr=1.32e-07, grad=M:0.0836, status=Epoch complete]
â–ˆ Epoch   5: Loss T 0.911074 V 1.039998 | F1 T 0.395318 V 0.344046 B 0.344046 SC 0/20 | Acc T 0.565580 V 0.430494 | LR 1.32e-07 | Grad â†“ 0.006308 â†‘ 0.386941 M 0.083552 | 2s
Saved model state: checkpoints/checkpoint_epoch_5_20241024-001450.pth
Epoch 6/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 10.28it/s, loss=0.9023, lr=1.82e-04, grad=M:0.0497, status=Epoch complete]
â–ˆ Epoch   6: Loss T 0.902276 V 0.989478 | F1 T 0.427527 V 0.382070 B 0.382070 SC 0/20 | Acc T 0.589115 V 0.471792 | LR 1.82e-04 | Grad â†“ 0.002472 â†‘ 0.198636 M 0.049725 | 2s
Epoch 7/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 11.81it/s, loss=0.8561, lr=1.33e-04, grad=M:0.1287, status=Epoch complete]
â–ˆ Epoch   7: Loss T 0.856097 V 0.977604 | F1 T 0.439412 V 0.393371 B 0.393371 SC 0/20 | Acc T 0.605765 V 0.487279 | LR 1.33e-04 | Grad â†“ 0.006509 â†‘ 0.646510 M 0.128657 | 2s
Epoch 8/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00,  9.97it/s, loss=0.8354, lr=7.16e-05, grad=M:0.1968, status=Epoch complete]
â–ˆ Epoch   8: Loss T 0.835444 V 0.962567 | F1 T 0.447502 V 0.399411 B 0.399411 SC 0/20 | Acc T 0.614070 V 0.494653 | LR 7.16e-05 | Grad â†“ 0.012442 â†‘ 0.925954 M 0.196784 | 2s
Epoch 9/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 11.63it/s, loss=0.8219, lr=2.07e-05, grad=M:0.0446, status=Epoch complete]
â–ˆ Epoch   9: Loss T 0.821923 V 0.955514 | F1 T 0.453028 V 0.405485 B 0.405485 SC 0/20 | Acc T 0.619457 V 0.499078 | LR 2.07e-05 | Grad â†“ 0.001581 â†‘ 0.125473 M 0.044590 | 2s
Epoch 10/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 11.49it/s, loss=0.8138, lr=1.32e-07, grad=M:0.1561, status=Epoch complete]
â–ˆ Epoch  10: Loss T 0.813802 V 0.952183 | F1 T 0.458149 V 0.412536 B 0.412536 SC 0/20 | Acc T 0.620877 V 0.501475 | LR 1.32e-07 | Grad â†“ 0.005588 â†‘ 0.605341 M 0.156052 | 2s
Memory: Rank 0: 3.60 GB | Rank 1: 3.75 GB | Rank 2: 3.75 GB | Rank 3: 3.75 GB | Rank 4: 3.75 GB | Rank 5: 3.75 GB | Rank 6: 3.75 GB | Rank 7: 3.60 GB (Max: 42.29 GB, Total: 338.28 GB)
Saved model state: checkpoints/checkpoint_epoch_10_20241024-001510.pth
Epoch 11/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 11.28it/s, loss=0.8736, lr=1.82e-04, grad=M:0.5611, status=Epoch complete]
â–ˆ Epoch  11: Loss T 0.873631 V 0.922753 | F1 T 0.477852 V 0.444242 B 0.444242 SC 0/20 | Acc T 0.609369 V 0.514012 | LR 1.82e-04 | Grad â†“ 0.033392 â†‘ 3.020307 M 0.561085 | 2s
Epoch 12/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 11.65it/s, loss=0.8077, lr=1.33e-04, grad=M:0.4177, status=Epoch complete]
â–ˆ Epoch  12: Loss T 0.807737 V 0.916693 | F1 T 0.579121 V 0.540479 B 0.540479 SC 0/20 | Acc T 0.652864 V 0.560103 | LR 1.33e-04 | Grad â†“ 0.024449 â†‘ 2.042228 M 0.417689 | 2s
Epoch 13/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 11.65it/s, loss=0.7681, lr=7.16e-05, grad=M:0.1631, status=Epoch complete]
â–ˆ Epoch  13: Loss T 0.768149 V 0.873765 | F1 T 0.628578 V 0.597116 B 0.597116 SC 0/20 | Acc T 0.669758 V 0.599189 | LR 7.16e-05 | Grad â†“ 0.008845 â†‘ 0.814034 M 0.163079 | 2s
Epoch 14/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 11.30it/s, loss=0.7514, lr=2.07e-05, grad=M:0.1403, status=Epoch complete]
â–ˆ Epoch  14: Loss T 0.751355 V 0.873442 | F1 T 0.634823 V 0.597882 B 0.597882 SC 0/20 | Acc T 0.677290 V 0.601032 | LR 2.07e-05 | Grad â†“ 0.007179 â†‘ 0.562659 M 0.140265 | 2s
Epoch 15/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 11.69it/s, loss=0.7458, lr=1.32e-07, grad=M:0.1801, status=Epoch complete]
â–ˆ Epoch  15: Loss T 0.745775 V 0.864718 | F1 T 0.640014 V 0.603870 B 0.603870 SC 0/20 | Acc T 0.679366 V 0.606379 | LR 1.32e-07 | Grad â†“ 0.010506 â†‘ 0.664322 M 0.180132 | 2s
Saved model state: checkpoints/checkpoint_epoch_15_20241024-001521.pth
Epoch 16/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 11.67it/s, loss=0.7408, lr=1.82e-04, grad=M:0.4159, status=Epoch complete]
â–ˆ Epoch  16: Loss T 0.740783 V 0.836025 | F1 T 0.657594 V 0.625003 B 0.625003 SC 0/20 | Acc T 0.689777 V 0.625369 | LR 1.82e-04 | Grad â†“ 0.021427 â†‘ 2.125517 M 0.415872 | 2s
Epoch 17/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 11.42it/s, loss=0.7265, lr=1.33e-04, grad=M:0.7036, status=Epoch complete]
â–ˆ Epoch  17: Loss T 0.726542 V 0.861855 | F1 T 0.649866 V 0.606492 B 0.625003 SC 1/20 | Acc T 0.691256 V 0.609513 | LR 1.33e-04 | Grad â†“ 0.031913 â†‘ 3.132718 M 0.703591 | 2s
Epoch 18/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 10.14it/s, loss=0.7099, lr=7.16e-05, grad=M:0.4206, status=Epoch complete]
â–ˆ Epoch  18: Loss T 0.709871 V 0.833944 | F1 T 0.665626 V 0.627100 B 0.627100 SC 0/20 | Acc T 0.698601 V 0.627765 | LR 7.16e-05 | Grad â†“ 0.019575 â†‘ 1.859716 M 0.420558 | 2s
Epoch 19/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 10.30it/s, loss=0.7040, lr=2.07e-05, grad=M:0.1961, status=Epoch complete]
â–ˆ Epoch  19: Loss T 0.703978 V 0.831938 | F1 T 0.668262 V 0.629542 B 0.629542 SC 0/20 | Acc T 0.700688 V 0.630347 | LR 2.07e-05 | Grad â†“ 0.006034 â†‘ 0.852693 M 0.196130 | 2s
Epoch 20/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 10.67it/s, loss=0.7006, lr=1.32e-07, grad=M:0.1744, status=Epoch complete]
â–ˆ Epoch  20: Loss T 0.700616 V 0.821554 | F1 T 0.672457 V 0.635808 B 0.635808 SC 0/20 | Acc T 0.702157 V 0.636431 | LR 1.32e-07 | Grad â†“ 0.008443 â†‘ 0.757224 M 0.174373 | 2s
Memory: Rank 0: 3.60 GB | Rank 1: 3.75 GB | Rank 2: 3.75 GB | Rank 3: 3.75 GB | Rank 4: 3.75 GB | Rank 5: 3.75 GB | Rank 6: 3.75 GB | Rank 7: 3.60 GB (Max: 42.29 GB, Total: 338.28 GB)
Saved model state: checkpoints/checkpoint_epoch_20_20241024-001533.pth
Epoch 21/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 11.71it/s, loss=0.7659, lr=1.82e-04, grad=M:0.5760, status=Epoch complete]
â–ˆ Epoch  21: Loss T 0.765937 V 0.829118 | F1 T 0.645627 V 0.631006 B 0.635808 SC 1/20 | Acc T 0.677564 V 0.633850 | LR 1.82e-04 | Grad â†“ 0.031220 â†‘ 2.932511 M 0.575988 | 2s
Epoch 22/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 11.03it/s, loss=0.7106, lr=1.33e-04, grad=M:0.1344, status=Epoch complete]
â–ˆ Epoch  22: Loss T 0.710620 V 0.804155 | F1 T 0.677310 V 0.647510 B 0.647510 SC 0/20 | Acc T 0.702970 V 0.647861 | LR 1.33e-04 | Grad â†“ 0.006735 â†‘ 0.653563 M 0.134447 | 2s
Epoch 23/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 11.86it/s, loss=0.6978, lr=7.16e-05, grad=M:0.6127, status=Epoch complete]
â–ˆ Epoch  23: Loss T 0.697777 V 0.827449 | F1 T 0.670837 V 0.629666 B 0.647510 SC 1/20 | Acc T 0.703782 V 0.631822 | LR 7.16e-05 | Grad â†“ 0.027454 â†‘ 2.916191 M 0.612735 | 2s
Epoch 24/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 11.47it/s, loss=0.6925, lr=2.07e-05, grad=M:0.4703, status=Epoch complete]
â–ˆ Epoch  24: Loss T 0.692470 V 0.806625 | F1 T 0.679617 V 0.647818 B 0.647818 SC 0/20 | Acc T 0.706084 V 0.648414 | LR 2.07e-05 | Grad â†“ 0.019297 â†‘ 2.447051 M 0.470339 | 2s
Epoch 25/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00,  9.44it/s, loss=0.6910, lr=1.32e-07, grad=M:0.2312, status=Epoch complete]
â–ˆ Epoch  25: Loss T 0.690972 V 0.810468 | F1 T 0.678143 V 0.646383 B 0.647818 SC 1/20 | Acc T 0.706074 V 0.646940 | LR 1.32e-07 | Grad â†“ 0.008841 â†‘ 1.158088 M 0.231221 | 2s
Saved model state: checkpoints/checkpoint_epoch_25_20241024-001544.pth
Epoch 26/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 11.22it/s, loss=0.6945, lr=1.82e-04, grad=M:0.3063, status=Epoch complete]
â–ˆ Epoch  26: Loss T 0.694483 V 0.810998 | F1 T 0.676851 V 0.641794 B 0.647818 SC 2/20 | Acc T 0.706241 V 0.642146 | LR 1.82e-04 | Grad â†“ 0.010807 â†‘ 1.528598 M 0.306326 | 2s
Epoch 27/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 11.34it/s, loss=0.6867, lr=1.33e-04, grad=M:0.2079, status=Epoch complete]
â–ˆ Epoch  27: Loss T 0.686748 V 0.799366 | F1 T 0.684098 V 0.653398 B 0.653398 SC 0/20 | Acc T 0.708278 V 0.654499 | LR 1.33e-04 | Grad â†“ 0.007426 â†‘ 0.996118 M 0.207935 | 2s
Epoch 28/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 10.36it/s, loss=0.6838, lr=7.16e-05, grad=M:0.2395, status=Epoch complete]
â–ˆ Epoch  28: Loss T 0.683844 V 0.793728 | F1 T 0.685026 V 0.655366 B 0.655366 SC 0/20 | Acc T 0.710158 V 0.655420 | LR 7.16e-05 | Grad â†“ 0.010602 â†‘ 1.183288 M 0.239533 | 2s
Epoch 29/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 11.58it/s, loss=0.6801, lr=2.07e-05, grad=M:0.2178, status=Epoch complete]
â–ˆ Epoch  29: Loss T 0.680119 V 0.804677 | F1 T 0.683220 V 0.647329 B 0.655366 SC 1/20 | Acc T 0.710912 V 0.648599 | LR 2.07e-05 | Grad â†“ 0.006382 â†‘ 1.064202 M 0.217779 | 2s
Epoch 30/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 10.20it/s, loss=0.6778, lr=1.32e-07, grad=M:0.2139, status=Epoch complete]
â–ˆ Epoch  30: Loss T 0.677810 V 0.800824 | F1 T 0.684503 V 0.652598 B 0.655366 SC 2/20 | Acc T 0.711128 V 0.653024 | LR 1.32e-07 | Grad â†“ 0.008363 â†‘ 1.158796 M 0.213879 | 2s
Memory: Rank 0: 3.60 GB | Rank 1: 3.75 GB | Rank 2: 3.75 GB | Rank 3: 3.75 GB | Rank 4: 3.75 GB | Rank 5: 3.75 GB | Rank 6: 3.75 GB | Rank 7: 3.60 GB (Max: 42.29 GB, Total: 338.28 GB)
Saved model state: checkpoints/checkpoint_epoch_30_20241024-001556.pth
Epoch 31/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 11.61it/s, loss=0.6878, lr=1.82e-04, grad=M:0.7878, status=Epoch complete]
â–ˆ Epoch  31: Loss T 0.687844 V 0.786112 | F1 T 0.686900 V 0.659038 B 0.659038 SC 0/20 | Acc T 0.711647 V 0.658739 | LR 1.82e-04 | Grad â†“ 0.032733 â†‘ 3.859143 M 0.787843 | 2s
Epoch 32/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 11.20it/s, loss=0.6814, lr=1.33e-04, grad=M:0.3751, status=Epoch complete]
â–ˆ Epoch  32: Loss T 0.681417 V 0.774600 | F1 T 0.689252 V 0.668460 B 0.668460 SC 0/20 | Acc T 0.710697 V 0.668142 | LR 1.33e-04 | Grad â†“ 0.014827 â†‘ 1.795607 M 0.375148 | 2s
Epoch 33/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 11.40it/s, loss=0.6766, lr=7.16e-05, grad=M:0.1754, status=Epoch complete]
â–ˆ Epoch  33: Loss T 0.676554 V 0.801806 | F1 T 0.685129 V 0.646619 B 0.668460 SC 1/20 | Acc T 0.713204 V 0.647677 | LR 7.16e-05 | Grad â†“ 0.007534 â†‘ 0.921442 M 0.175436 | 2s
Epoch 34/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 11.52it/s, loss=0.6723, lr=2.07e-05, grad=M:0.1222, status=Epoch complete]
â–ˆ Epoch  34: Loss T 0.672301 V 0.798798 | F1 T 0.686989 V 0.652320 B 0.668460 SC 2/20 | Acc T 0.714007 V 0.652286 | LR 2.07e-05 | Grad â†“ 0.005185 â†‘ 0.590019 M 0.122203 | 2s
Epoch 35/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 10.17it/s, loss=0.6711, lr=1.32e-07, grad=M:0.2150, status=Epoch complete]
â–ˆ Epoch  35: Loss T 0.671090 V 0.794623 | F1 T 0.688461 V 0.654155 B 0.668460 SC 3/20 | Acc T 0.714517 V 0.654314 | LR 1.32e-07 | Grad â†“ 0.007162 â†‘ 1.082201 M 0.214964 | 2s
Saved model state: checkpoints/checkpoint_epoch_35_20241024-001607.pth
Epoch 36/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 11.08it/s, loss=0.6911, lr=1.82e-04, grad=M:1.0102, status=Epoch complete]
â–ˆ Epoch  36: Loss T 0.691108 V 0.787568 | F1 T 0.690573 V 0.660992 B 0.668460 SC 4/20 | Acc T 0.714311 V 0.660951 | LR 1.82e-04 | Grad â†“ 0.035695 â†‘ 5.360192 M 1.010179 | 2s
Epoch 37/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 11.69it/s, loss=0.6732, lr=1.33e-04, grad=M:0.3684, status=Epoch complete]
â–ˆ Epoch  37: Loss T 0.673188 V 0.779052 | F1 T 0.692649 V 0.666368 B 0.668460 SC 5/20 | Acc T 0.714360 V 0.666298 | LR 1.33e-04 | Grad â†“ 0.014710 â†‘ 1.963994 M 0.368448 | 2s
Epoch 38/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 11.25it/s, loss=0.6702, lr=7.16e-05, grad=M:0.4792, status=Epoch complete]
â–ˆ Epoch  38: Loss T 0.670217 V 0.779215 | F1 T 0.690731 V 0.663058 B 0.668460 SC 6/20 | Acc T 0.714487 V 0.662795 | LR 7.16e-05 | Grad â†“ 0.018584 â†‘ 2.565567 M 0.479244 | 2s
Epoch 39/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 10.78it/s, loss=0.6683, lr=2.07e-05, grad=M:0.1067, status=Epoch complete]
â–ˆ Epoch  39: Loss T 0.668283 V 0.787524 | F1 T 0.691250 V 0.657470 B 0.668460 SC 7/20 | Acc T 0.716123 V 0.657448 | LR 2.07e-05 | Grad â†“ 0.003895 â†‘ 0.516455 M 0.106730 | 2s
Epoch 40/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 11.62it/s, loss=0.6653, lr=1.32e-07, grad=M:0.4500, status=Epoch complete]
â–ˆ Epoch  40: Loss T 0.665303 V 0.786008 | F1 T 0.691556 V 0.658573 B 0.668460 SC 8/20 | Acc T 0.716172 V 0.658739 | LR 1.32e-07 | Grad â†“ 0.018356 â†‘ 2.522140 M 0.449966 | 2s
Memory: Rank 0: 3.60 GB | Rank 1: 3.75 GB | Rank 2: 3.75 GB | Rank 3: 3.75 GB | Rank 4: 3.75 GB | Rank 5: 3.75 GB | Rank 6: 3.75 GB | Rank 7: 3.60 GB (Max: 42.29 GB, Total: 338.28 GB)
Saved model state: checkpoints/checkpoint_epoch_40_20241024-001620.pth
Epoch 41/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 10.30it/s, loss=0.6737, lr=1.82e-04, grad=M:0.2431, status=Epoch complete]
â–ˆ Epoch  41: Loss T 0.673693 V 0.810364 | F1 T 0.683879 V 0.638805 B 0.668460 SC 9/20 | Acc T 0.714409 V 0.641962 | LR 1.82e-04 | Grad â†“ 0.008097 â†‘ 1.283823 M 0.243129 | 2s
Epoch 42/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 11.36it/s, loss=0.6682, lr=1.33e-04, grad=M:0.5357, status=Epoch complete]
â–ˆ Epoch  42: Loss T 0.668223 V 0.795013 | F1 T 0.689815 V 0.655395 B 0.668460 SC 10/20 | Acc T 0.716661 V 0.655420 | LR 1.33e-04 | Grad â†“ 0.020941 â†‘ 2.986049 M 0.535720 | 2s
Epoch 43/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 11.21it/s, loss=0.6664, lr=7.16e-05, grad=M:0.3092, status=Epoch complete]
â–ˆ Epoch  43: Loss T 0.666366 V 0.788335 | F1 T 0.689315 V 0.657366 B 0.668460 SC 11/20 | Acc T 0.715143 V 0.657080 | LR 7.16e-05 | Grad â†“ 0.009968 â†‘ 1.727611 M 0.309236 | 2s
Epoch 44/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 11.23it/s, loss=0.6638, lr=2.07e-05, grad=M:0.2859, status=Epoch complete]
â–ˆ Epoch  44: Loss T 0.663773 V 0.792752 | F1 T 0.690628 V 0.651369 B 0.668460 SC 12/20 | Acc T 0.717278 V 0.651549 | LR 2.07e-05 | Grad â†“ 0.009165 â†‘ 1.533979 M 0.285923 | 2s
Epoch 45/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 11.66it/s, loss=0.6614, lr=1.32e-07, grad=M:0.1281, status=Epoch complete]
â–ˆ Epoch  45: Loss T 0.661432 V 0.789526 | F1 T 0.692383 V 0.654353 B 0.668460 SC 13/20 | Acc T 0.718042 V 0.654683 | LR 1.32e-07 | Grad â†“ 0.004033 â†‘ 0.686206 M 0.128103 | 2s
Saved model state: checkpoints/checkpoint_epoch_45_20241024-001631.pth
Epoch 46/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 11.64it/s, loss=0.6747, lr=1.82e-04, grad=M:0.5045, status=Epoch complete]
â–ˆ Epoch  46: Loss T 0.674690 V 0.803414 | F1 T 0.686745 V 0.639628 B 0.668460 SC 14/20 | Acc T 0.716906 V 0.641040 | LR 1.82e-04 | Grad â†“ 0.019923 â†‘ 2.819160 M 0.504545 | 2s
Epoch 47/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 11.56it/s, loss=0.6652, lr=1.33e-04, grad=M:0.4689, status=Epoch complete]
â–ˆ Epoch  47: Loss T 0.665219 V 0.787371 | F1 T 0.694663 V 0.656856 B 0.668460 SC 15/20 | Acc T 0.719355 V 0.657633 | LR 1.33e-04 | Grad â†“ 0.016737 â†‘ 2.615291 M 0.468922 | 2s
Epoch 48/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 11.89it/s, loss=0.6611, lr=7.16e-05, grad=M:0.4702, status=Epoch complete]
â–ˆ Epoch  48: Loss T 0.661115 V 0.788335 | F1 T 0.691183 V 0.656942 B 0.668460 SC 16/20 | Acc T 0.716926 V 0.656711 | LR 7.16e-05 | Grad â†“ 0.015820 â†‘ 2.563883 M 0.470207 | 2s
Epoch 49/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 11.47it/s, loss=0.6605, lr=2.07e-05, grad=M:0.2016, status=Epoch complete]
â–ˆ Epoch  49: Loss T 0.660459 V 0.779643 | F1 T 0.695526 V 0.663931 B 0.668460 SC 17/20 | Acc T 0.718894 V 0.663717 | LR 2.07e-05 | Grad â†“ 0.006782 â†‘ 1.076312 M 0.201569 | 2s
Epoch 50/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 10.56it/s, loss=0.6579, lr=1.32e-07, grad=M:0.1015, status=Epoch complete]
â–ˆ Epoch  50: Loss T 0.657858 V 0.783437 | F1 T 0.695068 V 0.656526 B 0.668460 SC 18/20 | Acc T 0.719649 V 0.656711 | LR 1.32e-07 | Grad â†“ 0.001904 â†‘ 0.471922 M 0.101496 | 2s
Memory: Rank 0: 3.60 GB | Rank 1: 3.75 GB | Rank 2: 3.75 GB | Rank 3: 3.75 GB | Rank 4: 3.75 GB | Rank 5: 3.75 GB | Rank 6: 3.75 GB | Rank 7: 3.60 GB (Max: 42.29 GB, Total: 338.28 GB)
Saved model state: checkpoints/checkpoint_epoch_50_20241024-001643.pth
Epoch 51/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 11.72it/s, loss=0.6671, lr=1.82e-04, grad=M:0.6178, status=Epoch complete]
â–ˆ Epoch  51: Loss T 0.667147 V 0.762735 | F1 T 0.697822 V 0.671972 B 0.671972 SC 0/20 | Acc T 0.718287 V 0.671829 | LR 1.82e-04 | Grad â†“ 0.022736 â†‘ 3.474029 M 0.617808 | 2s
Epoch 52/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 10.22it/s, loss=0.6652, lr=1.33e-04, grad=M:0.1099, status=Epoch complete]
â–ˆ Epoch  52: Loss T 0.665201 V 0.804173 | F1 T 0.689997 V 0.646859 B 0.671972 SC 1/20 | Acc T 0.717954 V 0.646940 | LR 1.33e-04 | Grad â†“ 0.004064 â†‘ 0.535443 M 0.109908 | 2s
Epoch 53/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 11.72it/s, loss=0.6579, lr=7.16e-05, grad=M:0.1915, status=Epoch complete]
â–ˆ Epoch  53: Loss T 0.657948 V 0.793716 | F1 T 0.692869 V 0.651106 B 0.671972 SC 2/20 | Acc T 0.720158 V 0.651917 | LR 7.16e-05 | Grad â†“ 0.009148 â†‘ 1.049854 M 0.191451 | 2s
Epoch 54/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 11.55it/s, loss=0.6561, lr=2.07e-05, grad=M:0.2986, status=Epoch complete]
â–ˆ Epoch  54: Loss T 0.656066 V 0.794058 | F1 T 0.693598 V 0.653137 B 0.671972 SC 3/20 | Acc T 0.720285 V 0.653392 | LR 2.07e-05 | Grad â†“ 0.011169 â†‘ 1.679832 M 0.298575 | 2s
Epoch 55/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 11.66it/s, loss=0.6545, lr=1.32e-07, grad=M:0.2021, status=Epoch complete]
â–ˆ Epoch  55: Loss T 0.654500 V 0.786562 | F1 T 0.695578 V 0.655110 B 0.671972 SC 4/20 | Acc T 0.720951 V 0.655420 | LR 1.32e-07 | Grad â†“ 0.006151 â†‘ 1.087698 M 0.202082 | 2s
Saved model state: checkpoints/checkpoint_epoch_55_20241024-001655.pth
Epoch 56/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 11.79it/s, loss=0.6691, lr=1.82e-04, grad=M:0.7619, status=Epoch complete]
â–ˆ Epoch  56: Loss T 0.669094 V 0.836422 | F1 T 0.681487 V 0.625738 B 0.671972 SC 5/20 | Acc T 0.715672 V 0.629978 | LR 1.82e-04 | Grad â†“ 0.028921 â†‘ 4.452361 M 0.761893 | 2s
Epoch 57/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 11.39it/s, loss=0.6581, lr=1.33e-04, grad=M:0.3432, status=Epoch complete]
â–ˆ Epoch  57: Loss T 0.658120 V 0.778427 | F1 T 0.695648 V 0.660956 B 0.671972 SC 6/20 | Acc T 0.720344 V 0.660951 | LR 1.33e-04 | Grad â†“ 0.013535 â†‘ 1.977965 M 0.343249 | 2s
Epoch 58/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 11.61it/s, loss=0.6548, lr=7.16e-05, grad=M:0.1720, status=Epoch complete]
â–ˆ Epoch  58: Loss T 0.654831 V 0.785167 | F1 T 0.697259 V 0.657608 B 0.671972 SC 7/20 | Acc T 0.722068 V 0.658555 | LR 7.16e-05 | Grad â†“ 0.007527 â†‘ 0.944991 M 0.172002 | 2s
Epoch 59/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 10.99it/s, loss=0.6525, lr=2.07e-05, grad=M:0.2094, status=Epoch complete]
â–ˆ Epoch  59: Loss T 0.652472 V 0.779193 | F1 T 0.697606 V 0.662823 B 0.671972 SC 8/20 | Acc T 0.721754 V 0.662795 | LR 2.07e-05 | Grad â†“ 0.011327 â†‘ 1.137053 M 0.209441 | 2s
Epoch 60/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 11.67it/s, loss=0.6514, lr=1.32e-07, grad=M:0.1074, status=Epoch complete]
â–ˆ Epoch  60: Loss T 0.651406 V 0.782243 | F1 T 0.697580 V 0.658594 B 0.671972 SC 9/20 | Acc T 0.722126 V 0.658923 | LR 1.32e-07 | Grad â†“ 0.004910 â†‘ 0.555423 M 0.107352 | 2s
Memory: Rank 0: 3.60 GB | Rank 1: 3.75 GB | Rank 2: 3.75 GB | Rank 3: 3.75 GB | Rank 4: 3.75 GB | Rank 5: 3.75 GB | Rank 6: 3.75 GB | Rank 7: 3.60 GB (Max: 42.29 GB, Total: 338.28 GB)
Saved model state: checkpoints/checkpoint_epoch_60_20241024-001707.pth
Epoch 61/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 10.93it/s, loss=0.6585, lr=1.82e-04, grad=M:0.7731, status=Epoch complete]
â–ˆ Epoch  61: Loss T 0.658461 V 0.770050 | F1 T 0.696233 V 0.667536 B 0.671972 SC 10/20 | Acc T 0.720168 V 0.667220 | LR 1.82e-04 | Grad â†“ 0.029717 â†‘ 4.511450 M 0.773055 | 2s
Epoch 62/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 11.18it/s, loss=0.6556, lr=1.33e-04, grad=M:0.8694, status=Epoch complete]
â–ˆ Epoch  62: Loss T 0.655617 V 0.785882 | F1 T 0.695857 V 0.655135 B 0.671972 SC 11/20 | Acc T 0.722459 V 0.655420 | LR 1.33e-04 | Grad â†“ 0.030051 â†‘ 4.942551 M 0.869404 | 2s
Epoch 63/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00,  9.91it/s, loss=0.6518, lr=7.16e-05, grad=M:0.1883, status=Epoch complete]
â–ˆ Epoch  63: Loss T 0.651849 V 0.793613 | F1 T 0.695148 V 0.649838 B 0.671972 SC 12/20 | Acc T 0.722655 V 0.651180 | LR 7.16e-05 | Grad â†“ 0.006751 â†‘ 1.078586 M 0.188327 | 2s
Epoch 64/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 11.33it/s, loss=0.6499, lr=2.07e-05, grad=M:0.1694, status=Epoch complete]
â–ˆ Epoch  64: Loss T 0.649923 V 0.775500 | F1 T 0.699639 V 0.663219 B 0.671972 SC 13/20 | Acc T 0.723458 V 0.663348 | LR 2.07e-05 | Grad â†“ 0.007622 â†‘ 0.946392 M 0.169365 | 2s
Epoch 65/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00,  9.18it/s, loss=0.6489, lr=1.32e-07, grad=M:0.1393, status=Epoch complete]
â–ˆ Epoch  65: Loss T 0.648894 V 0.782711 | F1 T 0.699062 V 0.659876 B 0.671972 SC 14/20 | Acc T 0.723674 V 0.660398 | LR 1.32e-07 | Grad â†“ 0.005057 â†‘ 0.763642 M 0.139304 | 2s
Saved model state: checkpoints/checkpoint_epoch_65_20241024-001719.pth
Epoch 66/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 11.59it/s, loss=0.6541, lr=1.82e-04, grad=M:1.3063, status=Epoch complete]
â–ˆ Epoch  66: Loss T 0.654110 V 0.826404 | F1 T 0.680226 V 0.623836 B 0.671972 SC 15/20 | Acc T 0.716162 V 0.627028 | LR 1.82e-04 | Grad â†“ 0.042297 â†‘ 7.458454 M 1.306321 | 2s
Epoch 67/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 11.35it/s, loss=0.6575, lr=1.33e-04, grad=M:0.6580, status=Epoch complete]
â–ˆ Epoch  67: Loss T 0.657511 V 0.761568 | F1 T 0.701366 V 0.675169 B 0.675169 SC 0/20 | Acc T 0.721490 V 0.674963 | LR 1.33e-04 | Grad â†“ 0.020213 â†‘ 3.827403 M 0.658034 | 2s
Epoch 68/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 11.60it/s, loss=0.6502, lr=7.16e-05, grad=M:0.5806, status=Epoch complete]
â–ˆ Epoch  68: Loss T 0.650198 V 0.765097 | F1 T 0.702038 V 0.670260 B 0.675169 SC 1/20 | Acc T 0.723380 V 0.670170 | LR 7.16e-05 | Grad â†“ 0.020083 â†‘ 3.350713 M 0.580594 | 2s
Epoch 69/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 11.57it/s, loss=0.6480, lr=2.07e-05, grad=M:0.2637, status=Epoch complete]
â–ˆ Epoch  69: Loss T 0.647972 V 0.779967 | F1 T 0.700711 V 0.660250 B 0.675169 SC 2/20 | Acc T 0.724986 V 0.660767 | LR 2.07e-05 | Grad â†“ 0.008410 â†‘ 1.506488 M 0.263707 | 2s
Epoch 70/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 11.70it/s, loss=0.6456, lr=1.32e-07, grad=M:0.2143, status=Epoch complete]
â–ˆ Epoch  70: Loss T 0.645609 V 0.778672 | F1 T 0.700670 V 0.659670 B 0.675169 SC 3/20 | Acc T 0.725114 V 0.660214 | LR 1.32e-07 | Grad â†“ 0.007595 â†‘ 1.232864 M 0.214323 | 2s
Memory: Rank 0: 3.60 GB | Rank 1: 3.75 GB | Rank 2: 3.75 GB | Rank 3: 3.75 GB | Rank 4: 3.75 GB | Rank 5: 3.75 GB | Rank 6: 3.75 GB | Rank 7: 3.60 GB (Max: 42.29 GB, Total: 338.28 GB)
Saved model state: checkpoints/checkpoint_epoch_70_20241024-001732.pth
Epoch 71/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 11.54it/s, loss=0.6637, lr=1.82e-04, grad=M:0.7618, status=Epoch complete]
â–ˆ Epoch  71: Loss T 0.663674 V 0.808644 | F1 T 0.678737 V 0.636775 B 0.675169 SC 4/20 | Acc T 0.711285 V 0.636615 | LR 1.82e-04 | Grad â†“ 0.028646 â†‘ 4.619201 M 0.761781 | 2s
Epoch 72/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 10.96it/s, loss=0.6538, lr=1.33e-04, grad=M:0.2536, status=Epoch complete]
â–ˆ Epoch  72: Loss T 0.653794 V 0.771632 | F1 T 0.700679 V 0.666912 B 0.675169 SC 5/20 | Acc T 0.723860 V 0.666851 | LR 1.33e-04 | Grad â†“ 0.008407 â†‘ 1.433862 M 0.253601 | 2s
Epoch 73/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 11.26it/s, loss=0.6466, lr=7.16e-05, grad=M:0.0813, status=Epoch complete]
â–ˆ Epoch  73: Loss T 0.646552 V 0.765731 | F1 T 0.702627 V 0.667043 B 0.675169 SC 6/20 | Acc T 0.724712 V 0.667404 | LR 7.16e-05 | Grad â†“ 0.003336 â†‘ 0.421857 M 0.081268 | 2s
Epoch 74/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00,  9.55it/s, loss=0.6456, lr=2.07e-05, grad=M:0.2588, status=Epoch complete]
â–ˆ Epoch  74: Loss T 0.645602 V 0.777372 | F1 T 0.701656 V 0.663543 B 0.675169 SC 7/20 | Acc T 0.725505 V 0.663717 | LR 2.07e-05 | Grad â†“ 0.009866 â†‘ 1.514462 M 0.258767 | 2s
Epoch 75/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 11.30it/s, loss=0.6434, lr=1.32e-07, grad=M:0.1595, status=Epoch complete]
â–ˆ Epoch  75: Loss T 0.643447 V 0.778016 | F1 T 0.701272 V 0.660869 B 0.675169 SC 8/20 | Acc T 0.725740 V 0.661504 | LR 1.32e-07 | Grad â†“ 0.005751 â†‘ 0.901064 M 0.159531 | 2s
Saved model state: checkpoints/checkpoint_epoch_75_20241024-001743.pth
Epoch 76/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 11.47it/s, loss=0.6504, lr=1.82e-04, grad=M:0.4558, status=Epoch complete]
â–ˆ Epoch  76: Loss T 0.650410 V 0.795710 | F1 T 0.696692 V 0.646520 B 0.675169 SC 9/20 | Acc T 0.725016 V 0.648414 | LR 1.82e-04 | Grad â†“ 0.014326 â†‘ 2.626201 M 0.455791 | 2s
Epoch 77/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 11.55it/s, loss=0.6466, lr=1.33e-04, grad=M:0.6201, status=Epoch complete]
â–ˆ Epoch  77: Loss T 0.646580 V 0.774726 | F1 T 0.701024 V 0.658474 B 0.675169 SC 10/20 | Acc T 0.725740 V 0.659476 | LR 1.33e-04 | Grad â†“ 0.021296 â†‘ 3.690608 M 0.620133 | 2s
Epoch 78/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 11.39it/s, loss=0.6455, lr=7.16e-05, grad=M:0.2179, status=Epoch complete]
â–ˆ Epoch  78: Loss T 0.645480 V 0.771058 | F1 T 0.703628 V 0.669377 B 0.675169 SC 11/20 | Acc T 0.724653 V 0.669617 | LR 7.16e-05 | Grad â†“ 0.007306 â†‘ 1.179568 M 0.217878 | 2s
Epoch 79/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 11.23it/s, loss=0.6426, lr=2.07e-05, grad=M:0.2403, status=Epoch complete]
â–ˆ Epoch  79: Loss T 0.642551 V 0.778738 | F1 T 0.701606 V 0.662133 B 0.675169 SC 12/20 | Acc T 0.726093 V 0.662242 | LR 2.07e-05 | Grad â†“ 0.008769 â†‘ 1.399538 M 0.240254 | 2s
Epoch 80/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 11.25it/s, loss=0.6408, lr=1.32e-07, grad=M:0.2308, status=Epoch complete]
â–ˆ Epoch  80: Loss T 0.640785 V 0.774324 | F1 T 0.703161 V 0.662605 B 0.675169 SC 13/20 | Acc T 0.726867 V 0.662979 | LR 1.32e-07 | Grad â†“ 0.008048 â†‘ 1.348822 M 0.230826 | 2s
Memory: Rank 0: 3.60 GB | Rank 1: 3.75 GB | Rank 2: 3.75 GB | Rank 3: 3.75 GB | Rank 4: 3.75 GB | Rank 5: 3.75 GB | Rank 6: 3.75 GB | Rank 7: 3.60 GB (Max: 42.29 GB, Total: 338.28 GB)
Saved model state: checkpoints/checkpoint_epoch_80_20241024-001756.pth
Epoch 81/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 12.10it/s, loss=0.6518, lr=1.82e-04, grad=M:0.4661, status=Epoch complete]
â–ˆ Epoch  81: Loss T 0.651784 V 0.785780 | F1 T 0.700188 V 0.661074 B 0.675169 SC 14/20 | Acc T 0.726279 V 0.661873 | LR 1.82e-04 | Grad â†“ 0.016217 â†‘ 2.750531 M 0.466084 | 2s
Epoch 82/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 11.61it/s, loss=0.6452, lr=1.33e-04, grad=M:0.1926, status=Epoch complete]
â–ˆ Epoch  82: Loss T 0.645183 V 0.777057 | F1 T 0.699366 V 0.655766 B 0.675169 SC 15/20 | Acc T 0.723596 V 0.658186 | LR 1.33e-04 | Grad â†“ 0.006624 â†‘ 1.124791 M 0.192641 | 2s
Epoch 83/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 11.01it/s, loss=0.6446, lr=7.16e-05, grad=M:0.4299, status=Epoch complete]
â–ˆ Epoch  83: Loss T 0.644615 V 0.768438 | F1 T 0.704913 V 0.668259 B 0.675169 SC 16/20 | Acc T 0.726622 V 0.668510 | LR 7.16e-05 | Grad â†“ 0.014509 â†‘ 2.571031 M 0.429895 | 2s
Epoch 84/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 11.48it/s, loss=0.6400, lr=2.07e-05, grad=M:0.3734, status=Epoch complete]
â–ˆ Epoch  84: Loss T 0.640041 V 0.778561 | F1 T 0.702910 V 0.660662 B 0.675169 SC 17/20 | Acc T 0.727797 V 0.661320 | LR 2.07e-05 | Grad â†“ 0.014438 â†‘ 2.232518 M 0.373391 | 2s
Epoch 85/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 10.54it/s, loss=0.6378, lr=1.32e-07, grad=M:0.0860, status=Epoch complete]
â–ˆ Epoch  85: Loss T 0.637818 V 0.775862 | F1 T 0.703358 V 0.662562 B 0.675169 SC 18/20 | Acc T 0.727572 V 0.662979 | LR 1.32e-07 | Grad â†“ 0.001089 â†‘ 0.416574 M 0.085964 | 2s
Saved model state: checkpoints/checkpoint_epoch_85_20241024-001807.pth
Epoch 86/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 11.30it/s, loss=0.6472, lr=1.82e-04, grad=M:1.6616, status=Epoch complete]
â–ˆ Epoch  86: Loss T 0.647175 V 0.779264 | F1 T 0.697675 V 0.658278 B 0.675169 SC 19/20 | Acc T 0.724634 V 0.658001 | LR 1.82e-04 | Grad â†“ 0.058348 â†‘ 10.034244 M 1.661578 | 2s
Epoch 87/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 11.54it/s, loss=0.6476, lr=1.33e-04, grad=M:0.2667, status=Epoch complete]
â–ˆ Epoch  87: Loss T 0.647646 V 0.754546 | F1 T 0.705987 V 0.675236 B 0.675236 SC 0/20 | Acc T 0.725985 V 0.675701 | LR 1.33e-04 | Grad â†“ 0.013292 â†‘ 1.580659 M 0.266702 | 2s
Epoch 88/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 11.47it/s, loss=0.6408, lr=7.16e-05, grad=M:0.5920, status=Epoch complete]
â–ˆ Epoch  88: Loss T 0.640814 V 0.778453 | F1 T 0.703128 V 0.660672 B 0.675236 SC 1/20 | Acc T 0.728679 V 0.661320 | LR 7.16e-05 | Grad â†“ 0.019124 â†‘ 3.527148 M 0.591963 | 2s
Epoch 89/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 11.51it/s, loss=0.6369, lr=2.07e-05, grad=M:0.1248, status=Epoch complete]
â–ˆ Epoch  89: Loss T 0.636882 V 0.763346 | F1 T 0.706672 V 0.670108 B 0.675236 SC 2/20 | Acc T 0.728718 V 0.670354 | LR 2.07e-05 | Grad â†“ 0.005387 â†‘ 0.690806 M 0.124801 | 2s
Epoch 90/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 11.71it/s, loss=0.6356, lr=1.32e-07, grad=M:0.1690, status=Epoch complete]
â–ˆ Epoch  90: Loss T 0.635623 V 0.767041 | F1 T 0.705630 V 0.667588 B 0.675236 SC 3/20 | Acc T 0.728189 V 0.667773 | LR 1.32e-07 | Grad â†“ 0.007281 â†‘ 0.990895 M 0.168957 | 2s
Memory: Rank 0: 3.60 GB | Rank 1: 3.75 GB | Rank 2: 3.75 GB | Rank 3: 3.75 GB | Rank 4: 3.75 GB | Rank 5: 3.75 GB | Rank 6: 3.75 GB | Rank 7: 3.60 GB (Max: 42.29 GB, Total: 338.28 GB)
Saved model state: checkpoints/checkpoint_epoch_90_20241024-001818.pth
Epoch 91/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 11.62it/s, loss=0.6456, lr=1.82e-04, grad=M:0.4967, status=Epoch complete]
â–ˆ Epoch  91: Loss T 0.645571 V 0.788131 | F1 T 0.697246 V 0.657399 B 0.675236 SC 4/20 | Acc T 0.724771 V 0.657264 | LR 1.82e-04 | Grad â†“ 0.018546 â†‘ 2.996389 M 0.496683 | 2s
Epoch 92/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 11.91it/s, loss=0.6460, lr=1.33e-04, grad=M:0.7413, status=Epoch complete]
â–ˆ Epoch  92: Loss T 0.646042 V 0.759655 | F1 T 0.706242 V 0.671586 B 0.675236 SC 5/20 | Acc T 0.728248 V 0.671645 | LR 1.33e-04 | Grad â†“ 0.026952 â†‘ 4.552817 M 0.741305 | 2s
Epoch 93/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 11.83it/s, loss=0.6359, lr=7.16e-05, grad=M:0.2473, status=Epoch complete]
â–ˆ Epoch  93: Loss T 0.635940 V 0.766266 | F1 T 0.706688 V 0.667142 B 0.675236 SC 6/20 | Acc T 0.729619 V 0.667588 | LR 7.16e-05 | Grad â†“ 0.010493 â†‘ 1.484987 M 0.247259 | 2s
Epoch 94/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 10.80it/s, loss=0.6339, lr=2.07e-05, grad=M:0.3214, status=Epoch complete]
â–ˆ Epoch  94: Loss T 0.633895 V 0.781281 | F1 T 0.704347 V 0.661340 B 0.675236 SC 7/20 | Acc T 0.729697 V 0.661873 | LR 2.07e-05 | Grad â†“ 0.012404 â†‘ 1.892907 M 0.321422 | 2s
Epoch 95/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 11.78it/s, loss=0.6327, lr=1.32e-07, grad=M:0.2915, status=Epoch complete]
â–ˆ Epoch  95: Loss T 0.632679 V 0.768825 | F1 T 0.706131 V 0.666620 B 0.675236 SC 8/20 | Acc T 0.729903 V 0.667035 | LR 1.32e-07 | Grad â†“ 0.010843 â†‘ 1.744175 M 0.291454 | 2s
Saved model state: checkpoints/checkpoint_epoch_95_20241024-001829.pth
Epoch 96/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 10.38it/s, loss=0.6405, lr=1.82e-04, grad=M:0.3879, status=Epoch complete]
â–ˆ Epoch  96: Loss T 0.640451 V 0.766780 | F1 T 0.706100 V 0.668464 B 0.675236 SC 9/20 | Acc T 0.729697 V 0.668510 | LR 1.82e-04 | Grad â†“ 0.018596 â†‘ 2.332374 M 0.387877 | 2s
Epoch 97/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 11.60it/s, loss=0.6377, lr=1.33e-04, grad=M:0.8382, status=Epoch complete]
â–ˆ Epoch  97: Loss T 0.637688 V 0.770872 | F1 T 0.705379 V 0.667951 B 0.675236 SC 10/20 | Acc T 0.729952 V 0.668142 | LR 1.33e-04 | Grad â†“ 0.036535 â†‘ 5.221142 M 0.838187 | 2s
Epoch 98/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 11.51it/s, loss=0.6352, lr=7.16e-05, grad=M:0.4700, status=Epoch complete]
â–ˆ Epoch  98: Loss T 0.635231 V 0.771529 | F1 T 0.703304 V 0.674001 B 0.675236 SC 11/20 | Acc T 0.727376 V 0.673673 | LR 7.16e-05 | Grad â†“ 0.015813 â†‘ 2.882298 M 0.470005 | 2s
Epoch 99/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 11.77it/s, loss=0.6329, lr=2.07e-05, grad=M:0.2922, status=Epoch complete]
â–ˆ Epoch  99: Loss T 0.632921 V 0.759540 | F1 T 0.707225 V 0.671883 B 0.675236 SC 12/20 | Acc T 0.730011 V 0.671645 | LR 2.07e-05 | Grad â†“ 0.013700 â†‘ 1.783514 M 0.292154 | 2s
Epoch 100/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 11.69it/s, loss=0.6297, lr=1.32e-07, grad=M:0.1496, status=Epoch complete]
â–ˆ Epoch 100: Loss T 0.629726 V 0.766684 | F1 T 0.707582 V 0.669718 B 0.675236 SC 13/20 | Acc T 0.730961 V 0.669985 | LR 1.32e-07 | Grad â†“ 0.006305 â†‘ 0.889701 M 0.149647 | 2s
Memory: Rank 0: 3.60 GB | Rank 1: 3.75 GB | Rank 2: 3.75 GB | Rank 3: 3.75 GB | Rank 4: 3.75 GB | Rank 5: 3.75 GB | Rank 6: 3.75 GB | Rank 7: 3.60 GB (Max: 42.29 GB, Total: 338.28 GB)
Saved model state: checkpoints/checkpoint_epoch_100_20241024-001841.pth
Saving model in ONNX format...
An error occurred during training: Module onnx is not installed!
Traceback (most recent call last):
  File "/home/ubuntu/nlp-osaka/sentiment/nlp/lib/python3.10/site-packages/torch/onnx/_internal/onnx_proto_utils.py", line 221, in _add_onnxscript_fn
    import onnx
ModuleNotFoundError: No module named 'onnx'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ubuntu/nlp-osaka/sentiment/ddp_sentiment_finetune.py", line 1206, in main
    classifier.fit(X_train, X_val, y_train, y_val, rank, world_size, debug, start_epoch, model_state_dict, optimizer_state_dict,
  File "/home/ubuntu/nlp-osaka/sentiment/torch_ddp_finetune_neural_classifier.py", line 1624, in fit
    torch.onnx.export(self.model.module, dummy_input, onnx_file_path, opset_version=13)
  File "/home/ubuntu/nlp-osaka/sentiment/nlp/lib/python3.10/site-packages/torch/onnx/utils.py", line 516, in export
    _export(
  File "/home/ubuntu/nlp-osaka/sentiment/nlp/lib/python3.10/site-packages/torch/onnx/utils.py", line 1670, in _export
    proto = onnx_proto_utils._add_onnxscript_fn(
  File "/home/ubuntu/nlp-osaka/sentiment/nlp/lib/python3.10/site-packages/torch/onnx/_internal/onnx_proto_utils.py", line 223, in _add_onnxscript_fn
    raise errors.OnnxExporterError("Module onnx is not installed!") from e
torch.onnx.errors.OnnxExporterError: Module onnx is not installed!
wandb: ðŸš€ View run run_1_merged_class at: https://wandb.ai/jimbeno/Electra Large/runs/u8ze04kp
wandb: Find logs at: wandb/run-20241024_001423-u8ze04kp/logs
(nlp) ubuntu@138-2-58-218:~/nlp-osaka/sentiment$ pip install onnx
Collecting onnx
  Downloading onnx-1.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 16.0/16.0 MB 81.8 MB/s eta 0:00:00
Requirement already satisfied: numpy>=1.20 in ./nlp/lib/python3.10/site-packages (from onnx) (1.26.4)
Requirement already satisfied: protobuf>=3.20.2 in ./nlp/lib/python3.10/site-packages (from onnx) (5.28.3)
Installing collected packages: onnx
Successfully installed onnx-1.17.0
(nlp) ubuntu@138-2-58-218:~/nlp-osaka/sentiment$ python ./ddp_sentiment_finetune.py --dataset 'merged_local' --weights_name 'google/electra-large-discriminator' --save_data --save_model --save_pickle --save_preds --lr 0.0002 --lr_decay 0.95 --epochs 100 --pooling 'mean' --dropout_rate 0.3 --num_layers 2 --hidden_dim 1024 --hidden_activation 'swishglu' --batch_size 512 --l2_strength 0.0001 --checkpoint_interval 5 --use_zero --optimizer 'adamw' --scheduler 'cosine_warmup' --scheduler_kwargs '{"T_0":5, "T_mult":1, "eta_min":1e-7}' --decimal 6 --use_val_split --eval_split 'test' --early_stop 'score' --n_iter_no_change 20 --wandb --wandb_project 'Electra Large' --wandb_run 'run_1_merged_class' --data_file 'saves/data_8_gpu_20241024-000103.npz'

Starting DDP PyTorch Training...
Device: cuda, Number of GPUs: 8
Spawning 8 processes...
Rank 7 - Device: cuda:7
Rank 5 - Device: cuda:5
Rank 3 - Device: cuda:3
Rank 1 - Device: cuda:1
Rank 4 - Device: cuda:4
Rank 6 - Device: cuda:6
Rank 2 - Device: cuda:2
Rank 0 - Device: cuda:0
8 process groups initialized with 'nccl' backend on localhost:12355
NCCL Timeout: 1 hr 0 min. NCCL Blocking Wait: Enabled
wandb: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: jbeno (jimbeno). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.5
wandb: Run data is saved locally in /home/ubuntu/nlp-osaka/sentiment/wandb/run-20241024_002212-rzzqasnp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run run_1_merged_class
wandb: â­ï¸ View project at https://wandb.ai/jimbeno/Electra%20Large
wandb: ðŸš€ View run at https://wandb.ai/jimbeno/Electra%20Large/runs/rzzqasnp
Wand run initialized.

Initializing 'google/electra-large-discriminator' tokenizer and model...
Checking for local files...
Found all files in cache, skipping download
All ranks loading tokenizer from local files...
All ranks loading model from local files...
Tokenizer and model initialized (6s)

Loading archived data from: saves/data_8_gpu_20241024-000103.npz...
X Train shape: [102097, 1024], y Train shape: [102097]
X Validation shape: [5421, 1024], y Validation shape: [5421]
X Test shape: [5421, 1024], y Dev shape: [5421]
X Test Sentences shape: [5421]
Train label distribution:
	      Negative: 21910
	       Neutral: 49148
	      Positive: 31039
Validation label distribution:
	      Negative: 1868
	       Neutral: 1669
	      Positive: 1884
Test label distribution:
	      Negative: 1868
	       Neutral: 1669
	      Positive: 1884
Archived data loaded (3.98s)

Initializing DDP Neural Classifier...
Layers: 2, Hidden Dim: 1024, Hidden Act: SwishGLU, Dropout: 0.3, Optimizer: AdamW, L2 Strength: 0.0001, Pooling: MEAN, Accumulation Steps: 1, Max Grad Norm: None
Batch Size: 512, Max Epochs: 100, LR: 0.0002, Early Stop: score, Fine-tune BERT: False, Fine-tune Layers: 1, Freeze BERT: False, Target Score: None, Interactive: False
Classifier initialized (14ms)

Fitting DDP Neural Classifier on training data...
Num Workers: 0, Prefetch: None
Score-based early stopping enabled (macro average F1 score against validation set). Validation fraction: 0.1
Training will stop early if the score does not improve by at least 0.00001 for 20 iterations.
Using provided validation set for early stopping.
Building dataset and dataloader...
Classes: ['negative', 'neutral', 'positive'], Number of classes: 3
Initializing model, graph, optimizer...

Model Architecture Summary:
Classifier(
  (layers): Sequential(
    (0): Linear(in_features=1024, out_features=1024, bias=True)
    (1): SwishGLU(
      (projection): Linear(in_features=1024, out_features=2048, bias=True)
      (activation): SiLU()
    )
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=1024, out_features=1024, bias=True)
    (4): SwishGLU(
      (projection): Linear(in_features=1024, out_features=2048, bias=True)
      (activation): SiLU()
    )
    (5): Dropout(p=0.3, inplace=False)
    (6): Linear(in_features=1024, out_features=3, bias=True)
  )
)

Model Parameters:
  layers.0: 1,049,600 (trainable)
  layers.1.projection: 2,099,200 (trainable)
  layers.3: 1,049,600 (trainable)
  layers.6: 3,075 (trainable)

Total layers: 4
Trainable layers: 4
Total parameters: 4,201,475
Trainable parameters: 4,201,475
Percentage of trainable parameters: 100.00%
Using optimizer: AdamW, Use Zero: True, Base Learning Rate: 0.0002, L2 strength: 0.0001
Using scheduler: CosineAnnealingWarmRestarts
Scheduler arguments:
- T_0: 5
- T_mult: 1
- eta_min: 1e-07

Starting training loop...
Start epoch: 1, Max Iterations: 100, Early Stop: score, Tolerance: 0.00001, Number Iterations No Change: 20
â–ˆ Epoch   1: Loss T 1.058017 V 1.131716 | F1 T 0.220246 V 0.156909 B 0.156909 SC 0/20 | Acc T 0.480608 V 0.306047 | LR 1.82e-04 | Grad â†“ 0.007653 â†‘ 0.142788 M 0.051265 | 3s
â–ˆ Epoch   2: Loss T 1.000388 V 1.088899 | F1 T 0.225029 V 0.164479 B 0.164479 SC 0/20 | Acc T 0.480206 V 0.307891 | LR 1.33e-04 | Grad â†“ 0.001269 â†‘ 0.082067 M 0.035585 | 2s
â–ˆ Epoch   3: Loss T 0.937542 V 1.059300 | F1 T 0.352938 V 0.299568 B 0.299568 SC 0/20 | Acc T 0.539264 V 0.387168 | LR 7.16e-05 | Grad â†“ 0.004494 â†‘ 0.309561 M 0.079576 | 2s
â–ˆ Epoch   4: Loss T 0.917026 V 1.041941 | F1 T 0.388332 V 0.336051 B 0.336051 SC 0/20 | Acc T 0.561633 V 0.422198 | LR 2.07e-05 | Grad â†“ 0.004164 â†‘ 0.276879 M 0.067226 | 2s
â–ˆ Epoch   5: Loss T 0.911074 V 1.039998 | F1 T 0.395318 V 0.344046 B 0.344046 SC 0/20 | Acc T 0.565580 V 0.430494 | LR 1.32e-07 | Grad â†“ 0.006308 â†‘ 0.386941 M 0.083552 | 2s
Saved model state: checkpoints/checkpoint_epoch_5_20241024-002241.pth
â–ˆ Epoch   6: Loss T 0.902276 V 0.989478 | F1 T 0.427527 V 0.382070 B 0.382070 SC 0/20 | Acc T 0.589115 V 0.471792 | LR 1.82e-04 | Grad â†“ 0.002472 â†‘ 0.198636 M 0.049725 | 2s
â–ˆ Epoch   7: Loss T 0.856097 V 0.977604 | F1 T 0.439412 V 0.393371 B 0.393371 SC 0/20 | Acc T 0.605765 V 0.487279 | LR 1.33e-04 | Grad â†“ 0.006509 â†‘ 0.646510 M 0.128657 | 2s
â–ˆ Epoch   8: Loss T 0.835444 V 0.962567 | F1 T 0.447502 V 0.399411 B 0.399411 SC 0/20 | Acc T 0.614070 V 0.494653 | LR 7.16e-05 | Grad â†“ 0.012442 â†‘ 0.925954 M 0.196784 | 2s
â–ˆ Epoch   9: Loss T 0.821923 V 0.955514 | F1 T 0.453028 V 0.405485 B 0.405485 SC 0/20 | Acc T 0.619457 V 0.499078 | LR 2.07e-05 | Grad â†“ 0.001581 â†‘ 0.125473 M 0.044590 | 2s
â–ˆ Epoch  10: Loss T 0.813802 V 0.952183 | F1 T 0.458149 V 0.412536 B 0.412536 SC 0/20 | Acc T 0.620877 V 0.501475 | LR 1.32e-07 | Grad â†“ 0.005588 â†‘ 0.605341 M 0.156052 | 2s
Memory: Rank 0: 3.60 GB | Rank 1: 3.75 GB | Rank 2: 3.75 GB | Rank 3: 3.75 GB | Rank 4: 3.75 GB | Rank 5: 3.75 GB | Rank 6: 3.75 GB | Rank 7: 3.60 GB (Max: 42.29 GB, Total: 338.28 GB)
Saved model state: checkpoints/checkpoint_epoch_10_20241024-002303.pth
â–ˆ Epoch  11: Loss T 0.873631 V 0.922753 | F1 T 0.477852 V 0.444242 B 0.444242 SC 0/20 | Acc T 0.609369 V 0.514012 | LR 1.82e-04 | Grad â†“ 0.033392 â†‘ 3.020307 M 0.561085 | 2s
â–ˆ Epoch  12: Loss T 0.807737 V 0.916693 | F1 T 0.579121 V 0.540479 B 0.540479 SC 0/20 | Acc T 0.652864 V 0.560103 | LR 1.33e-04 | Grad â†“ 0.024449 â†‘ 2.042228 M 0.417689 | 2s
â–ˆ Epoch  13: Loss T 0.768149 V 0.873765 | F1 T 0.628578 V 0.597116 B 0.597116 SC 0/20 | Acc T 0.669758 V 0.599189 | LR 7.16e-05 | Grad â†“ 0.008845 â†‘ 0.814034 M 0.163079 | 2s
â–ˆ Epoch  14: Loss T 0.751355 V 0.873442 | F1 T 0.634823 V 0.597882 B 0.597882 SC 0/20 | Acc T 0.677290 V 0.601032 | LR 2.07e-05 | Grad â†“ 0.007179 â†‘ 0.562659 M 0.140265 | 2s
â–ˆ Epoch  15: Loss T 0.745775 V 0.864718 | F1 T 0.640014 V 0.603870 B 0.603870 SC 0/20 | Acc T 0.679366 V 0.606379 | LR 1.32e-07 | Grad â†“ 0.010506 â†‘ 0.664322 M 0.180132 | 2s
Saved model state: checkpoints/checkpoint_epoch_15_20241024-002314.pth
â–ˆ Epoch  16: Loss T 0.740783 V 0.836025 | F1 T 0.657594 V 0.625003 B 0.625003 SC 0/20 | Acc T 0.689777 V 0.625369 | LR 1.82e-04 | Grad â†“ 0.021427 â†‘ 2.125517 M 0.415872 | 2s
â–ˆ Epoch  17: Loss T 0.726542 V 0.861855 | F1 T 0.649866 V 0.606492 B 0.625003 SC 1/20 | Acc T 0.691256 V 0.609513 | LR 1.33e-04 | Grad â†“ 0.031913 â†‘ 3.132718 M 0.703591 | 2s
â–ˆ Epoch  18: Loss T 0.709871 V 0.833944 | F1 T 0.665626 V 0.627100 B 0.627100 SC 0/20 | Acc T 0.698601 V 0.627765 | LR 7.16e-05 | Grad â†“ 0.019575 â†‘ 1.859716 M 0.420558 | 2s
â–ˆ Epoch  19: Loss T 0.703978 V 0.831938 | F1 T 0.668262 V 0.629542 B 0.629542 SC 0/20 | Acc T 0.700688 V 0.630347 | LR 2.07e-05 | Grad â†“ 0.006034 â†‘ 0.852693 M 0.196130 | 2s
â–ˆ Epoch  20: Loss T 0.700616 V 0.821554 | F1 T 0.672457 V 0.635808 B 0.635808 SC 0/20 | Acc T 0.702157 V 0.636431 | LR 1.32e-07 | Grad â†“ 0.008443 â†‘ 0.757224 M 0.174373 | 2s
Memory: Rank 0: 3.60 GB | Rank 1: 3.75 GB | Rank 2: 3.75 GB | Rank 3: 3.75 GB | Rank 4: 3.75 GB | Rank 5: 3.75 GB | Rank 6: 3.75 GB | Rank 7: 3.60 GB (Max: 42.29 GB, Total: 338.28 GB)
Saved model state: checkpoints/checkpoint_epoch_20_20241024-002326.pth
â–ˆ Epoch  21: Loss T 0.765937 V 0.829118 | F1 T 0.645627 V 0.631006 B 0.635808 SC 1/20 | Acc T 0.677564 V 0.633850 | LR 1.82e-04 | Grad â†“ 0.031220 â†‘ 2.932511 M 0.575988 | 2s
â–ˆ Epoch  22: Loss T 0.710620 V 0.804155 | F1 T 0.677310 V 0.647510 B 0.647510 SC 0/20 | Acc T 0.702970 V 0.647861 | LR 1.33e-04 | Grad â†“ 0.006735 â†‘ 0.653563 M 0.134447 | 2s
â–ˆ Epoch  23: Loss T 0.697777 V 0.827449 | F1 T 0.670837 V 0.629666 B 0.647510 SC 1/20 | Acc T 0.703782 V 0.631822 | LR 7.16e-05 | Grad â†“ 0.027454 â†‘ 2.916191 M 0.612735 | 2s
â–ˆ Epoch  24: Loss T 0.692470 V 0.806625 | F1 T 0.679617 V 0.647818 B 0.647818 SC 0/20 | Acc T 0.706084 V 0.648414 | LR 2.07e-05 | Grad â†“ 0.019297 â†‘ 2.447051 M 0.470339 | 2s
â–ˆ Epoch  25: Loss T 0.690972 V 0.810468 | F1 T 0.678143 V 0.646383 B 0.647818 SC 1/20 | Acc T 0.706074 V 0.646940 | LR 1.32e-07 | Grad â†“ 0.008841 â†‘ 1.158088 M 0.231221 | 2s
Saved model state: checkpoints/checkpoint_epoch_25_20241024-002338.pth
â–ˆ Epoch  26: Loss T 0.694483 V 0.810998 | F1 T 0.676851 V 0.641794 B 0.647818 SC 2/20 | Acc T 0.706241 V 0.642146 | LR 1.82e-04 | Grad â†“ 0.010807 â†‘ 1.528598 M 0.306326 | 2s
â–ˆ Epoch  27: Loss T 0.686748 V 0.799366 | F1 T 0.684098 V 0.653398 B 0.653398 SC 0/20 | Acc T 0.708278 V 0.654499 | LR 1.33e-04 | Grad â†“ 0.007426 â†‘ 0.996118 M 0.207935 | 2s
â–ˆ Epoch  28: Loss T 0.683844 V 0.793728 | F1 T 0.685026 V 0.655366 B 0.655366 SC 0/20 | Acc T 0.710158 V 0.655420 | LR 7.16e-05 | Grad â†“ 0.010602 â†‘ 1.183288 M 0.239533 | 2s
â–ˆ Epoch  29: Loss T 0.680119 V 0.804677 | F1 T 0.683220 V 0.647329 B 0.655366 SC 1/20 | Acc T 0.710912 V 0.648599 | LR 2.07e-05 | Grad â†“ 0.006382 â†‘ 1.064202 M 0.217779 | 2s
â–ˆ Epoch  30: Loss T 0.677810 V 0.800824 | F1 T 0.684503 V 0.652598 B 0.655366 SC 2/20 | Acc T 0.711128 V 0.653024 | LR 1.32e-07 | Grad â†“ 0.008363 â†‘ 1.158796 M 0.213879 | 2s
Memory: Rank 0: 3.60 GB | Rank 1: 3.75 GB | Rank 2: 3.75 GB | Rank 3: 3.75 GB | Rank 4: 3.75 GB | Rank 5: 3.75 GB | Rank 6: 3.75 GB | Rank 7: 3.60 GB (Max: 42.29 GB, Total: 338.28 GB)
Saved model state: checkpoints/checkpoint_epoch_30_20241024-002350.pth
â–ˆ Epoch  31: Loss T 0.687844 V 0.786112 | F1 T 0.686900 V 0.659038 B 0.659038 SC 0/20 | Acc T 0.711647 V 0.658739 | LR 1.82e-04 | Grad â†“ 0.032733 â†‘ 3.859143 M 0.787843 | 2s
â–ˆ Epoch  32: Loss T 0.681417 V 0.774600 | F1 T 0.689252 V 0.668460 B 0.668460 SC 0/20 | Acc T 0.710697 V 0.668142 | LR 1.33e-04 | Grad â†“ 0.014827 â†‘ 1.795607 M 0.375148 | 2s
â–ˆ Epoch  33: Loss T 0.676554 V 0.801806 | F1 T 0.685129 V 0.646619 B 0.668460 SC 1/20 | Acc T 0.713204 V 0.647677 | LR 7.16e-05 | Grad â†“ 0.007534 â†‘ 0.921442 M 0.175436 | 2s
â–ˆ Epoch  34: Loss T 0.672301 V 0.798798 | F1 T 0.686989 V 0.652320 B 0.668460 SC 2/20 | Acc T 0.714007 V 0.652286 | LR 2.07e-05 | Grad â†“ 0.005185 â†‘ 0.590019 M 0.122203 | 2s
â–ˆ Epoch  35: Loss T 0.671090 V 0.794623 | F1 T 0.688461 V 0.654155 B 0.668460 SC 3/20 | Acc T 0.714517 V 0.654314 | LR 1.32e-07 | Grad â†“ 0.007162 â†‘ 1.082201 M 0.214964 | 2s
Saved model state: checkpoints/checkpoint_epoch_35_20241024-002401.pth
â–ˆ Epoch  36: Loss T 0.691108 V 0.787568 | F1 T 0.690573 V 0.660992 B 0.668460 SC 4/20 | Acc T 0.714311 V 0.660951 | LR 1.82e-04 | Grad â†“ 0.035695 â†‘ 5.360192 M 1.010179 | 2s
â–ˆ Epoch  37: Loss T 0.673188 V 0.779052 | F1 T 0.692649 V 0.666368 B 0.668460 SC 5/20 | Acc T 0.714360 V 0.666298 | LR 1.33e-04 | Grad â†“ 0.014710 â†‘ 1.963994 M 0.368448 | 2s
â–ˆ Epoch  38: Loss T 0.670217 V 0.779215 | F1 T 0.690731 V 0.663058 B 0.668460 SC 6/20 | Acc T 0.714487 V 0.662795 | LR 7.16e-05 | Grad â†“ 0.018584 â†‘ 2.565567 M 0.479244 | 2s
â–ˆ Epoch  39: Loss T 0.668283 V 0.787524 | F1 T 0.691250 V 0.657470 B 0.668460 SC 7/20 | Acc T 0.716123 V 0.657448 | LR 2.07e-05 | Grad â†“ 0.003895 â†‘ 0.516455 M 0.106730 | 2s
â–ˆ Epoch  40: Loss T 0.665303 V 0.786008 | F1 T 0.691556 V 0.658573 B 0.668460 SC 8/20 | Acc T 0.716172 V 0.658739 | LR 1.32e-07 | Grad â†“ 0.018356 â†‘ 2.522140 M 0.449966 | 2s
Memory: Rank 0: 3.60 GB | Rank 1: 3.75 GB | Rank 2: 3.75 GB | Rank 3: 3.75 GB | Rank 4: 3.75 GB | Rank 5: 3.75 GB | Rank 6: 3.75 GB | Rank 7: 3.60 GB (Max: 42.29 GB, Total: 338.28 GB)
Saved model state: checkpoints/checkpoint_epoch_40_20241024-002413.pth
â–ˆ Epoch  41: Loss T 0.673693 V 0.810364 | F1 T 0.683879 V 0.638805 B 0.668460 SC 9/20 | Acc T 0.714409 V 0.641962 | LR 1.82e-04 | Grad â†“ 0.008097 â†‘ 1.283823 M 0.243129 | 2s
â–ˆ Epoch  42: Loss T 0.668223 V 0.795013 | F1 T 0.689815 V 0.655395 B 0.668460 SC 10/20 | Acc T 0.716661 V 0.655420 | LR 1.33e-04 | Grad â†“ 0.020941 â†‘ 2.986049 M 0.535720 | 2s
â–ˆ Epoch  43: Loss T 0.666366 V 0.788335 | F1 T 0.689315 V 0.657366 B 0.668460 SC 11/20 | Acc T 0.715143 V 0.657080 | LR 7.16e-05 | Grad â†“ 0.009968 â†‘ 1.727611 M 0.309236 | 2s
â–ˆ Epoch  44: Loss T 0.663773 V 0.792752 | F1 T 0.690628 V 0.651369 B 0.668460 SC 12/20 | Acc T 0.717278 V 0.651549 | LR 2.07e-05 | Grad â†“ 0.009165 â†‘ 1.533979 M 0.285923 | 2s
â–ˆ Epoch  45: Loss T 0.661432 V 0.789526 | F1 T 0.692383 V 0.654353 B 0.668460 SC 13/20 | Acc T 0.718042 V 0.654683 | LR 1.32e-07 | Grad â†“ 0.004033 â†‘ 0.686206 M 0.128103 | 2s
Saved model state: checkpoints/checkpoint_epoch_45_20241024-002424.pth
â–ˆ Epoch  46: Loss T 0.674690 V 0.803414 | F1 T 0.686745 V 0.639628 B 0.668460 SC 14/20 | Acc T 0.716906 V 0.641040 | LR 1.82e-04 | Grad â†“ 0.019923 â†‘ 2.819160 M 0.504545 | 2s
â–ˆ Epoch  47: Loss T 0.665219 V 0.787371 | F1 T 0.694663 V 0.656856 B 0.668460 SC 15/20 | Acc T 0.719355 V 0.657633 | LR 1.33e-04 | Grad â†“ 0.016737 â†‘ 2.615291 M 0.468922 | 2s
â–ˆ Epoch  48: Loss T 0.661115 V 0.788335 | F1 T 0.691183 V 0.656942 B 0.668460 SC 16/20 | Acc T 0.716926 V 0.656711 | LR 7.16e-05 | Grad â†“ 0.015820 â†‘ 2.563883 M 0.470207 | 2s
â–ˆ Epoch  49: Loss T 0.660459 V 0.779643 | F1 T 0.695526 V 0.663931 B 0.668460 SC 17/20 | Acc T 0.718894 V 0.663717 | LR 2.07e-05 | Grad â†“ 0.006782 â†‘ 1.076312 M 0.201569 | 2s
â–ˆ Epoch  50: Loss T 0.657858 V 0.783437 | F1 T 0.695068 V 0.656526 B 0.668460 SC 18/20 | Acc T 0.719649 V 0.656711 | LR 1.32e-07 | Grad â†“ 0.001904 â†‘ 0.471922 M 0.101496 | 2s
Memory: Rank 0: 3.60 GB | Rank 1: 3.75 GB | Rank 2: 3.75 GB | Rank 3: 3.75 GB | Rank 4: 3.75 GB | Rank 5: 3.75 GB | Rank 6: 3.75 GB | Rank 7: 3.60 GB (Max: 42.29 GB, Total: 338.28 GB)
Saved model state: checkpoints/checkpoint_epoch_50_20241024-002436.pth
â–ˆ Epoch  51: Loss T 0.667147 V 0.762735 | F1 T 0.697822 V 0.671972 B 0.671972 SC 0/20 | Acc T 0.718287 V 0.671829 | LR 1.82e-04 | Grad â†“ 0.022736 â†‘ 3.474029 M 0.617808 | 2s
â–ˆ Epoch  52: Loss T 0.665201 V 0.804173 | F1 T 0.689997 V 0.646859 B 0.671972 SC 1/20 | Acc T 0.717954 V 0.646940 | LR 1.33e-04 | Grad â†“ 0.004064 â†‘ 0.535443 M 0.109908 | 2s
â–ˆ Epoch  53: Loss T 0.657948 V 0.793716 | F1 T 0.692869 V 0.651106 B 0.671972 SC 2/20 | Acc T 0.720158 V 0.651917 | LR 7.16e-05 | Grad â†“ 0.009148 â†‘ 1.049854 M 0.191451 | 2s
â–ˆ Epoch  54: Loss T 0.656066 V 0.794058 | F1 T 0.693598 V 0.653137 B 0.671972 SC 3/20 | Acc T 0.720285 V 0.653392 | LR 2.07e-05 | Grad â†“ 0.011169 â†‘ 1.679832 M 0.298575 | 2s
â–ˆ Epoch  55: Loss T 0.654500 V 0.786562 | F1 T 0.695578 V 0.655110 B 0.671972 SC 4/20 | Acc T 0.720951 V 0.655420 | LR 1.32e-07 | Grad â†“ 0.006151 â†‘ 1.087698 M 0.202082 | 2s
Saved model state: checkpoints/checkpoint_epoch_55_20241024-002447.pth
â–ˆ Epoch  56: Loss T 0.669094 V 0.836422 | F1 T 0.681487 V 0.625738 B 0.671972 SC 5/20 | Acc T 0.715672 V 0.629978 | LR 1.82e-04 | Grad â†“ 0.028921 â†‘ 4.452361 M 0.761893 | 2s
â–ˆ Epoch  57: Loss T 0.658120 V 0.778427 | F1 T 0.695648 V 0.660956 B 0.671972 SC 6/20 | Acc T 0.720344 V 0.660951 | LR 1.33e-04 | Grad â†“ 0.013535 â†‘ 1.977965 M 0.343249 | 2s
â–ˆ Epoch  58: Loss T 0.654831 V 0.785167 | F1 T 0.697259 V 0.657608 B 0.671972 SC 7/20 | Acc T 0.722068 V 0.658555 | LR 7.16e-05 | Grad â†“ 0.007527 â†‘ 0.944991 M 0.172002 | 2s
â–ˆ Epoch  59: Loss T 0.652472 V 0.779193 | F1 T 0.697606 V 0.662823 B 0.671972 SC 8/20 | Acc T 0.721754 V 0.662795 | LR 2.07e-05 | Grad â†“ 0.011327 â†‘ 1.137053 M 0.209441 | 2s
â–ˆ Epoch  60: Loss T 0.651406 V 0.782243 | F1 T 0.697580 V 0.658594 B 0.671972 SC 9/20 | Acc T 0.722126 V 0.658923 | LR 1.32e-07 | Grad â†“ 0.004910 â†‘ 0.555423 M 0.107352 | 2s
Memory: Rank 0: 3.60 GB | Rank 1: 3.75 GB | Rank 2: 3.75 GB | Rank 3: 3.75 GB | Rank 4: 3.75 GB | Rank 5: 3.75 GB | Rank 6: 3.75 GB | Rank 7: 3.60 GB (Max: 42.29 GB, Total: 338.28 GB)
Saved model state: checkpoints/checkpoint_epoch_60_20241024-002500.pth
â–ˆ Epoch  61: Loss T 0.658461 V 0.770050 | F1 T 0.696233 V 0.667536 B 0.671972 SC 10/20 | Acc T 0.720168 V 0.667220 | LR 1.82e-04 | Grad â†“ 0.029717 â†‘ 4.511450 M 0.773055 | 2s
â–ˆ Epoch  62: Loss T 0.655617 V 0.785882 | F1 T 0.695857 V 0.655135 B 0.671972 SC 11/20 | Acc T 0.722459 V 0.655420 | LR 1.33e-04 | Grad â†“ 0.030051 â†‘ 4.942551 M 0.869404 | 2s
â–ˆ Epoch  63: Loss T 0.651849 V 0.793613 | F1 T 0.695148 V 0.649838 B 0.671972 SC 12/20 | Acc T 0.722655 V 0.651180 | LR 7.16e-05 | Grad â†“ 0.006751 â†‘ 1.078586 M 0.188327 | 2s
â–ˆ Epoch  64: Loss T 0.649923 V 0.775500 | F1 T 0.699639 V 0.663219 B 0.671972 SC 13/20 | Acc T 0.723458 V 0.663348 | LR 2.07e-05 | Grad â†“ 0.007622 â†‘ 0.946392 M 0.169365 | 2s
â–ˆ Epoch  65: Loss T 0.648894 V 0.782711 | F1 T 0.699062 V 0.659876 B 0.671972 SC 14/20 | Acc T 0.723674 V 0.660398 | LR 1.32e-07 | Grad â†“ 0.005057 â†‘ 0.763642 M 0.139304 | 2s
Saved model state: checkpoints/checkpoint_epoch_65_20241024-002511.pth
â–ˆ Epoch  66: Loss T 0.654110 V 0.826404 | F1 T 0.680226 V 0.623836 B 0.671972 SC 15/20 | Acc T 0.716162 V 0.627028 | LR 1.82e-04 | Grad â†“ 0.042297 â†‘ 7.458454 M 1.306321 | 2s
â–ˆ Epoch  67: Loss T 0.657511 V 0.761568 | F1 T 0.701366 V 0.675169 B 0.675169 SC 0/20 | Acc T 0.721490 V 0.674963 | LR 1.33e-04 | Grad â†“ 0.020213 â†‘ 3.827403 M 0.658034 | 2s
â–ˆ Epoch  68: Loss T 0.650198 V 0.765097 | F1 T 0.702038 V 0.670260 B 0.675169 SC 1/20 | Acc T 0.723380 V 0.670170 | LR 7.16e-05 | Grad â†“ 0.020083 â†‘ 3.350713 M 0.580594 | 2s
â–ˆ Epoch  69: Loss T 0.647972 V 0.779967 | F1 T 0.700711 V 0.660250 B 0.675169 SC 2/20 | Acc T 0.724986 V 0.660767 | LR 2.07e-05 | Grad â†“ 0.008410 â†‘ 1.506488 M 0.263707 | 2s
â–ˆ Epoch  70: Loss T 0.645609 V 0.778672 | F1 T 0.700670 V 0.659670 B 0.675169 SC 3/20 | Acc T 0.725114 V 0.660214 | LR 1.32e-07 | Grad â†“ 0.007595 â†‘ 1.232864 M 0.214323 | 2s
Memory: Rank 0: 3.60 GB | Rank 1: 3.75 GB | Rank 2: 3.75 GB | Rank 3: 3.75 GB | Rank 4: 3.75 GB | Rank 5: 3.75 GB | Rank 6: 3.75 GB | Rank 7: 3.60 GB (Max: 42.29 GB, Total: 338.28 GB)
Saved model state: checkpoints/checkpoint_epoch_70_20241024-002523.pth
â–ˆ Epoch  71: Loss T 0.663674 V 0.808644 | F1 T 0.678737 V 0.636775 B 0.675169 SC 4/20 | Acc T 0.711285 V 0.636615 | LR 1.82e-04 | Grad â†“ 0.028646 â†‘ 4.619201 M 0.761781 | 2s
â–ˆ Epoch  72: Loss T 0.653794 V 0.771632 | F1 T 0.700679 V 0.666912 B 0.675169 SC 5/20 | Acc T 0.723860 V 0.666851 | LR 1.33e-04 | Grad â†“ 0.008407 â†‘ 1.433862 M 0.253601 | 2s
â–ˆ Epoch  73: Loss T 0.646552 V 0.765731 | F1 T 0.702627 V 0.667043 B 0.675169 SC 6/20 | Acc T 0.724712 V 0.667404 | LR 7.16e-05 | Grad â†“ 0.003336 â†‘ 0.421857 M 0.081268 | 2s
â–ˆ Epoch  74: Loss T 0.645602 V 0.777372 | F1 T 0.701656 V 0.663543 B 0.675169 SC 7/20 | Acc T 0.725505 V 0.663717 | LR 2.07e-05 | Grad â†“ 0.009866 â†‘ 1.514462 M 0.258767 | 2s
â–ˆ Epoch  75: Loss T 0.643447 V 0.778016 | F1 T 0.701272 V 0.660869 B 0.675169 SC 8/20 | Acc T 0.725740 V 0.661504 | LR 1.32e-07 | Grad â†“ 0.005751 â†‘ 0.901064 M 0.159531 | 3s
Saved model state: checkpoints/checkpoint_epoch_75_20241024-002536.pth
â–ˆ Epoch  76: Loss T 0.650410 V 0.795710 | F1 T 0.696692 V 0.646520 B 0.675169 SC 9/20 | Acc T 0.725016 V 0.648414 | LR 1.82e-04 | Grad â†“ 0.014326 â†‘ 2.626201 M 0.455791 | 2s
â–ˆ Epoch  77: Loss T 0.646580 V 0.774726 | F1 T 0.701024 V 0.658474 B 0.675169 SC 10/20 | Acc T 0.725740 V 0.659476 | LR 1.33e-04 | Grad â†“ 0.021296 â†‘ 3.690608 M 0.620133 | 2s
â–ˆ Epoch  78: Loss T 0.645480 V 0.771058 | F1 T 0.703628 V 0.669377 B 0.675169 SC 11/20 | Acc T 0.724653 V 0.669617 | LR 7.16e-05 | Grad â†“ 0.007306 â†‘ 1.179568 M 0.217878 | 2s
â–ˆ Epoch  79: Loss T 0.642551 V 0.778738 | F1 T 0.701606 V 0.662133 B 0.675169 SC 12/20 | Acc T 0.726093 V 0.662242 | LR 2.07e-05 | Grad â†“ 0.008769 â†‘ 1.399538 M 0.240254 | 2s
â–ˆ Epoch  80: Loss T 0.640785 V 0.774324 | F1 T 0.703161 V 0.662605 B 0.675169 SC 13/20 | Acc T 0.726867 V 0.662979 | LR 1.32e-07 | Grad â†“ 0.008048 â†‘ 1.348822 M 0.230826 | 2s
Memory: Rank 0: 3.60 GB | Rank 1: 3.75 GB | Rank 2: 3.75 GB | Rank 3: 3.75 GB | Rank 4: 3.75 GB | Rank 5: 3.75 GB | Rank 6: 3.75 GB | Rank 7: 3.60 GB (Max: 42.29 GB, Total: 338.28 GB)
Saved model state: checkpoints/checkpoint_epoch_80_20241024-002547.pth
â–ˆ Epoch  81: Loss T 0.651784 V 0.785780 | F1 T 0.700188 V 0.661074 B 0.675169 SC 14/20 | Acc T 0.726279 V 0.661873 | LR 1.82e-04 | Grad â†“ 0.016217 â†‘ 2.750531 M 0.466084 | 2s
â–ˆ Epoch  82: Loss T 0.645183 V 0.777057 | F1 T 0.699366 V 0.655766 B 0.675169 SC 15/20 | Acc T 0.723596 V 0.658186 | LR 1.33e-04 | Grad â†“ 0.006624 â†‘ 1.124791 M 0.192641 | 2s
â–ˆ Epoch  83: Loss T 0.644615 V 0.768438 | F1 T 0.704913 V 0.668259 B 0.675169 SC 16/20 | Acc T 0.726622 V 0.668510 | LR 7.16e-05 | Grad â†“ 0.014509 â†‘ 2.571031 M 0.429895 | 2s
â–ˆ Epoch  84: Loss T 0.640041 V 0.778561 | F1 T 0.702910 V 0.660662 B 0.675169 SC 17/20 | Acc T 0.727797 V 0.661320 | LR 2.07e-05 | Grad â†“ 0.014438 â†‘ 2.232518 M 0.373391 | 2s
â–ˆ Epoch  85: Loss T 0.637818 V 0.775862 | F1 T 0.703358 V 0.662562 B 0.675169 SC 18/20 | Acc T 0.727572 V 0.662979 | LR 1.32e-07 | Grad â†“ 0.001089 â†‘ 0.416574 M 0.085964 | 2s
Saved model state: checkpoints/checkpoint_epoch_85_20241024-002559.pth
â–ˆ Epoch  86: Loss T 0.647175 V 0.779264 | F1 T 0.697675 V 0.658278 B 0.675169 SC 19/20 | Acc T 0.724634 V 0.658001 | LR 1.82e-04 | Grad â†“ 0.058348 â†‘ 10.034244 M 1.661578 | 2s
â–ˆ Epoch  87: Loss T 0.647646 V 0.754546 | F1 T 0.705987 V 0.675236 B 0.675236 SC 0/20 | Acc T 0.725985 V 0.675701 | LR 1.33e-04 | Grad â†“ 0.013292 â†‘ 1.580659 M 0.266702 | 2s
â–ˆ Epoch  88: Loss T 0.640814 V 0.778453 | F1 T 0.703128 V 0.660672 B 0.675236 SC 1/20 | Acc T 0.728679 V 0.661320 | LR 7.16e-05 | Grad â†“ 0.019124 â†‘ 3.527148 M 0.591963 | 2s
â–ˆ Epoch  89: Loss T 0.636882 V 0.763346 | F1 T 0.706672 V 0.670108 B 0.675236 SC 2/20 | Acc T 0.728718 V 0.670354 | LR 2.07e-05 | Grad â†“ 0.005387 â†‘ 0.690806 M 0.124801 | 2s
â–ˆ Epoch  90: Loss T 0.635623 V 0.767041 | F1 T 0.705630 V 0.667588 B 0.675236 SC 3/20 | Acc T 0.728189 V 0.667773 | LR 1.32e-07 | Grad â†“ 0.007281 â†‘ 0.990895 M 0.168957 | 2s
Memory: Rank 0: 3.60 GB | Rank 1: 3.75 GB | Rank 2: 3.75 GB | Rank 3: 3.75 GB | Rank 4: 3.75 GB | Rank 5: 3.75 GB | Rank 6: 3.75 GB | Rank 7: 3.60 GB (Max: 42.29 GB, Total: 338.28 GB)
Saved model state: checkpoints/checkpoint_epoch_90_20241024-002612.pth
â–ˆ Epoch  91: Loss T 0.645571 V 0.788131 | F1 T 0.697246 V 0.657399 B 0.675236 SC 4/20 | Acc T 0.724771 V 0.657264 | LR 1.82e-04 | Grad â†“ 0.018546 â†‘ 2.996389 M 0.496683 | 2s
â–ˆ Epoch  92: Loss T 0.646042 V 0.759655 | F1 T 0.706242 V 0.671586 B 0.675236 SC 5/20 | Acc T 0.728248 V 0.671645 | LR 1.33e-04 | Grad â†“ 0.026952 â†‘ 4.552817 M 0.741305 | 2s
â–ˆ Epoch  93: Loss T 0.635940 V 0.766266 | F1 T 0.706688 V 0.667142 B 0.675236 SC 6/20 | Acc T 0.729619 V 0.667588 | LR 7.16e-05 | Grad â†“ 0.010493 â†‘ 1.484987 M 0.247259 | 2s
â–ˆ Epoch  94: Loss T 0.633895 V 0.781281 | F1 T 0.704347 V 0.661340 B 0.675236 SC 7/20 | Acc T 0.729697 V 0.661873 | LR 2.07e-05 | Grad â†“ 0.012404 â†‘ 1.892907 M 0.321422 | 2s
â–ˆ Epoch  95: Loss T 0.632679 V 0.768825 | F1 T 0.706131 V 0.666620 B 0.675236 SC 8/20 | Acc T 0.729903 V 0.667035 | LR 1.32e-07 | Grad â†“ 0.010843 â†‘ 1.744175 M 0.291454 | 2s
Saved model state: checkpoints/checkpoint_epoch_95_20241024-002624.pth
â–ˆ Epoch  96: Loss T 0.640451 V 0.766780 | F1 T 0.706100 V 0.668464 B 0.675236 SC 9/20 | Acc T 0.729697 V 0.668510 | LR 1.82e-04 | Grad â†“ 0.018596 â†‘ 2.332374 M 0.387877 | 2s
â–ˆ Epoch  97: Loss T 0.637688 V 0.770872 | F1 T 0.705379 V 0.667951 B 0.675236 SC 10/20 | Acc T 0.729952 V 0.668142 | LR 1.33e-04 | Grad â†“ 0.036535 â†‘ 5.221142 M 0.838187 | 2s
â–ˆ Epoch  98: Loss T 0.635231 V 0.771529 | F1 T 0.703304 V 0.674001 B 0.675236 SC 11/20 | Acc T 0.727376 V 0.673673 | LR 7.16e-05 | Grad â†“ 0.015813 â†‘ 2.882298 M 0.470005 | 2s
â–ˆ Epoch  99: Loss T 0.632921 V 0.759540 | F1 T 0.707225 V 0.671883 B 0.675236 SC 12/20 | Acc T 0.730011 V 0.671645 | LR 2.07e-05 | Grad â†“ 0.013700 â†‘ 1.783514 M 0.292154 | 2s
â–ˆ Epoch 100: Loss T 0.629726 V 0.766684 | F1 T 0.707582 V 0.669718 B 0.675236 SC 13/20 | Acc T 0.730961 V 0.669985 | LR 1.32e-07 | Grad â†“ 0.006305 â†‘ 0.889701 M 0.149647 | 2s
Memory: Rank 0: 3.60 GB | Rank 1: 3.75 GB | Rank 2: 3.75 GB | Rank 3: 3.75 GB | Rank 4: 3.75 GB | Rank 5: 3.75 GB | Rank 6: 3.75 GB | Rank 7: 3.60 GB (Max: 42.29 GB, Total: 338.28 GB)
Saved model state: checkpoints/checkpoint_epoch_100_20241024-002635.pth
Saving model in ONNX format...
Model saved in ONNX format to saves/model_20241024-002636.onnx and uploaded to Weights & Biases.
Saved model state: checkpoints/final_model_20241024-002636.pth
Saved model pickle: checkpoints/final_model_20241024-002636.pkl
Training completed (4m 12s)

Evaluating model...

run_1_merged_class Multi-Class Classification Report

              precision    recall  f1-score   support

    negative   0.722257  0.616702  0.665319      1868
     neutral   0.602753  0.760935  0.672669      1669
    positive   0.731239  0.667197  0.697752      1884

    accuracy                       0.678657      5421
   macro avg   0.685416  0.681611  0.678580      5421
weighted avg   0.688586  0.678657  0.678854      5421

ROC AUC: 0.858704

Predicted  negative  neutral  positive
Actual                                
negative       1152      451       265
neutral         202     1270       197
positive        241      386      1257

Saved predictions: saves/predictions_20241024-002636.csv

Macro F1 Score: 0.68

Evaluation completed (1s)
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:            eval/macro_f1_score â–
wandb:             gradients/max_norm â–â–â–â–‚â–â–ƒâ–‚â–â–ƒâ–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–â–‚â–â–‚â–…â–‚â–…â–†â–â–ˆâ–„â–‚â–ƒâ–‚â–ƒâ–‚â–ƒâ–ƒâ–„â–â–…â–‚â–„
wandb:            gradients/mean_norm â–â–â–â–‚â–…â–‚â–‚â–„â–†â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–ˆâ–ƒâ–‚â–„â–ƒâ–‚â–„â–‚â–â–ƒâ–‚â–‚â–‚â–‚â–ƒâ–„â–‚â–‚â–„â–…â–‚â–ƒâ–ƒâ–„
wandb:             gradients/min_norm â–â–‚â–â–ƒâ–â–†â–…â–‚â–„â–„â–ƒâ–ƒâ–‚â–‚â–‡â–„â–‚â–‚â–„â–‚â–‚â–‚â–‚â–‚â–ˆâ–‚â–†â–‚â–ƒâ–„â–‚â–ƒâ–ƒâ–„â–‚â–…â–ƒâ–„â–‡â–ƒ
wandb:                    other/epoch â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆ
wandb:            other/learning_rate â–ˆâ–†â–„â–‚â–†â–ˆâ–â–‚â–‚â–†â–‚â–â–„â–â–ˆâ–ˆâ–„â–‚â–†â–‚â–ˆâ–†â–ˆâ–„â–‚â–ˆâ–†â–„â–â–†â–â–†â–„â–â–†â–†â–„â–‚â–â–‚
wandb:               other/stop_limit â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 train/accuracy â–â–ƒâ–„â–…â–…â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                     train/loss â–ˆâ–†â–…â–…â–„â–„â–„â–ƒâ–ƒâ–„â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–
wandb:           train/macro_f1_score â–â–ƒâ–„â–„â–„â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:               train/stop_count â–â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–ƒâ–„â–…â–†â–†â–ˆâ–â–â–‚â–‚â–„â–†â–‡â–â–â–‚â–ƒâ–ƒâ–…â–…â–‡â–ˆâ–‚â–ƒâ–†
wandb:            validation/accuracy â–â–‚â–„â–„â–†â–‡â–†â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆ
wandb: validation/best_macro_f1_score â–â–‚â–‚â–‚â–‚â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                validation/loss â–ˆâ–‡â–†â–…â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–ƒâ–‚â–â–‚â–‚â–â–â–â–‚â–â–‚â–â–â–â–â–â–
wandb:      validation/macro_f1_score â–â–ƒâ–ƒâ–ƒâ–ƒâ–…â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb: 
wandb: Run summary:
wandb:            eval/macro_f1_score 0.67858
wandb:             gradients/max_norm 0.8897
wandb:            gradients/mean_norm 0.14965
wandb:             gradients/min_norm 0.00631
wandb:                    other/epoch 100
wandb:            other/learning_rate 0.0
wandb:               other/stop_limit 20
wandb:                 train/accuracy 0.73096
wandb:                     train/loss 0.62973
wandb:           train/macro_f1_score 0.70758
wandb:               train/stop_count 13
wandb:            validation/accuracy 0.66999
wandb: validation/best_macro_f1_score 0.67524
wandb:                validation/loss 0.76668
wandb:      validation/macro_f1_score 0.66972
wandb: 
wandb: ðŸš€ View run run_1_merged_class at: https://wandb.ai/jimbeno/Electra%20Large/runs/rzzqasnp
wandb: â­ï¸ View project at: https://wandb.ai/jimbeno/Electra%20Large
wandb: Synced 4 W&B file(s), 0 media file(s), 5 artifact file(s) and 2 other file(s)
wandb: Find logs at: ./wandb/run-20241024_002212-rzzqasnp/logs
TOTAL Time: 5m 29s
(nlp) ubuntu@138-2-58-218:~/nlp-osaka/sentiment$ python ./ddp_sentiment_finetune.py --dataset 'merged_local' --weights_name 'google/electra-large-discriminator' --save_data --save_model --save_pickle --save_preds --lr 0.0001 --lr_decay 0.95 --epochs 25 --pooling 'mean' --dropout_rate 0.3 --num_layers 2 --hidden_dim 1024 --hidden_activation 'swishglu' --batch_size 64 --finetune_bert --finetune_layers 6 --l2_strength 0.0001 --checkpoint_interval 5 --use_zero --optimizer 'adamw' --scheduler 'cosine_warmup' --scheduler_kwargs '{"T_0":5, "T_mult":1, "eta_min":1e-7}' --decimal 6 --use_val_split --eval_split 'test' --early_stop 'score' --n_iter_no_change 25 --show_progress --wandb --wandb_project 'Electra Large' --wandb_run 'run_2_merged_ft6' --model_file 'checkpoint_epoch_100_20241024-002635.pth'

Starting DDP PyTorch Training...
Device: cuda, Number of GPUs: 8
Spawning 8 processes...
Rank 3 - Device: cuda:3
Rank 2 - Device: cuda:2
Rank 1 - Device: cuda:1
Rank 6 - Device: cuda:6
Rank 7 - Device: cuda:7
Rank 5 - Device: cuda:5
Rank 4 - Device: cuda:4
Rank 0 - Device: cuda:0
8 process groups initialized with 'nccl' backend on localhost:12355
NCCL Timeout: 1 hr 0 min. NCCL Blocking Wait: Enabled
wandb: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: jbeno (jimbeno). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.5
wandb: Run data is saved locally in /home/ubuntu/nlp-osaka/sentiment/wandb/run-20241024_003211-0qeu00ne
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run run_2_merged_ft6
wandb: â­ï¸ View project at https://wandb.ai/jimbeno/Electra%20Large
wandb: ðŸš€ View run at https://wandb.ai/jimbeno/Electra%20Large/runs/0qeu00ne
Wand run initialized.

Initializing 'google/electra-large-discriminator' tokenizer and model...
Checking for local files...
Found all files in cache, skipping download
All ranks loading tokenizer from local files...
All ranks loading model from local files...
Tokenizer and model initialized (6s)

Loading data...
Using the same dataset for training and evaluation
Splits:
- Train: Using merged_local 'train' split
- Validation: Using merged_local 'validation' split
- Evaluation: Using merged_local 'test' split
Train Data: Merged DynaSent Round 1, Round 2 and SST from Local: 'data/merged'
Validation Data: Merged DynaSent Round 1, Round 2 and SST from Local: 'data/merged'
Evaluation Data: Merged DynaSent Round 1, Round 2 and SST from Local: 'data/merged'
Train size: 102097
Validation size: 5421
Evaluation size: 5421
Train label distribution:
	      Negative: 21910
	       Neutral: 49148
	      Positive: 31039
Validation label distribution:
	      Negative: 1868
	       Neutral: 1669
	      Positive: 1884
Evaluation label distribution:
	      Negative: 1868
	       Neutral: 1669
	      Positive: 1884
Data loaded (2s)

Processing data...
(Batch size: 64, Pooling: Mean, Fine Tune BERT: True, Chunk size: None)...
Extracting sentences and labels...

Data saved to: saves/data_8_gpu_20241024-003222.npz
X Train shape: [102097], X Validation shape: [5421], X Test shape: [5421]
y Train shape: [102097], y Validation shape: [5421], y Test shape: [5421]
Data processed (880ms)

Initializing DDP Neural Classifier...
Layers: 2, Hidden Dim: 1024, Hidden Act: SwishGLU, Dropout: 0.3, Optimizer: AdamW, L2 Strength: 0.0001, Pooling: MEAN, Accumulation Steps: 1, Max Grad Norm: None
Batch Size: 64, Max Epochs: 25, LR: 0.0001, Early Stop: score, Fine-tune BERT: True, Fine-tune Layers: 6, Freeze BERT: False, Target Score: None, Interactive: False
Loading model from: checkpoints/checkpoint_epoch_100_20241024-002635.pth...
Loaded checkpoint: checkpoints/checkpoint_epoch_100_20241024-002635.pth
Retrieved model state dictionary.
Retrieved optimizer state dictionary.
Classifier initialized (1s)

Fitting DDP Neural Classifier on training data...
Num Workers: 0, Prefetch: None
Score-based early stopping enabled (macro average F1 score against validation set). Validation fraction: 0.1
Training will stop early if the score does not improve by at least 0.00001 for 25 iterations.
Using provided validation set for early stopping.
Building dataset and dataloader...
Initializing model, graph, optimizer...
BERT's original pooler removed. Using custom pooling type: mean
BERT has 75,577,344 trainable parameters and 258,514,944 non-trainable parameters
Number of BERT layers requiring gradients: 6 out of 24
Fine-tuning the last 6 out of 24 BERT layers

Model Architecture Summary:
BERTClassifier(
  (bert): ElectraModel(
    (embeddings): ElectraEmbeddings(
      (word_embeddings): Embedding(30522, 1024, padding_idx=0)
      (position_embeddings): Embedding(512, 1024)
      (token_type_embeddings): Embedding(2, 1024)
      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): ElectraEncoder(
      (layer): ModuleList(
        (0-23): 24 x ElectraLayer(
          (attention): ElectraAttention(
            (self): ElectraSelfAttention(
              (query): Linear(in_features=1024, out_features=1024, bias=True)
              (key): Linear(in_features=1024, out_features=1024, bias=True)
              (value): Linear(in_features=1024, out_features=1024, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): ElectraSelfOutput(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): ElectraIntermediate(
            (dense): Linear(in_features=1024, out_features=4096, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): ElectraOutput(
            (dense): Linear(in_features=4096, out_features=1024, bias=True)
            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
  (custom_pooling): PoolingLayer()
  (classifier): Classifier(
    (layers): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): SwishGLU(
        (projection): Linear(in_features=1024, out_features=2048, bias=True)
        (activation): SiLU()
      )
      (2): Dropout(p=0.3, inplace=False)
      (3): Linear(in_features=1024, out_features=1024, bias=True)
      (4): SwishGLU(
        (projection): Linear(in_features=1024, out_features=2048, bias=True)
        (activation): SiLU()
      )
      (5): Dropout(p=0.3, inplace=False)
      (6): Linear(in_features=1024, out_features=3, bias=True)
    )
  )
)

Model Parameters:
  bert.embeddings.word_embeddings: 31,254,528 (frozen)
  bert.embeddings.position_embeddings: 524,288 (frozen)
  bert.embeddings.token_type_embeddings: 2,048 (frozen)
  bert.embeddings.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.0.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.0.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.0.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.0.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.0.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.0.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.0.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.0.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.1.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.1.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.1.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.1.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.1.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.1.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.1.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.1.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.2.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.2.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.2.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.2.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.2.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.2.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.2.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.2.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.3.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.3.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.3.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.3.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.3.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.3.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.3.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.3.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.4.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.4.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.4.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.4.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.4.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.4.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.4.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.4.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.5.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.5.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.5.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.5.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.5.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.5.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.5.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.5.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.6.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.6.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.6.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.6.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.6.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.6.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.6.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.6.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.7.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.7.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.7.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.7.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.7.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.7.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.7.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.7.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.8.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.8.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.8.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.8.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.8.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.8.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.8.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.8.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.9.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.9.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.9.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.9.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.9.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.9.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.9.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.9.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.10.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.10.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.10.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.10.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.10.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.10.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.10.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.10.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.11.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.11.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.11.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.11.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.11.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.11.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.11.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.11.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.12.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.12.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.12.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.12.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.12.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.12.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.12.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.12.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.13.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.13.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.13.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.13.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.13.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.13.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.13.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.13.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.14.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.14.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.14.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.14.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.14.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.14.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.14.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.14.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.15.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.15.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.15.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.15.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.15.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.15.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.15.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.15.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.16.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.16.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.16.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.16.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.16.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.16.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.16.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.16.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.17.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.17.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.17.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.17.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.17.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.17.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.17.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.17.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.18.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.18.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.18.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.18.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.18.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.18.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.18.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.18.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.19.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.19.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.19.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.19.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.19.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.19.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.19.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.19.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.20.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.20.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.20.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.20.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.20.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.20.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.20.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.20.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.21.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.21.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.21.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.21.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.21.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.21.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.21.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.21.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.22.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.22.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.22.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.22.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.22.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.22.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.22.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.22.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.23.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.23.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.23.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.23.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.23.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.23.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.23.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.23.output.LayerNorm: 2,048 (trainable)
  classifier.layers.0: 1,049,600 (trainable)
  classifier.layers.1.projection: 2,099,200 (trainable)
  classifier.layers.3: 1,049,600 (trainable)
  classifier.layers.6: 3,075 (trainable)

Total layers: 200
Trainable layers: 52
Total parameters: 338,293,763
Trainable parameters: 79,778,819
Percentage of trainable parameters: 23.58%
Using optimizer: AdamW, Use Zero: True, Base Learning Rate: 0.0001, L2 strength: 0.0001
Layer-wise decay factor: 0.95
Using scheduler: CosineAnnealingWarmRestarts
Scheduler arguments:
- T_0: 5
- T_mult: 1
- eta_min: 1e-07
An error occurred during training: Error(s) in loading state_dict for BERTClassifier:
	Missing key(s) in state_dict: "bert.embeddings.word_embeddings.weight", "bert.embeddings.position_embeddings.weight", "bert.embeddings.token_type_embeddings.weight", "bert.embeddings.LayerNorm.weight", "bert.embeddings.LayerNorm.bias", "bert.encoder.layer.0.attention.self.query.weight", "bert.encoder.layer.0.attention.self.query.bias", "bert.encoder.layer.0.attention.self.key.weight", "bert.encoder.layer.0.attention.self.key.bias", "bert.encoder.layer.0.attention.self.value.weight", "bert.encoder.layer.0.attention.self.value.bias", "bert.encoder.layer.0.attention.output.dense.weight", "bert.encoder.layer.0.attention.output.dense.bias", "bert.encoder.layer.0.attention.output.LayerNorm.weight", "bert.encoder.layer.0.attention.output.LayerNorm.bias", "bert.encoder.layer.0.intermediate.dense.weight", "bert.encoder.layer.0.intermediate.dense.bias", "bert.encoder.layer.0.output.dense.weight", "bert.encoder.layer.0.output.dense.bias", "bert.encoder.layer.0.output.LayerNorm.weight", "bert.encoder.layer.0.output.LayerNorm.bias", "bert.encoder.layer.1.attention.self.query.weight", "bert.encoder.layer.1.attention.self.query.bias", "bert.encoder.layer.1.attention.self.key.weight", "bert.encoder.layer.1.attention.self.key.bias", "bert.encoder.layer.1.attention.self.value.weight", "bert.encoder.layer.1.attention.self.value.bias", "bert.encoder.layer.1.attention.output.dense.weight", "bert.encoder.layer.1.attention.output.dense.bias", "bert.encoder.layer.1.attention.output.LayerNorm.weight", "bert.encoder.layer.1.attention.output.LayerNorm.bias", "bert.encoder.layer.1.intermediate.dense.weight", "bert.encoder.layer.1.intermediate.dense.bias", "bert.encoder.layer.1.output.dense.weight", "bert.encoder.layer.1.output.dense.bias", "bert.encoder.layer.1.output.LayerNorm.weight", "bert.encoder.layer.1.output.LayerNorm.bias", "bert.encoder.layer.2.attention.self.query.weight", "bert.encoder.layer.2.attention.self.query.bias", "bert.encoder.layer.2.attention.self.key.weight", "bert.encoder.layer.2.attention.self.key.bias", "bert.encoder.layer.2.attention.self.value.weight", "bert.encoder.layer.2.attention.self.value.bias", "bert.encoder.layer.2.attention.output.dense.weight", "bert.encoder.layer.2.attention.output.dense.bias", "bert.encoder.layer.2.attention.output.LayerNorm.weight", "bert.encoder.layer.2.attention.output.LayerNorm.bias", "bert.encoder.layer.2.intermediate.dense.weight", "bert.encoder.layer.2.intermediate.dense.bias", "bert.encoder.layer.2.output.dense.weight", "bert.encoder.layer.2.output.dense.bias", "bert.encoder.layer.2.output.LayerNorm.weight", "bert.encoder.layer.2.output.LayerNorm.bias", "bert.encoder.layer.3.attention.self.query.weight", "bert.encoder.layer.3.attention.self.query.bias", "bert.encoder.layer.3.attention.self.key.weight", "bert.encoder.layer.3.attention.self.key.bias", "bert.encoder.layer.3.attention.self.value.weight", "bert.encoder.layer.3.attention.self.value.bias", "bert.encoder.layer.3.attention.output.dense.weight", "bert.encoder.layer.3.attention.output.dense.bias", "bert.encoder.layer.3.attention.output.LayerNorm.weight", "bert.encoder.layer.3.attention.output.LayerNorm.bias", "bert.encoder.layer.3.intermediate.dense.weight", "bert.encoder.layer.3.intermediate.dense.bias", "bert.encoder.layer.3.output.dense.weight", "bert.encoder.layer.3.output.dense.bias", "bert.encoder.layer.3.output.LayerNorm.weight", "bert.encoder.layer.3.output.LayerNorm.bias", "bert.encoder.layer.4.attention.self.query.weight", "bert.encoder.layer.4.attention.self.query.bias", "bert.encoder.layer.4.attention.self.key.weight", "bert.encoder.layer.4.attention.self.key.bias", "bert.encoder.layer.4.attention.self.value.weight", "bert.encoder.layer.4.attention.self.value.bias", "bert.encoder.layer.4.attention.output.dense.weight", "bert.encoder.layer.4.attention.output.dense.bias", "bert.encoder.layer.4.attention.output.LayerNorm.weight", "bert.encoder.layer.4.attention.output.LayerNorm.bias", "bert.encoder.layer.4.intermediate.dense.weight", "bert.encoder.layer.4.intermediate.dense.bias", "bert.encoder.layer.4.output.dense.weight", "bert.encoder.layer.4.output.dense.bias", "bert.encoder.layer.4.output.LayerNorm.weight", "bert.encoder.layer.4.output.LayerNorm.bias", "bert.encoder.layer.5.attention.self.query.weight", "bert.encoder.layer.5.attention.self.query.bias", "bert.encoder.layer.5.attention.self.key.weight", "bert.encoder.layer.5.attention.self.key.bias", "bert.encoder.layer.5.attention.self.value.weight", "bert.encoder.layer.5.attention.self.value.bias", "bert.encoder.layer.5.attention.output.dense.weight", "bert.encoder.layer.5.attention.output.dense.bias", "bert.encoder.layer.5.attention.output.LayerNorm.weight", "bert.encoder.layer.5.attention.output.LayerNorm.bias", "bert.encoder.layer.5.intermediate.dense.weight", "bert.encoder.layer.5.intermediate.dense.bias", "bert.encoder.layer.5.output.dense.weight", "bert.encoder.layer.5.output.dense.bias", "bert.encoder.layer.5.output.LayerNorm.weight", "bert.encoder.layer.5.output.LayerNorm.bias", "bert.encoder.layer.6.attention.self.query.weight", "bert.encoder.layer.6.attention.self.query.bias", "bert.encoder.layer.6.attention.self.key.weight", "bert.encoder.layer.6.attention.self.key.bias", "bert.encoder.layer.6.attention.self.value.weight", "bert.encoder.layer.6.attention.self.value.bias", "bert.encoder.layer.6.attention.output.dense.weight", "bert.encoder.layer.6.attention.output.dense.bias", "bert.encoder.layer.6.attention.output.LayerNorm.weight", "bert.encoder.layer.6.attention.output.LayerNorm.bias", "bert.encoder.layer.6.intermediate.dense.weight", "bert.encoder.layer.6.intermediate.dense.bias", "bert.encoder.layer.6.output.dense.weight", "bert.encoder.layer.6.output.dense.bias", "bert.encoder.layer.6.output.LayerNorm.weight", "bert.encoder.layer.6.output.LayerNorm.bias", "bert.encoder.layer.7.attention.self.query.weight", "bert.encoder.layer.7.attention.self.query.bias", "bert.encoder.layer.7.attention.self.key.weight", "bert.encoder.layer.7.attention.self.key.bias", "bert.encoder.layer.7.attention.self.value.weight", "bert.encoder.layer.7.attention.self.value.bias", "bert.encoder.layer.7.attention.output.dense.weight", "bert.encoder.layer.7.attention.output.dense.bias", "bert.encoder.layer.7.attention.output.LayerNorm.weight", "bert.encoder.layer.7.attention.output.LayerNorm.bias", "bert.encoder.layer.7.intermediate.dense.weight", "bert.encoder.layer.7.intermediate.dense.bias", "bert.encoder.layer.7.output.dense.weight", "bert.encoder.layer.7.output.dense.bias", "bert.encoder.layer.7.output.LayerNorm.weight", "bert.encoder.layer.7.output.LayerNorm.bias", "bert.encoder.layer.8.attention.self.query.weight", "bert.encoder.layer.8.attention.self.query.bias", "bert.encoder.layer.8.attention.self.key.weight", "bert.encoder.layer.8.attention.self.key.bias", "bert.encoder.layer.8.attention.self.value.weight", "bert.encoder.layer.8.attention.self.value.bias", "bert.encoder.layer.8.attention.output.dense.weight", "bert.encoder.layer.8.attention.output.dense.bias", "bert.encoder.layer.8.attention.output.LayerNorm.weight", "bert.encoder.layer.8.attention.output.LayerNorm.bias", "bert.encoder.layer.8.intermediate.dense.weight", "bert.encoder.layer.8.intermediate.dense.bias", "bert.encoder.layer.8.output.dense.weight", "bert.encoder.layer.8.output.dense.bias", "bert.encoder.layer.8.output.LayerNorm.weight", "bert.encoder.layer.8.output.LayerNorm.bias", "bert.encoder.layer.9.attention.self.query.weight", "bert.encoder.layer.9.attention.self.query.bias", "bert.encoder.layer.9.attention.self.key.weight", "bert.encoder.layer.9.attention.self.key.bias", "bert.encoder.layer.9.attention.self.value.weight", "bert.encoder.layer.9.attention.self.value.bias", "bert.encoder.layer.9.attention.output.dense.weight", "bert.encoder.layer.9.attention.output.dense.bias", "bert.encoder.layer.9.attention.output.LayerNorm.weight", "bert.encoder.layer.9.attention.output.LayerNorm.bias", "bert.encoder.layer.9.intermediate.dense.weight", "bert.encoder.layer.9.intermediate.dense.bias", "bert.encoder.layer.9.output.dense.weight", "bert.encoder.layer.9.output.dense.bias", "bert.encoder.layer.9.output.LayerNorm.weight", "bert.encoder.layer.9.output.LayerNorm.bias", "bert.encoder.layer.10.attention.self.query.weight", "bert.encoder.layer.10.attention.self.query.bias", "bert.encoder.layer.10.attention.self.key.weight", "bert.encoder.layer.10.attention.self.key.bias", "bert.encoder.layer.10.attention.self.value.weight", "bert.encoder.layer.10.attention.self.value.bias", "bert.encoder.layer.10.attention.output.dense.weight", "bert.encoder.layer.10.attention.output.dense.bias", "bert.encoder.layer.10.attention.output.LayerNorm.weight", "bert.encoder.layer.10.attention.output.LayerNorm.bias", "bert.encoder.layer.10.intermediate.dense.weight", "bert.encoder.layer.10.intermediate.dense.bias", "bert.encoder.layer.10.output.dense.weight", "bert.encoder.layer.10.output.dense.bias", "bert.encoder.layer.10.output.LayerNorm.weight", "bert.encoder.layer.10.output.LayerNorm.bias", "bert.encoder.layer.11.attention.self.query.weight", "bert.encoder.layer.11.attention.self.query.bias", "bert.encoder.layer.11.attention.self.key.weight", "bert.encoder.layer.11.attention.self.key.bias", "bert.encoder.layer.11.attention.self.value.weight", "bert.encoder.layer.11.attention.self.value.bias", "bert.encoder.layer.11.attention.output.dense.weight", "bert.encoder.layer.11.attention.output.dense.bias", "bert.encoder.layer.11.attention.output.LayerNorm.weight", "bert.encoder.layer.11.attention.output.LayerNorm.bias", "bert.encoder.layer.11.intermediate.dense.weight", "bert.encoder.layer.11.intermediate.dense.bias", "bert.encoder.layer.11.output.dense.weight", "bert.encoder.layer.11.output.dense.bias", "bert.encoder.layer.11.output.LayerNorm.weight", "bert.encoder.layer.11.output.LayerNorm.bias", "bert.encoder.layer.12.attention.self.query.weight", "bert.encoder.layer.12.attention.self.query.bias", "bert.encoder.layer.12.attention.self.key.weight", "bert.encoder.layer.12.attention.self.key.bias", "bert.encoder.layer.12.attention.self.value.weight", "bert.encoder.layer.12.attention.self.value.bias", "bert.encoder.layer.12.attention.output.dense.weight", "bert.encoder.layer.12.attention.output.dense.bias", "bert.encoder.layer.12.attention.output.LayerNorm.weight", "bert.encoder.layer.12.attention.output.LayerNorm.bias", "bert.encoder.layer.12.intermediate.dense.weight", "bert.encoder.layer.12.intermediate.dense.bias", "bert.encoder.layer.12.output.dense.weight", "bert.encoder.layer.12.output.dense.bias", "bert.encoder.layer.12.output.LayerNorm.weight", "bert.encoder.layer.12.output.LayerNorm.bias", "bert.encoder.layer.13.attention.self.query.weight", "bert.encoder.layer.13.attention.self.query.bias", "bert.encoder.layer.13.attention.self.key.weight", "bert.encoder.layer.13.attention.self.key.bias", "bert.encoder.layer.13.attention.self.value.weight", "bert.encoder.layer.13.attention.self.value.bias", "bert.encoder.layer.13.attention.output.dense.weight", "bert.encoder.layer.13.attention.output.dense.bias", "bert.encoder.layer.13.attention.output.LayerNorm.weight", "bert.encoder.layer.13.attention.output.LayerNorm.bias", "bert.encoder.layer.13.intermediate.dense.weight", "bert.encoder.layer.13.intermediate.dense.bias", "bert.encoder.layer.13.output.dense.weight", "bert.encoder.layer.13.output.dense.bias", "bert.encoder.layer.13.output.LayerNorm.weight", "bert.encoder.layer.13.output.LayerNorm.bias", "bert.encoder.layer.14.attention.self.query.weight", "bert.encoder.layer.14.attention.self.query.bias", "bert.encoder.layer.14.attention.self.key.weight", "bert.encoder.layer.14.attention.self.key.bias", "bert.encoder.layer.14.attention.self.value.weight", "bert.encoder.layer.14.attention.self.value.bias", "bert.encoder.layer.14.attention.output.dense.weight", "bert.encoder.layer.14.attention.output.dense.bias", "bert.encoder.layer.14.attention.output.LayerNorm.weight", "bert.encoder.layer.14.attention.output.LayerNorm.bias", "bert.encoder.layer.14.intermediate.dense.weight", "bert.encoder.layer.14.intermediate.dense.bias", "bert.encoder.layer.14.output.dense.weight", "bert.encoder.layer.14.output.dense.bias", "bert.encoder.layer.14.output.LayerNorm.weight", "bert.encoder.layer.14.output.LayerNorm.bias", "bert.encoder.layer.15.attention.self.query.weight", "bert.encoder.layer.15.attention.self.query.bias", "bert.encoder.layer.15.attention.self.key.weight", "bert.encoder.layer.15.attention.self.key.bias", "bert.encoder.layer.15.attention.self.value.weight", "bert.encoder.layer.15.attention.self.value.bias", "bert.encoder.layer.15.attention.output.dense.weight", "bert.encoder.layer.15.attention.output.dense.bias", "bert.encoder.layer.15.attention.output.LayerNorm.weight", "bert.encoder.layer.15.attention.output.LayerNorm.bias", "bert.encoder.layer.15.intermediate.dense.weight", "bert.encoder.layer.15.intermediate.dense.bias", "bert.encoder.layer.15.output.dense.weight", "bert.encoder.layer.15.output.dense.bias", "bert.encoder.layer.15.output.LayerNorm.weight", "bert.encoder.layer.15.output.LayerNorm.bias", "bert.encoder.layer.16.attention.self.query.weight", "bert.encoder.layer.16.attention.self.query.bias", "bert.encoder.layer.16.attention.self.key.weight", "bert.encoder.layer.16.attention.self.key.bias", "bert.encoder.layer.16.attention.self.value.weight", "bert.encoder.layer.16.attention.self.value.bias", "bert.encoder.layer.16.attention.output.dense.weight", "bert.encoder.layer.16.attention.output.dense.bias", "bert.encoder.layer.16.attention.output.LayerNorm.weight", "bert.encoder.layer.16.attention.output.LayerNorm.bias", "bert.encoder.layer.16.intermediate.dense.weight", "bert.encoder.layer.16.intermediate.dense.bias", "bert.encoder.layer.16.output.dense.weight", "bert.encoder.layer.16.output.dense.bias", "bert.encoder.layer.16.output.LayerNorm.weight", "bert.encoder.layer.16.output.LayerNorm.bias", "bert.encoder.layer.17.attention.self.query.weight", "bert.encoder.layer.17.attention.self.query.bias", "bert.encoder.layer.17.attention.self.key.weight", "bert.encoder.layer.17.attention.self.key.bias", "bert.encoder.layer.17.attention.self.value.weight", "bert.encoder.layer.17.attention.self.value.bias", "bert.encoder.layer.17.attention.output.dense.weight", "bert.encoder.layer.17.attention.output.dense.bias", "bert.encoder.layer.17.attention.output.LayerNorm.weight", "bert.encoder.layer.17.attention.output.LayerNorm.bias", "bert.encoder.layer.17.intermediate.dense.weight", "bert.encoder.layer.17.intermediate.dense.bias", "bert.encoder.layer.17.output.dense.weight", "bert.encoder.layer.17.output.dense.bias", "bert.encoder.layer.17.output.LayerNorm.weight", "bert.encoder.layer.17.output.LayerNorm.bias", "bert.encoder.layer.18.attention.self.query.weight", "bert.encoder.layer.18.attention.self.query.bias", "bert.encoder.layer.18.attention.self.key.weight", "bert.encoder.layer.18.attention.self.key.bias", "bert.encoder.layer.18.attention.self.value.weight", "bert.encoder.layer.18.attention.self.value.bias", "bert.encoder.layer.18.attention.output.dense.weight", "bert.encoder.layer.18.attention.output.dense.bias", "bert.encoder.layer.18.attention.output.LayerNorm.weight", "bert.encoder.layer.18.attention.output.LayerNorm.bias", "bert.encoder.layer.18.intermediate.dense.weight", "bert.encoder.layer.18.intermediate.dense.bias", "bert.encoder.layer.18.output.dense.weight", "bert.encoder.layer.18.output.dense.bias", "bert.encoder.layer.18.output.LayerNorm.weight", "bert.encoder.layer.18.output.LayerNorm.bias", "bert.encoder.layer.19.attention.self.query.weight", "bert.encoder.layer.19.attention.self.query.bias", "bert.encoder.layer.19.attention.self.key.weight", "bert.encoder.layer.19.attention.self.key.bias", "bert.encoder.layer.19.attention.self.value.weight", "bert.encoder.layer.19.attention.self.value.bias", "bert.encoder.layer.19.attention.output.dense.weight", "bert.encoder.layer.19.attention.output.dense.bias", "bert.encoder.layer.19.attention.output.LayerNorm.weight", "bert.encoder.layer.19.attention.output.LayerNorm.bias", "bert.encoder.layer.19.intermediate.dense.weight", "bert.encoder.layer.19.intermediate.dense.bias", "bert.encoder.layer.19.output.dense.weight", "bert.encoder.layer.19.output.dense.bias", "bert.encoder.layer.19.output.LayerNorm.weight", "bert.encoder.layer.19.output.LayerNorm.bias", "bert.encoder.layer.20.attention.self.query.weight", "bert.encoder.layer.20.attention.self.query.bias", "bert.encoder.layer.20.attention.self.key.weight", "bert.encoder.layer.20.attention.self.key.bias", "bert.encoder.layer.20.attention.self.value.weight", "bert.encoder.layer.20.attention.self.value.bias", "bert.encoder.layer.20.attention.output.dense.weight", "bert.encoder.layer.20.attention.output.dense.bias", "bert.encoder.layer.20.attention.output.LayerNorm.weight", "bert.encoder.layer.20.attention.output.LayerNorm.bias", "bert.encoder.layer.20.intermediate.dense.weight", "bert.encoder.layer.20.intermediate.dense.bias", "bert.encoder.layer.20.output.dense.weight", "bert.encoder.layer.20.output.dense.bias", "bert.encoder.layer.20.output.LayerNorm.weight", "bert.encoder.layer.20.output.LayerNorm.bias", "bert.encoder.layer.21.attention.self.query.weight", "bert.encoder.layer.21.attention.self.query.bias", "bert.encoder.layer.21.attention.self.key.weight", "bert.encoder.layer.21.attention.self.key.bias", "bert.encoder.layer.21.attention.self.value.weight", "bert.encoder.layer.21.attention.self.value.bias", "bert.encoder.layer.21.attention.output.dense.weight", "bert.encoder.layer.21.attention.output.dense.bias", "bert.encoder.layer.21.attention.output.LayerNorm.weight", "bert.encoder.layer.21.attention.output.LayerNorm.bias", "bert.encoder.layer.21.intermediate.dense.weight", "bert.encoder.layer.21.intermediate.dense.bias", "bert.encoder.layer.21.output.dense.weight", "bert.encoder.layer.21.output.dense.bias", "bert.encoder.layer.21.output.LayerNorm.weight", "bert.encoder.layer.21.output.LayerNorm.bias", "bert.encoder.layer.22.attention.self.query.weight", "bert.encoder.layer.22.attention.self.query.bias", "bert.encoder.layer.22.attention.self.key.weight", "bert.encoder.layer.22.attention.self.key.bias", "bert.encoder.layer.22.attention.self.value.weight", "bert.encoder.layer.22.attention.self.value.bias", "bert.encoder.layer.22.attention.output.dense.weight", "bert.encoder.layer.22.attention.output.dense.bias", "bert.encoder.layer.22.attention.output.LayerNorm.weight", "bert.encoder.layer.22.attention.output.LayerNorm.bias", "bert.encoder.layer.22.intermediate.dense.weight", "bert.encoder.layer.22.intermediate.dense.bias", "bert.encoder.layer.22.output.dense.weight", "bert.encoder.layer.22.output.dense.bias", "bert.encoder.layer.22.output.LayerNorm.weight", "bert.encoder.layer.22.output.LayerNorm.bias", "bert.encoder.layer.23.attention.self.query.weight", "bert.encoder.layer.23.attention.self.query.bias", "bert.encoder.layer.23.attention.self.key.weight", "bert.encoder.layer.23.attention.self.key.bias", "bert.encoder.layer.23.attention.self.value.weight", "bert.encoder.layer.23.attention.self.value.bias", "bert.encoder.layer.23.attention.output.dense.weight", "bert.encoder.layer.23.attention.output.dense.bias", "bert.encoder.layer.23.attention.output.LayerNorm.weight", "bert.encoder.layer.23.attention.output.LayerNorm.bias", "bert.encoder.layer.23.intermediate.dense.weight", "bert.encoder.layer.23.intermediate.dense.bias", "bert.encoder.layer.23.output.dense.weight", "bert.encoder.layer.23.output.dense.bias", "bert.encoder.layer.23.output.LayerNorm.weight", "bert.encoder.layer.23.output.LayerNorm.bias", "classifier.layers.0.weight", "classifier.layers.0.bias", "classifier.layers.1.projection.weight", "classifier.layers.1.projection.bias", "classifier.layers.3.weight", "classifier.layers.3.bias", "classifier.layers.4.projection.weight", "classifier.layers.4.projection.bias", "classifier.layers.6.weight", "classifier.layers.6.bias". 
	Unexpected key(s) in state_dict: "layers.0.weight", "layers.0.bias", "layers.1.projection.weight", "layers.1.projection.bias", "layers.3.weight", "layers.3.bias", "layers.4.projection.weight", "layers.4.projection.bias", "layers.6.weight", "layers.6.bias". 
An error occurred during training: Error(s) in loading state_dict for BERTClassifier:
	Missing key(s) in state_dict: "bert.embeddings.word_embeddings.weight", "bert.embeddings.position_embeddings.weight", "bert.embeddings.token_type_embeddings.weight", "bert.embeddings.LayerNorm.weight", "bert.embeddings.LayerNorm.bias", "bert.encoder.layer.0.attention.self.query.weight", "bert.encoder.layer.0.attention.self.query.bias", "bert.encoder.layer.0.attention.self.key.weight", "bert.encoder.layer.0.attention.self.key.bias", "bert.encoder.layer.0.attention.self.value.weight", "bert.encoder.layer.0.attention.self.value.bias", "bert.encoder.layer.0.attention.output.dense.weight", "bert.encoder.layer.0.attention.output.dense.bias", "bert.encoder.layer.0.attention.output.LayerNorm.weight", "bert.encoder.layer.0.attention.output.LayerNorm.bias", "bert.encoder.layer.0.intermediate.dense.weight", "bert.encoder.layer.0.intermediate.dense.bias", "bert.encoder.layer.0.output.dense.weight", "bert.encoder.layer.0.output.dense.bias", "bert.encoder.layer.0.output.LayerNorm.weight", "bert.encoder.layer.0.output.LayerNorm.bias", "bert.encoder.layer.1.attention.self.query.weight", "bert.encoder.layer.1.attention.self.query.bias", "bert.encoder.layer.1.attention.self.key.weight", "bert.encoder.layer.1.attention.self.key.bias", "bert.encoder.layer.1.attention.self.value.weight", "bert.encoder.layer.1.attention.self.value.bias", "bert.encoder.layer.1.attention.output.dense.weight", "bert.encoder.layer.1.attention.output.dense.bias", "bert.encoder.layer.1.attention.output.LayerNorm.weight", "bert.encoder.layer.1.attention.output.LayerNorm.bias", "bert.encoder.layer.1.intermediate.dense.weight", "bert.encoder.layer.1.intermediate.dense.bias", "bert.encoder.layer.1.output.dense.weight", "bert.encoder.layer.1.output.dense.bias", "bert.encoder.layer.1.output.LayerNorm.weight", "bert.encoder.layer.1.output.LayerNorm.bias", "bert.encoder.layer.2.attention.self.query.weight", "bert.encoder.layer.2.attention.self.query.bias", "bert.encoder.layer.2.attention.self.key.weight", "bert.encoder.layer.2.attention.self.key.bias", "bert.encoder.layer.2.attention.self.value.weight", "bert.encoder.layer.2.attention.self.value.bias", "bert.encoder.layer.2.attention.output.dense.weight", "bert.encoder.layer.2.attention.output.dense.bias", "bert.encoder.layer.2.attention.output.LayerNorm.weight", "bert.encoder.layer.2.attention.output.LayerNorm.bias", "bert.encoder.layer.2.intermediate.dense.weight", "bert.encoder.layer.2.intermediate.dense.bias", "bert.encoder.layer.2.output.dense.weight", "bert.encoder.layer.2.output.dense.bias", "bert.encoder.layer.2.output.LayerNorm.weight", "bert.encoder.layer.2.output.LayerNorm.bias", "bert.encoder.layer.3.attention.self.query.weight", "bert.encoder.layer.3.attention.self.query.bias", "bert.encoder.layer.3.attention.self.key.weight", "bert.encoder.layer.3.attention.self.key.bias", "bert.encoder.layer.3.attention.self.value.weight", "bert.encoder.layer.3.attention.self.value.bias", "bert.encoder.layer.3.attention.output.dense.weight", "bert.encoder.layer.3.attention.output.dense.bias", "bert.encoder.layer.3.attention.output.LayerNorm.weight", "bert.encoder.layer.3.attention.output.LayerNorm.bias", "bert.encoder.layer.3.intermediate.dense.weight", "bert.encoder.layer.3.intermediate.dense.bias", "bert.encoder.layer.3.output.dense.weight", "bert.encoder.layer.3.output.dense.bias", "bert.encoder.layer.3.output.LayerNorm.weight", "bert.encoder.layer.3.output.LayerNorm.bias", "bert.encoder.layer.4.attention.self.query.weight", "bert.encoder.layer.4.attention.self.query.bias", "bert.encoder.layer.4.attention.self.key.weight", "bert.encoder.layer.4.attention.self.key.bias", "bert.encoder.layer.4.attention.self.value.weight", "bert.encoder.layer.4.attention.self.value.bias", "bert.encoder.layer.4.attention.output.dense.weight", "bert.encoder.layer.4.attention.output.dense.bias", "bert.encoder.layer.4.attention.output.LayerNorm.weight", "bert.encoder.layer.4.attention.output.LayerNorm.bias", "bert.encoder.layer.4.intermediate.dense.weight", "bert.encoder.layer.4.intermediate.dense.bias", "bert.encoder.layer.4.output.dense.weight", "bert.encoder.layer.4.output.dense.bias", "bert.encoder.layer.4.output.LayerNorm.weight", "bert.encoder.layer.4.output.LayerNorm.bias", "bert.encoder.layer.5.attention.self.query.weight", "bert.encoder.layer.5.attention.self.query.bias", "bert.encoder.layer.5.attention.self.key.weight", "bert.encoder.layer.5.attention.self.key.bias", "bert.encoder.layer.5.attention.self.value.weight", "bert.encoder.layer.5.attention.self.value.bias", "bert.encoder.layer.5.attention.output.dense.weight", "bert.encoder.layer.5.attention.output.dense.bias", "bert.encoder.layer.5.attention.output.LayerNorm.weight", "bert.encoder.layer.5.attention.output.LayerNorm.bias", "bert.encoder.layer.5.intermediate.dense.weight", "bert.encoder.layer.5.intermediate.dense.bias", "bert.encoder.layer.5.output.dense.weight", "bert.encoder.layer.5.output.dense.bias", "bert.encoder.layer.5.output.LayerNorm.weight", "bert.encoder.layer.5.output.LayerNorm.bias", "bert.encoder.layer.6.attention.self.query.weight", "bert.encoder.layer.6.attention.self.query.bias", "bert.encoder.layer.6.attention.self.key.weight", "bert.encoder.layer.6.attention.self.key.bias", "bert.encoder.layer.6.attention.self.value.weight", "bert.encoder.layer.6.attention.self.value.bias", "bert.encoder.layer.6.attention.output.dense.weight", "bert.encoder.layer.6.attention.output.dense.bias", "bert.encoder.layer.6.attention.output.LayerNorm.weight", "bert.encoder.layer.6.attention.output.LayerNorm.bias", "bert.encoder.layer.6.intermediate.dense.weight", "bert.encoder.layer.6.intermediate.dense.bias", "bert.encoder.layer.6.output.dense.weight", "bert.encoder.layer.6.output.dense.bias", "bert.encoder.layer.6.output.LayerNorm.weight", "bert.encoder.layer.6.output.LayerNorm.bias", "bert.encoder.layer.7.attention.self.query.weight", "bert.encoder.layer.7.attention.self.query.bias", "bert.encoder.layer.7.attention.self.key.weight", "bert.encoder.layer.7.attention.self.key.bias", "bert.encoder.layer.7.attention.self.value.weight", "bert.encoder.layer.7.attention.self.value.bias", "bert.encoder.layer.7.attention.output.dense.weight", "bert.encoder.layer.7.attention.output.dense.bias", "bert.encoder.layer.7.attention.output.LayerNorm.weight", "bert.encoder.layer.7.attention.output.LayerNorm.bias", "bert.encoder.layer.7.intermediate.dense.weight", "bert.encoder.layer.7.intermediate.dense.bias", "bert.encoder.layer.7.output.dense.weight", "bert.encoder.layer.7.output.dense.bias", "bert.encoder.layer.7.output.LayerNorm.weight", "bert.encoder.layer.7.output.LayerNorm.bias", "bert.encoder.layer.8.attention.self.query.weight", "bert.encoder.layer.8.attention.self.query.bias", "bert.encoder.layer.8.attention.self.key.weight", "bert.encoder.layer.8.attention.self.key.bias", "bert.encoder.layer.8.attention.self.value.weight", "bert.encoder.layer.8.attention.self.value.bias", "bert.encoder.layer.8.attention.output.dense.weight", "bert.encoder.layer.8.attention.output.dense.bias", "bert.encoder.layer.8.attention.output.LayerNorm.weight", "bert.encoder.layer.8.attention.output.LayerNorm.bias", "bert.encoder.layer.8.intermediate.dense.weight", "bert.encoder.layer.8.intermediate.dense.bias", "bert.encoder.layer.8.output.dense.weight", "bert.encoder.layer.8.output.dense.bias", "bert.encoder.layer.8.output.LayerNorm.weight", "bert.encoder.layer.8.output.LayerNorm.bias", "bert.encoder.layer.9.attention.self.query.weight", "bert.encoder.layer.9.attention.self.query.bias", "bert.encoder.layer.9.attention.self.key.weight", "bert.encoder.layer.9.attention.self.key.bias", "bert.encoder.layer.9.attention.self.value.weight", "bert.encoder.layer.9.attention.self.value.bias", "bert.encoder.layer.9.attention.output.dense.weight", "bert.encoder.layer.9.attention.output.dense.bias", "bert.encoder.layer.9.attention.output.LayerNorm.weight", "bert.encoder.layer.9.attention.output.LayerNorm.bias", "bert.encoder.layer.9.intermediate.dense.weight", "bert.encoder.layer.9.intermediate.dense.bias", "bert.encoder.layer.9.output.dense.weight", "bert.encoder.layer.9.output.dense.bias", "bert.encoder.layer.9.output.LayerNorm.weight", "bert.encoder.layer.9.output.LayerNorm.bias", "bert.encoder.layer.10.attention.self.query.weight", "bert.encoder.layer.10.attention.self.query.bias", "bert.encoder.layer.10.attention.self.key.weight", "bert.encoder.layer.10.attention.self.key.bias", "bert.encoder.layer.10.attention.self.value.weight", "bert.encoder.layer.10.attention.self.value.bias", "bert.encoder.layer.10.attention.output.dense.weight", "bert.encoder.layer.10.attention.output.dense.bias", "bert.encoder.layer.10.attention.output.LayerNorm.weight", "bert.encoder.layer.10.attention.output.LayerNorm.bias", "bert.encoder.layer.10.intermediate.dense.weight", "bert.encoder.layer.10.intermediate.dense.bias", "bert.encoder.layer.10.output.dense.weight", "bert.encoder.layer.10.output.dense.bias", "bert.encoder.layer.10.output.LayerNorm.weight", "bert.encoder.layer.10.output.LayerNorm.bias", "bert.encoder.layer.11.attention.self.query.weight", "bert.encoder.layer.11.attention.self.query.bias", "bert.encoder.layer.11.attention.self.key.weight", "bert.encoder.layer.11.attention.self.key.bias", "bert.encoder.layer.11.attention.self.value.weight", "bert.encoder.layer.11.attention.self.value.bias", "bert.encoder.layer.11.attention.output.dense.weight", "bert.encoder.layer.11.attention.output.dense.bias", "bert.encoder.layer.11.attention.output.LayerNorm.weight", "bert.encoder.layer.11.attention.output.LayerNorm.bias", "bert.encoder.layer.11.intermediate.dense.weight", "bert.encoder.layer.11.intermediate.dense.bias", "bert.encoder.layer.11.output.dense.weight", "bert.encoder.layer.11.output.dense.bias", "bert.encoder.layer.11.output.LayerNorm.weight", "bert.encoder.layer.11.output.LayerNorm.bias", "bert.encoder.layer.12.attention.self.query.weight", "bert.encoder.layer.12.attention.self.query.bias", "bert.encoder.layer.12.attention.self.key.weight", "bert.encoder.layer.12.attention.self.key.bias", "bert.encoder.layer.12.attention.self.value.weight", "bert.encoder.layer.12.attention.self.value.bias", "bert.encoder.layer.12.attention.output.dense.weight", "bert.encoder.layer.12.attention.output.dense.bias", "bert.encoder.layer.12.attention.output.LayerNorm.weight", "bert.encoder.layer.12.attention.output.LayerNorm.bias", "bert.encoder.layer.12.intermediate.dense.weight", "bert.encoder.layer.12.intermediate.dense.bias", "bert.encoder.layer.12.output.dense.weight", "bert.encoder.layer.12.output.dense.bias", "bert.encoder.layer.12.output.LayerNorm.weight", "bert.encoder.layer.12.output.LayerNorm.bias", "bert.encoder.layer.13.attention.self.query.weight", "bert.encoder.layer.13.attention.self.query.bias", "bert.encoder.layer.13.attention.self.key.weight", "bert.encoder.layer.13.attention.self.key.bias", "bert.encoder.layer.13.attention.self.value.weight", "bert.encoder.layer.13.attention.self.value.bias", "bert.encoder.layer.13.attention.output.dense.weight", "bert.encoder.layer.13.attention.output.dense.bias", "bert.encoder.layer.13.attention.output.LayerNorm.weight", "bert.encoder.layer.13.attention.output.LayerNorm.bias", "bert.encoder.layer.13.intermediate.dense.weight", "bert.encoder.layer.13.intermediate.dense.bias", "bert.encoder.layer.13.output.dense.weight", "bert.encoder.layer.13.output.dense.bias", "bert.encoder.layer.13.output.LayerNorm.weight", "bert.encoder.layer.13.output.LayerNorm.bias", "bert.encoder.layer.14.attention.self.query.weight", "bert.encoder.layer.14.attention.self.query.bias", "bert.encoder.layer.14.attention.self.key.weight", "bert.encoder.layer.14.attention.self.key.bias", "bert.encoder.layer.14.attention.self.value.weight", "bert.encoder.layer.14.attention.self.value.bias", "bert.encoder.layer.14.attention.output.dense.weight", "bert.encoder.layer.14.attention.output.dense.bias", "bert.encoder.layer.14.attention.output.LayerNorm.weight", "bert.encoder.layer.14.attention.output.LayerNorm.bias", "bert.encoder.layer.14.intermediate.dense.weight", "bert.encoder.layer.14.intermediate.dense.bias", "bert.encoder.layer.14.output.dense.weight", "bert.encoder.layer.14.output.dense.bias", "bert.encoder.layer.14.output.LayerNorm.weight", "bert.encoder.layer.14.output.LayerNorm.bias", "bert.encoder.layer.15.attention.self.query.weight", "bert.encoder.layer.15.attention.self.query.bias", "bert.encoder.layer.15.attention.self.key.weight", "bert.encoder.layer.15.attention.self.key.bias", "bert.encoder.layer.15.attention.self.value.weight", "bert.encoder.layer.15.attention.self.value.bias", "bert.encoder.layer.15.attention.output.dense.weight", "bert.encoder.layer.15.attention.output.dense.bias", "bert.encoder.layer.15.attention.output.LayerNorm.weight", "bert.encoder.layer.15.attention.output.LayerNorm.bias", "bert.encoder.layer.15.intermediate.dense.weight", "bert.encoder.layer.15.intermediate.dense.bias", "bert.encoder.layer.15.output.dense.weight", "bert.encoder.layer.15.output.dense.bias", "bert.encoder.layer.15.output.LayerNorm.weight", "bert.encoder.layer.15.output.LayerNorm.bias", "bert.encoder.layer.16.attention.self.query.weight", "bert.encoder.layer.16.attention.self.query.bias", "bert.encoder.layer.16.attention.self.key.weight", "bert.encoder.layer.16.attention.self.key.bias", "bert.encoder.layer.16.attention.self.value.weight", "bert.encoder.layer.16.attention.self.value.bias", "bert.encoder.layer.16.attention.output.dense.weight", "bert.encoder.layer.16.attention.output.dense.bias", "bert.encoder.layer.16.attention.output.LayerNorm.weight", "bert.encoder.layer.16.attention.output.LayerNorm.bias", "bert.encoder.layer.16.intermediate.dense.weight", "bert.encoder.layer.16.intermediate.dense.bias", "bert.encoder.layer.16.output.dense.weight", "bert.encoder.layer.16.output.dense.bias", "bert.encoder.layer.16.output.LayerNorm.weight", "bert.encoder.layer.16.output.LayerNorm.bias", "bert.encoder.layer.17.attention.self.query.weight", "bert.encoder.layer.17.attention.self.query.bias", "bert.encoder.layer.17.attention.self.key.weight", "bert.encoder.layer.17.attention.self.key.bias", "bert.encoder.layer.17.attention.self.value.weight", "bert.encoder.layer.17.attention.self.value.bias", "bert.encoder.layer.17.attention.output.dense.weight", "bert.encoder.layer.17.attention.output.dense.bias", "bert.encoder.layer.17.attention.output.LayerNorm.weight", "bert.encoder.layer.17.attention.output.LayerNorm.bias", "bert.encoder.layer.17.intermediate.dense.weight", "bert.encoder.layer.17.intermediate.dense.bias", "bert.encoder.layer.17.output.dense.weight", "bert.encoder.layer.17.output.dense.bias", "bert.encoder.layer.17.output.LayerNorm.weight", "bert.encoder.layer.17.output.LayerNorm.bias", "bert.encoder.layer.18.attention.self.query.weight", "bert.encoder.layer.18.attention.self.query.bias", "bert.encoder.layer.18.attention.self.key.weight", "bert.encoder.layer.18.attention.self.key.bias", "bert.encoder.layer.18.attention.self.value.weight", "bert.encoder.layer.18.attention.self.value.bias", "bert.encoder.layer.18.attention.output.dense.weight", "bert.encoder.layer.18.attention.output.dense.bias", "bert.encoder.layer.18.attention.output.LayerNorm.weight", "bert.encoder.layer.18.attention.output.LayerNorm.bias", "bert.encoder.layer.18.intermediate.dense.weight", "bert.encoder.layer.18.intermediate.dense.bias", "bert.encoder.layer.18.output.dense.weight", "bert.encoder.layer.18.output.dense.bias", "bert.encoder.layer.18.output.LayerNorm.weight", "bert.encoder.layer.18.output.LayerNorm.bias", "bert.encoder.layer.19.attention.self.query.weight", "bert.encoder.layer.19.attention.self.query.bias", "bert.encoder.layer.19.attention.self.key.weight", "bert.encoder.layer.19.attention.self.key.bias", "bert.encoder.layer.19.attention.self.value.weight", "bert.encoder.layer.19.attention.self.value.bias", "bert.encoder.layer.19.attention.output.dense.weight", "bert.encoder.layer.19.attention.output.dense.bias", "bert.encoder.layer.19.attention.output.LayerNorm.weight", "bert.encoder.layer.19.attention.output.LayerNorm.bias", "bert.encoder.layer.19.intermediate.dense.weight", "bert.encoder.layer.19.intermediate.dense.bias", "bert.encoder.layer.19.output.dense.weight", "bert.encoder.layer.19.output.dense.bias", "bert.encoder.layer.19.output.LayerNorm.weight", "bert.encoder.layer.19.output.LayerNorm.bias", "bert.encoder.layer.20.attention.self.query.weight", "bert.encoder.layer.20.attention.self.query.bias", "bert.encoder.layer.20.attention.self.key.weight", "bert.encoder.layer.20.attention.self.key.bias", "bert.encoder.layer.20.attention.self.value.weight", "bert.encoder.layer.20.attention.self.value.bias", "bert.encoder.layer.20.attention.output.dense.weight", "bert.encoder.layer.20.attention.output.dense.bias", "bert.encoder.layer.20.attention.output.LayerNorm.weight", "bert.encoder.layer.20.attention.output.LayerNorm.bias", "bert.encoder.layer.20.intermediate.dense.weight", "bert.encoder.layer.20.intermediate.dense.bias", "bert.encoder.layer.20.output.dense.weight", "bert.encoder.layer.20.output.dense.bias", "bert.encoder.layer.20.output.LayerNorm.weight", "bert.encoder.layer.20.output.LayerNorm.bias", "bert.encoder.layer.21.attention.self.query.weight", "bert.encoder.layer.21.attention.self.query.bias", "bert.encoder.layer.21.attention.self.key.weight", "bert.encoder.layer.21.attention.self.key.bias", "bert.encoder.layer.21.attention.self.value.weight", "bert.encoder.layer.21.attention.self.value.bias", "bert.encoder.layer.21.attention.output.dense.weight", "bert.encoder.layer.21.attention.output.dense.bias", "bert.encoder.layer.21.attention.output.LayerNorm.weight", "bert.encoder.layer.21.attention.output.LayerNorm.bias", "bert.encoder.layer.21.intermediate.dense.weight", "bert.encoder.layer.21.intermediate.dense.bias", "bert.encoder.layer.21.output.dense.weight", "bert.encoder.layer.21.output.dense.bias", "bert.encoder.layer.21.output.LayerNorm.weight", "bert.encoder.layer.21.output.LayerNorm.bias", "bert.encoder.layer.22.attention.self.query.weight", "bert.encoder.layer.22.attention.self.query.bias", "bert.encoder.layer.22.attention.self.key.weight", "bert.encoder.layer.22.attention.self.key.bias", "bert.encoder.layer.22.attention.self.value.weight", "bert.encoder.layer.22.attention.self.value.bias", "bert.encoder.layer.22.attention.output.dense.weight", "bert.encoder.layer.22.attention.output.dense.bias", "bert.encoder.layer.22.attention.output.LayerNorm.weight", "bert.encoder.layer.22.attention.output.LayerNorm.bias", "bert.encoder.layer.22.intermediate.dense.weight", "bert.encoder.layer.22.intermediate.dense.bias", "bert.encoder.layer.22.output.dense.weight", "bert.encoder.layer.22.output.dense.bias", "bert.encoder.layer.22.output.LayerNorm.weight", "bert.encoder.layer.22.output.LayerNorm.bias", "bert.encoder.layer.23.attention.self.query.weight", "bert.encoder.layer.23.attention.self.query.bias", "bert.encoder.layer.23.attention.self.key.weight", "bert.encoder.layer.23.attention.self.key.bias", "bert.encoder.layer.23.attention.self.value.weight", "bert.encoder.layer.23.attention.self.value.bias", "bert.encoder.layer.23.attention.output.dense.weight", "bert.encoder.layer.23.attention.output.dense.bias", "bert.encoder.layer.23.attention.output.LayerNorm.weight", "bert.encoder.layer.23.attention.output.LayerNorm.bias", "bert.encoder.layer.23.intermediate.dense.weight", "bert.encoder.layer.23.intermediate.dense.bias", "bert.encoder.layer.23.output.dense.weight", "bert.encoder.layer.23.output.dense.bias", "bert.encoder.layer.23.output.LayerNorm.weight", "bert.encoder.layer.23.output.LayerNorm.bias", "classifier.layers.0.weight", "classifier.layers.0.bias", "classifier.layers.1.projection.weight", "classifier.layers.1.projection.bias", "classifier.layers.3.weight", "classifier.layers.3.bias", "classifier.layers.4.projection.weight", "classifier.layers.4.projection.bias", "classifier.layers.6.weight", "classifier.layers.6.bias". 
	Unexpected key(s) in state_dict: "layers.0.weight", "layers.0.bias", "layers.1.projection.weight", "layers.1.projection.bias", "layers.3.weight", "layers.3.bias", "layers.4.projection.weight", "layers.4.projection.bias", "layers.6.weight", "layers.6.bias". An error occurred during training: Error(s) in loading state_dict for BERTClassifier:
	Missing key(s) in state_dict: "bert.embeddings.word_embeddings.weight", "bert.embeddings.position_embeddings.weight", "bert.embeddings.token_type_embeddings.weight", "bert.embeddings.LayerNorm.weight", "bert.embeddings.LayerNorm.bias", "bert.encoder.layer.0.attention.self.query.weight", "bert.encoder.layer.0.attention.self.query.bias", "bert.encoder.layer.0.attention.self.key.weight", "bert.encoder.layer.0.attention.self.key.bias", "bert.encoder.layer.0.attention.self.value.weight", "bert.encoder.layer.0.attention.self.value.bias", "bert.encoder.layer.0.attention.output.dense.weight", "bert.encoder.layer.0.attention.output.dense.bias", "bert.encoder.layer.0.attention.output.LayerNorm.weight", "bert.encoder.layer.0.attention.output.LayerNorm.bias", "bert.encoder.layer.0.intermediate.dense.weight", "bert.encoder.layer.0.intermediate.dense.bias", "bert.encoder.layer.0.output.dense.weight", "bert.encoder.layer.0.output.dense.bias", "bert.encoder.layer.0.output.LayerNorm.weight", "bert.encoder.layer.0.output.LayerNorm.bias", "bert.encoder.layer.1.attention.self.query.weight", "bert.encoder.layer.1.attention.self.query.bias", "bert.encoder.layer.1.attention.self.key.weight", "bert.encoder.layer.1.attention.self.key.bias", "bert.encoder.layer.1.attention.self.value.weight", "bert.encoder.layer.1.attention.self.value.bias", "bert.encoder.layer.1.attention.output.dense.weight", "bert.encoder.layer.1.attention.output.dense.bias", "bert.encoder.layer.1.attention.output.LayerNorm.weight", "bert.encoder.layer.1.attention.output.LayerNorm.bias", "bert.encoder.layer.1.intermediate.dense.weight", "bert.encoder.layer.1.intermediate.dense.bias", "bert.encoder.layer.1.output.dense.weight", "bert.encoder.layer.1.output.dense.bias", "bert.encoder.layer.1.output.LayerNorm.weight", "bert.encoder.layer.1.output.LayerNorm.bias", "bert.encoder.layer.2.attention.self.query.weight", "bert.encoder.layer.2.attention.self.query.bias", "bert.encoder.layer.2.attention.self.key.weight", "bert.encoder.layer.2.attention.self.key.bias", "bert.encoder.layer.2.attention.self.value.weight", "bert.encoder.layer.2.attention.self.value.bias", "bert.encoder.layer.2.attention.output.dense.weight", "bert.encoder.layer.2.attention.output.dense.bias", "bert.encoder.layer.2.attention.output.LayerNorm.weight", "bert.encoder.layer.2.attention.output.LayerNorm.bias", "bert.encoder.layer.2.intermediate.dense.weight", "bert.encoder.layer.2.intermediate.dense.bias", "bert.encoder.layer.2.output.dense.weight", "bert.encoder.layer.2.output.dense.bias", "bert.encoder.layer.2.output.LayerNorm.weight", "bert.encoder.layer.2.output.LayerNorm.bias", "bert.encoder.layer.3.attention.self.query.weight", "bert.encoder.layer.3.attention.self.query.bias", "bert.encoder.layer.3.attention.self.key.weight", "bert.encoder.layer.3.attention.self.key.bias", "bert.encoder.layer.3.attention.self.value.weight", "bert.encoder.layer.3.attention.self.value.bias", "bert.encoder.layer.3.attention.output.dense.weight", "bert.encoder.layer.3.attention.output.dense.bias", "bert.encoder.layer.3.attention.output.LayerNorm.weight", "bert.encoder.layer.3.attention.output.LayerNorm.bias", "bert.encoder.layer.3.intermediate.dense.weight", "bert.encoder.layer.3.intermediate.dense.bias", "bert.encoder.layer.3.output.dense.weight", "bert.encoder.layer.3.output.dense.bias", "bert.encoder.layer.3.output.LayerNorm.weight", "bert.encoder.layer.3.output.LayerNorm.bias", "bert.encoder.layer.4.attention.self.query.weight", "bert.encoder.layer.4.attention.self.query.bias", "bert.encoder.layer.4.attention.self.key.weight", "bert.encoder.layer.4.attention.self.key.bias", "bert.encoder.layer.4.attention.self.value.weight", "bert.encoder.layer.4.attention.self.value.bias", "bert.encoder.layer.4.attention.output.dense.weight", "bert.encoder.layer.4.attention.output.dense.bias", "bert.encoder.layer.4.attention.output.LayerNorm.weight", "bert.encoder.layer.4.attention.output.LayerNorm.bias", "bert.encoder.layer.4.intermediate.dense.weight", "bert.encoder.layer.4.intermediate.dense.bias", "bert.encoder.layer.4.output.dense.weight", "bert.encoder.layer.4.output.dense.bias", "bert.encoder.layer.4.output.LayerNorm.weight", "bert.encoder.layer.4.output.LayerNorm.bias", "bert.encoder.layer.5.attention.self.query.weight", "bert.encoder.layer.5.attention.self.query.bias", "bert.encoder.layer.5.attention.self.key.weight", "bert.encoder.layer.5.attention.self.key.bias", "bert.encoder.layer.5.attention.self.value.weight", "bert.encoder.layer.5.attention.self.value.bias", "bert.encoder.layer.5.attention.output.dense.weight", "bert.encoder.layer.5.attention.output.dense.bias", "bert.encoder.layer.5.attention.output.LayerNorm.weight", "bert.encoder.layer.5.attention.output.LayerNorm.bias", "bert.encoder.layer.5.intermediate.dense.weight", "bert.encoder.layer.5.intermediate.dense.bias", "bert.encoder.layer.5.output.dense.weight", "bert.encoder.layer.5.output.dense.bias", "bert.encoder.layer.5.output.LayerNorm.weight", "bert.encoder.layer.5.output.LayerNorm.bias", "bert.encoder.layer.6.attention.self.query.weight", "bert.encoder.layer.6.attention.self.query.bias", "bert.encoder.layer.6.attention.self.key.weight", "bert.encoder.layer.6.attention.self.key.bias", "bert.encoder.layer.6.attention.self.value.weight", "bert.encoder.layer.6.attention.self.value.bias", "bert.encoder.layer.6.attention.output.dense.weight", "bert.encoder.layer.6.attention.output.dense.bias", "bert.encoder.layer.6.attention.output.LayerNorm.weight", "bert.encoder.layer.6.attention.output.LayerNorm.bias", "bert.encoder.layer.6.intermediate.dense.weight", "bert.encoder.layer.6.intermediate.dense.bias", "bert.encoder.layer.6.output.dense.weight", "bert.encoder.layer.6.output.dense.bias", "bert.encoder.layer.6.output.LayerNorm.weight", "bert.encoder.layer.6.output.LayerNorm.bias", "bert.encoder.layer.7.attention.self.query.weight", "bert.encoder.layer.7.attention.self.query.bias", "bert.encoder.layer.7.attention.self.key.weight", "bert.encoder.layer.7.attention.self.key.bias", "bert.encoder.layer.7.attention.self.value.weight", "bert.encoder.layer.7.attention.self.value.bias", "bert.encoder.layer.7.attention.output.dense.weight", "bert.encoder.layer.7.attention.output.dense.bias", "bert.encoder.layer.7.attention.output.LayerNorm.weight", "bert.encoder.layer.7.attention.output.LayerNorm.bias", "bert.encoder.layer.7.intermediate.dense.weight", "bert.encoder.layer.7.intermediate.dense.bias", "bert.encoder.layer.7.output.dense.weight", "bert.encoder.layer.7.output.dense.bias", "bert.encoder.layer.7.output.LayerNorm.weight", "bert.encoder.layer.7.output.LayerNorm.bias", "bert.encoder.layer.8.attention.self.query.weight", "bert.encoder.layer.8.attention.self.query.bias", "bert.encoder.layer.8.attention.self.key.weight", "bert.encoder.layer.8.attention.self.key.bias", "bert.encoder.layer.8.attention.self.value.weight", "bert.encoder.layer.8.attention.self.value.bias", "bert.encoder.layer.8.attention.output.dense.weight", "bert.encoder.layer.8.attention.output.dense.bias", "bert.encoder.layer.8.attention.output.LayerNorm.weight", "bert.encoder.layer.8.attention.output.LayerNorm.bias", "bert.encoder.layer.8.intermediate.dense.weight", "bert.encoder.layer.8.intermediate.dense.bias", "bert.encoder.layer.8.output.dense.weight", "bert.encoder.layer.8.output.dense.bias", "bert.encoder.layer.8.output.LayerNorm.weight", "bert.encoder.layer.8.output.LayerNorm.bias", "bert.encoder.layer.9.attention.self.query.weight", "bert.encoder.layer.9.attention.self.query.bias", "bert.encoder.layer.9.attention.self.key.weight", "bert.encoder.layer.9.attention.self.key.bias", "bert.encoder.layer.9.attention.self.value.weight", "bert.encoder.layer.9.attention.self.value.bias", "bert.encoder.layer.9.attention.output.dense.weight", "bert.encoder.layer.9.attention.output.dense.bias", "bert.encoder.layer.9.attention.output.LayerNorm.weight", "bert.encoder.layer.9.attention.output.LayerNorm.bias", "bert.encoder.layer.9.intermediate.dense.weight", "bert.encoder.layer.9.intermediate.dense.bias", "bert.encoder.layer.9.output.dense.weight", "bert.encoder.layer.9.output.dense.bias", "bert.encoder.layer.9.output.LayerNorm.weight", "bert.encoder.layer.9.output.LayerNorm.bias", "bert.encoder.layer.10.attention.self.query.weight", "bert.encoder.layer.10.attention.self.query.bias", "bert.encoder.layer.10.attention.self.key.weight", "bert.encoder.layer.10.attention.self.key.bias", "bert.encoder.layer.10.attention.self.value.weight", "bert.encoder.layer.10.attention.self.value.bias", "bert.encoder.layer.10.attention.output.dense.weight", "bert.encoder.layer.10.attention.output.dense.bias", "bert.encoder.layer.10.attention.output.LayerNorm.weight", "bert.encoder.layer.10.attention.output.LayerNorm.bias", "bert.encoder.layer.10.intermediate.dense.weight", "bert.encoder.layer.10.intermediate.dense.bias", "bert.encoder.layer.10.output.dense.weight", "bert.encoder.layer.10.output.dense.bias", "bert.encoder.layer.10.output.LayerNorm.weight", "bert.encoder.layer.10.output.LayerNorm.bias", "bert.encoder.layer.11.attention.self.query.weight", "bert.encoder.layer.11.attention.self.query.bias", "bert.encoder.layer.11.attention.self.key.weight", "bert.encoder.layer.11.attention.self.key.bias", "bert.encoder.layer.11.attention.self.value.weight", "bert.encoder.layer.11.attention.self.value.bias", "bert.encoder.layer.11.attention.output.dense.weight", "bert.encoder.layer.11.attention.output.dense.bias", "bert.encoder.layer.11.attention.output.LayerNorm.weight", "bert.encoder.layer.11.attention.output.LayerNorm.bias", "bert.encoder.layer.11.intermediate.dense.weight", "bert.encoder.layer.11.intermediate.dense.bias", "bert.encoder.layer.11.output.dense.weight", "bert.encoder.layer.11.output.dense.bias", "bert.encoder.layer.11.output.LayerNorm.weight", "bert.encoder.layer.11.output.LayerNorm.bias", "bert.encoder.layer.12.attention.self.query.weight", "bert.encoder.layer.12.attention.self.query.bias", "bert.encoder.layer.12.attention.self.key.weight", "bert.encoder.layer.12.attention.self.key.bias", "bert.encoder.layer.12.attention.self.value.weight", "bert.encoder.layer.12.attention.self.value.bias", "bert.encoder.layer.12.attention.output.dense.weight", "bert.encoder.layer.12.attention.output.dense.bias", "bert.encoder.layer.12.attention.output.LayerNorm.weight", "bert.encoder.layer.12.attention.output.LayerNorm.bias", "bert.encoder.layer.12.intermediate.dense.weight", "bert.encoder.layer.12.intermediate.dense.bias", "bert.encoder.layer.12.output.dense.weight", "bert.encoder.layer.12.output.dense.bias", "bert.encoder.layer.12.output.LayerNorm.weight", "bert.encoder.layer.12.output.LayerNorm.bias", "bert.encoder.layer.13.attention.self.query.weight", "bert.encoder.layer.13.attention.self.query.bias", "bert.encoder.layer.13.attention.self.key.weight", "bert.encoder.layer.13.attention.self.key.bias", "bert.encoder.layer.13.attention.self.value.weight", "bert.encoder.layer.13.attention.self.value.bias", "bert.encoder.layer.13.attention.output.dense.weight", "bert.encoder.layer.13.attention.output.dense.bias", "bert.encoder.layer.13.attention.output.LayerNorm.weight", "bert.encoder.layer.13.attention.output.LayerNorm.bias", "bert.encoder.layer.13.intermediate.dense.weight", "bert.encoder.layer.13.intermediate.dense.bias", "bert.encoder.layer.13.output.dense.weight", "bert.encoder.layer.13.output.dense.bias", "bert.encoder.layer.13.output.LayerNorm.weight", "bert.encoder.layer.13.output.LayerNorm.bias", "bert.encoder.layer.14.attention.self.query.weight", "bert.encoder.layer.14.attention.self.query.bias", "bert.encoder.layer.14.attention.self.key.weight", "bert.encoder.layer.14.attention.self.key.bias", "bert.encoder.layer.14.attention.self.value.weight", "bert.encoder.layer.14.attention.self.value.bias", "bert.encoder.layer.14.attention.output.dense.weight", "bert.encoder.layer.14.attention.output.dense.bias", "bert.encoder.layer.14.attention.output.LayerNorm.weight", "bert.encoder.layer.14.attention.output.LayerNorm.bias", "bert.encoder.layer.14.intermediate.dense.weight", "bert.encoder.layer.14.intermediate.dense.bias", "bert.encoder.layer.14.output.dense.weight", "bert.encoder.layer.14.output.dense.bias", "bert.encoder.layer.14.output.LayerNorm.weight", "bert.encoder.layer.14.output.LayerNorm.bias", "bert.encoder.layer.15.attention.self.query.weight", "bert.encoder.layer.15.attention.self.query.bias", "bert.encoder.layer.15.attention.self.key.weight", "bert.encoder.layer.15.attention.self.key.bias", "bert.encoder.layer.15.attention.self.value.weight", "bert.encoder.layer.15.attention.self.value.bias", "bert.encoder.layer.15.attention.output.dense.weight", "bert.encoder.layer.15.attention.output.dense.bias", "bert.encoder.layer.15.attention.output.LayerNorm.weight", "bert.encoder.layer.15.attention.output.LayerNorm.bias", "bert.encoder.layer.15.intermediate.dense.weight", "bert.encoder.layer.15.intermediate.dense.bias", "bert.encoder.layer.15.output.dense.weight", "bert.encoder.layer.15.output.dense.bias", "bert.encoder.layer.15.output.LayerNorm.weight", "bert.encoder.layer.15.output.LayerNorm.bias", "bert.encoder.layer.16.attention.self.query.weight", "bert.encoder.layer.16.attention.self.query.bias", "bert.encoder.layer.16.attention.self.key.weight", "bert.encoder.layer.16.attention.self.key.bias", "bert.encoder.layer.16.attention.self.value.weight", "bert.encoder.layer.16.attention.self.value.bias", "bert.encoder.layer.16.attention.output.dense.weight", "bert.encoder.layer.16.attention.output.dense.bias", "bert.encoder.layer.16.attention.output.LayerNorm.weight", "bert.encoder.layer.16.attention.output.LayerNorm.bias", "bert.encoder.layer.16.intermediate.dense.weight", "bert.encoder.layer.16.intermediate.dense.bias", "bert.encoder.layer.16.output.dense.weight", "bert.encoder.layer.16.output.dense.bias", "bert.encoder.layer.16.output.LayerNorm.weight", "bert.encoder.layer.16.output.LayerNorm.bias", "bert.encoder.layer.17.attention.self.query.weight", "bert.encoder.layer.17.attention.self.query.bias", "bert.encoder.layer.17.attention.self.key.weight", "bert.encoder.layer.17.attention.self.key.bias", "bert.encoder.layer.17.attention.self.value.weight", "bert.encoder.layer.17.attention.self.value.bias", "bert.encoder.layer.17.attention.output.dense.weight", "bert.encoder.layer.17.attention.output.dense.bias", "bert.encoder.layer.17.attention.output.LayerNorm.weight", "bert.encoder.layer.17.attention.output.LayerNorm.bias", "bert.encoder.layer.17.intermediate.dense.weight", "bert.encoder.layer.17.intermediate.dense.bias", "bert.encoder.layer.17.output.dense.weight", "bert.encoder.layer.17.output.dense.bias", "bert.encoder.layer.17.output.LayerNorm.weight", "bert.encoder.layer.17.output.LayerNorm.bias", "bert.encoder.layer.18.attention.self.query.weight", "bert.encoder.layer.18.attention.self.query.bias", "bert.encoder.layer.18.attention.self.key.weight", "bert.encoder.layer.18.attention.self.key.bias", "bert.encoder.layer.18.attention.self.value.weight", "bert.encoder.layer.18.attention.self.value.bias", "bert.encoder.layer.18.attention.output.dense.weight", "bert.encoder.layer.18.attention.output.dense.bias", "bert.encoder.layer.18.attention.output.LayerNorm.weight", "bert.encoder.layer.18.attention.output.LayerNorm.bias", "bert.encoder.layer.18.intermediate.dense.weight", "bert.encoder.layer.18.intermediate.dense.bias", "bert.encoder.layer.18.output.dense.weight", "bert.encoder.layer.18.output.dense.bias", "bert.encoder.layer.18.output.LayerNorm.weight", "bert.encoder.layer.18.output.LayerNorm.bias", "bert.encoder.layer.19.attention.self.query.weight", "bert.encoder.layer.19.attention.self.query.bias", "bert.encoder.layer.19.attention.self.key.weight", "bert.encoder.layer.19.attention.self.key.bias", "bert.encoder.layer.19.attention.self.value.weight", "bert.encoder.layer.19.attention.self.value.bias", "bert.encoder.layer.19.attention.output.dense.weight", "bert.encoder.layer.19.attention.output.dense.bias", "bert.encoder.layer.19.attention.output.LayerNorm.weight", "bert.encoder.layer.19.attention.output.LayerNorm.bias", "bert.encoder.layer.19.intermediate.dense.weight", "bert.encoder.layer.19.intermediate.dense.bias", "bert.encoder.layer.19.output.dense.weight", "bert.encoder.layer.19.output.dense.bias", "bert.encoder.layer.19.output.LayerNorm.weight", "bert.encoder.layer.19.output.LayerNorm.bias", "bert.encoder.layer.20.attention.self.query.weight", "bert.encoder.layer.20.attention.self.query.bias", "bert.encoder.layer.20.attention.self.key.weight", "bert.encoder.layer.20.attention.self.key.bias", "bert.encoder.layer.20.attention.self.value.weight", "bert.encoder.layer.20.attention.self.value.bias", "bert.encoder.layer.20.attention.output.dense.weight", "bert.encoder.layer.20.attention.output.dense.bias", "bert.encoder.layer.20.attention.output.LayerNorm.weight", "bert.encoder.layer.20.attention.output.LayerNorm.bias", "bert.encoder.layer.20.intermediate.dense.weight", "bert.encoder.layer.20.intermediate.dense.bias", "bert.encoder.layer.20.output.dense.weight", "bert.encoder.layer.20.output.dense.bias", "bert.encoder.layer.20.output.LayerNorm.weight", "bert.encoder.layer.20.output.LayerNorm.bias", "bert.encoder.layer.21.attention.self.query.weight", "bert.encoder.layer.21.attention.self.query.bias", "bert.encoder.layer.21.attention.self.key.weight", "bert.encoder.layer.21.attention.self.key.bias", "bert.encoder.layer.21.attention.self.value.weight", "bert.encoder.layer.21.attention.self.value.bias", "bert.encoder.layer.21.attention.output.dense.weight", "bert.encoder.layer.21.attention.output.dense.bias", "bert.encoder.layer.21.attention.output.LayerNorm.weight", "bert.encoder.layer.21.attention.output.LayerNorm.bias", "bert.encoder.layer.21.intermediate.dense.weight", "bert.encoder.layer.21.intermediate.dense.bias", "bert.encoder.layer.21.output.dense.weight", "bert.encoder.layer.21.output.dense.bias", "bert.encoder.layer.21.output.LayerNorm.weight", "bert.encoder.layer.21.output.LayerNorm.bias", "bert.encoder.layer.22.attention.self.query.weight", "bert.encoder.layer.22.attention.self.query.bias", "bert.encoder.layer.22.attention.self.key.weight", "bert.encoder.layer.22.attention.self.key.bias", "bert.encoder.layer.22.attention.self.value.weight", "bert.encoder.layer.22.attention.self.value.bias", "bert.encoder.layer.22.attention.output.dense.weight", "bert.encoder.layer.22.attention.output.dense.bias", "bert.encoder.layer.22.attention.output.LayerNorm.weight", "bert.encoder.layer.22.attention.output.LayerNorm.bias", "bert.encoder.layer.22.intermediate.dense.weight", "bert.encoder.layer.22.intermediate.dense.bias", "bert.encoder.layer.22.output.dense.weight", "bert.encoder.layer.22.output.dense.bias", "bert.encoder.layer.22.output.LayerNorm.weight", "bert.encoder.layer.22.output.LayerNorm.bias", "bert.encoder.layer.23.attention.self.query.weight", "bert.encoder.layer.23.attention.self.query.bias", "bert.encoder.layer.23.attention.self.key.weight", "bert.encoder.layer.23.attention.self.key.bias", "bert.encoder.layer.23.attention.self.value.weight", "bert.encoder.layer.23.attention.self.value.bias", "bert.encoder.layer.23.attention.output.dense.weight", "bert.encoder.layer.23.attention.output.dense.bias", "bert.encoder.layer.23.attention.output.LayerNorm.weight", "bert.encoder.layer.23.attention.output.LayerNorm.bias", "bert.encoder.layer.23.intermediate.dense.weight", "bert.encoder.layer.23.intermediate.dense.bias", "bert.encoder.layer.23.output.dense.weight", "bert.encoder.layer.23.output.dense.bias", "bert.encoder.layer.23.output.LayerNorm.weight", "bert.encoder.layer.23.output.LayerNorm.bias", "classifier.layers.0.weight", "classifier.layers.0.bias", "classifier.layers.1.projection.weight", "classifier.layers.1.projection.bias", "classifier.layers.3.weight", "classifier.layers.3.bias", "classifier.layers.4.projection.weight", "classifier.layers.4.projection.bias", "classifier.layers.6.weight", "classifier.layers.6.bias". 
	Unexpected key(s) in state_dict: "layers.0.weight", "layers.0.bias", "layers.1.projection.weight", "layers.1.projection.bias", "layers.3.weight", "layers.3.bias", "layers.4.projection.weight", "layers.4.projection.bias", "layers.6.weight", "layers.6.bias". An error occurred during training: Error(s) in loading state_dict for BERTClassifier:
	Missing key(s) in state_dict: "bert.embeddings.word_embeddings.weight", "bert.embeddings.position_embeddings.weight", "bert.embeddings.token_type_embeddings.weight", "bert.embeddings.LayerNorm.weight", "bert.embeddings.LayerNorm.bias", "bert.encoder.layer.0.attention.self.query.weight", "bert.encoder.layer.0.attention.self.query.bias", "bert.encoder.layer.0.attention.self.key.weight", "bert.encoder.layer.0.attention.self.key.bias", "bert.encoder.layer.0.attention.self.value.weight", "bert.encoder.layer.0.attention.self.value.bias", "bert.encoder.layer.0.attention.output.dense.weight", "bert.encoder.layer.0.attention.output.dense.bias", "bert.encoder.layer.0.attention.output.LayerNorm.weight", "bert.encoder.layer.0.attention.output.LayerNorm.bias", "bert.encoder.layer.0.intermediate.dense.weight", "bert.encoder.layer.0.intermediate.dense.bias", "bert.encoder.layer.0.output.dense.weight", "bert.encoder.layer.0.output.dense.bias", "bert.encoder.layer.0.output.LayerNorm.weight", "bert.encoder.layer.0.output.LayerNorm.bias", "bert.encoder.layer.1.attention.self.query.weight", "bert.encoder.layer.1.attention.self.query.bias", "bert.encoder.layer.1.attention.self.key.weight", "bert.encoder.layer.1.attention.self.key.bias", "bert.encoder.layer.1.attention.self.value.weight", "bert.encoder.layer.1.attention.self.value.bias", "bert.encoder.layer.1.attention.output.dense.weight", "bert.encoder.layer.1.attention.output.dense.bias", "bert.encoder.layer.1.attention.output.LayerNorm.weight", "bert.encoder.layer.1.attention.output.LayerNorm.bias", "bert.encoder.layer.1.intermediate.dense.weight", "bert.encoder.layer.1.intermediate.dense.bias", "bert.encoder.layer.1.output.dense.weight", "bert.encoder.layer.1.output.dense.bias", "bert.encoder.layer.1.output.LayerNorm.weight", "bert.encoder.layer.1.output.LayerNorm.bias", "bert.encoder.layer.2.attention.self.query.weight", "bert.encoder.layer.2.attention.self.query.bias", "bert.encoder.layer.2.attention.self.key.weight", "bert.encoder.layer.2.attention.self.key.bias", "bert.encoder.layer.2.attention.self.value.weight", "bert.encoder.layer.2.attention.self.value.bias", "bert.encoder.layer.2.attention.output.dense.weight", "bert.encoder.layer.2.attention.output.dense.bias", "bert.encoder.layer.2.attention.output.LayerNorm.weight", "bert.encoder.layer.2.attention.output.LayerNorm.bias", "bert.encoder.layer.2.intermediate.dense.weight", "bert.encoder.layer.2.intermediate.dense.bias", "bert.encoder.layer.2.output.dense.weight", "bert.encoder.layer.2.output.dense.bias", "bert.encoder.layer.2.output.LayerNorm.weight", "bert.encoder.layer.2.output.LayerNorm.bias", "bert.encoder.layer.3.attention.self.query.weight", "bert.encoder.layer.3.attention.self.query.bias", "bert.encoder.layer.3.attention.self.key.weight", "bert.encoder.layer.3.attention.self.key.bias", "bert.encoder.layer.3.attention.self.value.weight", "bert.encoder.layer.3.attention.self.value.bias", "bert.encoder.layer.3.attention.output.dense.weight", "bert.encoder.layer.3.attention.output.dense.bias", "bert.encoder.layer.3.attention.output.LayerNorm.weight", "bert.encoder.layer.3.attention.output.LayerNorm.bias", "bert.encoder.layer.3.intermediate.dense.weight", "bert.encoder.layer.3.intermediate.dense.bias", "bert.encoder.layer.3.output.dense.weight", "bert.encoder.layer.3.output.dense.bias", "bert.encoder.layer.3.output.LayerNorm.weight", "bert.encoder.layer.3.output.LayerNorm.bias", "bert.encoder.layer.4.attention.self.query.weight", "bert.encoder.layer.4.attention.self.query.bias", "bert.encoder.layer.4.attention.self.key.weight", "bert.encoder.layer.4.attention.self.key.bias", "bert.encoder.layer.4.attention.self.value.weight", "bert.encoder.layer.4.attention.self.value.bias", "bert.encoder.layer.4.attention.output.dense.weight", "bert.encoder.layer.4.attention.output.dense.bias", "bert.encoder.layer.4.attention.output.LayerNorm.weight", "bert.encoder.layer.4.attention.output.LayerNorm.bias", "bert.encoder.layer.4.intermediate.dense.weight", "bert.encoder.layer.4.intermediate.dense.bias", "bert.encoder.layer.4.output.dense.weight", "bert.encoder.layer.4.output.dense.bias", "bert.encoder.layer.4.output.LayerNorm.weight", "bert.encoder.layer.4.output.LayerNorm.bias", "bert.encoder.layer.5.attention.self.query.weight", "bert.encoder.layer.5.attention.self.query.bias", "bert.encoder.layer.5.attention.self.key.weight", "bert.encoder.layer.5.attention.self.key.bias", "bert.encoder.layer.5.attention.self.value.weight", "bert.encoder.layer.5.attention.self.value.bias", "bert.encoder.layer.5.attention.output.dense.weight", "bert.encoder.layer.5.attention.output.dense.bias", "bert.encoder.layer.5.attention.output.LayerNorm.weight", "bert.encoder.layer.5.attention.output.LayerNorm.bias", "bert.encoder.layer.5.intermediate.dense.weight", "bert.encoder.layer.5.intermediate.dense.bias", "bert.encoder.layer.5.output.dense.weight", "bert.encoder.layer.5.output.dense.bias", "bert.encoder.layer.5.output.LayerNorm.weight", "bert.encoder.layer.5.output.LayerNorm.bias", "bert.encoder.layer.6.attention.self.query.weight", "bert.encoder.layer.6.attention.self.query.bias", "bert.encoder.layer.6.attention.self.key.weight", "bert.encoder.layer.6.attention.self.key.bias", "bert.encoder.layer.6.attention.self.value.weight", "bert.encoder.layer.6.attention.self.value.bias", "bert.encoder.layer.6.attention.output.dense.weight", "bert.encoder.layer.6.attention.output.dense.bias", "bert.encoder.layer.6.attention.output.LayerNorm.weight", "bert.encoder.layer.6.attention.output.LayerNorm.bias", "bert.encoder.layer.6.intermediate.dense.weight", "bert.encoder.layer.6.intermediate.dense.bias", "bert.encoder.layer.6.output.dense.weight", "bert.encoder.layer.6.output.dense.bias", "bert.encoder.layer.6.output.LayerNorm.weight", "bert.encoder.layer.6.output.LayerNorm.bias", "bert.encoder.layer.7.attention.self.query.weight", "bert.encoder.layer.7.attention.self.query.bias", "bert.encoder.layer.7.attention.self.key.weight", "bert.encoder.layer.7.attention.self.key.bias", "bert.encoder.layer.7.attention.self.value.weight", "bert.encoder.layer.7.attention.self.value.bias", "bert.encoder.layer.7.attention.output.dense.weight", "bert.encoder.layer.7.attention.output.dense.bias", "bert.encoder.layer.7.attention.output.LayerNorm.weight", "bert.encoder.layer.7.attention.output.LayerNorm.bias", "bert.encoder.layer.7.intermediate.dense.weight", "bert.encoder.layer.7.intermediate.dense.bias", "bert.encoder.layer.7.output.dense.weight", "bert.encoder.layer.7.output.dense.bias", "bert.encoder.layer.7.output.LayerNorm.weight", "bert.encoder.layer.7.output.LayerNorm.bias", "bert.encoder.layer.8.attention.self.query.weight", "bert.encoder.layer.8.attention.self.query.bias", "bert.encoder.layer.8.attention.self.key.weight", "bert.encoder.layer.8.attention.self.key.bias", "bert.encoder.layer.8.attention.self.value.weight", "bert.encoder.layer.8.attention.self.value.bias", "bert.encoder.layer.8.attention.output.dense.weight", "bert.encoder.layer.8.attention.output.dense.bias", "bert.encoder.layer.8.attention.output.LayerNorm.weight", "bert.encoder.layer.8.attention.output.LayerNorm.bias", "bert.encoder.layer.8.intermediate.dense.weight", "bert.encoder.layer.8.intermediate.dense.bias", "bert.encoder.layer.8.output.dense.weight", "bert.encoder.layer.8.output.dense.bias", "bert.encoder.layer.8.output.LayerNorm.weight", "bert.encoder.layer.8.output.LayerNorm.bias", "bert.encoder.layer.9.attention.self.query.weight", "bert.encoder.layer.9.attention.self.query.bias", "bert.encoder.layer.9.attention.self.key.weight", "bert.encoder.layer.9.attention.self.key.bias", "bert.encoder.layer.9.attention.self.value.weight", "bert.encoder.layer.9.attention.self.value.bias", "bert.encoder.layer.9.attention.output.dense.weight", "bert.encoder.layer.9.attention.output.dense.bias", "bert.encoder.layer.9.attention.output.LayerNorm.weight", "bert.encoder.layer.9.attention.output.LayerNorm.bias", "bert.encoder.layer.9.intermediate.dense.weight", "bert.encoder.layer.9.intermediate.dense.bias", "bert.encoder.layer.9.output.dense.weight", "bert.encoder.layer.9.output.dense.bias", "bert.encoder.layer.9.output.LayerNorm.weight", "bert.encoder.layer.9.output.LayerNorm.bias", "bert.encoder.layer.10.attention.self.query.weight", "bert.encoder.layer.10.attention.self.query.bias", "bert.encoder.layer.10.attention.self.key.weight", "bert.encoder.layer.10.attention.self.key.bias", "bert.encoder.layer.10.attention.self.value.weight", "bert.encoder.layer.10.attention.self.value.bias", "bert.encoder.layer.10.attention.output.dense.weight", "bert.encoder.layer.10.attention.output.dense.bias", "bert.encoder.layer.10.attention.output.LayerNorm.weight", "bert.encoder.layer.10.attention.output.LayerNorm.bias", "bert.encoder.layer.10.intermediate.dense.weight", "bert.encoder.layer.10.intermediate.dense.bias", "bert.encoder.layer.10.output.dense.weight", "bert.encoder.layer.10.output.dense.bias", "bert.encoder.layer.10.output.LayerNorm.weight", "bert.encoder.layer.10.output.LayerNorm.bias", "bert.encoder.layer.11.attention.self.query.weight", "bert.encoder.layer.11.attention.self.query.bias", "bert.encoder.layer.11.attention.self.key.weight", "bert.encoder.layer.11.attention.self.key.bias", "bert.encoder.layer.11.attention.self.value.weight", "bert.encoder.layer.11.attention.self.value.bias", "bert.encoder.layer.11.attention.output.dense.weight", "bert.encoder.layer.11.attention.output.dense.bias", "bert.encoder.layer.11.attention.output.LayerNorm.weight", "bert.encoder.layer.11.attention.output.LayerNorm.bias", "bert.encoder.layer.11.intermediate.dense.weight", "bert.encoder.layer.11.intermediate.dense.bias", "bert.encoder.layer.11.output.dense.weight", "bert.encoder.layer.11.output.dense.bias", "bert.encoder.layer.11.output.LayerNorm.weight", "bert.encoder.layer.11.output.LayerNorm.bias", "bert.encoder.layer.12.attention.self.query.weight", "bert.encoder.layer.12.attention.self.query.bias", "bert.encoder.layer.12.attention.self.key.weight", "bert.encoder.layer.12.attention.self.key.bias", "bert.encoder.layer.12.attention.self.value.weight", "bert.encoder.layer.12.attention.self.value.bias", "bert.encoder.layer.12.attention.output.dense.weight", "bert.encoder.layer.12.attention.output.dense.bias", "bert.encoder.layer.12.attention.output.LayerNorm.weight", "bert.encoder.layer.12.attention.output.LayerNorm.bias", "bert.encoder.layer.12.intermediate.dense.weight", "bert.encoder.layer.12.intermediate.dense.bias", "bert.encoder.layer.12.output.dense.weight", "bert.encoder.layer.12.output.dense.bias", "bert.encoder.layer.12.output.LayerNorm.weight", "bert.encoder.layer.12.output.LayerNorm.bias", "bert.encoder.layer.13.attention.self.query.weight", "bert.encoder.layer.13.attention.self.query.bias", "bert.encoder.layer.13.attention.self.key.weight", "bert.encoder.layer.13.attention.self.key.bias", "bert.encoder.layer.13.attention.self.value.weight", "bert.encoder.layer.13.attention.self.value.bias", "bert.encoder.layer.13.attention.output.dense.weight", "bert.encoder.layer.13.attention.output.dense.bias", "bert.encoder.layer.13.attention.output.LayerNorm.weight", "bert.encoder.layer.13.attention.output.LayerNorm.bias", "bert.encoder.layer.13.intermediate.dense.weight", "bert.encoder.layer.13.intermediate.dense.bias", "bert.encoder.layer.13.output.dense.weight", "bert.encoder.layer.13.output.dense.bias", "bert.encoder.layer.13.output.LayerNorm.weight", "bert.encoder.layer.13.output.LayerNorm.bias", "bert.encoder.layer.14.attention.self.query.weight", "bert.encoder.layer.14.attention.self.query.bias", "bert.encoder.layer.14.attention.self.key.weight", "bert.encoder.layer.14.attention.self.key.bias", "bert.encoder.layer.14.attention.self.value.weight", "bert.encoder.layer.14.attention.self.value.bias", "bert.encoder.layer.14.attention.output.dense.weight", "bert.encoder.layer.14.attention.output.dense.bias", "bert.encoder.layer.14.attention.output.LayerNorm.weight", "bert.encoder.layer.14.attention.output.LayerNorm.bias", "bert.encoder.layer.14.intermediate.dense.weight", "bert.encoder.layer.14.intermediate.dense.bias", "bert.encoder.layer.14.output.dense.weight", "bert.encoder.layer.14.output.dense.bias", "bert.encoder.layer.14.output.LayerNorm.weight", "bert.encoder.layer.14.output.LayerNorm.bias", "bert.encoder.layer.15.attention.self.query.weight", "bert.encoder.layer.15.attention.self.query.bias", "bert.encoder.layer.15.attention.self.key.weight", "bert.encoder.layer.15.attention.self.key.bias", "bert.encoder.layer.15.attention.self.value.weight", "bert.encoder.layer.15.attention.self.value.bias", "bert.encoder.layer.15.attention.output.dense.weight", "bert.encoder.layer.15.attention.output.dense.bias", "bert.encoder.layer.15.attention.output.LayerNorm.weight", "bert.encoder.layer.15.attention.output.LayerNorm.bias", "bert.encoder.layer.15.intermediate.dense.weight", "bert.encoder.layer.15.intermediate.dense.bias", "bert.encoder.layer.15.output.dense.weight", "bert.encoder.layer.15.output.dense.bias", "bert.encoder.layer.15.output.LayerNorm.weight", "bert.encoder.layer.15.output.LayerNorm.bias", "bert.encoder.layer.16.attention.self.query.weight", "bert.encoder.layer.16.attention.self.query.bias", "bert.encoder.layer.16.attention.self.key.weight", "bert.encoder.layer.16.attention.self.key.bias", "bert.encoder.layer.16.attention.self.value.weight", "bert.encoder.layer.16.attention.self.value.bias", "bert.encoder.layer.16.attention.output.dense.weight", "bert.encoder.layer.16.attention.output.dense.bias", "bert.encoder.layer.16.attention.output.LayerNorm.weight", "bert.encoder.layer.16.attention.output.LayerNorm.bias", "bert.encoder.layer.16.intermediate.dense.weight", "bert.encoder.layer.16.intermediate.dense.bias", "bert.encoder.layer.16.output.dense.weight", "bert.encoder.layer.16.output.dense.bias", "bert.encoder.layer.16.output.LayerNorm.weight", "bert.encoder.layer.16.output.LayerNorm.bias", "bert.encoder.layer.17.attention.self.query.weight", "bert.encoder.layer.17.attention.self.query.bias", "bert.encoder.layer.17.attention.self.key.weight", "bert.encoder.layer.17.attention.self.key.bias", "bert.encoder.layer.17.attention.self.value.weight", "bert.encoder.layer.17.attention.self.value.bias", "bert.encoder.layer.17.attention.output.dense.weight", "bert.encoder.layer.17.attention.output.dense.bias", "bert.encoder.layer.17.attention.output.LayerNorm.weight", "bert.encoder.layer.17.attention.output.LayerNorm.bias", "bert.encoder.layer.17.intermediate.dense.weight", "bert.encoder.layer.17.intermediate.dense.bias", "bert.encoder.layer.17.output.dense.weight", "bert.encoder.layer.17.output.dense.bias", "bert.encoder.layer.17.output.LayerNorm.weight", "bert.encoder.layer.17.output.LayerNorm.bias", "bert.encoder.layer.18.attention.self.query.weight", "bert.encoder.layer.18.attention.self.query.bias", "bert.encoder.layer.18.attention.self.key.weight", "bert.encoder.layer.18.attention.self.key.bias", "bert.encoder.layer.18.attention.self.value.weight", "bert.encoder.layer.18.attention.self.value.bias", "bert.encoder.layer.18.attention.output.dense.weight", "bert.encoder.layer.18.attention.output.dense.bias", "bert.encoder.layer.18.attention.output.LayerNorm.weight", "bert.encoder.layer.18.attention.output.LayerNorm.bias", "bert.encoder.layer.18.intermediate.dense.weight", "bert.encoder.layer.18.intermediate.dense.bias", "bert.encoder.layer.18.output.dense.weight", "bert.encoder.layer.18.output.dense.bias", "bert.encoder.layer.18.output.LayerNorm.weight", "bert.encoder.layer.18.output.LayerNorm.bias", "bert.encoder.layer.19.attention.self.query.weight", "bert.encoder.layer.19.attention.self.query.bias", "bert.encoder.layer.19.attention.self.key.weight", "bert.encoder.layer.19.attention.self.key.bias", "bert.encoder.layer.19.attention.self.value.weight", "bert.encoder.layer.19.attention.self.value.bias", "bert.encoder.layer.19.attention.output.dense.weight", "bert.encoder.layer.19.attention.output.dense.bias", "bert.encoder.layer.19.attention.output.LayerNorm.weight", "bert.encoder.layer.19.attention.output.LayerNorm.bias", "bert.encoder.layer.19.intermediate.dense.weight", "bert.encoder.layer.19.intermediate.dense.bias", "bert.encoder.layer.19.output.dense.weight", "bert.encoder.layer.19.output.dense.bias", "bert.encoder.layer.19.output.LayerNorm.weight", "bert.encoder.layer.19.output.LayerNorm.bias", "bert.encoder.layer.20.attention.self.query.weight", "bert.encoder.layer.20.attention.self.query.bias", "bert.encoder.layer.20.attention.self.key.weight", "bert.encoder.layer.20.attention.self.key.bias", "bert.encoder.layer.20.attention.self.value.weight", "bert.encoder.layer.20.attention.self.value.bias", "bert.encoder.layer.20.attention.output.dense.weight", "bert.encoder.layer.20.attention.output.dense.bias", "bert.encoder.layer.20.attention.output.LayerNorm.weight", "bert.encoder.layer.20.attention.output.LayerNorm.bias", "bert.encoder.layer.20.intermediate.dense.weight", "bert.encoder.layer.20.intermediate.dense.bias", "bert.encoder.layer.20.output.dense.weight", "bert.encoder.layer.20.output.dense.bias", "bert.encoder.layer.20.output.LayerNorm.weight", "bert.encoder.layer.20.output.LayerNorm.bias", "bert.encoder.layer.21.attention.self.query.weight", "bert.encoder.layer.21.attention.self.query.bias", "bert.encoder.layer.21.attention.self.key.weight", "bert.encoder.layer.21.attention.self.key.bias", "bert.encoder.layer.21.attention.self.value.weight", "bert.encoder.layer.21.attention.self.value.bias", "bert.encoder.layer.21.attention.output.dense.weight", "bert.encoder.layer.21.attention.output.dense.bias", "bert.encoder.layer.21.attention.output.LayerNorm.weight", "bert.encoder.layer.21.attention.output.LayerNorm.bias", "bert.encoder.layer.21.intermediate.dense.weight", "bert.encoder.layer.21.intermediate.dense.bias", "bert.encoder.layer.21.output.dense.weight", "bert.encoder.layer.21.output.dense.bias", "bert.encoder.layer.21.output.LayerNorm.weight", "bert.encoder.layer.21.output.LayerNorm.bias", "bert.encoder.layer.22.attention.self.query.weight", "bert.encoder.layer.22.attention.self.query.bias", "bert.encoder.layer.22.attention.self.key.weight", "bert.encoder.layer.22.attention.self.key.bias", "bert.encoder.layer.22.attention.self.value.weight", "bert.encoder.layer.22.attention.self.value.bias", "bert.encoder.layer.22.attention.output.dense.weight", "bert.encoder.layer.22.attention.output.dense.bias", "bert.encoder.layer.22.attention.output.LayerNorm.weight", "bert.encoder.layer.22.attention.output.LayerNorm.bias", "bert.encoder.layer.22.intermediate.dense.weight", "bert.encoder.layer.22.intermediate.dense.bias", "bert.encoder.layer.22.output.dense.weight", "bert.encoder.layer.22.output.dense.bias", "bert.encoder.layer.22.output.LayerNorm.weight", "bert.encoder.layer.22.output.LayerNorm.bias", "bert.encoder.layer.23.attention.self.query.weight", "bert.encoder.layer.23.attention.self.query.bias", "bert.encoder.layer.23.attention.self.key.weight", "bert.encoder.layer.23.attention.self.key.bias", "bert.encoder.layer.23.attention.self.value.weight", "bert.encoder.layer.23.attention.self.value.bias", "bert.encoder.layer.23.attention.output.dense.weight", "bert.encoder.layer.23.attention.output.dense.bias", "bert.encoder.layer.23.attention.output.LayerNorm.weight", "bert.encoder.layer.23.attention.output.LayerNorm.bias", "bert.encoder.layer.23.intermediate.dense.weight", "bert.encoder.layer.23.intermediate.dense.bias", "bert.encoder.layer.23.output.dense.weight", "bert.encoder.layer.23.output.dense.bias", "bert.encoder.layer.23.output.LayerNorm.weight", "bert.encoder.layer.23.output.LayerNorm.bias", "classifier.layers.0.weight", "classifier.layers.0.bias", "classifier.layers.1.projection.weight", "classifier.layers.1.projection.bias", "classifier.layers.3.weight", "classifier.layers.3.bias", "classifier.layers.4.projection.weight", "classifier.layers.4.projection.bias", "classifier.layers.6.weight", "classifier.layers.6.bias". 
	Unexpected key(s) in state_dict: "layers.0.weight", "layers.0.bias", "layers.1.projection.weight", "layers.1.projection.bias", "layers.3.weight", "layers.3.bias", "layers.4.projection.weight", "layers.4.projection.bias", "layers.6.weight", "layers.6.bias". An error occurred during training: Error(s) in loading state_dict for BERTClassifier:
	Missing key(s) in state_dict: "bert.embeddings.word_embeddings.weight", "bert.embeddings.position_embeddings.weight", "bert.embeddings.token_type_embeddings.weight", "bert.embeddings.LayerNorm.weight", "bert.embeddings.LayerNorm.bias", "bert.encoder.layer.0.attention.self.query.weight", "bert.encoder.layer.0.attention.self.query.bias", "bert.encoder.layer.0.attention.self.key.weight", "bert.encoder.layer.0.attention.self.key.bias", "bert.encoder.layer.0.attention.self.value.weight", "bert.encoder.layer.0.attention.self.value.bias", "bert.encoder.layer.0.attention.output.dense.weight", "bert.encoder.layer.0.attention.output.dense.bias", "bert.encoder.layer.0.attention.output.LayerNorm.weight", "bert.encoder.layer.0.attention.output.LayerNorm.bias", "bert.encoder.layer.0.intermediate.dense.weight", "bert.encoder.layer.0.intermediate.dense.bias", "bert.encoder.layer.0.output.dense.weight", "bert.encoder.layer.0.output.dense.bias", "bert.encoder.layer.0.output.LayerNorm.weight", "bert.encoder.layer.0.output.LayerNorm.bias", "bert.encoder.layer.1.attention.self.query.weight", "bert.encoder.layer.1.attention.self.query.bias", "bert.encoder.layer.1.attention.self.key.weight", "bert.encoder.layer.1.attention.self.key.bias", "bert.encoder.layer.1.attention.self.value.weight", "bert.encoder.layer.1.attention.self.value.bias", "bert.encoder.layer.1.attention.output.dense.weight", "bert.encoder.layer.1.attention.output.dense.bias", "bert.encoder.layer.1.attention.output.LayerNorm.weight", "bert.encoder.layer.1.attention.output.LayerNorm.bias", "bert.encoder.layer.1.intermediate.dense.weight", "bert.encoder.layer.1.intermediate.dense.bias", "bert.encoder.layer.1.output.dense.weight", "bert.encoder.layer.1.output.dense.bias", "bert.encoder.layer.1.output.LayerNorm.weight", "bert.encoder.layer.1.output.LayerNorm.bias", "bert.encoder.layer.2.attention.self.query.weight", "bert.encoder.layer.2.attention.self.query.bias", "bert.encoder.layer.2.attention.self.key.weight", "bert.encoder.layer.2.attention.self.key.bias", "bert.encoder.layer.2.attention.self.value.weight", "bert.encoder.layer.2.attention.self.value.bias", "bert.encoder.layer.2.attention.output.dense.weight", "bert.encoder.layer.2.attention.output.dense.bias", "bert.encoder.layer.2.attention.output.LayerNorm.weight", "bert.encoder.layer.2.attention.output.LayerNorm.bias", "bert.encoder.layer.2.intermediate.dense.weight", "bert.encoder.layer.2.intermediate.dense.bias", "bert.encoder.layer.2.output.dense.weight", "bert.encoder.layer.2.output.dense.bias", "bert.encoder.layer.2.output.LayerNorm.weight", "bert.encoder.layer.2.output.LayerNorm.bias", "bert.encoder.layer.3.attention.self.query.weight", "bert.encoder.layer.3.attention.self.query.bias", "bert.encoder.layer.3.attention.self.key.weight", "bert.encoder.layer.3.attention.self.key.bias", "bert.encoder.layer.3.attention.self.value.weight", "bert.encoder.layer.3.attention.self.value.bias", "bert.encoder.layer.3.attention.output.dense.weight", "bert.encoder.layer.3.attention.output.dense.bias", "bert.encoder.layer.3.attention.output.LayerNorm.weight", "bert.encoder.layer.3.attention.output.LayerNorm.bias", "bert.encoder.layer.3.intermediate.dense.weight", "bert.encoder.layer.3.intermediate.dense.bias", "bert.encoder.layer.3.output.dense.weight", "bert.encoder.layer.3.output.dense.bias", "bert.encoder.layer.3.output.LayerNorm.weight", "bert.encoder.layer.3.output.LayerNorm.bias", "bert.encoder.layer.4.attention.self.query.weight", "bert.encoder.layer.4.attention.self.query.bias", "bert.encoder.layer.4.attention.self.key.weight", "bert.encoder.layer.4.attention.self.key.bias", "bert.encoder.layer.4.attention.self.value.weight", "bert.encoder.layer.4.attention.self.value.bias", "bert.encoder.layer.4.attention.output.dense.weight", "bert.encoder.layer.4.attention.output.dense.bias", "bert.encoder.layer.4.attention.output.LayerNorm.weight", "bert.encoder.layer.4.attention.output.LayerNorm.bias", "bert.encoder.layer.4.intermediate.dense.weight", "bert.encoder.layer.4.intermediate.dense.bias", "bert.encoder.layer.4.output.dense.weight", "bert.encoder.layer.4.output.dense.bias", "bert.encoder.layer.4.output.LayerNorm.weight", "bert.encoder.layer.4.output.LayerNorm.bias", "bert.encoder.layer.5.attention.self.query.weight", "bert.encoder.layer.5.attention.self.query.bias", "bert.encoder.layer.5.attention.self.key.weight", "bert.encoder.layer.5.attention.self.key.bias", "bert.encoder.layer.5.attention.self.value.weight", "bert.encoder.layer.5.attention.self.value.bias", "bert.encoder.layer.5.attention.output.dense.weight", "bert.encoder.layer.5.attention.output.dense.bias", "bert.encoder.layer.5.attention.output.LayerNorm.weight", "bert.encoder.layer.5.attention.output.LayerNorm.bias", "bert.encoder.layer.5.intermediate.dense.weight", "bert.encoder.layer.5.intermediate.dense.bias", "bert.encoder.layer.5.output.dense.weight", "bert.encoder.layer.5.output.dense.bias", "bert.encoder.layer.5.output.LayerNorm.weight", "bert.encoder.layer.5.output.LayerNorm.bias", "bert.encoder.layer.6.attention.self.query.weight", "bert.encoder.layer.6.attention.self.query.bias", "bert.encoder.layer.6.attention.self.key.weight", "bert.encoder.layer.6.attention.self.key.bias", "bert.encoder.layer.6.attention.self.value.weight", "bert.encoder.layer.6.attention.self.value.bias", "bert.encoder.layer.6.attention.output.dense.weight", "bert.encoder.layer.6.attention.output.dense.bias", "bert.encoder.layer.6.attention.output.LayerNorm.weight", "bert.encoder.layer.6.attention.output.LayerNorm.bias", "bert.encoder.layer.6.intermediate.dense.weight", "bert.encoder.layer.6.intermediate.dense.bias", "bert.encoder.layer.6.output.dense.weight", "bert.encoder.layer.6.output.dense.bias", "bert.encoder.layer.6.output.LayerNorm.weight", "bert.encoder.layer.6.output.LayerNorm.bias", "bert.encoder.layer.7.attention.self.query.weight", "bert.encoder.layer.7.attention.self.query.bias", "bert.encoder.layer.7.attention.self.key.weight", "bert.encoder.layer.7.attention.self.key.bias", "bert.encoder.layer.7.attention.self.value.weight", "bert.encoder.layer.7.attention.self.value.bias", "bert.encoder.layer.7.attention.output.dense.weight", "bert.encoder.layer.7.attention.output.dense.bias", "bert.encoder.layer.7.attention.output.LayerNorm.weight", "bert.encoder.layer.7.attention.output.LayerNorm.bias", "bert.encoder.layer.7.intermediate.dense.weight", "bert.encoder.layer.7.intermediate.dense.bias", "bert.encoder.layer.7.output.dense.weight", "bert.encoder.layer.7.output.dense.bias", "bert.encoder.layer.7.output.LayerNorm.weight", "bert.encoder.layer.7.output.LayerNorm.bias", "bert.encoder.layer.8.attention.self.query.weight", "bert.encoder.layer.8.attention.self.query.bias", "bert.encoder.layer.8.attention.self.key.weight", "bert.encoder.layer.8.attention.self.key.bias", "bert.encoder.layer.8.attention.self.value.weight", "bert.encoder.layer.8.attention.self.value.bias", "bert.encoder.layer.8.attention.output.dense.weight", "bert.encoder.layer.8.attention.output.dense.bias", "bert.encoder.layer.8.attention.output.LayerNorm.weight", "bert.encoder.layer.8.attention.output.LayerNorm.bias", "bert.encoder.layer.8.intermediate.dense.weight", "bert.encoder.layer.8.intermediate.dense.bias", "bert.encoder.layer.8.output.dense.weight", "bert.encoder.layer.8.output.dense.bias", "bert.encoder.layer.8.output.LayerNorm.weight", "bert.encoder.layer.8.output.LayerNorm.bias", "bert.encoder.layer.9.attention.self.query.weight", "bert.encoder.layer.9.attention.self.query.bias", "bert.encoder.layer.9.attention.self.key.weight", "bert.encoder.layer.9.attention.self.key.bias", "bert.encoder.layer.9.attention.self.value.weight", "bert.encoder.layer.9.attention.self.value.bias", "bert.encoder.layer.9.attention.output.dense.weight", "bert.encoder.layer.9.attention.output.dense.bias", "bert.encoder.layer.9.attention.output.LayerNorm.weight", "bert.encoder.layer.9.attention.output.LayerNorm.bias", "bert.encoder.layer.9.intermediate.dense.weight", "bert.encoder.layer.9.intermediate.dense.bias", "bert.encoder.layer.9.output.dense.weight", "bert.encoder.layer.9.output.dense.bias", "bert.encoder.layer.9.output.LayerNorm.weight", "bert.encoder.layer.9.output.LayerNorm.bias", "bert.encoder.layer.10.attention.self.query.weight", "bert.encoder.layer.10.attention.self.query.bias", "bert.encoder.layer.10.attention.self.key.weight", "bert.encoder.layer.10.attention.self.key.bias", "bert.encoder.layer.10.attention.self.value.weight", "bert.encoder.layer.10.attention.self.value.bias", "bert.encoder.layer.10.attention.output.dense.weight", "bert.encoder.layer.10.attention.output.dense.bias", "bert.encoder.layer.10.attention.output.LayerNorm.weight", "bert.encoder.layer.10.attention.output.LayerNorm.bias", "bert.encoder.layer.10.intermediate.dense.weight", "bert.encoder.layer.10.intermediate.dense.bias", "bert.encoder.layer.10.output.dense.weight", "bert.encoder.layer.10.output.dense.bias", "bert.encoder.layer.10.output.LayerNorm.weight", "bert.encoder.layer.10.output.LayerNorm.bias", "bert.encoder.layer.11.attention.self.query.weight", "bert.encoder.layer.11.attention.self.query.bias", "bert.encoder.layer.11.attention.self.key.weight", "bert.encoder.layer.11.attention.self.key.bias", "bert.encoder.layer.11.attention.self.value.weight", "bert.encoder.layer.11.attention.self.value.bias", "bert.encoder.layer.11.attention.output.dense.weight", "bert.encoder.layer.11.attention.output.dense.bias", "bert.encoder.layer.11.attention.output.LayerNorm.weight", "bert.encoder.layer.11.attention.output.LayerNorm.bias", "bert.encoder.layer.11.intermediate.dense.weight", "bert.encoder.layer.11.intermediate.dense.bias", "bert.encoder.layer.11.output.dense.weight", "bert.encoder.layer.11.output.dense.bias", "bert.encoder.layer.11.output.LayerNorm.weight", "bert.encoder.layer.11.output.LayerNorm.bias", "bert.encoder.layer.12.attention.self.query.weight", "bert.encoder.layer.12.attention.self.query.bias", "bert.encoder.layer.12.attention.self.key.weight", "bert.encoder.layer.12.attention.self.key.bias", "bert.encoder.layer.12.attention.self.value.weight", "bert.encoder.layer.12.attention.self.value.bias", "bert.encoder.layer.12.attention.output.dense.weight", "bert.encoder.layer.12.attention.output.dense.bias", "bert.encoder.layer.12.attention.output.LayerNorm.weight", "bert.encoder.layer.12.attention.output.LayerNorm.bias", "bert.encoder.layer.12.intermediate.dense.weight", "bert.encoder.layer.12.intermediate.dense.bias", "bert.encoder.layer.12.output.dense.weight", "bert.encoder.layer.12.output.dense.bias", "bert.encoder.layer.12.output.LayerNorm.weight", "bert.encoder.layer.12.output.LayerNorm.bias", "bert.encoder.layer.13.attention.self.query.weight", "bert.encoder.layer.13.attention.self.query.bias", "bert.encoder.layer.13.attention.self.key.weight", "bert.encoder.layer.13.attention.self.key.bias", "bert.encoder.layer.13.attention.self.value.weight", "bert.encoder.layer.13.attention.self.value.bias", "bert.encoder.layer.13.attention.output.dense.weight", "bert.encoder.layer.13.attention.output.dense.bias", "bert.encoder.layer.13.attention.output.LayerNorm.weight", "bert.encoder.layer.13.attention.output.LayerNorm.bias", "bert.encoder.layer.13.intermediate.dense.weight", "bert.encoder.layer.13.intermediate.dense.bias", "bert.encoder.layer.13.output.dense.weight", "bert.encoder.layer.13.output.dense.bias", "bert.encoder.layer.13.output.LayerNorm.weight", "bert.encoder.layer.13.output.LayerNorm.bias", "bert.encoder.layer.14.attention.self.query.weight", "bert.encoder.layer.14.attention.self.query.bias", "bert.encoder.layer.14.attention.self.key.weight", "bert.encoder.layer.14.attention.self.key.bias", "bert.encoder.layer.14.attention.self.value.weight", "bert.encoder.layer.14.attention.self.value.bias", "bert.encoder.layer.14.attention.output.dense.weight", "bert.encoder.layer.14.attention.output.dense.bias", "bert.encoder.layer.14.attention.output.LayerNorm.weight", "bert.encoder.layer.14.attention.output.LayerNorm.bias", "bert.encoder.layer.14.intermediate.dense.weight", "bert.encoder.layer.14.intermediate.dense.bias", "bert.encoder.layer.14.output.dense.weight", "bert.encoder.layer.14.output.dense.bias", "bert.encoder.layer.14.output.LayerNorm.weight", "bert.encoder.layer.14.output.LayerNorm.bias", "bert.encoder.layer.15.attention.self.query.weight", "bert.encoder.layer.15.attention.self.query.bias", "bert.encoder.layer.15.attention.self.key.weight", "bert.encoder.layer.15.attention.self.key.bias", "bert.encoder.layer.15.attention.self.value.weight", "bert.encoder.layer.15.attention.self.value.bias", "bert.encoder.layer.15.attention.output.dense.weight", "bert.encoder.layer.15.attention.output.dense.bias", "bert.encoder.layer.15.attention.output.LayerNorm.weight", "bert.encoder.layer.15.attention.output.LayerNorm.bias", "bert.encoder.layer.15.intermediate.dense.weight", "bert.encoder.layer.15.intermediate.dense.bias", "bert.encoder.layer.15.output.dense.weight", "bert.encoder.layer.15.output.dense.bias", "bert.encoder.layer.15.output.LayerNorm.weight", "bert.encoder.layer.15.output.LayerNorm.bias", "bert.encoder.layer.16.attention.self.query.weight", "bert.encoder.layer.16.attention.self.query.bias", "bert.encoder.layer.16.attention.self.key.weight", "bert.encoder.layer.16.attention.self.key.bias", "bert.encoder.layer.16.attention.self.value.weight", "bert.encoder.layer.16.attention.self.value.bias", "bert.encoder.layer.16.attention.output.dense.weight", "bert.encoder.layer.16.attention.output.dense.bias", "bert.encoder.layer.16.attention.output.LayerNorm.weight", "bert.encoder.layer.16.attention.output.LayerNorm.bias", "bert.encoder.layer.16.intermediate.dense.weight", "bert.encoder.layer.16.intermediate.dense.bias", "bert.encoder.layer.16.output.dense.weight", "bert.encoder.layer.16.output.dense.bias", "bert.encoder.layer.16.output.LayerNorm.weight", "bert.encoder.layer.16.output.LayerNorm.bias", "bert.encoder.layer.17.attention.self.query.weight", "bert.encoder.layer.17.attention.self.query.bias", "bert.encoder.layer.17.attention.self.key.weight", "bert.encoder.layer.17.attention.self.key.bias", "bert.encoder.layer.17.attention.self.value.weight", "bert.encoder.layer.17.attention.self.value.bias", "bert.encoder.layer.17.attention.output.dense.weight", "bert.encoder.layer.17.attention.output.dense.bias", "bert.encoder.layer.17.attention.output.LayerNorm.weight", "bert.encoder.layer.17.attention.output.LayerNorm.bias", "bert.encoder.layer.17.intermediate.dense.weight", "bert.encoder.layer.17.intermediate.dense.bias", "bert.encoder.layer.17.output.dense.weight", "bert.encoder.layer.17.output.dense.bias", "bert.encoder.layer.17.output.LayerNorm.weight", "bert.encoder.layer.17.output.LayerNorm.bias", "bert.encoder.layer.18.attention.self.query.weight", "bert.encoder.layer.18.attention.self.query.bias", "bert.encoder.layer.18.attention.self.key.weight", "bert.encoder.layer.18.attention.self.key.bias", "bert.encoder.layer.18.attention.self.value.weight", "bert.encoder.layer.18.attention.self.value.bias", "bert.encoder.layer.18.attention.output.dense.weight", "bert.encoder.layer.18.attention.output.dense.bias", "bert.encoder.layer.18.attention.output.LayerNorm.weight", "bert.encoder.layer.18.attention.output.LayerNorm.bias", "bert.encoder.layer.18.intermediate.dense.weight", "bert.encoder.layer.18.intermediate.dense.bias", "bert.encoder.layer.18.output.dense.weight", "bert.encoder.layer.18.output.dense.bias", "bert.encoder.layer.18.output.LayerNorm.weight", "bert.encoder.layer.18.output.LayerNorm.bias", "bert.encoder.layer.19.attention.self.query.weight", "bert.encoder.layer.19.attention.self.query.bias", "bert.encoder.layer.19.attention.self.key.weight", "bert.encoder.layer.19.attention.self.key.bias", "bert.encoder.layer.19.attention.self.value.weight", "bert.encoder.layer.19.attention.self.value.bias", "bert.encoder.layer.19.attention.output.dense.weight", "bert.encoder.layer.19.attention.output.dense.bias", "bert.encoder.layer.19.attention.output.LayerNorm.weight", "bert.encoder.layer.19.attention.output.LayerNorm.bias", "bert.encoder.layer.19.intermediate.dense.weight", "bert.encoder.layer.19.intermediate.dense.bias", "bert.encoder.layer.19.output.dense.weight", "bert.encoder.layer.19.output.dense.bias", "bert.encoder.layer.19.output.LayerNorm.weight", "bert.encoder.layer.19.output.LayerNorm.bias", "bert.encoder.layer.20.attention.self.query.weight", "bert.encoder.layer.20.attention.self.query.bias", "bert.encoder.layer.20.attention.self.key.weight", "bert.encoder.layer.20.attention.self.key.bias", "bert.encoder.layer.20.attention.self.value.weight", "bert.encoder.layer.20.attention.self.value.bias", "bert.encoder.layer.20.attention.output.dense.weight", "bert.encoder.layer.20.attention.output.dense.bias", "bert.encoder.layer.20.attention.output.LayerNorm.weight", "bert.encoder.layer.20.attention.output.LayerNorm.bias", "bert.encoder.layer.20.intermediate.dense.weight", "bert.encoder.layer.20.intermediate.dense.bias", "bert.encoder.layer.20.output.dense.weight", "bert.encoder.layer.20.output.dense.bias", "bert.encoder.layer.20.output.LayerNorm.weight", "bert.encoder.layer.20.output.LayerNorm.bias", "bert.encoder.layer.21.attention.self.query.weight", "bert.encoder.layer.21.attention.self.query.bias", "bert.encoder.layer.21.attention.self.key.weight", "bert.encoder.layer.21.attention.self.key.bias", "bert.encoder.layer.21.attention.self.value.weight", "bert.encoder.layer.21.attention.self.value.bias", "bert.encoder.layer.21.attention.output.dense.weight", "bert.encoder.layer.21.attention.output.dense.bias", "bert.encoder.layer.21.attention.output.LayerNorm.weight", "bert.encoder.layer.21.attention.output.LayerNorm.bias", "bert.encoder.layer.21.intermediate.dense.weight", "bert.encoder.layer.21.intermediate.dense.bias", "bert.encoder.layer.21.output.dense.weight", "bert.encoder.layer.21.output.dense.bias", "bert.encoder.layer.21.output.LayerNorm.weight", "bert.encoder.layer.21.output.LayerNorm.bias", "bert.encoder.layer.22.attention.self.query.weight", "bert.encoder.layer.22.attention.self.query.bias", "bert.encoder.layer.22.attention.self.key.weight", "bert.encoder.layer.22.attention.self.key.bias", "bert.encoder.layer.22.attention.self.value.weight", "bert.encoder.layer.22.attention.self.value.bias", "bert.encoder.layer.22.attention.output.dense.weight", "bert.encoder.layer.22.attention.output.dense.bias", "bert.encoder.layer.22.attention.output.LayerNorm.weight", "bert.encoder.layer.22.attention.output.LayerNorm.bias", "bert.encoder.layer.22.intermediate.dense.weight", "bert.encoder.layer.22.intermediate.dense.bias", "bert.encoder.layer.22.output.dense.weight", "bert.encoder.layer.22.output.dense.bias", "bert.encoder.layer.22.output.LayerNorm.weight", "bert.encoder.layer.22.output.LayerNorm.bias", "bert.encoder.layer.23.attention.self.query.weight", "bert.encoder.layer.23.attention.self.query.bias", "bert.encoder.layer.23.attention.self.key.weight", "bert.encoder.layer.23.attention.self.key.bias", "bert.encoder.layer.23.attention.self.value.weight", "bert.encoder.layer.23.attention.self.value.bias", "bert.encoder.layer.23.attention.output.dense.weight", "bert.encoder.layer.23.attention.output.dense.bias", "bert.encoder.layer.23.attention.output.LayerNorm.weight", "bert.encoder.layer.23.attention.output.LayerNorm.bias", "bert.encoder.layer.23.intermediate.dense.weight", "bert.encoder.layer.23.intermediate.dense.bias", "bert.encoder.layer.23.output.dense.weight", "bert.encoder.layer.23.output.dense.bias", "bert.encoder.layer.23.output.LayerNorm.weight", "bert.encoder.layer.23.output.LayerNorm.bias", "classifier.layers.0.weight", "classifier.layers.0.bias", "classifier.layers.1.projection.weight", "classifier.layers.1.projection.bias", "classifier.layers.3.weight", "classifier.layers.3.bias", "classifier.layers.4.projection.weight", "classifier.layers.4.projection.bias", "classifier.layers.6.weight", "classifier.layers.6.bias". 
	Unexpected key(s) in state_dict: "layers.0.weight", "layers.0.bias", "layers.1.projection.weight", "layers.1.projection.bias", "layers.3.weight", "layers.3.bias", "layers.4.projection.weight", "layers.4.projection.bias", "layers.6.weight", "layers.6.bias". An error occurred during training: Error(s) in loading state_dict for BERTClassifier:
	Missing key(s) in state_dict: "bert.embeddings.word_embeddings.weight", "bert.embeddings.position_embeddings.weight", "bert.embeddings.token_type_embeddings.weight", "bert.embeddings.LayerNorm.weight", "bert.embeddings.LayerNorm.bias", "bert.encoder.layer.0.attention.self.query.weight", "bert.encoder.layer.0.attention.self.query.bias", "bert.encoder.layer.0.attention.self.key.weight", "bert.encoder.layer.0.attention.self.key.bias", "bert.encoder.layer.0.attention.self.value.weight", "bert.encoder.layer.0.attention.self.value.bias", "bert.encoder.layer.0.attention.output.dense.weight", "bert.encoder.layer.0.attention.output.dense.bias", "bert.encoder.layer.0.attention.output.LayerNorm.weight", "bert.encoder.layer.0.attention.output.LayerNorm.bias", "bert.encoder.layer.0.intermediate.dense.weight", "bert.encoder.layer.0.intermediate.dense.bias", "bert.encoder.layer.0.output.dense.weight", "bert.encoder.layer.0.output.dense.bias", "bert.encoder.layer.0.output.LayerNorm.weight", "bert.encoder.layer.0.output.LayerNorm.bias", "bert.encoder.layer.1.attention.self.query.weight", "bert.encoder.layer.1.attention.self.query.bias", "bert.encoder.layer.1.attention.self.key.weight", "bert.encoder.layer.1.attention.self.key.bias", "bert.encoder.layer.1.attention.self.value.weight", "bert.encoder.layer.1.attention.self.value.bias", "bert.encoder.layer.1.attention.output.dense.weight", "bert.encoder.layer.1.attention.output.dense.bias", "bert.encoder.layer.1.attention.output.LayerNorm.weight", "bert.encoder.layer.1.attention.output.LayerNorm.bias", "bert.encoder.layer.1.intermediate.dense.weight", "bert.encoder.layer.1.intermediate.dense.bias", "bert.encoder.layer.1.output.dense.weight", "bert.encoder.layer.1.output.dense.bias", "bert.encoder.layer.1.output.LayerNorm.weight", "bert.encoder.layer.1.output.LayerNorm.bias", "bert.encoder.layer.2.attention.self.query.weight", "bert.encoder.layer.2.attention.self.query.bias", "bert.encoder.layer.2.attention.self.key.weight", "bert.encoder.layer.2.attention.self.key.bias", "bert.encoder.layer.2.attention.self.value.weight", "bert.encoder.layer.2.attention.self.value.bias", "bert.encoder.layer.2.attention.output.dense.weight", "bert.encoder.layer.2.attention.output.dense.bias", "bert.encoder.layer.2.attention.output.LayerNorm.weight", "bert.encoder.layer.2.attention.output.LayerNorm.bias", "bert.encoder.layer.2.intermediate.dense.weight", "bert.encoder.layer.2.intermediate.dense.bias", "bert.encoder.layer.2.output.dense.weight", "bert.encoder.layer.2.output.dense.bias", "bert.encoder.layer.2.output.LayerNorm.weight", "bert.encoder.layer.2.output.LayerNorm.bias", "bert.encoder.layer.3.attention.self.query.weight", "bert.encoder.layer.3.attention.self.query.bias", "bert.encoder.layer.3.attention.self.key.weight", "bert.encoder.layer.3.attention.self.key.bias", "bert.encoder.layer.3.attention.self.value.weight", "bert.encoder.layer.3.attention.self.value.bias", "bert.encoder.layer.3.attention.output.dense.weight", "bert.encoder.layer.3.attention.output.dense.bias", "bert.encoder.layer.3.attention.output.LayerNorm.weight", "bert.encoder.layer.3.attention.output.LayerNorm.bias", "bert.encoder.layer.3.intermediate.dense.weight", "bert.encoder.layer.3.intermediate.dense.bias", "bert.encoder.layer.3.output.dense.weight", "bert.encoder.layer.3.output.dense.bias", "bert.encoder.layer.3.output.LayerNorm.weight", "bert.encoder.layer.3.output.LayerNorm.bias", "bert.encoder.layer.4.attention.self.query.weight", "bert.encoder.layer.4.attention.self.query.bias", "bert.encoder.layer.4.attention.self.key.weight", "bert.encoder.layer.4.attention.self.key.bias", "bert.encoder.layer.4.attention.self.value.weight", "bert.encoder.layer.4.attention.self.value.bias", "bert.encoder.layer.4.attention.output.dense.weight", "bert.encoder.layer.4.attention.output.dense.bias", "bert.encoder.layer.4.attention.output.LayerNorm.weight", "bert.encoder.layer.4.attention.output.LayerNorm.bias", "bert.encoder.layer.4.intermediate.dense.weight", "bert.encoder.layer.4.intermediate.dense.bias", "bert.encoder.layer.4.output.dense.weight", "bert.encoder.layer.4.output.dense.bias", "bert.encoder.layer.4.output.LayerNorm.weight", "bert.encoder.layer.4.output.LayerNorm.bias", "bert.encoder.layer.5.attention.self.query.weight", "bert.encoder.layer.5.attention.self.query.bias", "bert.encoder.layer.5.attention.self.key.weight", "bert.encoder.layer.5.attention.self.key.bias", "bert.encoder.layer.5.attention.self.value.weight", "bert.encoder.layer.5.attention.self.value.bias", "bert.encoder.layer.5.attention.output.dense.weight", "bert.encoder.layer.5.attention.output.dense.bias", "bert.encoder.layer.5.attention.output.LayerNorm.weight", "bert.encoder.layer.5.attention.output.LayerNorm.bias", "bert.encoder.layer.5.intermediate.dense.weight", "bert.encoder.layer.5.intermediate.dense.bias", "bert.encoder.layer.5.output.dense.weight", "bert.encoder.layer.5.output.dense.bias", "bert.encoder.layer.5.output.LayerNorm.weight", "bert.encoder.layer.5.output.LayerNorm.bias", "bert.encoder.layer.6.attention.self.query.weight", "bert.encoder.layer.6.attention.self.query.bias", "bert.encoder.layer.6.attention.self.key.weight", "bert.encoder.layer.6.attention.self.key.bias", "bert.encoder.layer.6.attention.self.value.weight", "bert.encoder.layer.6.attention.self.value.bias", "bert.encoder.layer.6.attention.output.dense.weight", "bert.encoder.layer.6.attention.output.dense.bias", "bert.encoder.layer.6.attention.output.LayerNorm.weight", "bert.encoder.layer.6.attention.output.LayerNorm.bias", "bert.encoder.layer.6.intermediate.dense.weight", "bert.encoder.layer.6.intermediate.dense.bias", "bert.encoder.layer.6.output.dense.weight", "bert.encoder.layer.6.output.dense.bias", "bert.encoder.layer.6.output.LayerNorm.weight", "bert.encoder.layer.6.output.LayerNorm.bias", "bert.encoder.layer.7.attention.self.query.weight", "bert.encoder.layer.7.attention.self.query.bias", "bert.encoder.layer.7.attention.self.key.weight", "bert.encoder.layer.7.attention.self.key.bias", "bert.encoder.layer.7.attention.self.value.weight", "bert.encoder.layer.7.attention.self.value.bias", "bert.encoder.layer.7.attention.output.dense.weight", "bert.encoder.layer.7.attention.output.dense.bias", "bert.encoder.layer.7.attention.output.LayerNorm.weight", "bert.encoder.layer.7.attention.output.LayerNorm.bias", "bert.encoder.layer.7.intermediate.dense.weight", "bert.encoder.layer.7.intermediate.dense.bias", "bert.encoder.layer.7.output.dense.weight", "bert.encoder.layer.7.output.dense.bias", "bert.encoder.layer.7.output.LayerNorm.weight", "bert.encoder.layer.7.output.LayerNorm.bias", "bert.encoder.layer.8.attention.self.query.weight", "bert.encoder.layer.8.attention.self.query.bias", "bert.encoder.layer.8.attention.self.key.weight", "bert.encoder.layer.8.attention.self.key.bias", "bert.encoder.layer.8.attention.self.value.weight", "bert.encoder.layer.8.attention.self.value.bias", "bert.encoder.layer.8.attention.output.dense.weight", "bert.encoder.layer.8.attention.output.dense.bias", "bert.encoder.layer.8.attention.output.LayerNorm.weight", "bert.encoder.layer.8.attention.output.LayerNorm.bias", "bert.encoder.layer.8.intermediate.dense.weight", "bert.encoder.layer.8.intermediate.dense.bias", "bert.encoder.layer.8.output.dense.weight", "bert.encoder.layer.8.output.dense.bias", "bert.encoder.layer.8.output.LayerNorm.weight", "bert.encoder.layer.8.output.LayerNorm.bias", "bert.encoder.layer.9.attention.self.query.weight", "bert.encoder.layer.9.attention.self.query.bias", "bert.encoder.layer.9.attention.self.key.weight", "bert.encoder.layer.9.attention.self.key.bias", "bert.encoder.layer.9.attention.self.value.weight", "bert.encoder.layer.9.attention.self.value.bias", "bert.encoder.layer.9.attention.output.dense.weight", "bert.encoder.layer.9.attention.output.dense.bias", "bert.encoder.layer.9.attention.output.LayerNorm.weight", "bert.encoder.layer.9.attention.output.LayerNorm.bias", "bert.encoder.layer.9.intermediate.dense.weight", "bert.encoder.layer.9.intermediate.dense.bias", "bert.encoder.layer.9.output.dense.weight", "bert.encoder.layer.9.output.dense.bias", "bert.encoder.layer.9.output.LayerNorm.weight", "bert.encoder.layer.9.output.LayerNorm.bias", "bert.encoder.layer.10.attention.self.query.weight", "bert.encoder.layer.10.attention.self.query.bias", "bert.encoder.layer.10.attention.self.key.weight", "bert.encoder.layer.10.attention.self.key.bias", "bert.encoder.layer.10.attention.self.value.weight", "bert.encoder.layer.10.attention.self.value.bias", "bert.encoder.layer.10.attention.output.dense.weight", "bert.encoder.layer.10.attention.output.dense.bias", "bert.encoder.layer.10.attention.output.LayerNorm.weight", "bert.encoder.layer.10.attention.output.LayerNorm.bias", "bert.encoder.layer.10.intermediate.dense.weight", "bert.encoder.layer.10.intermediate.dense.bias", "bert.encoder.layer.10.output.dense.weight", "bert.encoder.layer.10.output.dense.bias", "bert.encoder.layer.10.output.LayerNorm.weight", "bert.encoder.layer.10.output.LayerNorm.bias", "bert.encoder.layer.11.attention.self.query.weight", "bert.encoder.layer.11.attention.self.query.bias", "bert.encoder.layer.11.attention.self.key.weight", "bert.encoder.layer.11.attention.self.key.bias", "bert.encoder.layer.11.attention.self.value.weight", "bert.encoder.layer.11.attention.self.value.bias", "bert.encoder.layer.11.attention.output.dense.weight", "bert.encoder.layer.11.attention.output.dense.bias", "bert.encoder.layer.11.attention.output.LayerNorm.weight", "bert.encoder.layer.11.attention.output.LayerNorm.bias", "bert.encoder.layer.11.intermediate.dense.weight", "bert.encoder.layer.11.intermediate.dense.bias", "bert.encoder.layer.11.output.dense.weight", "bert.encoder.layer.11.output.dense.bias", "bert.encoder.layer.11.output.LayerNorm.weight", "bert.encoder.layer.11.output.LayerNorm.bias", "bert.encoder.layer.12.attention.self.query.weight", "bert.encoder.layer.12.attention.self.query.bias", "bert.encoder.layer.12.attention.self.key.weight", "bert.encoder.layer.12.attention.self.key.bias", "bert.encoder.layer.12.attention.self.value.weight", "bert.encoder.layer.12.attention.self.value.bias", "bert.encoder.layer.12.attention.output.dense.weight", "bert.encoder.layer.12.attention.output.dense.bias", "bert.encoder.layer.12.attention.output.LayerNorm.weight", "bert.encoder.layer.12.attention.output.LayerNorm.bias", "bert.encoder.layer.12.intermediate.dense.weight", "bert.encoder.layer.12.intermediate.dense.bias", "bert.encoder.layer.12.output.dense.weight", "bert.encoder.layer.12.output.dense.bias", "bert.encoder.layer.12.output.LayerNorm.weight", "bert.encoder.layer.12.output.LayerNorm.bias", "bert.encoder.layer.13.attention.self.query.weight", "bert.encoder.layer.13.attention.self.query.bias", "bert.encoder.layer.13.attention.self.key.weight", "bert.encoder.layer.13.attention.self.key.bias", "bert.encoder.layer.13.attention.self.value.weight", "bert.encoder.layer.13.attention.self.value.bias", "bert.encoder.layer.13.attention.output.dense.weight", "bert.encoder.layer.13.attention.output.dense.bias", "bert.encoder.layer.13.attention.output.LayerNorm.weight", "bert.encoder.layer.13.attention.output.LayerNorm.bias", "bert.encoder.layer.13.intermediate.dense.weight", "bert.encoder.layer.13.intermediate.dense.bias", "bert.encoder.layer.13.output.dense.weight", "bert.encoder.layer.13.output.dense.bias", "bert.encoder.layer.13.output.LayerNorm.weight", "bert.encoder.layer.13.output.LayerNorm.bias", "bert.encoder.layer.14.attention.self.query.weight", "bert.encoder.layer.14.attention.self.query.bias", "bert.encoder.layer.14.attention.self.key.weight", "bert.encoder.layer.14.attention.self.key.bias", "bert.encoder.layer.14.attention.self.value.weight", "bert.encoder.layer.14.attention.self.value.bias", "bert.encoder.layer.14.attention.output.dense.weight", "bert.encoder.layer.14.attention.output.dense.bias", "bert.encoder.layer.14.attention.output.LayerNorm.weight", "bert.encoder.layer.14.attention.output.LayerNorm.bias", "bert.encoder.layer.14.intermediate.dense.weight", "bert.encoder.layer.14.intermediate.dense.bias", "bert.encoder.layer.14.output.dense.weight", "bert.encoder.layer.14.output.dense.bias", "bert.encoder.layer.14.output.LayerNorm.weight", "bert.encoder.layer.14.output.LayerNorm.bias", "bert.encoder.layer.15.attention.self.query.weight", "bert.encoder.layer.15.attention.self.query.bias", "bert.encoder.layer.15.attention.self.key.weight", "bert.encoder.layer.15.attention.self.key.bias", "bert.encoder.layer.15.attention.self.value.weight", "bert.encoder.layer.15.attention.self.value.bias", "bert.encoder.layer.15.attention.output.dense.weight", "bert.encoder.layer.15.attention.output.dense.bias", "bert.encoder.layer.15.attention.output.LayerNorm.weight", "bert.encoder.layer.15.attention.output.LayerNorm.bias", "bert.encoder.layer.15.intermediate.dense.weight", "bert.encoder.layer.15.intermediate.dense.bias", "bert.encoder.layer.15.output.dense.weight", "bert.encoder.layer.15.output.dense.bias", "bert.encoder.layer.15.output.LayerNorm.weight", "bert.encoder.layer.15.output.LayerNorm.bias", "bert.encoder.layer.16.attention.self.query.weight", "bert.encoder.layer.16.attention.self.query.bias", "bert.encoder.layer.16.attention.self.key.weight", "bert.encoder.layer.16.attention.self.key.bias", "bert.encoder.layer.16.attention.self.value.weight", "bert.encoder.layer.16.attention.self.value.bias", "bert.encoder.layer.16.attention.output.dense.weight", "bert.encoder.layer.16.attention.output.dense.bias", "bert.encoder.layer.16.attention.output.LayerNorm.weight", "bert.encoder.layer.16.attention.output.LayerNorm.bias", "bert.encoder.layer.16.intermediate.dense.weight", "bert.encoder.layer.16.intermediate.dense.bias", "bert.encoder.layer.16.output.dense.weight", "bert.encoder.layer.16.output.dense.bias", "bert.encoder.layer.16.output.LayerNorm.weight", "bert.encoder.layer.16.output.LayerNorm.bias", "bert.encoder.layer.17.attention.self.query.weight", "bert.encoder.layer.17.attention.self.query.bias", "bert.encoder.layer.17.attention.self.key.weight", "bert.encoder.layer.17.attention.self.key.bias", "bert.encoder.layer.17.attention.self.value.weight", "bert.encoder.layer.17.attention.self.value.bias", "bert.encoder.layer.17.attention.output.dense.weight", "bert.encoder.layer.17.attention.output.dense.bias", "bert.encoder.layer.17.attention.output.LayerNorm.weight", "bert.encoder.layer.17.attention.output.LayerNorm.bias", "bert.encoder.layer.17.intermediate.dense.weight", "bert.encoder.layer.17.intermediate.dense.bias", "bert.encoder.layer.17.output.dense.weight", "bert.encoder.layer.17.output.dense.bias", "bert.encoder.layer.17.output.LayerNorm.weight", "bert.encoder.layer.17.output.LayerNorm.bias", "bert.encoder.layer.18.attention.self.query.weight", "bert.encoder.layer.18.attention.self.query.bias", "bert.encoder.layer.18.attention.self.key.weight", "bert.encoder.layer.18.attention.self.key.bias", "bert.encoder.layer.18.attention.self.value.weight", "bert.encoder.layer.18.attention.self.value.bias", "bert.encoder.layer.18.attention.output.dense.weight", "bert.encoder.layer.18.attention.output.dense.bias", "bert.encoder.layer.18.attention.output.LayerNorm.weight", "bert.encoder.layer.18.attention.output.LayerNorm.bias", "bert.encoder.layer.18.intermediate.dense.weight", "bert.encoder.layer.18.intermediate.dense.bias", "bert.encoder.layer.18.output.dense.weight", "bert.encoder.layer.18.output.dense.bias", "bert.encoder.layer.18.output.LayerNorm.weight", "bert.encoder.layer.18.output.LayerNorm.bias", "bert.encoder.layer.19.attention.self.query.weight", "bert.encoder.layer.19.attention.self.query.bias", "bert.encoder.layer.19.attention.self.key.weight", "bert.encoder.layer.19.attention.self.key.bias", "bert.encoder.layer.19.attention.self.value.weight", "bert.encoder.layer.19.attention.self.value.bias", "bert.encoder.layer.19.attention.output.dense.weight", "bert.encoder.layer.19.attention.output.dense.bias", "bert.encoder.layer.19.attention.output.LayerNorm.weight", "bert.encoder.layer.19.attention.output.LayerNorm.bias", "bert.encoder.layer.19.intermediate.dense.weight", "bert.encoder.layer.19.intermediate.dense.bias", "bert.encoder.layer.19.output.dense.weight", "bert.encoder.layer.19.output.dense.bias", "bert.encoder.layer.19.output.LayerNorm.weight", "bert.encoder.layer.19.output.LayerNorm.bias", "bert.encoder.layer.20.attention.self.query.weight", "bert.encoder.layer.20.attention.self.query.bias", "bert.encoder.layer.20.attention.self.key.weight", "bert.encoder.layer.20.attention.self.key.bias", "bert.encoder.layer.20.attention.self.value.weight", "bert.encoder.layer.20.attention.self.value.bias", "bert.encoder.layer.20.attention.output.dense.weight", "bert.encoder.layer.20.attention.output.dense.bias", "bert.encoder.layer.20.attention.output.LayerNorm.weight", "bert.encoder.layer.20.attention.output.LayerNorm.bias", "bert.encoder.layer.20.intermediate.dense.weight", "bert.encoder.layer.20.intermediate.dense.bias", "bert.encoder.layer.20.output.dense.weight", "bert.encoder.layer.20.output.dense.bias", "bert.encoder.layer.20.output.LayerNorm.weight", "bert.encoder.layer.20.output.LayerNorm.bias", "bert.encoder.layer.21.attention.self.query.weight", "bert.encoder.layer.21.attention.self.query.bias", "bert.encoder.layer.21.attention.self.key.weight", "bert.encoder.layer.21.attention.self.key.bias", "bert.encoder.layer.21.attention.self.value.weight", "bert.encoder.layer.21.attention.self.value.bias", "bert.encoder.layer.21.attention.output.dense.weight", "bert.encoder.layer.21.attention.output.dense.bias", "bert.encoder.layer.21.attention.output.LayerNorm.weight", "bert.encoder.layer.21.attention.output.LayerNorm.bias", "bert.encoder.layer.21.intermediate.dense.weight", "bert.encoder.layer.21.intermediate.dense.bias", "bert.encoder.layer.21.output.dense.weight", "bert.encoder.layer.21.output.dense.bias", "bert.encoder.layer.21.output.LayerNorm.weight", "bert.encoder.layer.21.output.LayerNorm.bias", "bert.encoder.layer.22.attention.self.query.weight", "bert.encoder.layer.22.attention.self.query.bias", "bert.encoder.layer.22.attention.self.key.weight", "bert.encoder.layer.22.attention.self.key.bias", "bert.encoder.layer.22.attention.self.value.weight", "bert.encoder.layer.22.attention.self.value.bias", "bert.encoder.layer.22.attention.output.dense.weight", "bert.encoder.layer.22.attention.output.dense.bias", "bert.encoder.layer.22.attention.output.LayerNorm.weight", "bert.encoder.layer.22.attention.output.LayerNorm.bias", "bert.encoder.layer.22.intermediate.dense.weight", "bert.encoder.layer.22.intermediate.dense.bias", "bert.encoder.layer.22.output.dense.weight", "bert.encoder.layer.22.output.dense.bias", "bert.encoder.layer.22.output.LayerNorm.weight", "bert.encoder.layer.22.output.LayerNorm.bias", "bert.encoder.layer.23.attention.self.query.weight", "bert.encoder.layer.23.attention.self.query.bias", "bert.encoder.layer.23.attention.self.key.weight", "bert.encoder.layer.23.attention.self.key.bias", "bert.encoder.layer.23.attention.self.value.weight", "bert.encoder.layer.23.attention.self.value.bias", "bert.encoder.layer.23.attention.output.dense.weight", "bert.encoder.layer.23.attention.output.dense.bias", "bert.encoder.layer.23.attention.output.LayerNorm.weight", "bert.encoder.layer.23.attention.output.LayerNorm.bias", "bert.encoder.layer.23.intermediate.dense.weight", "bert.encoder.layer.23.intermediate.dense.bias", "bert.encoder.layer.23.output.dense.weight", "bert.encoder.layer.23.output.dense.bias", "bert.encoder.layer.23.output.LayerNorm.weight", "bert.encoder.layer.23.output.LayerNorm.bias", "classifier.layers.0.weight", "classifier.layers.0.bias", "classifier.layers.1.projection.weight", "classifier.layers.1.projection.bias", "classifier.layers.3.weight", "classifier.layers.3.bias", "classifier.layers.4.projection.weight", "classifier.layers.4.projection.bias", "classifier.layers.6.weight", "classifier.layers.6.bias". 
	Unexpected key(s) in state_dict: "layers.0.weight", "layers.0.bias", "layers.1.projection.weight", "layers.1.projection.bias", "layers.3.weight", "layers.3.bias", "layers.4.projection.weight", "layers.4.projection.bias", "layers.6.weight", "layers.6.bias". 



An error occurred during training: Error(s) in loading state_dict for BERTClassifier:
	Missing key(s) in state_dict: "bert.embeddings.word_embeddings.weight", "bert.embeddings.position_embeddings.weight", "bert.embeddings.token_type_embeddings.weight", "bert.embeddings.LayerNorm.weight", "bert.embeddings.LayerNorm.bias", "bert.encoder.layer.0.attention.self.query.weight", "bert.encoder.layer.0.attention.self.query.bias", "bert.encoder.layer.0.attention.self.key.weight", "bert.encoder.layer.0.attention.self.key.bias", "bert.encoder.layer.0.attention.self.value.weight", "bert.encoder.layer.0.attention.self.value.bias", "bert.encoder.layer.0.attention.output.dense.weight", "bert.encoder.layer.0.attention.output.dense.bias", "bert.encoder.layer.0.attention.output.LayerNorm.weight", "bert.encoder.layer.0.attention.output.LayerNorm.bias", "bert.encoder.layer.0.intermediate.dense.weight", "bert.encoder.layer.0.intermediate.dense.bias", "bert.encoder.layer.0.output.dense.weight", "bert.encoder.layer.0.output.dense.bias", "bert.encoder.layer.0.output.LayerNorm.weight", "bert.encoder.layer.0.output.LayerNorm.bias", "bert.encoder.layer.1.attention.self.query.weight", "bert.encoder.layer.1.attention.self.query.bias", "bert.encoder.layer.1.attention.self.key.weight", "bert.encoder.layer.1.attention.self.key.bias", "bert.encoder.layer.1.attention.self.value.weight", "bert.encoder.layer.1.attention.self.value.bias", "bert.encoder.layer.1.attention.output.dense.weight", "bert.encoder.layer.1.attention.output.dense.bias", "bert.encoder.layer.1.attention.output.LayerNorm.weight", "bert.encoder.layer.1.attention.output.LayerNorm.bias", "bert.encoder.layer.1.intermediate.dense.weight", "bert.encoder.layer.1.intermediate.dense.bias", "bert.encoder.layer.1.output.dense.weight", "bert.encoder.layer.1.output.dense.bias", "bert.encoder.layer.1.output.LayerNorm.weight", "bert.encoder.layer.1.output.LayerNorm.bias", "bert.encoder.layer.2.attention.self.query.weight", "bert.encoder.layer.2.attention.self.query.bias", "bert.encoder.layer.2.attention.self.key.weight", "bert.encoder.layer.2.attention.self.key.bias", "bert.encoder.layer.2.attention.self.value.weight", "bert.encoder.layer.2.attention.self.value.bias", "bert.encoder.layer.2.attention.output.dense.weight", "bert.encoder.layer.2.attention.output.dense.bias", "bert.encoder.layer.2.attention.output.LayerNorm.weight", "bert.encoder.layer.2.attention.output.LayerNorm.bias", "bert.encoder.layer.2.intermediate.dense.weight", "bert.encoder.layer.2.intermediate.dense.bias", "bert.encoder.layer.2.output.dense.weight", "bert.encoder.layer.2.output.dense.bias", "bert.encoder.layer.2.output.LayerNorm.weight", "bert.encoder.layer.2.output.LayerNorm.bias", "bert.encoder.layer.3.attention.self.query.weight", "bert.encoder.layer.3.attention.self.query.bias", "bert.encoder.layer.3.attention.self.key.weight", "bert.encoder.layer.3.attention.self.key.bias", "bert.encoder.layer.3.attention.self.value.weight", "bert.encoder.layer.3.attention.self.value.bias", "bert.encoder.layer.3.attention.output.dense.weight", "bert.encoder.layer.3.attention.output.dense.bias", "bert.encoder.layer.3.attention.output.LayerNorm.weight", "bert.encoder.layer.3.attention.output.LayerNorm.bias", "bert.encoder.layer.3.intermediate.dense.weight", "bert.encoder.layer.3.intermediate.dense.bias", "bert.encoder.layer.3.output.dense.weight", "bert.encoder.layer.3.output.dense.bias", "bert.encoder.layer.3.output.LayerNorm.weight", "bert.encoder.layer.3.output.LayerNorm.bias", "bert.encoder.layer.4.attention.self.query.weight", "bert.encoder.layer.4.attention.self.query.bias", "bert.encoder.layer.4.attention.self.key.weight", "bert.encoder.layer.4.attention.self.key.bias", "bert.encoder.layer.4.attention.self.value.weight", "bert.encoder.layer.4.attention.self.value.bias", "bert.encoder.layer.4.attention.output.dense.weight", "bert.encoder.layer.4.attention.output.dense.bias", "bert.encoder.layer.4.attention.output.LayerNorm.weight", "bert.encoder.layer.4.attention.output.LayerNorm.bias", "bert.encoder.layer.4.intermediate.dense.weight", "bert.encoder.layer.4.intermediate.dense.bias", "bert.encoder.layer.4.output.dense.weight", "bert.encoder.layer.4.output.dense.bias", "bert.encoder.layer.4.output.LayerNorm.weight", "bert.encoder.layer.4.output.LayerNorm.bias", "bert.encoder.layer.5.attention.self.query.weight", "bert.encoder.layer.5.attention.self.query.bias", "bert.encoder.layer.5.attention.self.key.weight", "bert.encoder.layer.5.attention.self.key.bias", "bert.encoder.layer.5.attention.self.value.weight", "bert.encoder.layer.5.attention.self.value.bias", "bert.encoder.layer.5.attention.output.dense.weight", "bert.encoder.layer.5.attention.output.dense.bias", "bert.encoder.layer.5.attention.output.LayerNorm.weight", "bert.encoder.layer.5.attention.output.LayerNorm.bias", "bert.encoder.layer.5.intermediate.dense.weight", "bert.encoder.layer.5.intermediate.dense.bias", "bert.encoder.layer.5.output.dense.weight", "bert.encoder.layer.5.output.dense.bias", "bert.encoder.layer.5.output.LayerNorm.weight", "bert.encoder.layer.5.output.LayerNorm.bias", "bert.encoder.layer.6.attention.self.query.weight", "bert.encoder.layer.6.attention.self.query.bias", "bert.encoder.layer.6.attention.self.key.weight", "bert.encoder.layer.6.attention.self.key.bias", "bert.encoder.layer.6.attention.self.value.weight", "bert.encoder.layer.6.attention.self.value.bias", "bert.encoder.layer.6.attention.output.dense.weight", "bert.encoder.layer.6.attention.output.dense.bias", "bert.encoder.layer.6.attention.output.LayerNorm.weight", "bert.encoder.layer.6.attention.output.LayerNorm.bias", "bert.encoder.layer.6.intermediate.dense.weight", "bert.encoder.layer.6.intermediate.dense.bias", "bert.encoder.layer.6.output.dense.weight", "bert.encoder.layer.6.output.dense.bias", "bert.encoder.layer.6.output.LayerNorm.weight", "bert.encoder.layer.6.output.LayerNorm.bias", "bert.encoder.layer.7.attention.self.query.weight", "bert.encoder.layer.7.attention.self.query.bias", "bert.encoder.layer.7.attention.self.key.weight", "bert.encoder.layer.7.attention.self.key.bias", "bert.encoder.layer.7.attention.self.value.weight", "bert.encoder.layer.7.attention.self.value.bias", "bert.encoder.layer.7.attention.output.dense.weight", "bert.encoder.layer.7.attention.output.dense.bias", "bert.encoder.layer.7.attention.output.LayerNorm.weight", "bert.encoder.layer.7.attention.output.LayerNorm.bias", "bert.encoder.layer.7.intermediate.dense.weight", "bert.encoder.layer.7.intermediate.dense.bias", "bert.encoder.layer.7.output.dense.weight", "bert.encoder.layer.7.output.dense.bias", "bert.encoder.layer.7.output.LayerNorm.weight", "bert.encoder.layer.7.output.LayerNorm.bias", "bert.encoder.layer.8.attention.self.query.weight", "bert.encoder.layer.8.attention.self.query.bias", "bert.encoder.layer.8.attention.self.key.weight", "bert.encoder.layer.8.attention.self.key.bias", "bert.encoder.layer.8.attention.self.value.weight", "bert.encoder.layer.8.attention.self.value.bias", "bert.encoder.layer.8.attention.output.dense.weight", "bert.encoder.layer.8.attention.output.dense.bias", "bert.encoder.layer.8.attention.output.LayerNorm.weight", "bert.encoder.layer.8.attention.output.LayerNorm.bias", "bert.encoder.layer.8.intermediate.dense.weight", "bert.encoder.layer.8.intermediate.dense.bias", "bert.encoder.layer.8.output.dense.weight", "bert.encoder.layer.8.output.dense.bias", "bert.encoder.layer.8.output.LayerNorm.weight", "bert.encoder.layer.8.output.LayerNorm.bias", "bert.encoder.layer.9.attention.self.query.weight", "bert.encoder.layer.9.attention.self.query.bias", "bert.encoder.layer.9.attention.self.key.weight", "bert.encoder.layer.9.attention.self.key.bias", "bert.encoder.layer.9.attention.self.value.weight", "bert.encoder.layer.9.attention.self.value.bias", "bert.encoder.layer.9.attention.output.dense.weight", "bert.encoder.layer.9.attention.output.dense.bias", "bert.encoder.layer.9.attention.output.LayerNorm.weight", "bert.encoder.layer.9.attention.output.LayerNorm.bias", "bert.encoder.layer.9.intermediate.dense.weight", "bert.encoder.layer.9.intermediate.dense.bias", "bert.encoder.layer.9.output.dense.weight", "bert.encoder.layer.9.output.dense.bias", "bert.encoder.layer.9.output.LayerNorm.weight", "bert.encoder.layer.9.output.LayerNorm.bias", "bert.encoder.layer.10.attention.self.query.weight", "bert.encoder.layer.10.attention.self.query.bias", "bert.encoder.layer.10.attention.self.key.weight", "bert.encoder.layer.10.attention.self.key.bias", "bert.encoder.layer.10.attention.self.value.weight", "bert.encoder.layer.10.attention.self.value.bias", "bert.encoder.layer.10.attention.output.dense.weight", "bert.encoder.layer.10.attention.output.dense.bias", "bert.encoder.layer.10.attention.output.LayerNorm.weight", "bert.encoder.layer.10.attention.output.LayerNorm.bias", "bert.encoder.layer.10.intermediate.dense.weight", "bert.encoder.layer.10.intermediate.dense.bias", "bert.encoder.layer.10.output.dense.weight", "bert.encoder.layer.10.output.dense.bias", "bert.encoder.layer.10.output.LayerNorm.weight", "bert.encoder.layer.10.output.LayerNorm.bias", "bert.encoder.layer.11.attention.self.query.weight", "bert.encoder.layer.11.attention.self.query.bias", "bert.encoder.layer.11.attention.self.key.weight", "bert.encoder.layer.11.attention.self.key.bias", "bert.encoder.layer.11.attention.self.value.weight", "bert.encoder.layer.11.attention.self.value.bias", "bert.encoder.layer.11.attention.output.dense.weight", "bert.encoder.layer.11.attention.output.dense.bias", "bert.encoder.layer.11.attention.output.LayerNorm.weight", "bert.encoder.layer.11.attention.output.LayerNorm.bias", "bert.encoder.layer.11.intermediate.dense.weight", "bert.encoder.layer.11.intermediate.dense.bias", "bert.encoder.layer.11.output.dense.weight", "bert.encoder.layer.11.output.dense.bias", "bert.encoder.layer.11.output.LayerNorm.weight", "bert.encoder.layer.11.output.LayerNorm.bias", "bert.encoder.layer.12.attention.self.query.weight", "bert.encoder.layer.12.attention.self.query.bias", "bert.encoder.layer.12.attention.self.key.weight", "bert.encoder.layer.12.attention.self.key.bias", "bert.encoder.layer.12.attention.self.value.weight", "bert.encoder.layer.12.attention.self.value.bias", "bert.encoder.layer.12.attention.output.dense.weight", "bert.encoder.layer.12.attention.output.dense.bias", "bert.encoder.layer.12.attention.output.LayerNorm.weight", "bert.encoder.layer.12.attention.output.LayerNorm.bias", "bert.encoder.layer.12.intermediate.dense.weight", "bert.encoder.layer.12.intermediate.dense.bias", "bert.encoder.layer.12.output.dense.weight", "bert.encoder.layer.12.output.dense.bias", "bert.encoder.layer.12.output.LayerNorm.weight", "bert.encoder.layer.12.output.LayerNorm.bias", "bert.encoder.layer.13.attention.self.query.weight", "bert.encoder.layer.13.attention.self.query.bias", "bert.encoder.layer.13.attention.self.key.weight", "bert.encoder.layer.13.attention.self.key.bias", "bert.encoder.layer.13.attention.self.value.weight", "bert.encoder.layer.13.attention.self.value.bias", "bert.encoder.layer.13.attention.output.dense.weight", "bert.encoder.layer.13.attention.output.dense.bias", "bert.encoder.layer.13.attention.output.LayerNorm.weight", "bert.encoder.layer.13.attention.output.LayerNorm.bias", "bert.encoder.layer.13.intermediate.dense.weight", "bert.encoder.layer.13.intermediate.dense.bias", "bert.encoder.layer.13.output.dense.weight", "bert.encoder.layer.13.output.dense.bias", "bert.encoder.layer.13.output.LayerNorm.weight", "bert.encoder.layer.13.output.LayerNorm.bias", "bert.encoder.layer.14.attention.self.query.weight", "bert.encoder.layer.14.attention.self.query.bias", "bert.encoder.layer.14.attention.self.key.weight", "bert.encoder.layer.14.attention.self.key.bias", "bert.encoder.layer.14.attention.self.value.weight", "bert.encoder.layer.14.attention.self.value.bias", "bert.encoder.layer.14.attention.output.dense.weight", "bert.encoder.layer.14.attention.output.dense.bias", "bert.encoder.layer.14.attention.output.LayerNorm.weight", "bert.encoder.layer.14.attention.output.LayerNorm.bias", "bert.encoder.layer.14.intermediate.dense.weight", "bert.encoder.layer.14.intermediate.dense.bias", "bert.encoder.layer.14.output.dense.weight", "bert.encoder.layer.14.output.dense.bias", "bert.encoder.layer.14.output.LayerNorm.weight", "bert.encoder.layer.14.output.LayerNorm.bias", "bert.encoder.layer.15.attention.self.query.weight", "bert.encoder.layer.15.attention.self.query.bias", "bert.encoder.layer.15.attention.self.key.weight", "bert.encoder.layer.15.attention.self.key.bias", "bert.encoder.layer.15.attention.self.value.weight", "bert.encoder.layer.15.attention.self.value.bias", "bert.encoder.layer.15.attention.output.dense.weight", "bert.encoder.layer.15.attention.output.dense.bias", "bert.encoder.layer.15.attention.output.LayerNorm.weight", "bert.encoder.layer.15.attention.output.LayerNorm.bias", "bert.encoder.layer.15.intermediate.dense.weight", "bert.encoder.layer.15.intermediate.dense.bias", "bert.encoder.layer.15.output.dense.weight", "bert.encoder.layer.15.output.dense.bias", "bert.encoder.layer.15.output.LayerNorm.weight", "bert.encoder.layer.15.output.LayerNorm.bias", "bert.encoder.layer.16.attention.self.query.weight", "bert.encoder.layer.16.attention.self.query.bias", "bert.encoder.layer.16.attention.self.key.weight", "bert.encoder.layer.16.attention.self.key.bias", "bert.encoder.layer.16.attention.self.value.weight", "bert.encoder.layer.16.attention.self.value.bias", "bert.encoder.layer.16.attention.output.dense.weight", "bert.encoder.layer.16.attention.output.dense.bias", "bert.encoder.layer.16.attention.output.LayerNorm.weight", "bert.encoder.layer.16.attention.output.LayerNorm.bias", "bert.encoder.layer.16.intermediate.dense.weight", "bert.encoder.layer.16.intermediate.dense.bias", "bert.encoder.layer.16.output.dense.weight", "bert.encoder.layer.16.output.dense.bias", "bert.encoder.layer.16.output.LayerNorm.weight", "bert.encoder.layer.16.output.LayerNorm.bias", "bert.encoder.layer.17.attention.self.query.weight", "bert.encoder.layer.17.attention.self.query.bias", "bert.encoder.layer.17.attention.self.key.weight", "bert.encoder.layer.17.attention.self.key.bias", "bert.encoder.layer.17.attention.self.value.weight", "bert.encoder.layer.17.attention.self.value.bias", "bert.encoder.layer.17.attention.output.dense.weight", "bert.encoder.layer.17.attention.output.dense.bias", "bert.encoder.layer.17.attention.output.LayerNorm.weight", "bert.encoder.layer.17.attention.output.LayerNorm.bias", "bert.encoder.layer.17.intermediate.dense.weight", "bert.encoder.layer.17.intermediate.dense.bias", "bert.encoder.layer.17.output.dense.weight", "bert.encoder.layer.17.output.dense.bias", "bert.encoder.layer.17.output.LayerNorm.weight", "bert.encoder.layer.17.output.LayerNorm.bias", "bert.encoder.layer.18.attention.self.query.weight", "bert.encoder.layer.18.attention.self.query.bias", "bert.encoder.layer.18.attention.self.key.weight", "bert.encoder.layer.18.attention.self.key.bias", "bert.encoder.layer.18.attention.self.value.weight", "bert.encoder.layer.18.attention.self.value.bias", "bert.encoder.layer.18.attention.output.dense.weight", "bert.encoder.layer.18.attention.output.dense.bias", "bert.encoder.layer.18.attention.output.LayerNorm.weight", "bert.encoder.layer.18.attention.output.LayerNorm.bias", "bert.encoder.layer.18.intermediate.dense.weight", "bert.encoder.layer.18.intermediate.dense.bias", "bert.encoder.layer.18.output.dense.weight", "bert.encoder.layer.18.output.dense.bias", "bert.encoder.layer.18.output.LayerNorm.weight", "bert.encoder.layer.18.output.LayerNorm.bias", "bert.encoder.layer.19.attention.self.query.weight", "bert.encoder.layer.19.attention.self.query.bias", "bert.encoder.layer.19.attention.self.key.weight", "bert.encoder.layer.19.attention.self.key.bias", "bert.encoder.layer.19.attention.self.value.weight", "bert.encoder.layer.19.attention.self.value.bias", "bert.encoder.layer.19.attention.output.dense.weight", "bert.encoder.layer.19.attention.output.dense.bias", "bert.encoder.layer.19.attention.output.LayerNorm.weight", "bert.encoder.layer.19.attention.output.LayerNorm.bias", "bert.encoder.layer.19.intermediate.dense.weight", "bert.encoder.layer.19.intermediate.dense.bias", "bert.encoder.layer.19.output.dense.weight", "bert.encoder.layer.19.output.dense.bias", "bert.encoder.layer.19.output.LayerNorm.weight", "bert.encoder.layer.19.output.LayerNorm.bias", "bert.encoder.layer.20.attention.self.query.weight", "bert.encoder.layer.20.attention.self.query.bias", "bert.encoder.layer.20.attention.self.key.weight", "bert.encoder.layer.20.attention.self.key.bias", "bert.encoder.layer.20.attention.self.value.weight", "bert.encoder.layer.20.attention.self.value.bias", "bert.encoder.layer.20.attention.output.dense.weight", "bert.encoder.layer.20.attention.output.dense.bias", "bert.encoder.layer.20.attention.output.LayerNorm.weight", "bert.encoder.layer.20.attention.output.LayerNorm.bias", "bert.encoder.layer.20.intermediate.dense.weight", "bert.encoder.layer.20.intermediate.dense.bias", "bert.encoder.layer.20.output.dense.weight", "bert.encoder.layer.20.output.dense.bias", "bert.encoder.layer.20.output.LayerNorm.weight", "bert.encoder.layer.20.output.LayerNorm.bias", "bert.encoder.layer.21.attention.self.query.weight", "bert.encoder.layer.21.attention.self.query.bias", "bert.encoder.layer.21.attention.self.key.weight", "bert.encoder.layer.21.attention.self.key.bias", "bert.encoder.layer.21.attention.self.value.weight", "bert.encoder.layer.21.attention.self.value.bias", "bert.encoder.layer.21.attention.output.dense.weight", "bert.encoder.layer.21.attention.output.dense.bias", "bert.encoder.layer.21.attention.output.LayerNorm.weight", "bert.encoder.layer.21.attention.output.LayerNorm.bias", "bert.encoder.layer.21.intermediate.dense.weight", "bert.encoder.layer.21.intermediate.dense.bias", "bert.encoder.layer.21.output.dense.weight", "bert.encoder.layer.21.output.dense.bias", "bert.encoder.layer.21.output.LayerNorm.weight", "bert.encoder.layer.21.output.LayerNorm.bias", "bert.encoder.layer.22.attention.self.query.weight", "bert.encoder.layer.22.attention.self.query.bias", "bert.encoder.layer.22.attention.self.key.weight", "bert.encoder.layer.22.attention.self.key.bias", "bert.encoder.layer.22.attention.self.value.weight", "bert.encoder.layer.22.attention.self.value.bias", "bert.encoder.layer.22.attention.output.dense.weight", "bert.encoder.layer.22.attention.output.dense.bias", "bert.encoder.layer.22.attention.output.LayerNorm.weight", "bert.encoder.layer.22.attention.output.LayerNorm.bias", "bert.encoder.layer.22.intermediate.dense.weight", "bert.encoder.layer.22.intermediate.dense.bias", "bert.encoder.layer.22.output.dense.weight", "bert.encoder.layer.22.output.dense.bias", "bert.encoder.layer.22.output.LayerNorm.weight", "bert.encoder.layer.22.output.LayerNorm.bias", "bert.encoder.layer.23.attention.self.query.weight", "bert.encoder.layer.23.attention.self.query.bias", "bert.encoder.layer.23.attention.self.key.weight", "bert.encoder.layer.23.attention.self.key.bias", "bert.encoder.layer.23.attention.self.value.weight", "bert.encoder.layer.23.attention.self.value.bias", "bert.encoder.layer.23.attention.output.dense.weight", "bert.encoder.layer.23.attention.output.dense.bias", "bert.encoder.layer.23.attention.output.LayerNorm.weight", "bert.encoder.layer.23.attention.output.LayerNorm.bias", "bert.encoder.layer.23.intermediate.dense.weight", "bert.encoder.layer.23.intermediate.dense.bias", "bert.encoder.layer.23.output.dense.weight", "bert.encoder.layer.23.output.dense.bias", "bert.encoder.layer.23.output.LayerNorm.weight", "bert.encoder.layer.23.output.LayerNorm.bias", "classifier.layers.0.weight", "classifier.layers.0.bias", "classifier.layers.1.projection.weight", "classifier.layers.1.projection.bias", "classifier.layers.3.weight", "classifier.layers.3.bias", "classifier.layers.4.projection.weight", "classifier.layers.4.projection.bias", "classifier.layers.6.weight", "classifier.layers.6.bias". 
	Unexpected key(s) in state_dict: "layers.0.weight", "layers.0.bias", "layers.1.projection.weight", "layers.1.projection.bias", "layers.3.weight", "layers.3.bias", "layers.4.projection.weight", "layers.4.projection.bias", "layers.6.weight", "layers.6.bias". 

An error occurred during training: Error(s) in loading state_dict for BERTClassifier:
	Missing key(s) in state_dict: "bert.embeddings.word_embeddings.weight", "bert.embeddings.position_embeddings.weight", "bert.embeddings.token_type_embeddings.weight", "bert.embeddings.LayerNorm.weight", "bert.embeddings.LayerNorm.bias", "bert.encoder.layer.0.attention.self.query.weight", "bert.encoder.layer.0.attention.self.query.bias", "bert.encoder.layer.0.attention.self.key.weight", "bert.encoder.layer.0.attention.self.key.bias", "bert.encoder.layer.0.attention.self.value.weight", "bert.encoder.layer.0.attention.self.value.bias", "bert.encoder.layer.0.attention.output.dense.weight", "bert.encoder.layer.0.attention.output.dense.bias", "bert.encoder.layer.0.attention.output.LayerNorm.weight", "bert.encoder.layer.0.attention.output.LayerNorm.bias", "bert.encoder.layer.0.intermediate.dense.weight", "bert.encoder.layer.0.intermediate.dense.bias", "bert.encoder.layer.0.output.dense.weight", "bert.encoder.layer.0.output.dense.bias", "bert.encoder.layer.0.output.LayerNorm.weight", "bert.encoder.layer.0.output.LayerNorm.bias", "bert.encoder.layer.1.attention.self.query.weight", "bert.encoder.layer.1.attention.self.query.bias", "bert.encoder.layer.1.attention.self.key.weight", "bert.encoder.layer.1.attention.self.key.bias", "bert.encoder.layer.1.attention.self.value.weight", "bert.encoder.layer.1.attention.self.value.bias", "bert.encoder.layer.1.attention.output.dense.weight", "bert.encoder.layer.1.attention.output.dense.bias", "bert.encoder.layer.1.attention.output.LayerNorm.weight", "bert.encoder.layer.1.attention.output.LayerNorm.bias", "bert.encoder.layer.1.intermediate.dense.weight", "bert.encoder.layer.1.intermediate.dense.bias", "bert.encoder.layer.1.output.dense.weight", "bert.encoder.layer.1.output.dense.bias", "bert.encoder.layer.1.output.LayerNorm.weight", "bert.encoder.layer.1.output.LayerNorm.bias", "bert.encoder.layer.2.attention.self.query.weight", "bert.encoder.layer.2.attention.self.query.bias", "bert.encoder.layer.2.attention.self.key.weight", "bert.encoder.layer.2.attention.self.key.bias", "bert.encoder.layer.2.attention.self.value.weight", "bert.encoder.layer.2.attention.self.value.bias", "bert.encoder.layer.2.attention.output.dense.weight", "bert.encoder.layer.2.attention.output.dense.bias", "bert.encoder.layer.2.attention.output.LayerNorm.weight", "bert.encoder.layer.2.attention.output.LayerNorm.bias", "bert.encoder.layer.2.intermediate.dense.weight", "bert.encoder.layer.2.intermediate.dense.bias", "bert.encoder.layer.2.output.dense.weight", "bert.encoder.layer.2.output.dense.bias", "bert.encoder.layer.2.output.LayerNorm.weight", "bert.encoder.layer.2.output.LayerNorm.bias", "bert.encoder.layer.3.attention.self.query.weight", "bert.encoder.layer.3.attention.self.query.bias", "bert.encoder.layer.3.attention.self.key.weight", "bert.encoder.layer.3.attention.self.key.bias", "bert.encoder.layer.3.attention.self.value.weight", "bert.encoder.layer.3.attention.self.value.bias", "bert.encoder.layer.3.attention.output.dense.weight", "bert.encoder.layer.3.attention.output.dense.bias", "bert.encoder.layer.3.attention.output.LayerNorm.weight", "bert.encoder.layer.3.attention.output.LayerNorm.bias", "bert.encoder.layer.3.intermediate.dense.weight", "bert.encoder.layer.3.intermediate.dense.bias", "bert.encoder.layer.3.output.dense.weight", "bert.encoder.layer.3.output.dense.bias", "bert.encoder.layer.3.output.LayerNorm.weight", "bert.encoder.layer.3.output.LayerNorm.bias", "bert.encoder.layer.4.attention.self.query.weight", "bert.encoder.layer.4.attention.self.query.bias", "bert.encoder.layer.4.attention.self.key.weight", "bert.encoder.layer.4.attention.self.key.bias", "bert.encoder.layer.4.attention.self.value.weight", "bert.encoder.layer.4.attention.self.value.bias", "bert.encoder.layer.4.attention.output.dense.weight", "bert.encoder.layer.4.attention.output.dense.bias", "bert.encoder.layer.4.attention.output.LayerNorm.weight", "bert.encoder.layer.4.attention.output.LayerNorm.bias", "bert.encoder.layer.4.intermediate.dense.weight", "bert.encoder.layer.4.intermediate.dense.bias", "bert.encoder.layer.4.output.dense.weight", "bert.encoder.layer.4.output.dense.bias", "bert.encoder.layer.4.output.LayerNorm.weight", "bert.encoder.layer.4.output.LayerNorm.bias", "bert.encoder.layer.5.attention.self.query.weight", "bert.encoder.layer.5.attention.self.query.bias", "bert.encoder.layer.5.attention.self.key.weight", "bert.encoder.layer.5.attention.self.key.bias", "bert.encoder.layer.5.attention.self.value.weight", "bert.encoder.layer.5.attention.self.value.bias", "bert.encoder.layer.5.attention.output.dense.weight", "bert.encoder.layer.5.attention.output.dense.bias", "bert.encoder.layer.5.attention.output.LayerNorm.weight", "bert.encoder.layer.5.attention.output.LayerNorm.bias", "bert.encoder.layer.5.intermediate.dense.weight", "bert.encoder.layer.5.intermediate.dense.bias", "bert.encoder.layer.5.output.dense.weight", "bert.encoder.layer.5.output.dense.bias", "bert.encoder.layer.5.output.LayerNorm.weight", "bert.encoder.layer.5.output.LayerNorm.bias", "bert.encoder.layer.6.attention.self.query.weight", "bert.encoder.layer.6.attention.self.query.bias", "bert.encoder.layer.6.attention.self.key.weight", "bert.encoder.layer.6.attention.self.key.bias", "bert.encoder.layer.6.attention.self.value.weight", "bert.encoder.layer.6.attention.self.value.bias", "bert.encoder.layer.6.attention.output.dense.weight", "bert.encoder.layer.6.attention.output.dense.bias", "bert.encoder.layer.6.attention.output.LayerNorm.weight", "bert.encoder.layer.6.attention.output.LayerNorm.bias", "bert.encoder.layer.6.intermediate.dense.weight", "bert.encoder.layer.6.intermediate.dense.bias", "bert.encoder.layer.6.output.dense.weight", "bert.encoder.layer.6.output.dense.bias", "bert.encoder.layer.6.output.LayerNorm.weight", "bert.encoder.layer.6.output.LayerNorm.bias", "bert.encoder.layer.7.attention.self.query.weight", "bert.encoder.layer.7.attention.self.query.bias", "bert.encoder.layer.7.attention.self.key.weight", "bert.encoder.layer.7.attention.self.key.bias", "bert.encoder.layer.7.attention.self.value.weight", "bert.encoder.layer.7.attention.self.value.bias", "bert.encoder.layer.7.attention.output.dense.weight", "bert.encoder.layer.7.attention.output.dense.bias", "bert.encoder.layer.7.attention.output.LayerNorm.weight", "bert.encoder.layer.7.attention.output.LayerNorm.bias", "bert.encoder.layer.7.intermediate.dense.weight", "bert.encoder.layer.7.intermediate.dense.bias", "bert.encoder.layer.7.output.dense.weight", "bert.encoder.layer.7.output.dense.bias", "bert.encoder.layer.7.output.LayerNorm.weight", "bert.encoder.layer.7.output.LayerNorm.bias", "bert.encoder.layer.8.attention.self.query.weight", "bert.encoder.layer.8.attention.self.query.bias", "bert.encoder.layer.8.attention.self.key.weight", "bert.encoder.layer.8.attention.self.key.bias", "bert.encoder.layer.8.attention.self.value.weight", "bert.encoder.layer.8.attention.self.value.bias", "bert.encoder.layer.8.attention.output.dense.weight", "bert.encoder.layer.8.attention.output.dense.bias", "bert.encoder.layer.8.attention.output.LayerNorm.weight", "bert.encoder.layer.8.attention.output.LayerNorm.bias", "bert.encoder.layer.8.intermediate.dense.weight", "bert.encoder.layer.8.intermediate.dense.bias", "bert.encoder.layer.8.output.dense.weight", "bert.encoder.layer.8.output.dense.bias", "bert.encoder.layer.8.output.LayerNorm.weight", "bert.encoder.layer.8.output.LayerNorm.bias", "bert.encoder.layer.9.attention.self.query.weight", "bert.encoder.layer.9.attention.self.query.bias", "bert.encoder.layer.9.attention.self.key.weight", "bert.encoder.layer.9.attention.self.key.bias", "bert.encoder.layer.9.attention.self.value.weight", "bert.encoder.layer.9.attention.self.value.bias", "bert.encoder.layer.9.attention.output.dense.weight", "bert.encoder.layer.9.attention.output.dense.bias", "bert.encoder.layer.9.attention.output.LayerNorm.weight", "bert.encoder.layer.9.attention.output.LayerNorm.bias", "bert.encoder.layer.9.intermediate.dense.weight", "bert.encoder.layer.9.intermediate.dense.bias", "bert.encoder.layer.9.output.dense.weight", "bert.encoder.layer.9.output.dense.bias", "bert.encoder.layer.9.output.LayerNorm.weight", "bert.encoder.layer.9.output.LayerNorm.bias", "bert.encoder.layer.10.attention.self.query.weight", "bert.encoder.layer.10.attention.self.query.bias", "bert.encoder.layer.10.attention.self.key.weight", "bert.encoder.layer.10.attention.self.key.bias", "bert.encoder.layer.10.attention.self.value.weight", "bert.encoder.layer.10.attention.self.value.bias", "bert.encoder.layer.10.attention.output.dense.weight", "bert.encoder.layer.10.attention.output.dense.bias", "bert.encoder.layer.10.attention.output.LayerNorm.weight", "bert.encoder.layer.10.attention.output.LayerNorm.bias", "bert.encoder.layer.10.intermediate.dense.weight", "bert.encoder.layer.10.intermediate.dense.bias", "bert.encoder.layer.10.output.dense.weight", "bert.encoder.layer.10.output.dense.bias", "bert.encoder.layer.10.output.LayerNorm.weight", "bert.encoder.layer.10.output.LayerNorm.bias", "bert.encoder.layer.11.attention.self.query.weight", "bert.encoder.layer.11.attention.self.query.bias", "bert.encoder.layer.11.attention.self.key.weight", "bert.encoder.layer.11.attention.self.key.bias", "bert.encoder.layer.11.attention.self.value.weight", "bert.encoder.layer.11.attention.self.value.bias", "bert.encoder.layer.11.attention.output.dense.weight", "bert.encoder.layer.11.attention.output.dense.bias", "bert.encoder.layer.11.attention.output.LayerNorm.weight", "bert.encoder.layer.11.attention.output.LayerNorm.bias", "bert.encoder.layer.11.intermediate.dense.weight", "bert.encoder.layer.11.intermediate.dense.bias", "bert.encoder.layer.11.output.dense.weight", "bert.encoder.layer.11.output.dense.bias", "bert.encoder.layer.11.output.LayerNorm.weight", "bert.encoder.layer.11.output.LayerNorm.bias", "bert.encoder.layer.12.attention.self.query.weight", "bert.encoder.layer.12.attention.self.query.bias", "bert.encoder.layer.12.attention.self.key.weight", "bert.encoder.layer.12.attention.self.key.bias", "bert.encoder.layer.12.attention.self.value.weight", "bert.encoder.layer.12.attention.self.value.bias", "bert.encoder.layer.12.attention.output.dense.weight", "bert.encoder.layer.12.attention.output.dense.bias", "bert.encoder.layer.12.attention.output.LayerNorm.weight", "bert.encoder.layer.12.attention.output.LayerNorm.bias", "bert.encoder.layer.12.intermediate.dense.weight", "bert.encoder.layer.12.intermediate.dense.bias", "bert.encoder.layer.12.output.dense.weight", "bert.encoder.layer.12.output.dense.bias", "bert.encoder.layer.12.output.LayerNorm.weight", "bert.encoder.layer.12.output.LayerNorm.bias", "bert.encoder.layer.13.attention.self.query.weight", "bert.encoder.layer.13.attention.self.query.bias", "bert.encoder.layer.13.attention.self.key.weight", "bert.encoder.layer.13.attention.self.key.bias", "bert.encoder.layer.13.attention.self.value.weight", "bert.encoder.layer.13.attention.self.value.bias", "bert.encoder.layer.13.attention.output.dense.weight", "bert.encoder.layer.13.attention.output.dense.bias", "bert.encoder.layer.13.attention.output.LayerNorm.weight", "bert.encoder.layer.13.attention.output.LayerNorm.bias", "bert.encoder.layer.13.intermediate.dense.weight", "bert.encoder.layer.13.intermediate.dense.bias", "bert.encoder.layer.13.output.dense.weight", "bert.encoder.layer.13.output.dense.bias", "bert.encoder.layer.13.output.LayerNorm.weight", "bert.encoder.layer.13.output.LayerNorm.bias", "bert.encoder.layer.14.attention.self.query.weight", "bert.encoder.layer.14.attention.self.query.bias", "bert.encoder.layer.14.attention.self.key.weight", "bert.encoder.layer.14.attention.self.key.bias", "bert.encoder.layer.14.attention.self.value.weight", "bert.encoder.layer.14.attention.self.value.bias", "bert.encoder.layer.14.attention.output.dense.weight", "bert.encoder.layer.14.attention.output.dense.bias", "bert.encoder.layer.14.attention.output.LayerNorm.weight", "bert.encoder.layer.14.attention.output.LayerNorm.bias", "bert.encoder.layer.14.intermediate.dense.weight", "bert.encoder.layer.14.intermediate.dense.bias", "bert.encoder.layer.14.output.dense.weight", "bert.encoder.layer.14.output.dense.bias", "bert.encoder.layer.14.output.LayerNorm.weight", "bert.encoder.layer.14.output.LayerNorm.bias", "bert.encoder.layer.15.attention.self.query.weight", "bert.encoder.layer.15.attention.self.query.bias", "bert.encoder.layer.15.attention.self.key.weight", "bert.encoder.layer.15.attention.self.key.bias", "bert.encoder.layer.15.attention.self.value.weight", "bert.encoder.layer.15.attention.self.value.bias", "bert.encoder.layer.15.attention.output.dense.weight", "bert.encoder.layer.15.attention.output.dense.bias", "bert.encoder.layer.15.attention.output.LayerNorm.weight", "bert.encoder.layer.15.attention.output.LayerNorm.bias", "bert.encoder.layer.15.intermediate.dense.weight", "bert.encoder.layer.15.intermediate.dense.bias", "bert.encoder.layer.15.output.dense.weight", "bert.encoder.layer.15.output.dense.bias", "bert.encoder.layer.15.output.LayerNorm.weight", "bert.encoder.layer.15.output.LayerNorm.bias", "bert.encoder.layer.16.attention.self.query.weight", "bert.encoder.layer.16.attention.self.query.bias", "bert.encoder.layer.16.attention.self.key.weight", "bert.encoder.layer.16.attention.self.key.bias", "bert.encoder.layer.16.attention.self.value.weight", "bert.encoder.layer.16.attention.self.value.bias", "bert.encoder.layer.16.attention.output.dense.weight", "bert.encoder.layer.16.attention.output.dense.bias", "bert.encoder.layer.16.attention.output.LayerNorm.weight", "bert.encoder.layer.16.attention.output.LayerNorm.bias", "bert.encoder.layer.16.intermediate.dense.weight", "bert.encoder.layer.16.intermediate.dense.bias", "bert.encoder.layer.16.output.dense.weight", "bert.encoder.layer.16.output.dense.bias", "bert.encoder.layer.16.output.LayerNorm.weight", "bert.encoder.layer.16.output.LayerNorm.bias", "bert.encoder.layer.17.attention.self.query.weight", "bert.encoder.layer.17.attention.self.query.bias", "bert.encoder.layer.17.attention.self.key.weight", "bert.encoder.layer.17.attention.self.key.bias", "bert.encoder.layer.17.attention.self.value.weight", "bert.encoder.layer.17.attention.self.value.bias", "bert.encoder.layer.17.attention.output.dense.weight", "bert.encoder.layer.17.attention.output.dense.bias", "bert.encoder.layer.17.attention.output.LayerNorm.weight", "bert.encoder.layer.17.attention.output.LayerNorm.bias", "bert.encoder.layer.17.intermediate.dense.weight", "bert.encoder.layer.17.intermediate.dense.bias", "bert.encoder.layer.17.output.dense.weight", "bert.encoder.layer.17.output.dense.bias", "bert.encoder.layer.17.output.LayerNorm.weight", "bert.encoder.layer.17.output.LayerNorm.bias", "bert.encoder.layer.18.attention.self.query.weight", "bert.encoder.layer.18.attention.self.query.bias", "bert.encoder.layer.18.attention.self.key.weight", "bert.encoder.layer.18.attention.self.key.bias", "bert.encoder.layer.18.attention.self.value.weight", "bert.encoder.layer.18.attention.self.value.bias", "bert.encoder.layer.18.attention.output.dense.weight", "bert.encoder.layer.18.attention.output.dense.bias", "bert.encoder.layer.18.attention.output.LayerNorm.weight", "bert.encoder.layer.18.attention.output.LayerNorm.bias", "bert.encoder.layer.18.intermediate.dense.weight", "bert.encoder.layer.18.intermediate.dense.bias", "bert.encoder.layer.18.output.dense.weight", "bert.encoder.layer.18.output.dense.bias", "bert.encoder.layer.18.output.LayerNorm.weight", "bert.encoder.layer.18.output.LayerNorm.bias", "bert.encoder.layer.19.attention.self.query.weight", "bert.encoder.layer.19.attention.self.query.bias", "bert.encoder.layer.19.attention.self.key.weight", "bert.encoder.layer.19.attention.self.key.bias", "bert.encoder.layer.19.attention.self.value.weight", "bert.encoder.layer.19.attention.self.value.bias", "bert.encoder.layer.19.attention.output.dense.weight", "bert.encoder.layer.19.attention.output.dense.bias", "bert.encoder.layer.19.attention.output.LayerNorm.weight", "bert.encoder.layer.19.attention.output.LayerNorm.bias", "bert.encoder.layer.19.intermediate.dense.weight", "bert.encoder.layer.19.intermediate.dense.bias", "bert.encoder.layer.19.output.dense.weight", "bert.encoder.layer.19.output.dense.bias", "bert.encoder.layer.19.output.LayerNorm.weight", "bert.encoder.layer.19.output.LayerNorm.bias", "bert.encoder.layer.20.attention.self.query.weight", "bert.encoder.layer.20.attention.self.query.bias", "bert.encoder.layer.20.attention.self.key.weight", "bert.encoder.layer.20.attention.self.key.bias", "bert.encoder.layer.20.attention.self.value.weight", "bert.encoder.layer.20.attention.self.value.bias", "bert.encoder.layer.20.attention.output.dense.weight", "bert.encoder.layer.20.attention.output.dense.bias", "bert.encoder.layer.20.attention.output.LayerNorm.weight", "bert.encoder.layer.20.attention.output.LayerNorm.bias", "bert.encoder.layer.20.intermediate.dense.weight", "bert.encoder.layer.20.intermediate.dense.bias", "bert.encoder.layer.20.output.dense.weight", "bert.encoder.layer.20.output.dense.bias", "bert.encoder.layer.20.output.LayerNorm.weight", "bert.encoder.layer.20.output.LayerNorm.bias", "bert.encoder.layer.21.attention.self.query.weight", "bert.encoder.layer.21.attention.self.query.bias", "bert.encoder.layer.21.attention.self.key.weight", "bert.encoder.layer.21.attention.self.key.bias", "bert.encoder.layer.21.attention.self.value.weight", "bert.encoder.layer.21.attention.self.value.bias", "bert.encoder.layer.21.attention.output.dense.weight", "bert.encoder.layer.21.attention.output.dense.bias", "bert.encoder.layer.21.attention.output.LayerNorm.weight", "bert.encoder.layer.21.attention.output.LayerNorm.bias", "bert.encoder.layer.21.intermediate.dense.weight", "bert.encoder.layer.21.intermediate.dense.bias", "bert.encoder.layer.21.output.dense.weight", "bert.encoder.layer.21.output.dense.bias", "bert.encoder.layer.21.output.LayerNorm.weight", "bert.encoder.layer.21.output.LayerNorm.bias", "bert.encoder.layer.22.attention.self.query.weight", "bert.encoder.layer.22.attention.self.query.bias", "bert.encoder.layer.22.attention.self.key.weight", "bert.encoder.layer.22.attention.self.key.bias", "bert.encoder.layer.22.attention.self.value.weight", "bert.encoder.layer.22.attention.self.value.bias", "bert.encoder.layer.22.attention.output.dense.weight", "bert.encoder.layer.22.attention.output.dense.bias", "bert.encoder.layer.22.attention.output.LayerNorm.weight", "bert.encoder.layer.22.attention.output.LayerNorm.bias", "bert.encoder.layer.22.intermediate.dense.weight", "bert.encoder.layer.22.intermediate.dense.bias", "bert.encoder.layer.22.output.dense.weight", "bert.encoder.layer.22.output.dense.bias", "bert.encoder.layer.22.output.LayerNorm.weight", "bert.encoder.layer.22.output.LayerNorm.bias", "bert.encoder.layer.23.attention.self.query.weight", "bert.encoder.layer.23.attention.self.query.bias", "bert.encoder.layer.23.attention.self.key.weight", "bert.encoder.layer.23.attention.self.key.bias", "bert.encoder.layer.23.attention.self.value.weight", "bert.encoder.layer.23.attention.self.value.bias", "bert.encoder.layer.23.attention.output.dense.weight", "bert.encoder.layer.23.attention.output.dense.bias", "bert.encoder.layer.23.attention.output.LayerNorm.weight", "bert.encoder.layer.23.attention.output.LayerNorm.bias", "bert.encoder.layer.23.intermediate.dense.weight", "bert.encoder.layer.23.intermediate.dense.bias", "bert.encoder.layer.23.output.dense.weight", "bert.encoder.layer.23.output.dense.bias", "bert.encoder.layer.23.output.LayerNorm.weight", "bert.encoder.layer.23.output.LayerNorm.bias", "classifier.layers.0.weight", "classifier.layers.0.bias", "classifier.layers.1.projection.weight", "classifier.layers.1.projection.bias", "classifier.layers.3.weight", "classifier.layers.3.bias", "classifier.layers.4.projection.weight", "classifier.layers.4.projection.bias", "classifier.layers.6.weight", "classifier.layers.6.bias". 
	Unexpected key(s) in state_dict: "layers.0.weight", "layers.0.bias", "layers.1.projection.weight", "layers.1.projection.bias", "layers.3.weight", "layers.3.bias", "layers.4.projection.weight", "layers.4.projection.bias", "layers.6.weight", "layers.6.bias". 
Traceback (most recent call last):
  File "/home/ubuntu/nlp-osaka/sentiment/ddp_sentiment_finetune.py", line 1206, in main
    classifier.fit(X_train, X_val, y_train, y_val, rank, world_size, debug, start_epoch, model_state_dict, optimizer_state_dict,
  File "/home/ubuntu/nlp-osaka/sentiment/torch_ddp_finetune_neural_classifier.py", line 1070, in fit
    self.model.load_state_dict(model_state_dict)
  File "/home/ubuntu/nlp-osaka/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 2152, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for BERTClassifier:
	Missing key(s) in state_dict: "bert.embeddings.word_embeddings.weight", "bert.embeddings.position_embeddings.weight", "bert.embeddings.token_type_embeddings.weight", "bert.embeddings.LayerNorm.weight", "bert.embeddings.LayerNorm.bias", "bert.encoder.layer.0.attention.self.query.weight", "bert.encoder.layer.0.attention.self.query.bias", "bert.encoder.layer.0.attention.self.key.weight", "bert.encoder.layer.0.attention.self.key.bias", "bert.encoder.layer.0.attention.self.value.weight", "bert.encoder.layer.0.attention.self.value.bias", "bert.encoder.layer.0.attention.output.dense.weight", "bert.encoder.layer.0.attention.output.dense.bias", "bert.encoder.layer.0.attention.output.LayerNorm.weight", "bert.encoder.layer.0.attention.output.LayerNorm.bias", "bert.encoder.layer.0.intermediate.dense.weight", "bert.encoder.layer.0.intermediate.dense.bias", "bert.encoder.layer.0.output.dense.weight", "bert.encoder.layer.0.output.dense.bias", "bert.encoder.layer.0.output.LayerNorm.weight", "bert.encoder.layer.0.output.LayerNorm.bias", "bert.encoder.layer.1.attention.self.query.weight", "bert.encoder.layer.1.attention.self.query.bias", "bert.encoder.layer.1.attention.self.key.weight", "bert.encoder.layer.1.attention.self.key.bias", "bert.encoder.layer.1.attention.self.value.weight", "bert.encoder.layer.1.attention.self.value.bias", "bert.encoder.layer.1.attention.output.dense.weight", "bert.encoder.layer.1.attention.output.dense.bias", "bert.encoder.layer.1.attention.output.LayerNorm.weight", "bert.encoder.layer.1.attention.output.LayerNorm.bias", "bert.encoder.layer.1.intermediate.dense.weight", "bert.encoder.layer.1.intermediate.dense.bias", "bert.encoder.layer.1.output.dense.weight", "bert.encoder.layer.1.output.dense.bias", "bert.encoder.layer.1.output.LayerNorm.weight", "bert.encoder.layer.1.output.LayerNorm.bias", "bert.encoder.layer.2.attention.self.query.weight", "bert.encoder.layer.2.attention.self.query.bias", "bert.encoder.layer.2.attention.self.key.weight", "bert.encoder.layer.2.attention.self.key.bias", "bert.encoder.layer.2.attention.self.value.weight", "bert.encoder.layer.2.attention.self.value.bias", "bert.encoder.layer.2.attention.output.dense.weight", "bert.encoder.layer.2.attention.output.dense.bias", "bert.encoder.layer.2.attention.output.LayerNorm.weight", "bert.encoder.layer.2.attention.output.LayerNorm.bias", "bert.encoder.layer.2.intermediate.dense.weight", "bert.encoder.layer.2.intermediate.dense.bias", "bert.encoder.layer.2.output.dense.weight", "bert.encoder.layer.2.output.dense.bias", "bert.encoder.layer.2.output.LayerNorm.weight", "bert.encoder.layer.2.output.LayerNorm.bias", "bert.encoder.layer.3.attention.self.query.weight", "bert.encoder.layer.3.attention.self.query.bias", "bert.encoder.layer.3.attention.self.key.weight", "bert.encoder.layer.3.attention.self.key.bias", "bert.encoder.layer.3.attention.self.value.weight", "bert.encoder.layer.3.attention.self.value.bias", "bert.encoder.layer.3.attention.output.dense.weight", "bert.encoder.layer.3.attention.output.dense.bias", "bert.encoder.layer.3.attention.output.LayerNorm.weight", "bert.encoder.layer.3.attention.output.LayerNorm.bias", "bert.encoder.layer.3.intermediate.dense.weight", "bert.encoder.layer.3.intermediate.dense.bias", "bert.encoder.layer.3.output.dense.weight", "bert.encoder.layer.3.output.dense.bias", "bert.encoder.layer.3.output.LayerNorm.weight", "bert.encoder.layer.3.output.LayerNorm.bias", "bert.encoder.layer.4.attention.self.query.weight", "bert.encoder.layer.4.attention.self.query.bias", "bert.encoder.layer.4.attention.self.key.weight", "bert.encoder.layer.4.attention.self.key.bias", "bert.encoder.layer.4.attention.self.value.weight", "bert.encoder.layer.4.attention.self.value.bias", "bert.encoder.layer.4.attention.output.dense.weight", "bert.encoder.layer.4.attention.output.dense.bias", "bert.encoder.layer.4.attention.output.LayerNorm.weight", "bert.encoder.layer.4.attention.output.LayerNorm.bias", "bert.encoder.layer.4.intermediate.dense.weight", "bert.encoder.layer.4.intermediate.dense.bias", "bert.encoder.layer.4.output.dense.weight", "bert.encoder.layer.4.output.dense.bias", "bert.encoder.layer.4.output.LayerNorm.weight", "bert.encoder.layer.4.output.LayerNorm.bias", "bert.encoder.layer.5.attention.self.query.weight", "bert.encoder.layer.5.attention.self.query.bias", "bert.encoder.layer.5.attention.self.key.weight", "bert.encoder.layer.5.attention.self.key.bias", "bert.encoder.layer.5.attention.self.value.weight", "bert.encoder.layer.5.attention.self.value.bias", "bert.encoder.layer.5.attention.output.dense.weight", "bert.encoder.layer.5.attention.output.dense.bias", "bert.encoder.layer.5.attention.output.LayerNorm.weight", "bert.encoder.layer.5.attention.output.LayerNorm.bias", "bert.encoder.layer.5.intermediate.dense.weight", "bert.encoder.layer.5.intermediate.dense.bias", "bert.encoder.layer.5.output.dense.weight", "bert.encoder.layer.5.output.dense.bias", "bert.encoder.layer.5.output.LayerNorm.weight", "bert.encoder.layer.5.output.LayerNorm.bias", "bert.encoder.layer.6.attention.self.query.weight", "bert.encoder.layer.6.attention.self.query.bias", "bert.encoder.layer.6.attention.self.key.weight", "bert.encoder.layer.6.attention.self.key.bias", "bert.encoder.layer.6.attention.self.value.weight", "bert.encoder.layer.6.attention.self.value.bias", "bert.encoder.layer.6.attention.output.dense.weight", "bert.encoder.layer.6.attention.output.dense.bias", "bert.encoder.layer.6.attention.output.LayerNorm.weight", "bert.encoder.layer.6.attention.output.LayerNorm.bias", "bert.encoder.layer.6.intermediate.dense.weight", "bert.encoder.layer.6.intermediate.dense.bias", "bert.encoder.layer.6.output.dense.weight", "bert.encoder.layer.6.output.dense.bias", "bert.encoder.layer.6.output.LayerNorm.weight", "bert.encoder.layer.6.output.LayerNorm.bias", "bert.encoder.layer.7.attention.self.query.weight", "bert.encoder.layer.7.attention.self.query.bias", "bert.encoder.layer.7.attention.self.key.weight", "bert.encoder.layer.7.attention.self.key.bias", "bert.encoder.layer.7.attention.self.value.weight", "bert.encoder.layer.7.attention.self.value.bias", "bert.encoder.layer.7.attention.output.dense.weight", "bert.encoder.layer.7.attention.output.dense.bias", "bert.encoder.layer.7.attention.output.LayerNorm.weight", "bert.encoder.layer.7.attention.output.LayerNorm.bias", "bert.encoder.layer.7.intermediate.dense.weight", "bert.encoder.layer.7.intermediate.dense.bias", "bert.encoder.layer.7.output.dense.weight", "bert.encoder.layer.7.output.dense.bias", "bert.encoder.layer.7.output.LayerNorm.weight", "bert.encoder.layer.7.output.LayerNorm.bias", "bert.encoder.layer.8.attention.self.query.weight", "bert.encoder.layer.8.attention.self.query.bias", "bert.encoder.layer.8.attention.self.key.weight", "bert.encoder.layer.8.attention.self.key.bias", "bert.encoder.layer.8.attention.self.value.weight", "bert.encoder.layer.8.attention.self.value.bias", "bert.encoder.layer.8.attention.output.dense.weight", "bert.encoder.layer.8.attention.output.dense.bias", "bert.encoder.layer.8.attention.output.LayerNorm.weight", "bert.encoder.layer.8.attention.output.LayerNorm.bias", "bert.encoder.layer.8.intermediate.dense.weight", "bert.encoder.layer.8.intermediate.dense.bias", "bert.encoder.layer.8.output.dense.weight", "bert.encoder.layer.8.output.dense.bias", "bert.encoder.layer.8.output.LayerNorm.weight", "bert.encoder.layer.8.output.LayerNorm.bias", "bert.encoder.layer.9.attention.self.query.weight", "bert.encoder.layer.9.attention.self.query.bias", "bert.encoder.layer.9.attention.self.key.weight", "bert.encoder.layer.9.attention.self.key.bias", "bert.encoder.layer.9.attention.self.value.weight", "bert.encoder.layer.9.attention.self.value.bias", "bert.encoder.layer.9.attention.output.dense.weight", "bert.encoder.layer.9.attention.output.dense.bias", "bert.encoder.layer.9.attention.output.LayerNorm.weight", "bert.encoder.layer.9.attention.output.LayerNorm.bias", "bert.encoder.layer.9.intermediate.dense.weight", "bert.encoder.layer.9.intermediate.dense.bias", "bert.encoder.layer.9.output.dense.weight", "bert.encoder.layer.9.output.dense.bias", "bert.encoder.layer.9.output.LayerNorm.weight", "bert.encoder.layer.9.output.LayerNorm.bias", "bert.encoder.layer.10.attention.self.query.weight", "bert.encoder.layer.10.attention.self.query.bias", "bert.encoder.layer.10.attention.self.key.weight", "bert.encoder.layer.10.attention.self.key.bias", "bert.encoder.layer.10.attention.self.value.weight", "bert.encoder.layer.10.attention.self.value.bias", "bert.encoder.layer.10.attention.output.dense.weight", "bert.encoder.layer.10.attention.output.dense.bias", "bert.encoder.layer.10.attention.output.LayerNorm.weight", "bert.encoder.layer.10.attention.output.LayerNorm.bias", "bert.encoder.layer.10.intermediate.dense.weight", "bert.encoder.layer.10.intermediate.dense.bias", "bert.encoder.layer.10.output.dense.weight", "bert.encoder.layer.10.output.dense.bias", "bert.encoder.layer.10.output.LayerNorm.weight", "bert.encoder.layer.10.output.LayerNorm.bias", "bert.encoder.layer.11.attention.self.query.weight", "bert.encoder.layer.11.attention.self.query.bias", "bert.encoder.layer.11.attention.self.key.weight", "bert.encoder.layer.11.attention.self.key.bias", "bert.encoder.layer.11.attention.self.value.weight", "bert.encoder.layer.11.attention.self.value.bias", "bert.encoder.layer.11.attention.output.dense.weight", "bert.encoder.layer.11.attention.output.dense.bias", "bert.encoder.layer.11.attention.output.LayerNorm.weight", "bert.encoder.layer.11.attention.output.LayerNorm.bias", "bert.encoder.layer.11.intermediate.dense.weight", "bert.encoder.layer.11.intermediate.dense.bias", "bert.encoder.layer.11.output.dense.weight", "bert.encoder.layer.11.output.dense.bias", "bert.encoder.layer.11.output.LayerNorm.weight", "bert.encoder.layer.11.output.LayerNorm.bias", "bert.encoder.layer.12.attention.self.query.weight", "bert.encoder.layer.12.attention.self.query.bias", "bert.encoder.layer.12.attention.self.key.weight", "bert.encoder.layer.12.attention.self.key.bias", "bert.encoder.layer.12.attention.self.value.weight", "bert.encoder.layer.12.attention.self.value.bias", "bert.encoder.layer.12.attention.output.dense.weight", "bert.encoder.layer.12.attention.output.dense.bias", "bert.encoder.layer.12.attention.output.LayerNorm.weight", "bert.encoder.layer.12.attention.output.LayerNorm.bias", "bert.encoder.layer.12.intermediate.dense.weight", "bert.encoder.layer.12.intermediate.dense.bias", "bert.encoder.layer.12.output.dense.weight", "bert.encoder.layer.12.output.dense.bias", "bert.encoder.layer.12.output.LayerNorm.weight", "bert.encoder.layer.12.output.LayerNorm.bias", "bert.encoder.layer.13.attention.self.query.weight", "bert.encoder.layer.13.attention.self.query.bias", "bert.encoder.layer.13.attention.self.key.weight", "bert.encoder.layer.13.attention.self.key.bias", "bert.encoder.layer.13.attention.self.value.weight", "bert.encoder.layer.13.attention.self.value.bias", "bert.encoder.layer.13.attention.output.dense.weight", "bert.encoder.layer.13.attention.output.dense.bias", "bert.encoder.layer.13.attention.output.LayerNorm.weight", "bert.encoder.layer.13.attention.output.LayerNorm.bias", "bert.encoder.layer.13.intermediate.dense.weight", "bert.encoder.layer.13.intermediate.dense.bias", "bert.encoder.layer.13.output.dense.weight", "bert.encoder.layer.13.output.dense.bias", "bert.encoder.layer.13.output.LayerNorm.weight", "bert.encoder.layer.13.output.LayerNorm.bias", "bert.encoder.layer.14.attention.self.query.weight", "bert.encoder.layer.14.attention.self.query.bias", "bert.encoder.layer.14.attention.self.key.weight", "bert.encoder.layer.14.attention.self.key.bias", "bert.encoder.layer.14.attention.self.value.weight", "bert.encoder.layer.14.attention.self.value.bias", "bert.encoder.layer.14.attention.output.dense.weight", "bert.encoder.layer.14.attention.output.dense.bias", "bert.encoder.layer.14.attention.output.LayerNorm.weight", "bert.encoder.layer.14.attention.output.LayerNorm.bias", "bert.encoder.layer.14.intermediate.dense.weight", "bert.encoder.layer.14.intermediate.dense.bias", "bert.encoder.layer.14.output.dense.weight", "bert.encoder.layer.14.output.dense.bias", "bert.encoder.layer.14.output.LayerNorm.weight", "bert.encoder.layer.14.output.LayerNorm.bias", "bert.encoder.layer.15.attention.self.query.weight", "bert.encoder.layer.15.attention.self.query.bias", "bert.encoder.layer.15.attention.self.key.weight", "bert.encoder.layer.15.attention.self.key.bias", "bert.encoder.layer.15.attention.self.value.weight", "bert.encoder.layer.15.attention.self.value.bias", "bert.encoder.layer.15.attention.output.dense.weight", "bert.encoder.layer.15.attention.output.dense.bias", "bert.encoder.layer.15.attention.output.LayerNorm.weight", "bert.encoder.layer.15.attention.output.LayerNorm.bias", "bert.encoder.layer.15.intermediate.dense.weight", "bert.encoder.layer.15.intermediate.dense.bias", "bert.encoder.layer.15.output.dense.weight", "bert.encoder.layer.15.output.dense.bias", "bert.encoder.layer.15.output.LayerNorm.weight", "bert.encoder.layer.15.output.LayerNorm.bias", "bert.encoder.layer.16.attention.self.query.weight", "bert.encoder.layer.16.attention.self.query.bias", "bert.encoder.layer.16.attention.self.key.weight", "bert.encoder.layer.16.attention.self.key.bias", "bert.encoder.layer.16.attention.self.value.weight", "bert.encoder.layer.16.attention.self.value.bias", "bert.encoder.layer.16.attention.output.dense.weight", "bert.encoder.layer.16.attention.output.dense.bias", "bert.encoder.layer.16.attention.output.LayerNorm.weight", "bert.encoder.layer.16.attention.output.LayerNorm.bias", "bert.encoder.layer.16.intermediate.dense.weight", "bert.encoder.layer.16.intermediate.dense.bias", "bert.encoder.layer.16.output.dense.weight", "bert.encoder.layer.16.output.dense.bias", "bert.encoder.layer.16.output.LayerNorm.weight", "bert.encoder.layer.16.output.LayerNorm.bias", "bert.encoder.layer.17.attention.self.query.weight", "bert.encoder.layer.17.attention.self.query.bias", "bert.encoder.layer.17.attention.self.key.weight", "bert.encoder.layer.17.attention.self.key.bias", "bert.encoder.layer.17.attention.self.value.weight", "bert.encoder.layer.17.attention.self.value.bias", "bert.encoder.layer.17.attention.output.dense.weight", "bert.encoder.layer.17.attention.output.dense.bias", "bert.encoder.layer.17.attention.output.LayerNorm.weight", "bert.encoder.layer.17.attention.output.LayerNorm.bias", "bert.encoder.layer.17.intermediate.dense.weight", "bert.encoder.layer.17.intermediate.dense.bias", "bert.encoder.layer.17.output.dense.weight", "bert.encoder.layer.17.output.dense.bias", "bert.encoder.layer.17.output.LayerNorm.weight", "bert.encoder.layer.17.output.LayerNorm.bias", "bert.encoder.layer.18.attention.self.query.weight", "bert.encoder.layer.18.attention.self.query.bias", "bert.encoder.layer.18.attention.self.key.weight", "bert.encoder.layer.18.attention.self.key.bias", "bert.encoder.layer.18.attention.self.value.weight", "bert.encoder.layer.18.attention.self.value.bias", "bert.encoder.layer.18.attention.output.dense.weight", "bert.encoder.layer.18.attention.output.dense.bias", "bert.encoder.layer.18.attention.output.LayerNorm.weight", "bert.encoder.layer.18.attention.output.LayerNorm.bias", "bert.encoder.layer.18.intermediate.dense.weight", "bert.encoder.layer.18.intermediate.dense.bias", "bert.encoder.layer.18.output.dense.weight", "bert.encoder.layer.18.output.dense.bias", "bert.encoder.layer.18.output.LayerNorm.weight", "bert.encoder.layer.18.output.LayerNorm.bias", "bert.encoder.layer.19.attention.self.query.weight", "bert.encoder.layer.19.attention.self.query.bias", "bert.encoder.layer.19.attention.self.key.weight", "bert.encoder.layer.19.attention.self.key.bias", "bert.encoder.layer.19.attention.self.value.weight", "bert.encoder.layer.19.attention.self.value.bias", "bert.encoder.layer.19.attention.output.dense.weight", "bert.encoder.layer.19.attention.output.dense.bias", "bert.encoder.layer.19.attention.output.LayerNorm.weight", "bert.encoder.layer.19.attention.output.LayerNorm.bias", "bert.encoder.layer.19.intermediate.dense.weight", "bert.encoder.layer.19.intermediate.dense.bias", "bert.encoder.layer.19.output.dense.weight", "bert.encoder.layer.19.output.dense.bias", "bert.encoder.layer.19.output.LayerNorm.weight", "bert.encoder.layer.19.output.LayerNorm.bias", "bert.encoder.layer.20.attention.self.query.weight", "bert.encoder.layer.20.attention.self.query.bias", "bert.encoder.layer.20.attention.self.key.weight", "bert.encoder.layer.20.attention.self.key.bias", "bert.encoder.layer.20.attention.self.value.weight", "bert.encoder.layer.20.attention.self.value.bias", "bert.encoder.layer.20.attention.output.dense.weight", "bert.encoder.layer.20.attention.output.dense.bias", "bert.encoder.layer.20.attention.output.LayerNorm.weight", "bert.encoder.layer.20.attention.output.LayerNorm.bias", "bert.encoder.layer.20.intermediate.dense.weight", "bert.encoder.layer.20.intermediate.dense.bias", "bert.encoder.layer.20.output.dense.weight", "bert.encoder.layer.20.output.dense.bias", "bert.encoder.layer.20.output.LayerNorm.weight", "bert.encoder.layer.20.output.LayerNorm.bias", "bert.encoder.layer.21.attention.self.query.weight", "bert.encoder.layer.21.attention.self.query.bias", "bert.encoder.layer.21.attention.self.key.weight", "bert.encoder.layer.21.attention.self.key.bias", "bert.encoder.layer.21.attention.self.value.weight", "bert.encoder.layer.21.attention.self.value.bias", "bert.encoder.layer.21.attention.output.dense.weight", "bert.encoder.layer.21.attention.output.dense.bias", "bert.encoder.layer.21.attention.output.LayerNorm.weight", "bert.encoder.layer.21.attention.output.LayerNorm.bias", "bert.encoder.layer.21.intermediate.dense.weight", "bert.encoder.layer.21.intermediate.dense.bias", "bert.encoder.layer.21.output.dense.weight", "bert.encoder.layer.21.output.dense.bias", "bert.encoder.layer.21.output.LayerNorm.weight", "bert.encoder.layer.21.output.LayerNorm.bias", "bert.encoder.layer.22.attention.self.query.weight", "bert.encoder.layer.22.attention.self.query.bias", "bert.encoder.layer.22.attention.self.key.weight", "bert.encoder.layer.22.attention.self.key.bias", "bert.encoder.layer.22.attention.self.value.weight", "bert.encoder.layer.22.attention.self.value.bias", "bert.encoder.layer.22.attention.output.dense.weight", "bert.encoder.layer.22.attention.output.dense.bias", "bert.encoder.layer.22.attention.output.LayerNorm.weight", "bert.encoder.layer.22.attention.output.LayerNorm.bias", "bert.encoder.layer.22.intermediate.dense.weight", "bert.encoder.layer.22.intermediate.dense.bias", "bert.encoder.layer.22.output.dense.weight", "bert.encoder.layer.22.output.dense.bias", "bert.encoder.layer.22.output.LayerNorm.weight", "bert.encoder.layer.22.output.LayerNorm.bias", "bert.encoder.layer.23.attention.self.query.weight", "bert.encoder.layer.23.attention.self.query.bias", "bert.encoder.layer.23.attention.self.key.weight", "bert.encoder.layer.23.attention.self.key.bias", "bert.encoder.layer.23.attention.self.value.weight", "bert.encoder.layer.23.attention.self.value.bias", "bert.encoder.layer.23.attention.output.dense.weight", "bert.encoder.layer.23.attention.output.dense.bias", "bert.encoder.layer.23.attention.output.LayerNorm.weight", "bert.encoder.layer.23.attention.output.LayerNorm.bias", "bert.encoder.layer.23.intermediate.dense.weight", "bert.encoder.layer.23.intermediate.dense.bias", "bert.encoder.layer.23.output.dense.weight", "bert.encoder.layer.23.output.dense.bias", "bert.encoder.layer.23.output.LayerNorm.weight", "bert.encoder.layer.23.output.LayerNorm.bias", "classifier.layers.0.weight", "classifier.layers.0.bias", "classifier.layers.1.projection.weight", "classifier.layers.1.projection.bias", "classifier.layers.3.weight", "classifier.layers.3.bias", "classifier.layers.4.projection.weight", "classifier.layers.4.projection.bias", "classifier.layers.6.weight", "classifier.layers.6.bias". 
	Unexpected key(s) in state_dict: "layers.0.weight", "layers.0.bias", "layers.1.projection.weight", "layers.1.projection.bias", "layers.3.weight", "layers.3.bias", "layers.4.projection.weight", "layers.4.projection.bias", "layers.6.weight", "layers.6.bias". 
Traceback (most recent call last):
Traceback (most recent call last):
  File "/home/ubuntu/nlp-osaka/sentiment/ddp_sentiment_finetune.py", line 1206, in main
    classifier.fit(X_train, X_val, y_train, y_val, rank, world_size, debug, start_epoch, model_state_dict, optimizer_state_dict,
  File "/home/ubuntu/nlp-osaka/sentiment/torch_ddp_finetune_neural_classifier.py", line 1070, in fit
    self.model.load_state_dict(model_state_dict)
  File "/home/ubuntu/nlp-osaka/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 2152, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
  File "/home/ubuntu/nlp-osaka/sentiment/ddp_sentiment_finetune.py", line 1206, in main
    classifier.fit(X_train, X_val, y_train, y_val, rank, world_size, debug, start_epoch, model_state_dict, optimizer_state_dict,
RuntimeError: Error(s) in loading state_dict for BERTClassifier:
	Missing key(s) in state_dict: "bert.embeddings.word_embeddings.weight", "bert.embeddings.position_embeddings.weight", "bert.embeddings.token_type_embeddings.weight", "bert.embeddings.LayerNorm.weight", "bert.embeddings.LayerNorm.bias", "bert.encoder.layer.0.attention.self.query.weight", "bert.encoder.layer.0.attention.self.query.bias", "bert.encoder.layer.0.attention.self.key.weight", "bert.encoder.layer.0.attention.self.key.bias", "bert.encoder.layer.0.attention.self.value.weight", "bert.encoder.layer.0.attention.self.value.bias", "bert.encoder.layer.0.attention.output.dense.weight", "bert.encoder.layer.0.attention.output.dense.bias", "bert.encoder.layer.0.attention.output.LayerNorm.weight", "bert.encoder.layer.0.attention.output.LayerNorm.bias", "bert.encoder.layer.0.intermediate.dense.weight", "bert.encoder.layer.0.intermediate.dense.bias", "bert.encoder.layer.0.output.dense.weight", "bert.encoder.layer.0.output.dense.bias", "bert.encoder.layer.0.output.LayerNorm.weight", "bert.encoder.layer.0.output.LayerNorm.bias", "bert.encoder.layer.1.attention.self.query.weight", "bert.encoder.layer.1.attention.self.query.bias", "bert.encoder.layer.1.attention.self.key.weight", "bert.encoder.layer.1.attention.self.key.bias", "bert.encoder.layer.1.attention.self.value.weight", "bert.encoder.layer.1.attention.self.value.bias", "bert.encoder.layer.1.attention.output.dense.weight", "bert.encoder.layer.1.attention.output.dense.bias", "bert.encoder.layer.1.attention.output.LayerNorm.weight", "bert.encoder.layer.1.attention.output.LayerNorm.bias", "bert.encoder.layer.1.intermediate.dense.weight", "bert.encoder.layer.1.intermediate.dense.bias", "bert.encoder.layer.1.output.dense.weight", "bert.encoder.layer.1.output.dense.bias", "bert.encoder.layer.1.output.LayerNorm.weight", "bert.encoder.layer.1.output.LayerNorm.bias", "bert.encoder.layer.2.attention.self.query.weight", "bert.encoder.layer.2.attention.self.query.bias", "bert.encoder.layer.2.attention.self.key.weight", "bert.encoder.layer.2.attention.self.key.bias", "bert.encoder.layer.2.attention.self.value.weight", "bert.encoder.layer.2.attention.self.value.bias", "bert.encoder.layer.2.attention.output.dense.weight", "bert.encoder.layer.2.attention.output.dense.bias", "bert.encoder.layer.2.attention.output.LayerNorm.weight", "bert.encoder.layer.2.attention.output.LayerNorm.bias", "bert.encoder.layer.2.intermediate.dense.weight", "bert.encoder.layer.2.intermediate.dense.bias", "bert.encoder.layer.2.output.dense.weight", "bert.encoder.layer.2.output.dense.bias", "bert.encoder.layer.2.output.LayerNorm.weight", "bert.encoder.layer.2.output.LayerNorm.bias", "bert.encoder.layer.3.attention.self.query.weight", "bert.encoder.layer.3.attention.self.query.bias", "bert.encoder.layer.3.attention.self.key.weight", "bert.encoder.layer.3.attention.self.key.bias", "bert.encoder.layer.3.attention.self.value.weight", "bert.encoder.layer.3.attention.self.value.bias", "bert.encoder.layer.3.attention.output.dense.weight", "bert.encoder.layer.3.attention.output.dense.bias", "bert.encoder.layer.3.attention.output.LayerNorm.weight", "bert.encoder.layer.3.attention.output.LayerNorm.bias", "bert.encoder.layer.3.intermediate.dense.weight", "bert.encoder.layer.3.intermediate.dense.bias", "bert.encoder.layer.3.output.dense.weight", "bert.encoder.layer.3.output.dense.bias", "bert.encoder.layer.3.output.LayerNorm.weight", "bert.encoder.layer.3.output.LayerNorm.bias", "bert.encoder.layer.4.attention.self.query.weight", "bert.encoder.layer.4.attention.self.query.bias", "bert.encoder.layer.4.attention.self.key.weight", "bert.encoder.layer.4.attention.self.key.bias", "bert.encoder.layer.4.attention.self.value.weight", "bert.encoder.layer.4.attention.self.value.bias", "bert.encoder.layer.4.attention.output.dense.weight", "bert.encoder.layer.4.attention.output.dense.bias", "bert.encoder.layer.4.attention.output.LayerNorm.weight", "bert.encoder.layer.4.attention.output.LayerNorm.bias", "bert.encoder.layer.4.intermediate.dense.weight", "bert.encoder.layer.4.intermediate.dense.bias", "bert.encoder.layer.4.output.dense.weight", "bert.encoder.layer.4.output.dense.bias", "bert.encoder.layer.4.output.LayerNorm.weight", "bert.encoder.layer.4.output.LayerNorm.bias", "bert.encoder.layer.5.attention.self.query.weight", "bert.encoder.layer.5.attention.self.query.bias", "bert.encoder.layer.5.attention.self.key.weight", "bert.encoder.layer.5.attention.self.key.bias", "bert.encoder.layer.5.attention.self.value.weight", "bert.encoder.layer.5.attention.self.value.bias", "bert.encoder.layer.5.attention.output.dense.weight", "bert.encoder.layer.5.attention.output.dense.bias", "bert.encoder.layer.5.attention.output.LayerNorm.weight", "bert.encoder.layer.5.attention.output.LayerNorm.bias", "bert.encoder.layer.5.intermediate.dense.weight", "bert.encoder.layer.5.intermediate.dense.bias", "bert.encoder.layer.5.output.dense.weight", "bert.encoder.layer.5.output.dense.bias", "bert.encoder.layer.5.output.LayerNorm.weight", "bert.encoder.layer.5.output.LayerNorm.bias", "bert.encoder.layer.6.attention.self.query.weight", "bert.encoder.layer.6.attention.self.query.bias", "bert.encoder.layer.6.attention.self.key.weight", "bert.encoder.layer.6.attention.self.key.bias", "bert.encoder.layer.6.attention.self.value.weight", "bert.encoder.layer.6.attention.self.value.bias", "bert.encoder.layer.6.attention.output.dense.weight", "bert.encoder.layer.6.attention.output.dense.bias", "bert.encoder.layer.6.attention.output.LayerNorm.weight", "bert.encoder.layer.6.attention.output.LayerNorm.bias", "bert.encoder.layer.6.intermediate.dense.weight", "bert.encoder.layer.6.intermediate.dense.bias", "bert.encoder.layer.6.output.dense.weight", "bert.encoder.layer.6.output.dense.bias", "bert.encoder.layer.6.output.LayerNorm.weight", "bert.encoder.layer.6.output.LayerNorm.bias", "bert.encoder.layer.7.attention.self.query.weight", "bert.encoder.layer.7.attention.self.query.bias", "bert.encoder.layer.7.attention.self.key.weight", "bert.encoder.layer.7.attention.self.key.bias", "bert.encoder.layer.7.attention.self.value.weight", "bert.encoder.layer.7.attention.self.value.bias", "bert.encoder.layer.7.attention.output.dense.weight", "bert.encoder.layer.7.attention.output.dense.bias", "bert.encoder.layer.7.attention.output.LayerNorm.weight", "bert.encoder.layer.7.attention.output.LayerNorm.bias", "bert.encoder.layer.7.intermediate.dense.weight", "bert.encoder.layer.7.intermediate.dense.bias", "bert.encoder.layer.7.output.dense.weight", "bert.encoder.layer.7.output.dense.bias", "bert.encoder.layer.7.output.LayerNorm.weight", "bert.encoder.layer.7.output.LayerNorm.bias", "bert.encoder.layer.8.attention.self.query.weight", "bert.encoder.layer.8.attention.self.query.bias", "bert.encoder.layer.8.attention.self.key.weight", "bert.encoder.layer.8.attention.self.key.bias", "bert.encoder.layer.8.attention.self.value.weight", "bert.encoder.layer.8.attention.self.value.bias", "bert.encoder.layer.8.attention.output.dense.weight", "bert.encoder.layer.8.attention.output.dense.bias", "bert.encoder.layer.8.attention.output.LayerNorm.weight", "bert.encoder.layer.8.attention.output.LayerNorm.bias", "bert.encoder.layer.8.intermediate.dense.weight", "bert.encoder.layer.8.intermediate.dense.bias", "bert.encoder.layer.8.output.dense.weight", "bert.encoder.layer.8.output.dense.bias", "bert.encoder.layer.8.output.LayerNorm.weight", "bert.encoder.layer.8.output.LayerNorm.bias", "bert.encoder.layer.9.attention.self.query.weight", "bert.encoder.layer.9.attention.self.query.bias", "bert.encoder.layer.9.attention.self.key.weight", "bert.encoder.layer.9.attention.self.key.bias", "bert.encoder.layer.9.attention.self.value.weight", "bert.encoder.layer.9.attention.self.value.bias", "bert.encoder.layer.9.attention.output.dense.weight", "bert.encoder.layer.9.attention.output.dense.bias", "bert.encoder.layer.9.attention.output.LayerNorm.weight", "bert.encoder.layer.9.attention.output.LayerNorm.bias", "bert.encoder.layer.9.intermediate.dense.weight", "bert.encoder.layer.9.intermediate.dense.bias", "bert.encoder.layer.9.output.dense.weight", "bert.encoder.layer.9.output.dense.bias", "bert.encoder.layer.9.output.LayerNorm.weight", "bert.encoder.layer.9.output.LayerNorm.bias", "bert.encoder.layer.10.attention.self.query.weight", "bert.encoder.layer.10.attention.self.query.bias", "bert.encoder.layer.10.attention.self.key.weight", "bert.encoder.layer.10.attention.self.key.bias", "bert.encoder.layer.10.attention.self.value.weight", "bert.encoder.layer.10.attention.self.value.bias", "bert.encoder.layer.10.attention.output.dense.weight", "bert.encoder.layer.10.attention.output.dense.bias", "bert.encoder.layer.10.attention.output.LayerNorm.weight", "bert.encoder.layer.10.attention.output.LayerNorm.bias", "bert.encoder.layer.10.intermediate.dense.weight", "bert.encoder.layer.10.intermediate.dense.bias", "bert.encoder.layer.10.output.dense.weight", "bert.encoder.layer.10.output.dense.bias", "bert.encoder.layer.10.output.LayerNorm.weight", "bert.encoder.layer.10.output.LayerNorm.bias", "bert.encoder.layer.11.attention.self.query.weight", "bert.encoder.layer.11.attention.self.query.bias", "bert.encoder.layer.11.attention.self.key.weight", "bert.encoder.layer.11.attention.self.key.bias", "bert.encoder.layer.11.attention.self.value.weight", "bert.encoder.layer.11.attention.self.value.bias", "bert.encoder.layer.11.attention.output.dense.weight", "bert.encoder.layer.11.attention.output.dense.bias", "bert.encoder.layer.11.attention.output.LayerNorm.weight", "bert.encoder.layer.11.attention.output.LayerNorm.bias", "bert.encoder.layer.11.intermediate.dense.weight", "bert.encoder.layer.11.intermediate.dense.bias", "bert.encoder.layer.11.output.dense.weight", "bert.encoder.layer.11.output.dense.bias", "bert.encoder.layer.11.output.LayerNorm.weight", "bert.encoder.layer.11.output.LayerNorm.bias", "bert.encoder.layer.12.attention.self.query.weight", "bert.encoder.layer.12.attention.self.query.bias", "bert.encoder.layer.12.attention.self.key.weight", "bert.encoder.layer.12.attention.self.key.bias", "bert.encoder.layer.12.attention.self.value.weight", "bert.encoder.layer.12.attention.self.value.bias", "bert.encoder.layer.12.attention.output.dense.weight", "bert.encoder.layer.12.attention.output.dense.bias", "bert.encoder.layer.12.attention.output.LayerNorm.weight", "bert.encoder.layer.12.attention.output.LayerNorm.bias", "bert.encoder.layer.12.intermediate.dense.weight", "bert.encoder.layer.12.intermediate.dense.bias", "bert.encoder.layer.12.output.dense.weight", "bert.encoder.layer.12.output.dense.bias", "bert.encoder.layer.12.output.LayerNorm.weight", "bert.encoder.layer.12.output.LayerNorm.bias", "bert.encoder.layer.13.attention.self.query.weight", "bert.encoder.layer.13.attention.self.query.bias", "bert.encoder.layer.13.attention.self.key.weight", "bert.encoder.layer.13.attention.self.key.bias", "bert.encoder.layer.13.attention.self.value.weight", "bert.encoder.layer.13.attention.self.value.bias", "bert.encoder.layer.13.attention.output.dense.weight", "bert.encoder.layer.13.attention.output.dense.bias", "bert.encoder.layer.13.attention.output.LayerNorm.weight", "bert.encoder.layer.13.attention.output.LayerNorm.bias", "bert.encoder.layer.13.intermediate.dense.weight", "bert.encoder.layer.13.intermediate.dense.bias", "bert.encoder.layer.13.output.dense.weight", "bert.encoder.layer.13.output.dense.bias", "bert.encoder.layer.13.output.LayerNorm.weight", "bert.encoder.layer.13.output.LayerNorm.bias", "bert.encoder.layer.14.attention.self.query.weight", "bert.encoder.layer.14.attention.self.query.bias", "bert.encoder.layer.14.attention.self.key.weight", "bert.encoder.layer.14.attention.self.key.bias", "bert.encoder.layer.14.attention.self.value.weight", "bert.encoder.layer.14.attention.self.value.bias", "bert.encoder.layer.14.attention.output.dense.weight", "bert.encoder.layer.14.attention.output.dense.bias", "bert.encoder.layer.14.attention.output.LayerNorm.weight", "bert.encoder.layer.14.attention.output.LayerNorm.bias", "bert.encoder.layer.14.intermediate.dense.weight", "bert.encoder.layer.14.intermediate.dense.bias", "bert.encoder.layer.14.output.dense.weight", "bert.encoder.layer.14.output.dense.bias", "bert.encoder.layer.14.output.LayerNorm.weight", "bert.encoder.layer.14.output.LayerNorm.bias", "bert.encoder.layer.15.attention.self.query.weight", "bert.encoder.layer.15.attention.self.query.bias", "bert.encoder.layer.15.attention.self.key.weight", "bert.encoder.layer.15.attention.self.key.bias", "bert.encoder.layer.15.attention.self.value.weight", "bert.encoder.layer.15.attention.self.value.bias", "bert.encoder.layer.15.attention.output.dense.weight", "bert.encoder.layer.15.attention.output.dense.bias", "bert.encoder.layer.15.attention.output.LayerNorm.weight", "bert.encoder.layer.15.attention.output.LayerNorm.bias", "bert.encoder.layer.15.intermediate.dense.weight", "bert.encoder.layer.15.intermediate.dense.bias", "bert.encoder.layer.15.output.dense.weight", "bert.encoder.layer.15.output.dense.bias", "bert.encoder.layer.15.output.LayerNorm.weight", "bert.encoder.layer.15.output.LayerNorm.bias", "bert.encoder.layer.16.attention.self.query.weight", "bert.encoder.layer.16.attention.self.query.bias", "bert.encoder.layer.16.attention.self.key.weight", "bert.encoder.layer.16.attention.self.key.bias", "bert.encoder.layer.16.attention.self.value.weight", "bert.encoder.layer.16.attention.self.value.bias", "bert.encoder.layer.16.attention.output.dense.weight", "bert.encoder.layer.16.attention.output.dense.bias", "bert.encoder.layer.16.attention.output.LayerNorm.weight", "bert.encoder.layer.16.attention.output.LayerNorm.bias", "bert.encoder.layer.16.intermediate.dense.weight", "bert.encoder.layer.16.intermediate.dense.bias", "bert.encoder.layer.16.output.dense.weight", "bert.encoder.layer.16.output.dense.bias", "bert.encoder.layer.16.output.LayerNorm.weight", "bert.encoder.layer.16.output.LayerNorm.bias", "bert.encoder.layer.17.attention.self.query.weight", "bert.encoder.layer.17.attention.self.query.bias", "bert.encoder.layer.17.attention.self.key.weight", "bert.encoder.layer.17.attention.self.key.bias", "bert.encoder.layer.17.attention.self.value.weight", "bert.encoder.layer.17.attention.self.value.bias", "bert.encoder.layer.17.attention.output.dense.weight", "bert.encoder.layer.17.attention.output.dense.bias", "bert.encoder.layer.17.attention.output.LayerNorm.weight", "bert.encoder.layer.17.attention.output.LayerNorm.bias", "bert.encoder.layer.17.intermediate.dense.weight", "bert.encoder.layer.17.intermediate.dense.bias", "bert.encoder.layer.17.output.dense.weight", "bert.encoder.layer.17.output.dense.bias", "bert.encoder.layer.17.output.LayerNorm.weight", "bert.encoder.layer.17.output.LayerNorm.bias", "bert.encoder.layer.18.attention.self.query.weight", "bert.encoder.layer.18.attention.self.query.bias", "bert.encoder.layer.18.attention.self.key.weight", "bert.encoder.layer.18.attention.self.key.bias", "bert.encoder.layer.18.attention.self.value.weight", "bert.encoder.layer.18.attention.self.value.bias", "bert.encoder.layer.18.attention.output.dense.weight", "bert.encoder.layer.18.attention.output.dense.bias", "bert.encoder.layer.18.attention.output.LayerNorm.weight", "bert.encoder.layer.18.attention.output.LayerNorm.bias", "bert.encoder.layer.18.intermediate.dense.weight", "bert.encoder.layer.18.intermediate.dense.bias", "bert.encoder.layer.18.output.dense.weight", "bert.encoder.layer.18.output.dense.bias", "bert.encoder.layer.18.output.LayerNorm.weight", "bert.encoder.layer.18.output.LayerNorm.bias", "bert.encoder.layer.19.attention.self.query.weight", "bert.encoder.layer.19.attention.self.query.bias", "bert.encoder.layer.19.attention.self.key.weight", "bert.encoder.layer.19.attention.self.key.bias", "bert.encoder.layer.19.attention.self.value.weight", "bert.encoder.layer.19.attention.self.value.bias", "bert.encoder.layer.19.attention.output.dense.weight", "bert.encoder.layer.19.attention.output.dense.bias", "bert.encoder.layer.19.attention.output.LayerNorm.weight", "bert.encoder.layer.19.attention.output.LayerNorm.bias", "bert.encoder.layer.19.intermediate.dense.weight", "bert.encoder.layer.19.intermediate.dense.bias", "bert.encoder.layer.19.output.dense.weight", "bert.encoder.layer.19.output.dense.bias", "bert.encoder.layer.19.output.LayerNorm.weight", "bert.encoder.layer.19.output.LayerNorm.bias", "bert.encoder.layer.20.attention.self.query.weight", "bert.encoder.layer.20.attention.self.query.bias", "bert.encoder.layer.20.attention.self.key.weight", "bert.encoder.layer.20.attention.self.key.bias", "bert.encoder.layer.20.attention.self.value.weight", "bert.encoder.layer.20.attention.self.value.bias", "bert.encoder.layer.20.attention.output.dense.weight", "bert.encoder.layer.20.attention.output.dense.bias", "bert.encoder.layer.20.attention.output.LayerNorm.weight", "bert.encoder.layer.20.attention.output.LayerNorm.bias", "bert.encoder.layer.20.intermediate.dense.weight", "bert.encoder.layer.20.intermediate.dense.bias", "bert.encoder.layer.20.output.dense.weight", "bert.encoder.layer.20.output.dense.bias", "bert.encoder.layer.20.output.LayerNorm.weight", "bert.encoder.layer.20.output.LayerNorm.bias", "bert.encoder.layer.21.attention.self.query.weight", "bert.encoder.layer.21.attention.self.query.bias", "bert.encoder.layer.21.attention.self.key.weight", "bert.encoder.layer.21.attention.self.key.bias", "bert.encoder.layer.21.attention.self.value.weight", "bert.encoder.layer.21.attention.self.value.bias", "bert.encoder.layer.21.attention.output.dense.weight", "bert.encoder.layer.21.attention.output.dense.bias", "bert.encoder.layer.21.attention.output.LayerNorm.weight", "bert.encoder.layer.21.attention.output.LayerNorm.bias", "bert.encoder.layer.21.intermediate.dense.weight", "bert.encoder.layer.21.intermediate.dense.bias", "bert.encoder.layer.21.output.dense.weight", "bert.encoder.layer.21.output.dense.bias", "bert.encoder.layer.21.output.LayerNorm.weight", "bert.encoder.layer.21.output.LayerNorm.bias", "bert.encoder.layer.22.attention.self.query.weight", "bert.encoder.layer.22.attention.self.query.bias", "bert.encoder.layer.22.attention.self.key.weight", "bert.encoder.layer.22.attention.self.key.bias", "bert.encoder.layer.22.attention.self.value.weight", "bert.encoder.layer.22.attention.self.value.bias", "bert.encoder.layer.22.attention.output.dense.weight", "bert.encoder.layer.22.attention.output.dense.bias", "bert.encoder.layer.22.attention.output.LayerNorm.weight", "bert.encoder.layer.22.attention.output.LayerNorm.bias", "bert.encoder.layer.22.intermediate.dense.weight", "bert.encoder.layer.22.intermediate.dense.bias", "bert.encoder.layer.22.output.dense.weight", "bert.encoder.layer.22.output.dense.bias", "bert.encoder.layer.22.output.LayerNorm.weight", "bert.encoder.layer.22.output.LayerNorm.bias", "bert.encoder.layer.23.attention.self.query.weight", "bert.encoder.layer.23.attention.self.query.bias", "bert.encoder.layer.23.attention.self.key.weight", "bert.encoder.layer.23.attention.self.key.bias", "bert.encoder.layer.23.attention.self.value.weight", "bert.encoder.layer.23.attention.self.value.bias", "bert.encoder.layer.23.attention.output.dense.weight", "bert.encoder.layer.23.attention.output.dense.bias", "bert.encoder.layer.23.attention.output.LayerNorm.weight", "bert.encoder.layer.23.attention.output.LayerNorm.bias", "bert.encoder.layer.23.intermediate.dense.weight", "bert.encoder.layer.23.intermediate.dense.bias", "bert.encoder.layer.23.output.dense.weight", "bert.encoder.layer.23.output.dense.bias", "bert.encoder.layer.23.output.LayerNorm.weight", "bert.encoder.layer.23.output.LayerNorm.bias", "classifier.layers.0.weight", "classifier.layers.0.bias", "classifier.layers.1.projection.weight", "classifier.layers.1.projection.bias", "classifier.layers.3.weight", "classifier.layers.3.bias", "classifier.layers.4.projection.weight", "classifier.layers.4.projection.bias", "classifier.layers.6.weight", "classifier.layers.6.bias". 
	Unexpected key(s) in state_dict: "layers.0.weight", "layers.0.bias", "layers.1.projection.weight", "layers.1.projection.bias", "layers.3.weight", "layers.3.bias", "layers.4.projection.weight", "layers.4.projection.bias", "layers.6.weight", "layers.6.bias". 
  File "/home/ubuntu/nlp-osaka/sentiment/torch_ddp_finetune_neural_classifier.py", line 1070, in fit
    self.model.load_state_dict(model_state_dict)
Traceback (most recent call last):
  File "/home/ubuntu/nlp-osaka/sentiment/ddp_sentiment_finetune.py", line 1206, in main
    classifier.fit(X_train, X_val, y_train, y_val, rank, world_size, debug, start_epoch, model_state_dict, optimizer_state_dict,
  File "/home/ubuntu/nlp-osaka/sentiment/torch_ddp_finetune_neural_classifier.py", line 1070, in fit
    self.model.load_state_dict(model_state_dict)
  File "/home/ubuntu/nlp-osaka/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 2152, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
  File "/home/ubuntu/nlp-osaka/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 2152, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
Traceback (most recent call last):
RuntimeError: Error(s) in loading state_dict for BERTClassifier:
	Missing key(s) in state_dict: "bert.embeddings.word_embeddings.weight", "bert.embeddings.position_embeddings.weight", "bert.embeddings.token_type_embeddings.weight", "bert.embeddings.LayerNorm.weight", "bert.embeddings.LayerNorm.bias", "bert.encoder.layer.0.attention.self.query.weight", "bert.encoder.layer.0.attention.self.query.bias", "bert.encoder.layer.0.attention.self.key.weight", "bert.encoder.layer.0.attention.self.key.bias", "bert.encoder.layer.0.attention.self.value.weight", "bert.encoder.layer.0.attention.self.value.bias", "bert.encoder.layer.0.attention.output.dense.weight", "bert.encoder.layer.0.attention.output.dense.bias", "bert.encoder.layer.0.attention.output.LayerNorm.weight", "bert.encoder.layer.0.attention.output.LayerNorm.bias", "bert.encoder.layer.0.intermediate.dense.weight", "bert.encoder.layer.0.intermediate.dense.bias", "bert.encoder.layer.0.output.dense.weight", "bert.encoder.layer.0.output.dense.bias", "bert.encoder.layer.0.output.LayerNorm.weight", "bert.encoder.layer.0.output.LayerNorm.bias", "bert.encoder.layer.1.attention.self.query.weight", "bert.encoder.layer.1.attention.self.query.bias", "bert.encoder.layer.1.attention.self.key.weight", "bert.encoder.layer.1.attention.self.key.bias", "bert.encoder.layer.1.attention.self.value.weight", "bert.encoder.layer.1.attention.self.value.bias", "bert.encoder.layer.1.attention.output.dense.weight", "bert.encoder.layer.1.attention.output.dense.bias", "bert.encoder.layer.1.attention.output.LayerNorm.weight", "bert.encoder.layer.1.attention.output.LayerNorm.bias", "bert.encoder.layer.1.intermediate.dense.weight", "bert.encoder.layer.1.intermediate.dense.bias", "bert.encoder.layer.1.output.dense.weight", "bert.encoder.layer.1.output.dense.bias", "bert.encoder.layer.1.output.LayerNorm.weight", "bert.encoder.layer.1.output.LayerNorm.bias", "bert.encoder.layer.2.attention.self.query.weight", "bert.encoder.layer.2.attention.self.query.bias", "bert.encoder.layer.2.attention.self.key.weight", "bert.encoder.layer.2.attention.self.key.bias", "bert.encoder.layer.2.attention.self.value.weight", "bert.encoder.layer.2.attention.self.value.bias", "bert.encoder.layer.2.attention.output.dense.weight", "bert.encoder.layer.2.attention.output.dense.bias", "bert.encoder.layer.2.attention.output.LayerNorm.weight", "bert.encoder.layer.2.attention.output.LayerNorm.bias", "bert.encoder.layer.2.intermediate.dense.weight", "bert.encoder.layer.2.intermediate.dense.bias", "bert.encoder.layer.2.output.dense.weight", "bert.encoder.layer.2.output.dense.bias", "bert.encoder.layer.2.output.LayerNorm.weight", "bert.encoder.layer.2.output.LayerNorm.bias", "bert.encoder.layer.3.attention.self.query.weight", "bert.encoder.layer.3.attention.self.query.bias", "bert.encoder.layer.3.attention.self.key.weight", "bert.encoder.layer.3.attention.self.key.bias", "bert.encoder.layer.3.attention.self.value.weight", "bert.encoder.layer.3.attention.self.value.bias", "bert.encoder.layer.3.attention.output.dense.weight", "bert.encoder.layer.3.attention.output.dense.bias", "bert.encoder.layer.3.attention.output.LayerNorm.weight", "bert.encoder.layer.3.attention.output.LayerNorm.bias", "bert.encoder.layer.3.intermediate.dense.weight", "bert.encoder.layer.3.intermediate.dense.bias", "bert.encoder.layer.3.output.dense.weight", "bert.encoder.layer.3.output.dense.bias", "bert.encoder.layer.3.output.LayerNorm.weight", "bert.encoder.layer.3.output.LayerNorm.bias", "bert.encoder.layer.4.attention.self.query.weight", "bert.encoder.layer.4.attention.self.query.bias", "bert.encoder.layer.4.attention.self.key.weight", "bert.encoder.layer.4.attention.self.key.bias", "bert.encoder.layer.4.attention.self.value.weight", "bert.encoder.layer.4.attention.self.value.bias", "bert.encoder.layer.4.attention.output.dense.weight", "bert.encoder.layer.4.attention.output.dense.bias", "bert.encoder.layer.4.attention.output.LayerNorm.weight", "bert.encoder.layer.4.attention.output.LayerNorm.bias", "bert.encoder.layer.4.intermediate.dense.weight", "bert.encoder.layer.4.intermediate.dense.bias", "bert.encoder.layer.4.output.dense.weight", "bert.encoder.layer.4.output.dense.bias", "bert.encoder.layer.4.output.LayerNorm.weight", "bert.encoder.layer.4.output.LayerNorm.bias", "bert.encoder.layer.5.attention.self.query.weight", "bert.encoder.layer.5.attention.self.query.bias", "bert.encoder.layer.5.attention.self.key.weight", "bert.encoder.layer.5.attention.self.key.bias", "bert.encoder.layer.5.attention.self.value.weight", "bert.encoder.layer.5.attention.self.value.bias", "bert.encoder.layer.5.attention.output.dense.weight", "bert.encoder.layer.5.attention.output.dense.bias", "bert.encoder.layer.5.attention.output.LayerNorm.weight", "bert.encoder.layer.5.attention.output.LayerNorm.bias", "bert.encoder.layer.5.intermediate.dense.weight", "bert.encoder.layer.5.intermediate.dense.bias", "bert.encoder.layer.5.output.dense.weight", "bert.encoder.layer.5.output.dense.bias", "bert.encoder.layer.5.output.LayerNorm.weight", "bert.encoder.layer.5.output.LayerNorm.bias", "bert.encoder.layer.6.attention.self.query.weight", "bert.encoder.layer.6.attention.self.query.bias", "bert.encoder.layer.6.attention.self.key.weight", "bert.encoder.layer.6.attention.self.key.bias", "bert.encoder.layer.6.attention.self.value.weight", "bert.encoder.layer.6.attention.self.value.bias", "bert.encoder.layer.6.attention.output.dense.weight", "bert.encoder.layer.6.attention.output.dense.bias", "bert.encoder.layer.6.attention.output.LayerNorm.weight", "bert.encoder.layer.6.attention.output.LayerNorm.bias", "bert.encoder.layer.6.intermediate.dense.weight", "bert.encoder.layer.6.intermediate.dense.bias", "bert.encoder.layer.6.output.dense.weight", "bert.encoder.layer.6.output.dense.bias", "bert.encoder.layer.6.output.LayerNorm.weight", "bert.encoder.layer.6.output.LayerNorm.bias", "bert.encoder.layer.7.attention.self.query.weight", "bert.encoder.layer.7.attention.self.query.bias", "bert.encoder.layer.7.attention.self.key.weight", "bert.encoder.layer.7.attention.self.key.bias", "bert.encoder.layer.7.attention.self.value.weight", "bert.encoder.layer.7.attention.self.value.bias", "bert.encoder.layer.7.attention.output.dense.weight", "bert.encoder.layer.7.attention.output.dense.bias", "bert.encoder.layer.7.attention.output.LayerNorm.weight", "bert.encoder.layer.7.attention.output.LayerNorm.bias", "bert.encoder.layer.7.intermediate.dense.weight", "bert.encoder.layer.7.intermediate.dense.bias", "bert.encoder.layer.7.output.dense.weight", "bert.encoder.layer.7.output.dense.bias", "bert.encoder.layer.7.output.LayerNorm.weight", "bert.encoder.layer.7.output.LayerNorm.bias", "bert.encoder.layer.8.attention.self.query.weight", "bert.encoder.layer.8.attention.self.query.bias", "bert.encoder.layer.8.attention.self.key.weight", "bert.encoder.layer.8.attention.self.key.bias", "bert.encoder.layer.8.attention.self.value.weight", "bert.encoder.layer.8.attention.self.value.bias", "bert.encoder.layer.8.attention.output.dense.weight", "bert.encoder.layer.8.attention.output.dense.bias", "bert.encoder.layer.8.attention.output.LayerNorm.weight", "bert.encoder.layer.8.attention.output.LayerNorm.bias", "bert.encoder.layer.8.intermediate.dense.weight", "bert.encoder.layer.8.intermediate.dense.bias", "bert.encoder.layer.8.output.dense.weight", "bert.encoder.layer.8.output.dense.bias", "bert.encoder.layer.8.output.LayerNorm.weight", "bert.encoder.layer.8.output.LayerNorm.bias", "bert.encoder.layer.9.attention.self.query.weight", "bert.encoder.layer.9.attention.self.query.bias", "bert.encoder.layer.9.attention.self.key.weight", "bert.encoder.layer.9.attention.self.key.bias", "bert.encoder.layer.9.attention.self.value.weight", "bert.encoder.layer.9.attention.self.value.bias", "bert.encoder.layer.9.attention.output.dense.weight", "bert.encoder.layer.9.attention.output.dense.bias", "bert.encoder.layer.9.attention.output.LayerNorm.weight", "bert.encoder.layer.9.attention.output.LayerNorm.bias", "bert.encoder.layer.9.intermediate.dense.weight", "bert.encoder.layer.9.intermediate.dense.bias", "bert.encoder.layer.9.output.dense.weight", "bert.encoder.layer.9.output.dense.bias", "bert.encoder.layer.9.output.LayerNorm.weight", "bert.encoder.layer.9.output.LayerNorm.bias", "bert.encoder.layer.10.attention.self.query.weight", "bert.encoder.layer.10.attention.self.query.bias", "bert.encoder.layer.10.attention.self.key.weight", "bert.encoder.layer.10.attention.self.key.bias", "bert.encoder.layer.10.attention.self.value.weight", "bert.encoder.layer.10.attention.self.value.bias", "bert.encoder.layer.10.attention.output.dense.weight", "bert.encoder.layer.10.attention.output.dense.bias", "bert.encoder.layer.10.attention.output.LayerNorm.weight", "bert.encoder.layer.10.attention.output.LayerNorm.bias", "bert.encoder.layer.10.intermediate.dense.weight", "bert.encoder.layer.10.intermediate.dense.bias", "bert.encoder.layer.10.output.dense.weight", "bert.encoder.layer.10.output.dense.bias", "bert.encoder.layer.10.output.LayerNorm.weight", "bert.encoder.layer.10.output.LayerNorm.bias", "bert.encoder.layer.11.attention.self.query.weight", "bert.encoder.layer.11.attention.self.query.bias", "bert.encoder.layer.11.attention.self.key.weight", "bert.encoder.layer.11.attention.self.key.bias", "bert.encoder.layer.11.attention.self.value.weight", "bert.encoder.layer.11.attention.self.value.bias", "bert.encoder.layer.11.attention.output.dense.weight", "bert.encoder.layer.11.attention.output.dense.bias", "bert.encoder.layer.11.attention.output.LayerNorm.weight", "bert.encoder.layer.11.attention.output.LayerNorm.bias", "bert.encoder.layer.11.intermediate.dense.weight", "bert.encoder.layer.11.intermediate.dense.bias", "bert.encoder.layer.11.output.dense.weight", "bert.encoder.layer.11.output.dense.bias", "bert.encoder.layer.11.output.LayerNorm.weight", "bert.encoder.layer.11.output.LayerNorm.bias", "bert.encoder.layer.12.attention.self.query.weight", "bert.encoder.layer.12.attention.self.query.bias", "bert.encoder.layer.12.attention.self.key.weight", "bert.encoder.layer.12.attention.self.key.bias", "bert.encoder.layer.12.attention.self.value.weight", "bert.encoder.layer.12.attention.self.value.bias", "bert.encoder.layer.12.attention.output.dense.weight", "bert.encoder.layer.12.attention.output.dense.bias", "bert.encoder.layer.12.attention.output.LayerNorm.weight", "bert.encoder.layer.12.attention.output.LayerNorm.bias", "bert.encoder.layer.12.intermediate.dense.weight", "bert.encoder.layer.12.intermediate.dense.bias", "bert.encoder.layer.12.output.dense.weight", "bert.encoder.layer.12.output.dense.bias", "bert.encoder.layer.12.output.LayerNorm.weight", "bert.encoder.layer.12.output.LayerNorm.bias", "bert.encoder.layer.13.attention.self.query.weight", "bert.encoder.layer.13.attention.self.query.bias", "bert.encoder.layer.13.attention.self.key.weight", "bert.encoder.layer.13.attention.self.key.bias", "bert.encoder.layer.13.attention.self.value.weight", "bert.encoder.layer.13.attention.self.value.bias", "bert.encoder.layer.13.attention.output.dense.weight", "bert.encoder.layer.13.attention.output.dense.bias", "bert.encoder.layer.13.attention.output.LayerNorm.weight", "bert.encoder.layer.13.attention.output.LayerNorm.bias", "bert.encoder.layer.13.intermediate.dense.weight", "bert.encoder.layer.13.intermediate.dense.bias", "bert.encoder.layer.13.output.dense.weight", "bert.encoder.layer.13.output.dense.bias", "bert.encoder.layer.13.output.LayerNorm.weight", "bert.encoder.layer.13.output.LayerNorm.bias", "bert.encoder.layer.14.attention.self.query.weight", "bert.encoder.layer.14.attention.self.query.bias", "bert.encoder.layer.14.attention.self.key.weight", "bert.encoder.layer.14.attention.self.key.bias", "bert.encoder.layer.14.attention.self.value.weight", "bert.encoder.layer.14.attention.self.value.bias", "bert.encoder.layer.14.attention.output.dense.weight", "bert.encoder.layer.14.attention.output.dense.bias", "bert.encoder.layer.14.attention.output.LayerNorm.weight", "bert.encoder.layer.14.attention.output.LayerNorm.bias", "bert.encoder.layer.14.intermediate.dense.weight", "bert.encoder.layer.14.intermediate.dense.bias", "bert.encoder.layer.14.output.dense.weight", "bert.encoder.layer.14.output.dense.bias", "bert.encoder.layer.14.output.LayerNorm.weight", "bert.encoder.layer.14.output.LayerNorm.bias", "bert.encoder.layer.15.attention.self.query.weight", "bert.encoder.layer.15.attention.self.query.bias", "bert.encoder.layer.15.attention.self.key.weight", "bert.encoder.layer.15.attention.self.key.bias", "bert.encoder.layer.15.attention.self.value.weight", "bert.encoder.layer.15.attention.self.value.bias", "bert.encoder.layer.15.attention.output.dense.weight", "bert.encoder.layer.15.attention.output.dense.bias", "bert.encoder.layer.15.attention.output.LayerNorm.weight", "bert.encoder.layer.15.attention.output.LayerNorm.bias", "bert.encoder.layer.15.intermediate.dense.weight", "bert.encoder.layer.15.intermediate.dense.bias", "bert.encoder.layer.15.output.dense.weight", "bert.encoder.layer.15.output.dense.bias", "bert.encoder.layer.15.output.LayerNorm.weight", "bert.encoder.layer.15.output.LayerNorm.bias", "bert.encoder.layer.16.attention.self.query.weight", "bert.encoder.layer.16.attention.self.query.bias", "bert.encoder.layer.16.attention.self.key.weight", "bert.encoder.layer.16.attention.self.key.bias", "bert.encoder.layer.16.attention.self.value.weight", "bert.encoder.layer.16.attention.self.value.bias", "bert.encoder.layer.16.attention.output.dense.weight", "bert.encoder.layer.16.attention.output.dense.bias", "bert.encoder.layer.16.attention.output.LayerNorm.weight", "bert.encoder.layer.16.attention.output.LayerNorm.bias", "bert.encoder.layer.16.intermediate.dense.weight", "bert.encoder.layer.16.intermediate.dense.bias", "bert.encoder.layer.16.output.dense.weight", "bert.encoder.layer.16.output.dense.bias", "bert.encoder.layer.16.output.LayerNorm.weight", "bert.encoder.layer.16.output.LayerNorm.bias", "bert.encoder.layer.17.attention.self.query.weight", "bert.encoder.layer.17.attention.self.query.bias", "bert.encoder.layer.17.attention.self.key.weight", "bert.encoder.layer.17.attention.self.key.bias", "bert.encoder.layer.17.attention.self.value.weight", "bert.encoder.layer.17.attention.self.value.bias", "bert.encoder.layer.17.attention.output.dense.weight", "bert.encoder.layer.17.attention.output.dense.bias", "bert.encoder.layer.17.attention.output.LayerNorm.weight", "bert.encoder.layer.17.attention.output.LayerNorm.bias", "bert.encoder.layer.17.intermediate.dense.weight", "bert.encoder.layer.17.intermediate.dense.bias", "bert.encoder.layer.17.output.dense.weight", "bert.encoder.layer.17.output.dense.bias", "bert.encoder.layer.17.output.LayerNorm.weight", "bert.encoder.layer.17.output.LayerNorm.bias", "bert.encoder.layer.18.attention.self.query.weight", "bert.encoder.layer.18.attention.self.query.bias", "bert.encoder.layer.18.attention.self.key.weight", "bert.encoder.layer.18.attention.self.key.bias", "bert.encoder.layer.18.attention.self.value.weight", "bert.encoder.layer.18.attention.self.value.bias", "bert.encoder.layer.18.attention.output.dense.weight", "bert.encoder.layer.18.attention.output.dense.bias", "bert.encoder.layer.18.attention.output.LayerNorm.weight", "bert.encoder.layer.18.attention.output.LayerNorm.bias", "bert.encoder.layer.18.intermediate.dense.weight", "bert.encoder.layer.18.intermediate.dense.bias", "bert.encoder.layer.18.output.dense.weight", "bert.encoder.layer.18.output.dense.bias", "bert.encoder.layer.18.output.LayerNorm.weight", "bert.encoder.layer.18.output.LayerNorm.bias", "bert.encoder.layer.19.attention.self.query.weight", "bert.encoder.layer.19.attention.self.query.bias", "bert.encoder.layer.19.attention.self.key.weight", "bert.encoder.layer.19.attention.self.key.bias", "bert.encoder.layer.19.attention.self.value.weight", "bert.encoder.layer.19.attention.self.value.bias", "bert.encoder.layer.19.attention.output.dense.weight", "bert.encoder.layer.19.attention.output.dense.bias", "bert.encoder.layer.19.attention.output.LayerNorm.weight", "bert.encoder.layer.19.attention.output.LayerNorm.bias", "bert.encoder.layer.19.intermediate.dense.weight", "bert.encoder.layer.19.intermediate.dense.bias", "bert.encoder.layer.19.output.dense.weight", "bert.encoder.layer.19.output.dense.bias", "bert.encoder.layer.19.output.LayerNorm.weight", "bert.encoder.layer.19.output.LayerNorm.bias", "bert.encoder.layer.20.attention.self.query.weight", "bert.encoder.layer.20.attention.self.query.bias", "bert.encoder.layer.20.attention.self.key.weight", "bert.encoder.layer.20.attention.self.key.bias", "bert.encoder.layer.20.attention.self.value.weight", "bert.encoder.layer.20.attention.self.value.bias", "bert.encoder.layer.20.attention.output.dense.weight", "bert.encoder.layer.20.attention.output.dense.bias", "bert.encoder.layer.20.attention.output.LayerNorm.weight", "bert.encoder.layer.20.attention.output.LayerNorm.bias", "bert.encoder.layer.20.intermediate.dense.weight", "bert.encoder.layer.20.intermediate.dense.bias", "bert.encoder.layer.20.output.dense.weight", "bert.encoder.layer.20.output.dense.bias", "bert.encoder.layer.20.output.LayerNorm.weight", "bert.encoder.layer.20.output.LayerNorm.bias", "bert.encoder.layer.21.attention.self.query.weight", "bert.encoder.layer.21.attention.self.query.bias", "bert.encoder.layer.21.attention.self.key.weight", "bert.encoder.layer.21.attention.self.key.bias", "bert.encoder.layer.21.attention.self.value.weight", "bert.encoder.layer.21.attention.self.value.bias", "bert.encoder.layer.21.attention.output.dense.weight", "bert.encoder.layer.21.attention.output.dense.bias", "bert.encoder.layer.21.attention.output.LayerNorm.weight", "bert.encoder.layer.21.attention.output.LayerNorm.bias", "bert.encoder.layer.21.intermediate.dense.weight", "bert.encoder.layer.21.intermediate.dense.bias", "bert.encoder.layer.21.output.dense.weight", "bert.encoder.layer.21.output.dense.bias", "bert.encoder.layer.21.output.LayerNorm.weight", "bert.encoder.layer.21.output.LayerNorm.bias", "bert.encoder.layer.22.attention.self.query.weight", "bert.encoder.layer.22.attention.self.query.bias", "bert.encoder.layer.22.attention.self.key.weight", "bert.encoder.layer.22.attention.self.key.bias", "bert.encoder.layer.22.attention.self.value.weight", "bert.encoder.layer.22.attention.self.value.bias", "bert.encoder.layer.22.attention.output.dense.weight", "bert.encoder.layer.22.attention.output.dense.bias", "bert.encoder.layer.22.attention.output.LayerNorm.weight", "bert.encoder.layer.22.attention.output.LayerNorm.bias", "bert.encoder.layer.22.intermediate.dense.weight", "bert.encoder.layer.22.intermediate.dense.bias", "bert.encoder.layer.22.output.dense.weight", "bert.encoder.layer.22.output.dense.bias", "bert.encoder.layer.22.output.LayerNorm.weight", "bert.encoder.layer.22.output.LayerNorm.bias", "bert.encoder.layer.23.attention.self.query.weight", "bert.encoder.layer.23.attention.self.query.bias", "bert.encoder.layer.23.attention.self.key.weight", "bert.encoder.layer.23.attention.self.key.bias", "bert.encoder.layer.23.attention.self.value.weight", "bert.encoder.layer.23.attention.self.value.bias", "bert.encoder.layer.23.attention.output.dense.weight", "bert.encoder.layer.23.attention.output.dense.bias", "bert.encoder.layer.23.attention.output.LayerNorm.weight", "bert.encoder.layer.23.attention.output.LayerNorm.bias", "bert.encoder.layer.23.intermediate.dense.weight", "bert.encoder.layer.23.intermediate.dense.bias", "bert.encoder.layer.23.output.dense.weight", "bert.encoder.layer.23.output.dense.bias", "bert.encoder.layer.23.output.LayerNorm.weight", "bert.encoder.layer.23.output.LayerNorm.bias", "classifier.layers.0.weight", "classifier.layers.0.bias", "classifier.layers.1.projection.weight", "classifier.layers.1.projection.bias", "classifier.layers.3.weight", "classifier.layers.3.bias", "classifier.layers.4.projection.weight", "classifier.layers.4.projection.bias", "classifier.layers.6.weight", "classifier.layers.6.bias". 
	Unexpected key(s) in state_dict: "layers.0.weight", "layers.0.bias", "layers.1.projection.weight", "layers.1.projection.bias", "layers.3.weight", "layers.3.bias", "layers.4.projection.weight", "layers.4.projection.bias", "layers.6.weight", "layers.6.bias". 
  File "/home/ubuntu/nlp-osaka/sentiment/ddp_sentiment_finetune.py", line 1206, in main
    classifier.fit(X_train, X_val, y_train, y_val, rank, world_size, debug, start_epoch, model_state_dict, optimizer_state_dict,
  File "/home/ubuntu/nlp-osaka/sentiment/torch_ddp_finetune_neural_classifier.py", line 1070, in fit
    self.model.load_state_dict(model_state_dict)
  File "/home/ubuntu/nlp-osaka/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 2152, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for BERTClassifier:
	Missing key(s) in state_dict: "bert.embeddings.word_embeddings.weight", "bert.embeddings.position_embeddings.weight", "bert.embeddings.token_type_embeddings.weight", "bert.embeddings.LayerNorm.weight", "bert.embeddings.LayerNorm.bias", "bert.encoder.layer.0.attention.self.query.weight", "bert.encoder.layer.0.attention.self.query.bias", "bert.encoder.layer.0.attention.self.key.weight", "bert.encoder.layer.0.attention.self.key.bias", "bert.encoder.layer.0.attention.self.value.weight", "bert.encoder.layer.0.attention.self.value.bias", "bert.encoder.layer.0.attention.output.dense.weight", "bert.encoder.layer.0.attention.output.dense.bias", "bert.encoder.layer.0.attention.output.LayerNorm.weight", "bert.encoder.layer.0.attention.output.LayerNorm.bias", "bert.encoder.layer.0.intermediate.dense.weight", "bert.encoder.layer.0.intermediate.dense.bias", "bert.encoder.layer.0.output.dense.weight", "bert.encoder.layer.0.output.dense.bias", "bert.encoder.layer.0.output.LayerNorm.weight", "bert.encoder.layer.0.output.LayerNorm.bias", "bert.encoder.layer.1.attention.self.query.weight", "bert.encoder.layer.1.attention.self.query.bias", "bert.encoder.layer.1.attention.self.key.weight", "bert.encoder.layer.1.attention.self.key.bias", "bert.encoder.layer.1.attention.self.value.weight", "bert.encoder.layer.1.attention.self.value.bias", "bert.encoder.layer.1.attention.output.dense.weight", "bert.encoder.layer.1.attention.output.dense.bias", "bert.encoder.layer.1.attention.output.LayerNorm.weight", "bert.encoder.layer.1.attention.output.LayerNorm.bias", "bert.encoder.layer.1.intermediate.dense.weight", "bert.encoder.layer.1.intermediate.dense.bias", "bert.encoder.layer.1.output.dense.weight", "bert.encoder.layer.1.output.dense.bias", "bert.encoder.layer.1.output.LayerNorm.weight", "bert.encoder.layer.1.output.LayerNorm.bias", "bert.encoder.layer.2.attention.self.query.weight", "bert.encoder.layer.2.attention.self.query.bias", "bert.encoder.layer.2.attention.self.key.weight", "bert.encoder.layer.2.attention.self.key.bias", "bert.encoder.layer.2.attention.self.value.weight", "bert.encoder.layer.2.attention.self.value.bias", "bert.encoder.layer.2.attention.output.dense.weight", "bert.encoder.layer.2.attention.output.dense.bias", "bert.encoder.layer.2.attention.output.LayerNorm.weight", "bert.encoder.layer.2.attention.output.LayerNorm.bias", "bert.encoder.layer.2.intermediate.dense.weight", "bert.encoder.layer.2.intermediate.dense.bias", "bert.encoder.layer.2.output.dense.weight", "bert.encoder.layer.2.output.dense.bias", "bert.encoder.layer.2.output.LayerNorm.weight", "bert.encoder.layer.2.output.LayerNorm.bias", "bert.encoder.layer.3.attention.self.query.weight", "bert.encoder.layer.3.attention.self.query.bias", "bert.encoder.layer.3.attention.self.key.weight", "bert.encoder.layer.3.attention.self.key.bias", "bert.encoder.layer.3.attention.self.value.weight", "bert.encoder.layer.3.attention.self.value.bias", "bert.encoder.layer.3.attention.output.dense.weight", "bert.encoder.layer.3.attention.output.dense.bias", "bert.encoder.layer.3.attention.output.LayerNorm.weight", "bert.encoder.layer.3.attention.output.LayerNorm.bias", "bert.encoder.layer.3.intermediate.dense.weight", "bert.encoder.layer.3.intermediate.dense.bias", "bert.encoder.layer.3.output.dense.weight", "bert.encoder.layer.3.output.dense.bias", "bert.encoder.layer.3.output.LayerNorm.weight", "bert.encoder.layer.3.output.LayerNorm.bias", "bert.encoder.layer.4.attention.self.query.weight", "bert.encoder.layer.4.attention.self.query.bias", "bert.encoder.layer.4.attention.self.key.weight", "bert.encoder.layer.4.attention.self.key.bias", "bert.encoder.layer.4.attention.self.value.weight", "bert.encoder.layer.4.attention.self.value.bias", "bert.encoder.layer.4.attention.output.dense.weight", "bert.encoder.layer.4.attention.output.dense.bias", "bert.encoder.layer.4.attention.output.LayerNorm.weight", "bert.encoder.layer.4.attention.output.LayerNorm.bias", "bert.encoder.layer.4.intermediate.dense.weight", "bert.encoder.layer.4.intermediate.dense.bias", "bert.encoder.layer.4.output.dense.weight", "bert.encoder.layer.4.output.dense.bias", "bert.encoder.layer.4.output.LayerNorm.weight", "bert.encoder.layer.4.output.LayerNorm.bias", "bert.encoder.layer.5.attention.self.query.weight", "bert.encoder.layer.5.attention.self.query.bias", "bert.encoder.layer.5.attention.self.key.weight", "bert.encoder.layer.5.attention.self.key.bias", "bert.encoder.layer.5.attention.self.value.weight", "bert.encoder.layer.5.attention.self.value.bias", "bert.encoder.layer.5.attention.output.dense.weight", "bert.encoder.layer.5.attention.output.dense.bias", "bert.encoder.layer.5.attention.output.LayerNorm.weight", "bert.encoder.layer.5.attention.output.LayerNorm.bias", "bert.encoder.layer.5.intermediate.dense.weight", "bert.encoder.layer.5.intermediate.dense.bias", "bert.encoder.layer.5.output.dense.weight", "bert.encoder.layer.5.output.dense.bias", "bert.encoder.layer.5.output.LayerNorm.weight", "bert.encoder.layer.5.output.LayerNorm.bias", "bert.encoder.layer.6.attention.self.query.weight", "bert.encoder.layer.6.attention.self.query.bias", "bert.encoder.layer.6.attention.self.key.weight", "bert.encoder.layer.6.attention.self.key.bias", "bert.encoder.layer.6.attention.self.value.weight", "bert.encoder.layer.6.attention.self.value.bias", "bert.encoder.layer.6.attention.output.dense.weight", "bert.encoder.layer.6.attention.output.dense.bias", "bert.encoder.layer.6.attention.output.LayerNorm.weight", "bert.encoder.layer.6.attention.output.LayerNorm.bias", "bert.encoder.layer.6.intermediate.dense.weight", "bert.encoder.layer.6.intermediate.dense.bias", "bert.encoder.layer.6.output.dense.weight", "bert.encoder.layer.6.output.dense.bias", "bert.encoder.layer.6.output.LayerNorm.weight", "bert.encoder.layer.6.output.LayerNorm.bias", "bert.encoder.layer.7.attention.self.query.weight", "bert.encoder.layer.7.attention.self.query.bias", "bert.encoder.layer.7.attention.self.key.weight", "bert.encoder.layer.7.attention.self.key.bias", "bert.encoder.layer.7.attention.self.value.weight", "bert.encoder.layer.7.attention.self.value.bias", "bert.encoder.layer.7.attention.output.dense.weight", "bert.encoder.layer.7.attention.output.dense.bias", "bert.encoder.layer.7.attention.output.LayerNorm.weight", "bert.encoder.layer.7.attention.output.LayerNorm.bias", "bert.encoder.layer.7.intermediate.dense.weight", "bert.encoder.layer.7.intermediate.dense.bias", "bert.encoder.layer.7.output.dense.weight", "bert.encoder.layer.7.output.dense.bias", "bert.encoder.layer.7.output.LayerNorm.weight", "bert.encoder.layer.7.output.LayerNorm.bias", "bert.encoder.layer.8.attention.self.query.weight", "bert.encoder.layer.8.attention.self.query.bias", "bert.encoder.layer.8.attention.self.key.weight", "bert.encoder.layer.8.attention.self.key.bias", "bert.encoder.layer.8.attention.self.value.weight", "bert.encoder.layer.8.attention.self.value.bias", "bert.encoder.layer.8.attention.output.dense.weight", "bert.encoder.layer.8.attention.output.dense.bias", "bert.encoder.layer.8.attention.output.LayerNorm.weight", "bert.encoder.layer.8.attention.output.LayerNorm.bias", "bert.encoder.layer.8.intermediate.dense.weight", "bert.encoder.layer.8.intermediate.dense.bias", "bert.encoder.layer.8.output.dense.weight", "bert.encoder.layer.8.output.dense.bias", "bert.encoder.layer.8.output.LayerNorm.weight", "bert.encoder.layer.8.output.LayerNorm.bias", "bert.encoder.layer.9.attention.self.query.weight", "bert.encoder.layer.9.attention.self.query.bias", "bert.encoder.layer.9.attention.self.key.weight", "bert.encoder.layer.9.attention.self.key.bias", "bert.encoder.layer.9.attention.self.value.weight", "bert.encoder.layer.9.attention.self.value.bias", "bert.encoder.layer.9.attention.output.dense.weight", "bert.encoder.layer.9.attention.output.dense.bias", "bert.encoder.layer.9.attention.output.LayerNorm.weight", "bert.encoder.layer.9.attention.output.LayerNorm.bias", "bert.encoder.layer.9.intermediate.dense.weight", "bert.encoder.layer.9.intermediate.dense.bias", "bert.encoder.layer.9.output.dense.weight", "bert.encoder.layer.9.output.dense.bias", "bert.encoder.layer.9.output.LayerNorm.weight", "bert.encoder.layer.9.output.LayerNorm.bias", "bert.encoder.layer.10.attention.self.query.weight", "bert.encoder.layer.10.attention.self.query.bias", "bert.encoder.layer.10.attention.self.key.weight", "bert.encoder.layer.10.attention.self.key.bias", "bert.encoder.layer.10.attention.self.value.weight", "bert.encoder.layer.10.attention.self.value.bias", "bert.encoder.layer.10.attention.output.dense.weight", "bert.encoder.layer.10.attention.output.dense.bias", "bert.encoder.layer.10.attention.output.LayerNorm.weight", "bert.encoder.layer.10.attention.output.LayerNorm.bias", "bert.encoder.layer.10.intermediate.dense.weight", "bert.encoder.layer.10.intermediate.dense.bias", "bert.encoder.layer.10.output.dense.weight", "bert.encoder.layer.10.output.dense.bias", "bert.encoder.layer.10.output.LayerNorm.weight", "bert.encoder.layer.10.output.LayerNorm.bias", "bert.encoder.layer.11.attention.self.query.weight", "bert.encoder.layer.11.attention.self.query.bias", "bert.encoder.layer.11.attention.self.key.weight", "bert.encoder.layer.11.attention.self.key.bias", "bert.encoder.layer.11.attention.self.value.weight", "bert.encoder.layer.11.attention.self.value.bias", "bert.encoder.layer.11.attention.output.dense.weight", "bert.encoder.layer.11.attention.output.dense.bias", "bert.encoder.layer.11.attention.output.LayerNorm.weight", "bert.encoder.layer.11.attention.output.LayerNorm.bias", "bert.encoder.layer.11.intermediate.dense.weight", "bert.encoder.layer.11.intermediate.dense.bias", "bert.encoder.layer.11.output.dense.weight", "bert.encoder.layer.11.output.dense.bias", "bert.encoder.layer.11.output.LayerNorm.weight", "bert.encoder.layer.11.output.LayerNorm.bias", "bert.encoder.layer.12.attention.self.query.weight", "bert.encoder.layer.12.attention.self.query.bias", "bert.encoder.layer.12.attention.self.key.weight", "bert.encoder.layer.12.attention.self.key.bias", "bert.encoder.layer.12.attention.self.value.weight", "bert.encoder.layer.12.attention.self.value.bias", "bert.encoder.layer.12.attention.output.dense.weight", "bert.encoder.layer.12.attention.output.dense.bias", "bert.encoder.layer.12.attention.output.LayerNorm.weight", "bert.encoder.layer.12.attention.output.LayerNorm.bias", "bert.encoder.layer.12.intermediate.dense.weight", "bert.encoder.layer.12.intermediate.dense.bias", "bert.encoder.layer.12.output.dense.weight", "bert.encoder.layer.12.output.dense.bias", "bert.encoder.layer.12.output.LayerNorm.weight", "bert.encoder.layer.12.output.LayerNorm.bias", "bert.encoder.layer.13.attention.self.query.weight", "bert.encoder.layer.13.attention.self.query.bias", "bert.encoder.layer.13.attention.self.key.weight", "bert.encoder.layer.13.attention.self.key.bias", "bert.encoder.layer.13.attention.self.value.weight", "bert.encoder.layer.13.attention.self.value.bias", "bert.encoder.layer.13.attention.output.dense.weight", "bert.encoder.layer.13.attention.output.dense.bias", "bert.encoder.layer.13.attention.output.LayerNorm.weight", "bert.encoder.layer.13.attention.output.LayerNorm.bias", "bert.encoder.layer.13.intermediate.dense.weight", "bert.encoder.layer.13.intermediate.dense.bias", "bert.encoder.layer.13.output.dense.weight", "bert.encoder.layer.13.output.dense.bias", "bert.encoder.layer.13.output.LayerNorm.weight", "bert.encoder.layer.13.output.LayerNorm.bias", "bert.encoder.layer.14.attention.self.query.weight", "bert.encoder.layer.14.attention.self.query.bias", "bert.encoder.layer.14.attention.self.key.weight", "bert.encoder.layer.14.attention.self.key.bias", "bert.encoder.layer.14.attention.self.value.weight", "bert.encoder.layer.14.attention.self.value.bias", "bert.encoder.layer.14.attention.output.dense.weight", "bert.encoder.layer.14.attention.output.dense.bias", "bert.encoder.layer.14.attention.output.LayerNorm.weight", "bert.encoder.layer.14.attention.output.LayerNorm.bias", "bert.encoder.layer.14.intermediate.dense.weight", "bert.encoder.layer.14.intermediate.dense.bias", "bert.encoder.layer.14.output.dense.weight", "bert.encoder.layer.14.output.dense.bias", "bert.encoder.layer.14.output.LayerNorm.weight", "bert.encoder.layer.14.output.LayerNorm.bias", "bert.encoder.layer.15.attention.self.query.weight", "bert.encoder.layer.15.attention.self.query.bias", "bert.encoder.layer.15.attention.self.key.weight", "bert.encoder.layer.15.attention.self.key.bias", "bert.encoder.layer.15.attention.self.value.weight", "bert.encoder.layer.15.attention.self.value.bias", "bert.encoder.layer.15.attention.output.dense.weight", "bert.encoder.layer.15.attention.output.dense.bias", "bert.encoder.layer.15.attention.output.LayerNorm.weight", "bert.encoder.layer.15.attention.output.LayerNorm.bias", "bert.encoder.layer.15.intermediate.dense.weight", "bert.encoder.layer.15.intermediate.dense.bias", "bert.encoder.layer.15.output.dense.weight", "bert.encoder.layer.15.output.dense.bias", "bert.encoder.layer.15.output.LayerNorm.weight", "bert.encoder.layer.15.output.LayerNorm.bias", "bert.encoder.layer.16.attention.self.query.weight", "bert.encoder.layer.16.attention.self.query.bias", "bert.encoder.layer.16.attention.self.key.weight", "bert.encoder.layer.16.attention.self.key.bias", "bert.encoder.layer.16.attention.self.value.weight", "bert.encoder.layer.16.attention.self.value.bias", "bert.encoder.layer.16.attention.output.dense.weight", "bert.encoder.layer.16.attention.output.dense.bias", "bert.encoder.layer.16.attention.output.LayerNorm.weight", "bert.encoder.layer.16.attention.output.LayerNorm.bias", "bert.encoder.layer.16.intermediate.dense.weight", "bert.encoder.layer.16.intermediate.dense.bias", "bert.encoder.layer.16.output.dense.weight", "bert.encoder.layer.16.output.dense.bias", "bert.encoder.layer.16.output.LayerNorm.weight", "bert.encoder.layer.16.output.LayerNorm.bias", "bert.encoder.layer.17.attention.self.query.weight", "bert.encoder.layer.17.attention.self.query.bias", "bert.encoder.layer.17.attention.self.key.weight", "bert.encoder.layer.17.attention.self.key.bias", "bert.encoder.layer.17.attention.self.value.weight", "bert.encoder.layer.17.attention.self.value.bias", "bert.encoder.layer.17.attention.output.dense.weight", "bert.encoder.layer.17.attention.output.dense.bias", "bert.encoder.layer.17.attention.output.LayerNorm.weight", "bert.encoder.layer.17.attention.output.LayerNorm.bias", "bert.encoder.layer.17.intermediate.dense.weight", "bert.encoder.layer.17.intermediate.dense.bias", "bert.encoder.layer.17.output.dense.weight", "bert.encoder.layer.17.output.dense.bias", "bert.encoder.layer.17.output.LayerNorm.weight", "bert.encoder.layer.17.output.LayerNorm.bias", "bert.encoder.layer.18.attention.self.query.weight", "bert.encoder.layer.18.attention.self.query.bias", "bert.encoder.layer.18.attention.self.key.weight", "bert.encoder.layer.18.attention.self.key.bias", "bert.encoder.layer.18.attention.self.value.weight", "bert.encoder.layer.18.attention.self.value.bias", "bert.encoder.layer.18.attention.output.dense.weight", "bert.encoder.layer.18.attention.output.dense.bias", "bert.encoder.layer.18.attention.output.LayerNorm.weight", "bert.encoder.layer.18.attention.output.LayerNorm.bias", "bert.encoder.layer.18.intermediate.dense.weight", "bert.encoder.layer.18.intermediate.dense.bias", "bert.encoder.layer.18.output.dense.weight", "bert.encoder.layer.18.output.dense.bias", "bert.encoder.layer.18.output.LayerNorm.weight", "bert.encoder.layer.18.output.LayerNorm.bias", "bert.encoder.layer.19.attention.self.query.weight", "bert.encoder.layer.19.attention.self.query.bias", "bert.encoder.layer.19.attention.self.key.weight", "bert.encoder.layer.19.attention.self.key.bias", "bert.encoder.layer.19.attention.self.value.weight", "bert.encoder.layer.19.attention.self.value.bias", "bert.encoder.layer.19.attention.output.dense.weight", "bert.encoder.layer.19.attention.output.dense.bias", "bert.encoder.layer.19.attention.output.LayerNorm.weight", "bert.encoder.layer.19.attention.output.LayerNorm.bias", "bert.encoder.layer.19.intermediate.dense.weight", "bert.encoder.layer.19.intermediate.dense.bias", "bert.encoder.layer.19.output.dense.weight", "bert.encoder.layer.19.output.dense.bias", "bert.encoder.layer.19.output.LayerNorm.weight", "bert.encoder.layer.19.output.LayerNorm.bias", "bert.encoder.layer.20.attention.self.query.weight", "bert.encoder.layer.20.attention.self.query.bias", "bert.encoder.layer.20.attention.self.key.weight", "bert.encoder.layer.20.attention.self.key.bias", "bert.encoder.layer.20.attention.self.value.weight", "bert.encoder.layer.20.attention.self.value.bias", "bert.encoder.layer.20.attention.output.dense.weight", "bert.encoder.layer.20.attention.output.dense.bias", "bert.encoder.layer.20.attention.output.LayerNorm.weight", "bert.encoder.layer.20.attention.output.LayerNorm.bias", "bert.encoder.layer.20.intermediate.dense.weight", "bert.encoder.layer.20.intermediate.dense.bias", "bert.encoder.layer.20.output.dense.weight", "bert.encoder.layer.20.output.dense.bias", "bert.encoder.layer.20.output.LayerNorm.weight", "bert.encoder.layer.20.output.LayerNorm.bias", "bert.encoder.layer.21.attention.self.query.weight", "bert.encoder.layer.21.attention.self.query.bias", "bert.encoder.layer.21.attention.self.key.weight", "bert.encoder.layer.21.attention.self.key.bias", "bert.encoder.layer.21.attention.self.value.weight", "bert.encoder.layer.21.attention.self.value.bias", "bert.encoder.layer.21.attention.output.dense.weight", "bert.encoder.layer.21.attention.output.dense.bias", "bert.encoder.layer.21.attention.output.LayerNorm.weight", "bert.encoder.layer.21.attention.output.LayerNorm.bias", "bert.encoder.layer.21.intermediate.dense.weight", "bert.encoder.layer.21.intermediate.dense.bias", "bert.encoder.layer.21.output.dense.weight", "bert.encoder.layer.21.output.dense.bias", "bert.encoder.layer.21.output.LayerNorm.weight", "bert.encoder.layer.21.output.LayerNorm.bias", "bert.encoder.layer.22.attention.self.query.weight", "bert.encoder.layer.22.attention.self.query.bias", "bert.encoder.layer.22.attention.self.key.weight", "bert.encoder.layer.22.attention.self.key.bias", "bert.encoder.layer.22.attention.self.value.weight", "bert.encoder.layer.22.attention.self.value.bias", "bert.encoder.layer.22.attention.output.dense.weight", "bert.encoder.layer.22.attention.output.dense.bias", "bert.encoder.layer.22.attention.output.LayerNorm.weight", "bert.encoder.layer.22.attention.output.LayerNorm.bias", "bert.encoder.layer.22.intermediate.dense.weight", "bert.encoder.layer.22.intermediate.dense.bias", "bert.encoder.layer.22.output.dense.weight", "bert.encoder.layer.22.output.dense.bias", "bert.encoder.layer.22.output.LayerNorm.weight", "bert.encoder.layer.22.output.LayerNorm.bias", "bert.encoder.layer.23.attention.self.query.weight", "bert.encoder.layer.23.attention.self.query.bias", "bert.encoder.layer.23.attention.self.key.weight", "bert.encoder.layer.23.attention.self.key.bias", "bert.encoder.layer.23.attention.self.value.weight", "bert.encoder.layer.23.attention.self.value.bias", "bert.encoder.layer.23.attention.output.dense.weight", "bert.encoder.layer.23.attention.output.dense.bias", "bert.encoder.layer.23.attention.output.LayerNorm.weight", "bert.encoder.layer.23.attention.output.LayerNorm.bias", "bert.encoder.layer.23.intermediate.dense.weight", "bert.encoder.layer.23.intermediate.dense.bias", "bert.encoder.layer.23.output.dense.weight", "bert.encoder.layer.23.output.dense.bias", "bert.encoder.layer.23.output.LayerNorm.weight", "bert.encoder.layer.23.output.LayerNorm.bias", "classifier.layers.0.weight", "classifier.layers.0.bias", "classifier.layers.1.projection.weight", "classifier.layers.1.projection.bias", "classifier.layers.3.weight", "classifier.layers.3.bias", "classifier.layers.4.projection.weight", "classifier.layers.4.projection.bias", "classifier.layers.6.weight", "classifier.layers.6.bias". 
	Unexpected key(s) in state_dict: "layers.0.weight", "layers.0.bias", "layers.1.projection.weight", "layers.1.projection.bias", "layers.3.weight", "layers.3.bias", "layers.4.projection.weight", "layers.4.projection.bias", "layers.6.weight", "layers.6.bias". 
Traceback (most recent call last):
Traceback (most recent call last):
  File "/home/ubuntu/nlp-osaka/sentiment/ddp_sentiment_finetune.py", line 1206, in main
    classifier.fit(X_train, X_val, y_train, y_val, rank, world_size, debug, start_epoch, model_state_dict, optimizer_state_dict,
RuntimeError: Error(s) in loading state_dict for BERTClassifier:
	Missing key(s) in state_dict: "bert.embeddings.word_embeddings.weight", "bert.embeddings.position_embeddings.weight", "bert.embeddings.token_type_embeddings.weight", "bert.embeddings.LayerNorm.weight", "bert.embeddings.LayerNorm.bias", "bert.encoder.layer.0.attention.self.query.weight", "bert.encoder.layer.0.attention.self.query.bias", "bert.encoder.layer.0.attention.self.key.weight", "bert.encoder.layer.0.attention.self.key.bias", "bert.encoder.layer.0.attention.self.value.weight", "bert.encoder.layer.0.attention.self.value.bias", "bert.encoder.layer.0.attention.output.dense.weight", "bert.encoder.layer.0.attention.output.dense.bias", "bert.encoder.layer.0.attention.output.LayerNorm.weight", "bert.encoder.layer.0.attention.output.LayerNorm.bias", "bert.encoder.layer.0.intermediate.dense.weight", "bert.encoder.layer.0.intermediate.dense.bias", "bert.encoder.layer.0.output.dense.weight", "bert.encoder.layer.0.output.dense.bias", "bert.encoder.layer.0.output.LayerNorm.weight", "bert.encoder.layer.0.output.LayerNorm.bias", "bert.encoder.layer.1.attention.self.query.weight", "bert.encoder.layer.1.attention.self.query.bias", "bert.encoder.layer.1.attention.self.key.weight", "bert.encoder.layer.1.attention.self.key.bias", "bert.encoder.layer.1.attention.self.value.weight", "bert.encoder.layer.1.attention.self.value.bias", "bert.encoder.layer.1.attention.output.dense.weight", "bert.encoder.layer.1.attention.output.dense.bias", "bert.encoder.layer.1.attention.output.LayerNorm.weight", "bert.encoder.layer.1.attention.output.LayerNorm.bias", "bert.encoder.layer.1.intermediate.dense.weight", "bert.encoder.layer.1.intermediate.dense.bias", "bert.encoder.layer.1.output.dense.weight", "bert.encoder.layer.1.output.dense.bias", "bert.encoder.layer.1.output.LayerNorm.weight", "bert.encoder.layer.1.output.LayerNorm.bias", "bert.encoder.layer.2.attention.self.query.weight", "bert.encoder.layer.2.attention.self.query.bias", "bert.encoder.layer.2.attention.self.key.weight", "bert.encoder.layer.2.attention.self.key.bias", "bert.encoder.layer.2.attention.self.value.weight", "bert.encoder.layer.2.attention.self.value.bias", "bert.encoder.layer.2.attention.output.dense.weight", "bert.encoder.layer.2.attention.output.dense.bias", "bert.encoder.layer.2.attention.output.LayerNorm.weight", "bert.encoder.layer.2.attention.output.LayerNorm.bias", "bert.encoder.layer.2.intermediate.dense.weight", "bert.encoder.layer.2.intermediate.dense.bias", "bert.encoder.layer.2.output.dense.weight", "bert.encoder.layer.2.output.dense.bias", "bert.encoder.layer.2.output.LayerNorm.weight", "bert.encoder.layer.2.output.LayerNorm.bias", "bert.encoder.layer.3.attention.self.query.weight", "bert.encoder.layer.3.attention.self.query.bias", "bert.encoder.layer.3.attention.self.key.weight", "bert.encoder.layer.3.attention.self.key.bias", "bert.encoder.layer.3.attention.self.value.weight", "bert.encoder.layer.3.attention.self.value.bias", "bert.encoder.layer.3.attention.output.dense.weight", "bert.encoder.layer.3.attention.output.dense.bias", "bert.encoder.layer.3.attention.output.LayerNorm.weight", "bert.encoder.layer.3.attention.output.LayerNorm.bias", "bert.encoder.layer.3.intermediate.dense.weight", "bert.encoder.layer.3.intermediate.dense.bias", "bert.encoder.layer.3.output.dense.weight", "bert.encoder.layer.3.output.dense.bias", "bert.encoder.layer.3.output.LayerNorm.weight", "bert.encoder.layer.3.output.LayerNorm.bias", "bert.encoder.layer.4.attention.self.query.weight", "bert.encoder.layer.4.attention.self.query.bias", "bert.encoder.layer.4.attention.self.key.weight", "bert.encoder.layer.4.attention.self.key.bias", "bert.encoder.layer.4.attention.self.value.weight", "bert.encoder.layer.4.attention.self.value.bias", "bert.encoder.layer.4.attention.output.dense.weight", "bert.encoder.layer.4.attention.output.dense.bias", "bert.encoder.layer.4.attention.output.LayerNorm.weight", "bert.encoder.layer.4.attention.output.LayerNorm.bias", "bert.encoder.layer.4.intermediate.dense.weight", "bert.encoder.layer.4.intermediate.dense.bias", "bert.encoder.layer.4.output.dense.weight", "bert.encoder.layer.4.output.dense.bias", "bert.encoder.layer.4.output.LayerNorm.weight", "bert.encoder.layer.4.output.LayerNorm.bias", "bert.encoder.layer.5.attention.self.query.weight", "bert.encoder.layer.5.attention.self.query.bias", "bert.encoder.layer.5.attention.self.key.weight", "bert.encoder.layer.5.attention.self.key.bias", "bert.encoder.layer.5.attention.self.value.weight", "bert.encoder.layer.5.attention.self.value.bias", "bert.encoder.layer.5.attention.output.dense.weight", "bert.encoder.layer.5.attention.output.dense.bias", "bert.encoder.layer.5.attention.output.LayerNorm.weight", "bert.encoder.layer.5.attention.output.LayerNorm.bias", "bert.encoder.layer.5.intermediate.dense.weight", "bert.encoder.layer.5.intermediate.dense.bias", "bert.encoder.layer.5.output.dense.weight", "bert.encoder.layer.5.output.dense.bias", "bert.encoder.layer.5.output.LayerNorm.weight", "bert.encoder.layer.5.output.LayerNorm.bias", "bert.encoder.layer.6.attention.self.query.weight", "bert.encoder.layer.6.attention.self.query.bias", "bert.encoder.layer.6.attention.self.key.weight", "bert.encoder.layer.6.attention.self.key.bias", "bert.encoder.layer.6.attention.self.value.weight", "bert.encoder.layer.6.attention.self.value.bias", "bert.encoder.layer.6.attention.output.dense.weight", "bert.encoder.layer.6.attention.output.dense.bias", "bert.encoder.layer.6.attention.output.LayerNorm.weight", "bert.encoder.layer.6.attention.output.LayerNorm.bias", "bert.encoder.layer.6.intermediate.dense.weight", "bert.encoder.layer.6.intermediate.dense.bias", "bert.encoder.layer.6.output.dense.weight", "bert.encoder.layer.6.output.dense.bias", "bert.encoder.layer.6.output.LayerNorm.weight", "bert.encoder.layer.6.output.LayerNorm.bias", "bert.encoder.layer.7.attention.self.query.weight", "bert.encoder.layer.7.attention.self.query.bias", "bert.encoder.layer.7.attention.self.key.weight", "bert.encoder.layer.7.attention.self.key.bias", "bert.encoder.layer.7.attention.self.value.weight", "bert.encoder.layer.7.attention.self.value.bias", "bert.encoder.layer.7.attention.output.dense.weight", "bert.encoder.layer.7.attention.output.dense.bias", "bert.encoder.layer.7.attention.output.LayerNorm.weight", "bert.encoder.layer.7.attention.output.LayerNorm.bias", "bert.encoder.layer.7.intermediate.dense.weight", "bert.encoder.layer.7.intermediate.dense.bias", "bert.encoder.layer.7.output.dense.weight", "bert.encoder.layer.7.output.dense.bias", "bert.encoder.layer.7.output.LayerNorm.weight", "bert.encoder.layer.7.output.LayerNorm.bias", "bert.encoder.layer.8.attention.self.query.weight", "bert.encoder.layer.8.attention.self.query.bias", "bert.encoder.layer.8.attention.self.key.weight", "bert.encoder.layer.8.attention.self.key.bias", "bert.encoder.layer.8.attention.self.value.weight", "bert.encoder.layer.8.attention.self.value.bias", "bert.encoder.layer.8.attention.output.dense.weight", "bert.encoder.layer.8.attention.output.dense.bias", "bert.encoder.layer.8.attention.output.LayerNorm.weight", "bert.encoder.layer.8.attention.output.LayerNorm.bias", "bert.encoder.layer.8.intermediate.dense.weight", "bert.encoder.layer.8.intermediate.dense.bias", "bert.encoder.layer.8.output.dense.weight", "bert.encoder.layer.8.output.dense.bias", "bert.encoder.layer.8.output.LayerNorm.weight", "bert.encoder.layer.8.output.LayerNorm.bias", "bert.encoder.layer.9.attention.self.query.weight", "bert.encoder.layer.9.attention.self.query.bias", "bert.encoder.layer.9.attention.self.key.weight", "bert.encoder.layer.9.attention.self.key.bias", "bert.encoder.layer.9.attention.self.value.weight", "bert.encoder.layer.9.attention.self.value.bias", "bert.encoder.layer.9.attention.output.dense.weight", "bert.encoder.layer.9.attention.output.dense.bias", "bert.encoder.layer.9.attention.output.LayerNorm.weight", "bert.encoder.layer.9.attention.output.LayerNorm.bias", "bert.encoder.layer.9.intermediate.dense.weight", "bert.encoder.layer.9.intermediate.dense.bias", "bert.encoder.layer.9.output.dense.weight", "bert.encoder.layer.9.output.dense.bias", "bert.encoder.layer.9.output.LayerNorm.weight", "bert.encoder.layer.9.output.LayerNorm.bias", "bert.encoder.layer.10.attention.self.query.weight", "bert.encoder.layer.10.attention.self.query.bias", "bert.encoder.layer.10.attention.self.key.weight", "bert.encoder.layer.10.attention.self.key.bias", "bert.encoder.layer.10.attention.self.value.weight", "bert.encoder.layer.10.attention.self.value.bias", "bert.encoder.layer.10.attention.output.dense.weight", "bert.encoder.layer.10.attention.output.dense.bias", "bert.encoder.layer.10.attention.output.LayerNorm.weight", "bert.encoder.layer.10.attention.output.LayerNorm.bias", "bert.encoder.layer.10.intermediate.dense.weight", "bert.encoder.layer.10.intermediate.dense.bias", "bert.encoder.layer.10.output.dense.weight", "bert.encoder.layer.10.output.dense.bias", "bert.encoder.layer.10.output.LayerNorm.weight", "bert.encoder.layer.10.output.LayerNorm.bias", "bert.encoder.layer.11.attention.self.query.weight", "bert.encoder.layer.11.attention.self.query.bias", "bert.encoder.layer.11.attention.self.key.weight", "bert.encoder.layer.11.attention.self.key.bias", "bert.encoder.layer.11.attention.self.value.weight", "bert.encoder.layer.11.attention.self.value.bias", "bert.encoder.layer.11.attention.output.dense.weight", "bert.encoder.layer.11.attention.output.dense.bias", "bert.encoder.layer.11.attention.output.LayerNorm.weight", "bert.encoder.layer.11.attention.output.LayerNorm.bias", "bert.encoder.layer.11.intermediate.dense.weight", "bert.encoder.layer.11.intermediate.dense.bias", "bert.encoder.layer.11.output.dense.weight", "bert.encoder.layer.11.output.dense.bias", "bert.encoder.layer.11.output.LayerNorm.weight", "bert.encoder.layer.11.output.LayerNorm.bias", "bert.encoder.layer.12.attention.self.query.weight", "bert.encoder.layer.12.attention.self.query.bias", "bert.encoder.layer.12.attention.self.key.weight", "bert.encoder.layer.12.attention.self.key.bias", "bert.encoder.layer.12.attention.self.value.weight", "bert.encoder.layer.12.attention.self.value.bias", "bert.encoder.layer.12.attention.output.dense.weight", "bert.encoder.layer.12.attention.output.dense.bias", "bert.encoder.layer.12.attention.output.LayerNorm.weight", "bert.encoder.layer.12.attention.output.LayerNorm.bias", "bert.encoder.layer.12.intermediate.dense.weight", "bert.encoder.layer.12.intermediate.dense.bias", "bert.encoder.layer.12.output.dense.weight", "bert.encoder.layer.12.output.dense.bias", "bert.encoder.layer.12.output.LayerNorm.weight", "bert.encoder.layer.12.output.LayerNorm.bias", "bert.encoder.layer.13.attention.self.query.weight", "bert.encoder.layer.13.attention.self.query.bias", "bert.encoder.layer.13.attention.self.key.weight", "bert.encoder.layer.13.attention.self.key.bias", "bert.encoder.layer.13.attention.self.value.weight", "bert.encoder.layer.13.attention.self.value.bias", "bert.encoder.layer.13.attention.output.dense.weight", "bert.encoder.layer.13.attention.output.dense.bias", "bert.encoder.layer.13.attention.output.LayerNorm.weight", "bert.encoder.layer.13.attention.output.LayerNorm.bias", "bert.encoder.layer.13.intermediate.dense.weight", "bert.encoder.layer.13.intermediate.dense.bias", "bert.encoder.layer.13.output.dense.weight", "bert.encoder.layer.13.output.dense.bias", "bert.encoder.layer.13.output.LayerNorm.weight", "bert.encoder.layer.13.output.LayerNorm.bias", "bert.encoder.layer.14.attention.self.query.weight", "bert.encoder.layer.14.attention.self.query.bias", "bert.encoder.layer.14.attention.self.key.weight", "bert.encoder.layer.14.attention.self.key.bias", "bert.encoder.layer.14.attention.self.value.weight", "bert.encoder.layer.14.attention.self.value.bias", "bert.encoder.layer.14.attention.output.dense.weight", "bert.encoder.layer.14.attention.output.dense.bias", "bert.encoder.layer.14.attention.output.LayerNorm.weight", "bert.encoder.layer.14.attention.output.LayerNorm.bias", "bert.encoder.layer.14.intermediate.dense.weight", "bert.encoder.layer.14.intermediate.dense.bias", "bert.encoder.layer.14.output.dense.weight", "bert.encoder.layer.14.output.dense.bias", "bert.encoder.layer.14.output.LayerNorm.weight", "bert.encoder.layer.14.output.LayerNorm.bias", "bert.encoder.layer.15.attention.self.query.weight", "bert.encoder.layer.15.attention.self.query.bias", "bert.encoder.layer.15.attention.self.key.weight", "bert.encoder.layer.15.attention.self.key.bias", "bert.encoder.layer.15.attention.self.value.weight", "bert.encoder.layer.15.attention.self.value.bias", "bert.encoder.layer.15.attention.output.dense.weight", "bert.encoder.layer.15.attention.output.dense.bias", "bert.encoder.layer.15.attention.output.LayerNorm.weight", "bert.encoder.layer.15.attention.output.LayerNorm.bias", "bert.encoder.layer.15.intermediate.dense.weight", "bert.encoder.layer.15.intermediate.dense.bias", "bert.encoder.layer.15.output.dense.weight", "bert.encoder.layer.15.output.dense.bias", "bert.encoder.layer.15.output.LayerNorm.weight", "bert.encoder.layer.15.output.LayerNorm.bias", "bert.encoder.layer.16.attention.self.query.weight", "bert.encoder.layer.16.attention.self.query.bias", "bert.encoder.layer.16.attention.self.key.weight", "bert.encoder.layer.16.attention.self.key.bias", "bert.encoder.layer.16.attention.self.value.weight", "bert.encoder.layer.16.attention.self.value.bias", "bert.encoder.layer.16.attention.output.dense.weight", "bert.encoder.layer.16.attention.output.dense.bias", "bert.encoder.layer.16.attention.output.LayerNorm.weight", "bert.encoder.layer.16.attention.output.LayerNorm.bias", "bert.encoder.layer.16.intermediate.dense.weight", "bert.encoder.layer.16.intermediate.dense.bias", "bert.encoder.layer.16.output.dense.weight", "bert.encoder.layer.16.output.dense.bias", "bert.encoder.layer.16.output.LayerNorm.weight", "bert.encoder.layer.16.output.LayerNorm.bias", "bert.encoder.layer.17.attention.self.query.weight", "bert.encoder.layer.17.attention.self.query.bias", "bert.encoder.layer.17.attention.self.key.weight", "bert.encoder.layer.17.attention.self.key.bias", "bert.encoder.layer.17.attention.self.value.weight", "bert.encoder.layer.17.attention.self.value.bias", "bert.encoder.layer.17.attention.output.dense.weight", "bert.encoder.layer.17.attention.output.dense.bias", "bert.encoder.layer.17.attention.output.LayerNorm.weight", "bert.encoder.layer.17.attention.output.LayerNorm.bias", "bert.encoder.layer.17.intermediate.dense.weight", "bert.encoder.layer.17.intermediate.dense.bias", "bert.encoder.layer.17.output.dense.weight", "bert.encoder.layer.17.output.dense.bias", "bert.encoder.layer.17.output.LayerNorm.weight", "bert.encoder.layer.17.output.LayerNorm.bias", "bert.encoder.layer.18.attention.self.query.weight", "bert.encoder.layer.18.attention.self.query.bias", "bert.encoder.layer.18.attention.self.key.weight", "bert.encoder.layer.18.attention.self.key.bias", "bert.encoder.layer.18.attention.self.value.weight", "bert.encoder.layer.18.attention.self.value.bias", "bert.encoder.layer.18.attention.output.dense.weight", "bert.encoder.layer.18.attention.output.dense.bias", "bert.encoder.layer.18.attention.output.LayerNorm.weight", "bert.encoder.layer.18.attention.output.LayerNorm.bias", "bert.encoder.layer.18.intermediate.dense.weight", "bert.encoder.layer.18.intermediate.dense.bias", "bert.encoder.layer.18.output.dense.weight", "bert.encoder.layer.18.output.dense.bias", "bert.encoder.layer.18.output.LayerNorm.weight", "bert.encoder.layer.18.output.LayerNorm.bias", "bert.encoder.layer.19.attention.self.query.weight", "bert.encoder.layer.19.attention.self.query.bias", "bert.encoder.layer.19.attention.self.key.weight", "bert.encoder.layer.19.attention.self.key.bias", "bert.encoder.layer.19.attention.self.value.weight", "bert.encoder.layer.19.attention.self.value.bias", "bert.encoder.layer.19.attention.output.dense.weight", "bert.encoder.layer.19.attention.output.dense.bias", "bert.encoder.layer.19.attention.output.LayerNorm.weight", "bert.encoder.layer.19.attention.output.LayerNorm.bias", "bert.encoder.layer.19.intermediate.dense.weight", "bert.encoder.layer.19.intermediate.dense.bias", "bert.encoder.layer.19.output.dense.weight", "bert.encoder.layer.19.output.dense.bias", "bert.encoder.layer.19.output.LayerNorm.weight", "bert.encoder.layer.19.output.LayerNorm.bias", "bert.encoder.layer.20.attention.self.query.weight", "bert.encoder.layer.20.attention.self.query.bias", "bert.encoder.layer.20.attention.self.key.weight", "bert.encoder.layer.20.attention.self.key.bias", "bert.encoder.layer.20.attention.self.value.weight", "bert.encoder.layer.20.attention.self.value.bias", "bert.encoder.layer.20.attention.output.dense.weight", "bert.encoder.layer.20.attention.output.dense.bias", "bert.encoder.layer.20.attention.output.LayerNorm.weight", "bert.encoder.layer.20.attention.output.LayerNorm.bias", "bert.encoder.layer.20.intermediate.dense.weight", "bert.encoder.layer.20.intermediate.dense.bias", "bert.encoder.layer.20.output.dense.weight", "bert.encoder.layer.20.output.dense.bias", "bert.encoder.layer.20.output.LayerNorm.weight", "bert.encoder.layer.20.output.LayerNorm.bias", "bert.encoder.layer.21.attention.self.query.weight", "bert.encoder.layer.21.attention.self.query.bias", "bert.encoder.layer.21.attention.self.key.weight", "bert.encoder.layer.21.attention.self.key.bias", "bert.encoder.layer.21.attention.self.value.weight", "bert.encoder.layer.21.attention.self.value.bias", "bert.encoder.layer.21.attention.output.dense.weight", "bert.encoder.layer.21.attention.output.dense.bias", "bert.encoder.layer.21.attention.output.LayerNorm.weight", "bert.encoder.layer.21.attention.output.LayerNorm.bias", "bert.encoder.layer.21.intermediate.dense.weight", "bert.encoder.layer.21.intermediate.dense.bias", "bert.encoder.layer.21.output.dense.weight", "bert.encoder.layer.21.output.dense.bias", "bert.encoder.layer.21.output.LayerNorm.weight", "bert.encoder.layer.21.output.LayerNorm.bias", "bert.encoder.layer.22.attention.self.query.weight", "bert.encoder.layer.22.attention.self.query.bias", "bert.encoder.layer.22.attention.self.key.weight", "bert.encoder.layer.22.attention.self.key.bias", "bert.encoder.layer.22.attention.self.value.weight", "bert.encoder.layer.22.attention.self.value.bias", "bert.encoder.layer.22.attention.output.dense.weight", "bert.encoder.layer.22.attention.output.dense.bias", "bert.encoder.layer.22.attention.output.LayerNorm.weight", "bert.encoder.layer.22.attention.output.LayerNorm.bias", "bert.encoder.layer.22.intermediate.dense.weight", "bert.encoder.layer.22.intermediate.dense.bias", "bert.encoder.layer.22.output.dense.weight", "bert.encoder.layer.22.output.dense.bias", "bert.encoder.layer.22.output.LayerNorm.weight", "bert.encoder.layer.22.output.LayerNorm.bias", "bert.encoder.layer.23.attention.self.query.weight", "bert.encoder.layer.23.attention.self.query.bias", "bert.encoder.layer.23.attention.self.key.weight", "bert.encoder.layer.23.attention.self.key.bias", "bert.encoder.layer.23.attention.self.value.weight", "bert.encoder.layer.23.attention.self.value.bias", "bert.encoder.layer.23.attention.output.dense.weight", "bert.encoder.layer.23.attention.output.dense.bias", "bert.encoder.layer.23.attention.output.LayerNorm.weight", "bert.encoder.layer.23.attention.output.LayerNorm.bias", "bert.encoder.layer.23.intermediate.dense.weight", "bert.encoder.layer.23.intermediate.dense.bias", "bert.encoder.layer.23.output.dense.weight", "bert.encoder.layer.23.output.dense.bias", "bert.encoder.layer.23.output.LayerNorm.weight", "bert.encoder.layer.23.output.LayerNorm.bias", "classifier.layers.0.weight", "classifier.layers.0.bias", "classifier.layers.1.projection.weight", "classifier.layers.1.projection.bias", "classifier.layers.3.weight", "classifier.layers.3.bias", "classifier.layers.4.projection.weight", "classifier.layers.4.projection.bias", "classifier.layers.6.weight", "classifier.layers.6.bias". 
	Unexpected key(s) in state_dict: "layers.0.weight", "layers.0.bias", "layers.1.projection.weight", "layers.1.projection.bias", "layers.3.weight", "layers.3.bias", "layers.4.projection.weight", "layers.4.projection.bias", "layers.6.weight", "layers.6.bias". 
Traceback (most recent call last):
  File "/home/ubuntu/nlp-osaka/sentiment/ddp_sentiment_finetune.py", line 1206, in main
    classifier.fit(X_train, X_val, y_train, y_val, rank, world_size, debug, start_epoch, model_state_dict, optimizer_state_dict,
  File "/home/ubuntu/nlp-osaka/sentiment/torch_ddp_finetune_neural_classifier.py", line 1070, in fit
    self.model.load_state_dict(model_state_dict)
  File "/home/ubuntu/nlp-osaka/sentiment/torch_ddp_finetune_neural_classifier.py", line 1070, in fit
    self.model.load_state_dict(model_state_dict)
  File "/home/ubuntu/nlp-osaka/sentiment/ddp_sentiment_finetune.py", line 1206, in main
    classifier.fit(X_train, X_val, y_train, y_val, rank, world_size, debug, start_epoch, model_state_dict, optimizer_state_dict,
  File "/home/ubuntu/nlp-osaka/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 2152, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
  File "/home/ubuntu/nlp-osaka/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 2152, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
  File "/home/ubuntu/nlp-osaka/sentiment/torch_ddp_finetune_neural_classifier.py", line 1070, in fit
    self.model.load_state_dict(model_state_dict)
  File "/home/ubuntu/nlp-osaka/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 2152, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for BERTClassifier:
	Missing key(s) in state_dict: "bert.embeddings.word_embeddings.weight", "bert.embeddings.position_embeddings.weight", "bert.embeddings.token_type_embeddings.weight", "bert.embeddings.LayerNorm.weight", "bert.embeddings.LayerNorm.bias", "bert.encoder.layer.0.attention.self.query.weight", "bert.encoder.layer.0.attention.self.query.bias", "bert.encoder.layer.0.attention.self.key.weight", "bert.encoder.layer.0.attention.self.key.bias", "bert.encoder.layer.0.attention.self.value.weight", "bert.encoder.layer.0.attention.self.value.bias", "bert.encoder.layer.0.attention.output.dense.weight", "bert.encoder.layer.0.attention.output.dense.bias", "bert.encoder.layer.0.attention.output.LayerNorm.weight", "bert.encoder.layer.0.attention.output.LayerNorm.bias", "bert.encoder.layer.0.intermediate.dense.weight", "bert.encoder.layer.0.intermediate.dense.bias", "bert.encoder.layer.0.output.dense.weight", "bert.encoder.layer.0.output.dense.bias", "bert.encoder.layer.0.output.LayerNorm.weight", "bert.encoder.layer.0.output.LayerNorm.bias", "bert.encoder.layer.1.attention.self.query.weight", "bert.encoder.layer.1.attention.self.query.bias", "bert.encoder.layer.1.attention.self.key.weight", "bert.encoder.layer.1.attention.self.key.bias", "bert.encoder.layer.1.attention.self.value.weight", "bert.encoder.layer.1.attention.self.value.bias", "bert.encoder.layer.1.attention.output.dense.weight", "bert.encoder.layer.1.attention.output.dense.bias", "bert.encoder.layer.1.attention.output.LayerNorm.weight", "bert.encoder.layer.1.attention.output.LayerNorm.bias", "bert.encoder.layer.1.intermediate.dense.weight", "bert.encoder.layer.1.intermediate.dense.bias", "bert.encoder.layer.1.output.dense.weight", "bert.encoder.layer.1.output.dense.bias", "bert.encoder.layer.1.output.LayerNorm.weight", "bert.encoder.layer.1.output.LayerNorm.bias", "bert.encoder.layer.2.attention.self.query.weight", "bert.encoder.layer.2.attention.self.query.bias", "bert.encoder.layer.2.attention.self.key.weight", "bert.encoder.layer.2.attention.self.key.bias", "bert.encoder.layer.2.attention.self.value.weight", "bert.encoder.layer.2.attention.self.value.bias", "bert.encoder.layer.2.attention.output.dense.weight", "bert.encoder.layer.2.attention.output.dense.bias", "bert.encoder.layer.2.attention.output.LayerNorm.weight", "bert.encoder.layer.2.attention.output.LayerNorm.bias", "bert.encoder.layer.2.intermediate.dense.weight", "bert.encoder.layer.2.intermediate.dense.bias", "bert.encoder.layer.2.output.dense.weight", "bert.encoder.layer.2.output.dense.bias", "bert.encoder.layer.2.output.LayerNorm.weight", "bert.encoder.layer.2.output.LayerNorm.bias", "bert.encoder.layer.3.attention.self.query.weight", "bert.encoder.layer.3.attention.self.query.bias", "bert.encoder.layer.3.attention.self.key.weight", "bert.encoder.layer.3.attention.self.key.bias", "bert.encoder.layer.3.attention.self.value.weight", "bert.encoder.layer.3.attention.self.value.bias", "bert.encoder.layer.3.attention.output.dense.weight", "bert.encoder.layer.3.attention.output.dense.bias", "bert.encoder.layer.3.attention.output.LayerNorm.weight", "bert.encoder.layer.3.attention.output.LayerNorm.bias", "bert.encoder.layer.3.intermediate.dense.weight", "bert.encoder.layer.3.intermediate.dense.bias", "bert.encoder.layer.3.output.dense.weight", "bert.encoder.layer.3.output.dense.bias", "bert.encoder.layer.3.output.LayerNorm.weight", "bert.encoder.layer.3.output.LayerNorm.bias", "bert.encoder.layer.4.attention.self.query.weight", "bert.encoder.layer.4.attention.self.query.bias", "bert.encoder.layer.4.attention.self.key.weight", "bert.encoder.layer.4.attention.self.key.bias", "bert.encoder.layer.4.attention.self.value.weight", "bert.encoder.layer.4.attention.self.value.bias", "bert.encoder.layer.4.attention.output.dense.weight", "bert.encoder.layer.4.attention.output.dense.bias", "bert.encoder.layer.4.attention.output.LayerNorm.weight", "bert.encoder.layer.4.attention.output.LayerNorm.bias", "bert.encoder.layer.4.intermediate.dense.weight", "bert.encoder.layer.4.intermediate.dense.bias", "bert.encoder.layer.4.output.dense.weight", "bert.encoder.layer.4.output.dense.bias", "bert.encoder.layer.4.output.LayerNorm.weight", "bert.encoder.layer.4.output.LayerNorm.bias", "bert.encoder.layer.5.attention.self.query.weight", "bert.encoder.layer.5.attention.self.query.bias", "bert.encoder.layer.5.attention.self.key.weight", "bert.encoder.layer.5.attention.self.key.bias", "bert.encoder.layer.5.attention.self.value.weight", "bert.encoder.layer.5.attention.self.value.bias", "bert.encoder.layer.5.attention.output.dense.weight", "bert.encoder.layer.5.attention.output.dense.bias", "bert.encoder.layer.5.attention.output.LayerNorm.weight", "bert.encoder.layer.5.attention.output.LayerNorm.bias", "bert.encoder.layer.5.intermediate.dense.weight", "bert.encoder.layer.5.intermediate.dense.bias", "bert.encoder.layer.5.output.dense.weight", "bert.encoder.layer.5.output.dense.bias", "bert.encoder.layer.5.output.LayerNorm.weight", "bert.encoder.layer.5.output.LayerNorm.bias", "bert.encoder.layer.6.attention.self.query.weight", "bert.encoder.layer.6.attention.self.query.bias", "bert.encoder.layer.6.attention.self.key.weight", "bert.encoder.layer.6.attention.self.key.bias", "bert.encoder.layer.6.attention.self.value.weight", "bert.encoder.layer.6.attention.self.value.bias", "bert.encoder.layer.6.attention.output.dense.weight", "bert.encoder.layer.6.attention.output.dense.bias", "bert.encoder.layer.6.attention.output.LayerNorm.weight", "bert.encoder.layer.6.attention.output.LayerNorm.bias", "bert.encoder.layer.6.intermediate.dense.weight", "bert.encoder.layer.6.intermediate.dense.bias", "bert.encoder.layer.6.output.dense.weight", "bert.encoder.layer.6.output.dense.bias", "bert.encoder.layer.6.output.LayerNorm.weight", "bert.encoder.layer.6.output.LayerNorm.bias", "bert.encoder.layer.7.attention.self.query.weight", "bert.encoder.layer.7.attention.self.query.bias", "bert.encoder.layer.7.attention.self.key.weight", "bert.encoder.layer.7.attention.self.key.bias", "bert.encoder.layer.7.attention.self.value.weight", "bert.encoder.layer.7.attention.self.value.bias", "bert.encoder.layer.7.attention.output.dense.weight", "bert.encoder.layer.7.attention.output.dense.bias", "bert.encoder.layer.7.attention.output.LayerNorm.weight", "bert.encoder.layer.7.attention.output.LayerNorm.bias", "bert.encoder.layer.7.intermediate.dense.weight", "bert.encoder.layer.7.intermediate.dense.bias", "bert.encoder.layer.7.output.dense.weight", "bert.encoder.layer.7.output.dense.bias", "bert.encoder.layer.7.output.LayerNorm.weight", "bert.encoder.layer.7.output.LayerNorm.bias", "bert.encoder.layer.8.attention.self.query.weight", "bert.encoder.layer.8.attention.self.query.bias", "bert.encoder.layer.8.attention.self.key.weight", "bert.encoder.layer.8.attention.self.key.bias", "bert.encoder.layer.8.attention.self.value.weight", "bert.encoder.layer.8.attention.self.value.bias", "bert.encoder.layer.8.attention.output.dense.weight", "bert.encoder.layer.8.attention.output.dense.bias", "bert.encoder.layer.8.attention.output.LayerNorm.weight", "bert.encoder.layer.8.attention.output.LayerNorm.bias", "bert.encoder.layer.8.intermediate.dense.weight", "bert.encoder.layer.8.intermediate.dense.bias", "bert.encoder.layer.8.output.dense.weight", "bert.encoder.layer.8.output.dense.bias", "bert.encoder.layer.8.output.LayerNorm.weight", "bert.encoder.layer.8.output.LayerNorm.bias", "bert.encoder.layer.9.attention.self.query.weight", "bert.encoder.layer.9.attention.self.query.bias", "bert.encoder.layer.9.attention.self.key.weight", "bert.encoder.layer.9.attention.self.key.bias", "bert.encoder.layer.9.attention.self.value.weight", "bert.encoder.layer.9.attention.self.value.bias", "bert.encoder.layer.9.attention.output.dense.weight", "bert.encoder.layer.9.attention.output.dense.bias", "bert.encoder.layer.9.attention.output.LayerNorm.weight", "bert.encoder.layer.9.attention.output.LayerNorm.bias", "bert.encoder.layer.9.intermediate.dense.weight", "bert.encoder.layer.9.intermediate.dense.bias", "bert.encoder.layer.9.output.dense.weight", "bert.encoder.layer.9.output.dense.bias", "bert.encoder.layer.9.output.LayerNorm.weight", "bert.encoder.layer.9.output.LayerNorm.bias", "bert.encoder.layer.10.attention.self.query.weight", "bert.encoder.layer.10.attention.self.query.bias", "bert.encoder.layer.10.attention.self.key.weight", "bert.encoder.layer.10.attention.self.key.bias", "bert.encoder.layer.10.attention.self.value.weight", "bert.encoder.layer.10.attention.self.value.bias", "bert.encoder.layer.10.attention.output.dense.weight", "bert.encoder.layer.10.attention.output.dense.bias", "bert.encoder.layer.10.attention.output.LayerNorm.weight", "bert.encoder.layer.10.attention.output.LayerNorm.bias", "bert.encoder.layer.10.intermediate.dense.weight", "bert.encoder.layer.10.intermediate.dense.bias", "bert.encoder.layer.10.output.dense.weight", "bert.encoder.layer.10.output.dense.bias", "bert.encoder.layer.10.output.LayerNorm.weight", "bert.encoder.layer.10.output.LayerNorm.bias", "bert.encoder.layer.11.attention.self.query.weight", "bert.encoder.layer.11.attention.self.query.bias", "bert.encoder.layer.11.attention.self.key.weight", "bert.encoder.layer.11.attention.self.key.bias", "bert.encoder.layer.11.attention.self.value.weight", "bert.encoder.layer.11.attention.self.value.bias", "bert.encoder.layer.11.attention.output.dense.weight", "bert.encoder.layer.11.attention.output.dense.bias", "bert.encoder.layer.11.attention.output.LayerNorm.weight", "bert.encoder.layer.11.attention.output.LayerNorm.bias", "bert.encoder.layer.11.intermediate.dense.weight", "bert.encoder.layer.11.intermediate.dense.bias", "bert.encoder.layer.11.output.dense.weight", "bert.encoder.layer.11.output.dense.bias", "bert.encoder.layer.11.output.LayerNorm.weight", "bert.encoder.layer.11.output.LayerNorm.bias", "bert.encoder.layer.12.attention.self.query.weight", "bert.encoder.layer.12.attention.self.query.bias", "bert.encoder.layer.12.attention.self.key.weight", "bert.encoder.layer.12.attention.self.key.bias", "bert.encoder.layer.12.attention.self.value.weight", "bert.encoder.layer.12.attention.self.value.bias", "bert.encoder.layer.12.attention.output.dense.weight", "bert.encoder.layer.12.attention.output.dense.bias", "bert.encoder.layer.12.attention.output.LayerNorm.weight", "bert.encoder.layer.12.attention.output.LayerNorm.bias", "bert.encoder.layer.12.intermediate.dense.weight", "bert.encoder.layer.12.intermediate.dense.bias", "bert.encoder.layer.12.output.dense.weight", "bert.encoder.layer.12.output.dense.bias", "bert.encoder.layer.12.output.LayerNorm.weight", "bert.encoder.layer.12.output.LayerNorm.bias", "bert.encoder.layer.13.attention.self.query.weight", "bert.encoder.layer.13.attention.self.query.bias", "bert.encoder.layer.13.attention.self.key.weight", "bert.encoder.layer.13.attention.self.key.bias", "bert.encoder.layer.13.attention.self.value.weight", "bert.encoder.layer.13.attention.self.value.bias", "bert.encoder.layer.13.attention.output.dense.weight", "bert.encoder.layer.13.attention.output.dense.bias", "bert.encoder.layer.13.attention.output.LayerNorm.weight", "bert.encoder.layer.13.attention.output.LayerNorm.bias", "bert.encoder.layer.13.intermediate.dense.weight", "bert.encoder.layer.13.intermediate.dense.bias", "bert.encoder.layer.13.output.dense.weight", "bert.encoder.layer.13.output.dense.bias", "bert.encoder.layer.13.output.LayerNorm.weight", "bert.encoder.layer.13.output.LayerNorm.bias", "bert.encoder.layer.14.attention.self.query.weight", "bert.encoder.layer.14.attention.self.query.bias", "bert.encoder.layer.14.attention.self.key.weight", "bert.encoder.layer.14.attention.self.key.bias", "bert.encoder.layer.14.attention.self.value.weight", "bert.encoder.layer.14.attention.self.value.bias", "bert.encoder.layer.14.attention.output.dense.weight", "bert.encoder.layer.14.attention.output.dense.bias", "bert.encoder.layer.14.attention.output.LayerNorm.weight", "bert.encoder.layer.14.attention.output.LayerNorm.bias", "bert.encoder.layer.14.intermediate.dense.weight", "bert.encoder.layer.14.intermediate.dense.bias", "bert.encoder.layer.14.output.dense.weight", "bert.encoder.layer.14.output.dense.bias", "bert.encoder.layer.14.output.LayerNorm.weight", "bert.encoder.layer.14.output.LayerNorm.bias", "bert.encoder.layer.15.attention.self.query.weight", "bert.encoder.layer.15.attention.self.query.bias", "bert.encoder.layer.15.attention.self.key.weight", "bert.encoder.layer.15.attention.self.key.bias", "bert.encoder.layer.15.attention.self.value.weight", "bert.encoder.layer.15.attention.self.value.bias", "bert.encoder.layer.15.attention.output.dense.weight", "bert.encoder.layer.15.attention.output.dense.bias", "bert.encoder.layer.15.attention.output.LayerNorm.weight", "bert.encoder.layer.15.attention.output.LayerNorm.bias", "bert.encoder.layer.15.intermediate.dense.weight", "bert.encoder.layer.15.intermediate.dense.bias", "bert.encoder.layer.15.output.dense.weight", "bert.encoder.layer.15.output.dense.bias", "bert.encoder.layer.15.output.LayerNorm.weight", "bert.encoder.layer.15.output.LayerNorm.bias", "bert.encoder.layer.16.attention.self.query.weight", "bert.encoder.layer.16.attention.self.query.bias", "bert.encoder.layer.16.attention.self.key.weight", "bert.encoder.layer.16.attention.self.key.bias", "bert.encoder.layer.16.attention.self.value.weight", "bert.encoder.layer.16.attention.self.value.bias", "bert.encoder.layer.16.attention.output.dense.weight", "bert.encoder.layer.16.attention.output.dense.bias", "bert.encoder.layer.16.attention.output.LayerNorm.weight", "bert.encoder.layer.16.attention.output.LayerNorm.bias", "bert.encoder.layer.16.intermediate.dense.weight", "bert.encoder.layer.16.intermediate.dense.bias", "bert.encoder.layer.16.output.dense.weight", "bert.encoder.layer.16.output.dense.bias", "bert.encoder.layer.16.output.LayerNorm.weight", "bert.encoder.layer.16.output.LayerNorm.bias", "bert.encoder.layer.17.attention.self.query.weight", "bert.encoder.layer.17.attention.self.query.bias", "bert.encoder.layer.17.attention.self.key.weight", "bert.encoder.layer.17.attention.self.key.bias", "bert.encoder.layer.17.attention.self.value.weight", "bert.encoder.layer.17.attention.self.value.bias", "bert.encoder.layer.17.attention.output.dense.weight", "bert.encoder.layer.17.attention.output.dense.bias", "bert.encoder.layer.17.attention.output.LayerNorm.weight", "bert.encoder.layer.17.attention.output.LayerNorm.bias", "bert.encoder.layer.17.intermediate.dense.weight", "bert.encoder.layer.17.intermediate.dense.bias", "bert.encoder.layer.17.output.dense.weight", "bert.encoder.layer.17.output.dense.bias", "bert.encoder.layer.17.output.LayerNorm.weight", "bert.encoder.layer.17.output.LayerNorm.bias", "bert.encoder.layer.18.attention.self.query.weight", "bert.encoder.layer.18.attention.self.query.bias", "bert.encoder.layer.18.attention.self.key.weight", "bert.encoder.layer.18.attention.self.key.bias", "bert.encoder.layer.18.attention.self.value.weight", "bert.encoder.layer.18.attention.self.value.bias", "bert.encoder.layer.18.attention.output.dense.weight", "bert.encoder.layer.18.attention.output.dense.bias", "bert.encoder.layer.18.attention.output.LayerNorm.weight", "bert.encoder.layer.18.attention.output.LayerNorm.bias", "bert.encoder.layer.18.intermediate.dense.weight", "bert.encoder.layer.18.intermediate.dense.bias", "bert.encoder.layer.18.output.dense.weight", "bert.encoder.layer.18.output.dense.bias", "bert.encoder.layer.18.output.LayerNorm.weight", "bert.encoder.layer.18.output.LayerNorm.bias", "bert.encoder.layer.19.attention.self.query.weight", "bert.encoder.layer.19.attention.self.query.bias", "bert.encoder.layer.19.attention.self.key.weight", "bert.encoder.layer.19.attention.self.key.bias", "bert.encoder.layer.19.attention.self.value.weight", "bert.encoder.layer.19.attention.self.value.bias", "bert.encoder.layer.19.attention.output.dense.weight", "bert.encoder.layer.19.attention.output.dense.bias", "bert.encoder.layer.19.attention.output.LayerNorm.weight", "bert.encoder.layer.19.attention.output.LayerNorm.bias", "bert.encoder.layer.19.intermediate.dense.weight", "bert.encoder.layer.19.intermediate.dense.bias", "bert.encoder.layer.19.output.dense.weight", "bert.encoder.layer.19.output.dense.bias", "bert.encoder.layer.19.output.LayerNorm.weight", "bert.encoder.layer.19.output.LayerNorm.bias", "bert.encoder.layer.20.attention.self.query.weight", "bert.encoder.layer.20.attention.self.query.bias", "bert.encoder.layer.20.attention.self.key.weight", "bert.encoder.layer.20.attention.self.key.bias", "bert.encoder.layer.20.attention.self.value.weight", "bert.encoder.layer.20.attention.self.value.bias", "bert.encoder.layer.20.attention.output.dense.weight", "bert.encoder.layer.20.attention.output.dense.bias", "bert.encoder.layer.20.attention.output.LayerNorm.weight", "bert.encoder.layer.20.attention.output.LayerNorm.bias", "bert.encoder.layer.20.intermediate.dense.weight", "bert.encoder.layer.20.intermediate.dense.bias", "bert.encoder.layer.20.output.dense.weight", "bert.encoder.layer.20.output.dense.bias", "bert.encoder.layer.20.output.LayerNorm.weight", "bert.encoder.layer.20.output.LayerNorm.bias", "bert.encoder.layer.21.attention.self.query.weight", "bert.encoder.layer.21.attention.self.query.bias", "bert.encoder.layer.21.attention.self.key.weight", "bert.encoder.layer.21.attention.self.key.bias", "bert.encoder.layer.21.attention.self.value.weight", "bert.encoder.layer.21.attention.self.value.bias", "bert.encoder.layer.21.attention.output.dense.weight", "bert.encoder.layer.21.attention.output.dense.bias", "bert.encoder.layer.21.attention.output.LayerNorm.weight", "bert.encoder.layer.21.attention.output.LayerNorm.bias", "bert.encoder.layer.21.intermediate.dense.weight", "bert.encoder.layer.21.intermediate.dense.bias", "bert.encoder.layer.21.output.dense.weight", "bert.encoder.layer.21.output.dense.bias", "bert.encoder.layer.21.output.LayerNorm.weight", "bert.encoder.layer.21.output.LayerNorm.bias", "bert.encoder.layer.22.attention.self.query.weight", "bert.encoder.layer.22.attention.self.query.bias", "bert.encoder.layer.22.attention.self.key.weight", "bert.encoder.layer.22.attention.self.key.bias", "bert.encoder.layer.22.attention.self.value.weight", "bert.encoder.layer.22.attention.self.value.bias", "bert.encoder.layer.22.attention.output.dense.weight", "bert.encoder.layer.22.attention.output.dense.bias", "bert.encoder.layer.22.attention.output.LayerNorm.weight", "bert.encoder.layer.22.attention.output.LayerNorm.bias", "bert.encoder.layer.22.intermediate.dense.weight", "bert.encoder.layer.22.intermediate.dense.bias", "bert.encoder.layer.22.output.dense.weight", "bert.encoder.layer.22.output.dense.bias", "bert.encoder.layer.22.output.LayerNorm.weight", "bert.encoder.layer.22.output.LayerNorm.bias", "bert.encoder.layer.23.attention.self.query.weight", "bert.encoder.layer.23.attention.self.query.bias", "bert.encoder.layer.23.attention.self.key.weight", "bert.encoder.layer.23.attention.self.key.bias", "bert.encoder.layer.23.attention.self.value.weight", "bert.encoder.layer.23.attention.self.value.bias", "bert.encoder.layer.23.attention.output.dense.weight", "bert.encoder.layer.23.attention.output.dense.bias", "bert.encoder.layer.23.attention.output.LayerNorm.weight", "bert.encoder.layer.23.attention.output.LayerNorm.bias", "bert.encoder.layer.23.intermediate.dense.weight", "bert.encoder.layer.23.intermediate.dense.bias", "bert.encoder.layer.23.output.dense.weight", "bert.encoder.layer.23.output.dense.bias", "bert.encoder.layer.23.output.LayerNorm.weight", "bert.encoder.layer.23.output.LayerNorm.bias", "classifier.layers.0.weight", "classifier.layers.0.bias", "classifier.layers.1.projection.weight", "classifier.layers.1.projection.bias", "classifier.layers.3.weight", "classifier.layers.3.bias", "classifier.layers.4.projection.weight", "classifier.layers.4.projection.bias", "classifier.layers.6.weight", "classifier.layers.6.bias". 
	Unexpected key(s) in state_dict: "layers.0.weight", "layers.0.bias", "layers.1.projection.weight", "layers.1.projection.bias", "layers.3.weight", "layers.3.bias", "layers.4.projection.weight", "layers.4.projection.bias", "layers.6.weight", "layers.6.bias". 
RuntimeError: Error(s) in loading state_dict for BERTClassifier:
	Missing key(s) in state_dict: "bert.embeddings.word_embeddings.weight", "bert.embeddings.position_embeddings.weight", "bert.embeddings.token_type_embeddings.weight", "bert.embeddings.LayerNorm.weight", "bert.embeddings.LayerNorm.bias", "bert.encoder.layer.0.attention.self.query.weight", "bert.encoder.layer.0.attention.self.query.bias", "bert.encoder.layer.0.attention.self.key.weight", "bert.encoder.layer.0.attention.self.key.bias", "bert.encoder.layer.0.attention.self.value.weight", "bert.encoder.layer.0.attention.self.value.bias", "bert.encoder.layer.0.attention.output.dense.weight", "bert.encoder.layer.0.attention.output.dense.bias", "bert.encoder.layer.0.attention.output.LayerNorm.weight", "bert.encoder.layer.0.attention.output.LayerNorm.bias", "bert.encoder.layer.0.intermediate.dense.weight", "bert.encoder.layer.0.intermediate.dense.bias", "bert.encoder.layer.0.output.dense.weight", "bert.encoder.layer.0.output.dense.bias", "bert.encoder.layer.0.output.LayerNorm.weight", "bert.encoder.layer.0.output.LayerNorm.bias", "bert.encoder.layer.1.attention.self.query.weight", "bert.encoder.layer.1.attention.self.query.bias", "bert.encoder.layer.1.attention.self.key.weight", "bert.encoder.layer.1.attention.self.key.bias", "bert.encoder.layer.1.attention.self.value.weight", "bert.encoder.layer.1.attention.self.value.bias", "bert.encoder.layer.1.attention.output.dense.weight", "bert.encoder.layer.1.attention.output.dense.bias", "bert.encoder.layer.1.attention.output.LayerNorm.weight", "bert.encoder.layer.1.attention.output.LayerNorm.bias", "bert.encoder.layer.1.intermediate.dense.weight", "bert.encoder.layer.1.intermediate.dense.bias", "bert.encoder.layer.1.output.dense.weight", "bert.encoder.layer.1.output.dense.bias", "bert.encoder.layer.1.output.LayerNorm.weight", "bert.encoder.layer.1.output.LayerNorm.bias", "bert.encoder.layer.2.attention.self.query.weight", "bert.encoder.layer.2.attention.self.query.bias", "bert.encoder.layer.2.attention.self.key.weight", "bert.encoder.layer.2.attention.self.key.bias", "bert.encoder.layer.2.attention.self.value.weight", "bert.encoder.layer.2.attention.self.value.bias", "bert.encoder.layer.2.attention.output.dense.weight", "bert.encoder.layer.2.attention.output.dense.bias", "bert.encoder.layer.2.attention.output.LayerNorm.weight", "bert.encoder.layer.2.attention.output.LayerNorm.bias", "bert.encoder.layer.2.intermediate.dense.weight", "bert.encoder.layer.2.intermediate.dense.bias", "bert.encoder.layer.2.output.dense.weight", "bert.encoder.layer.2.output.dense.bias", "bert.encoder.layer.2.output.LayerNorm.weight", "bert.encoder.layer.2.output.LayerNorm.bias", "bert.encoder.layer.3.attention.self.query.weight", "bert.encoder.layer.3.attention.self.query.bias", "bert.encoder.layer.3.attention.self.key.weight", "bert.encoder.layer.3.attention.self.key.bias", "bert.encoder.layer.3.attention.self.value.weight", "bert.encoder.layer.3.attention.self.value.bias", "bert.encoder.layer.3.attention.output.dense.weight", "bert.encoder.layer.3.attention.output.dense.bias", "bert.encoder.layer.3.attention.output.LayerNorm.weight", "bert.encoder.layer.3.attention.output.LayerNorm.bias", "bert.encoder.layer.3.intermediate.dense.weight", "bert.encoder.layer.3.intermediate.dense.bias", "bert.encoder.layer.3.output.dense.weight", "bert.encoder.layer.3.output.dense.bias", "bert.encoder.layer.3.output.LayerNorm.weight", "bert.encoder.layer.3.output.LayerNorm.bias", "bert.encoder.layer.4.attention.self.query.weight", "bert.encoder.layer.4.attention.self.query.bias", "bert.encoder.layer.4.attention.self.key.weight", "bert.encoder.layer.4.attention.self.key.bias", "bert.encoder.layer.4.attention.self.value.weight", "bert.encoder.layer.4.attention.self.value.bias", "bert.encoder.layer.4.attention.output.dense.weight", "bert.encoder.layer.4.attention.output.dense.bias", "bert.encoder.layer.4.attention.output.LayerNorm.weight", "bert.encoder.layer.4.attention.output.LayerNorm.bias", "bert.encoder.layer.4.intermediate.dense.weight", "bert.encoder.layer.4.intermediate.dense.bias", "bert.encoder.layer.4.output.dense.weight", "bert.encoder.layer.4.output.dense.bias", "bert.encoder.layer.4.output.LayerNorm.weight", "bert.encoder.layer.4.output.LayerNorm.bias", "bert.encoder.layer.5.attention.self.query.weight", "bert.encoder.layer.5.attention.self.query.bias", "bert.encoder.layer.5.attention.self.key.weight", "bert.encoder.layer.5.attention.self.key.bias", "bert.encoder.layer.5.attention.self.value.weight", "bert.encoder.layer.5.attention.self.value.bias", "bert.encoder.layer.5.attention.output.dense.weight", "bert.encoder.layer.5.attention.output.dense.bias", "bert.encoder.layer.5.attention.output.LayerNorm.weight", "bert.encoder.layer.5.attention.output.LayerNorm.bias", "bert.encoder.layer.5.intermediate.dense.weight", "bert.encoder.layer.5.intermediate.dense.bias", "bert.encoder.layer.5.output.dense.weight", "bert.encoder.layer.5.output.dense.bias", "bert.encoder.layer.5.output.LayerNorm.weight", "bert.encoder.layer.5.output.LayerNorm.bias", "bert.encoder.layer.6.attention.self.query.weight", "bert.encoder.layer.6.attention.self.query.bias", "bert.encoder.layer.6.attention.self.key.weight", "bert.encoder.layer.6.attention.self.key.bias", "bert.encoder.layer.6.attention.self.value.weight", "bert.encoder.layer.6.attention.self.value.bias", "bert.encoder.layer.6.attention.output.dense.weight", "bert.encoder.layer.6.attention.output.dense.bias", "bert.encoder.layer.6.attention.output.LayerNorm.weight", "bert.encoder.layer.6.attention.output.LayerNorm.bias", "bert.encoder.layer.6.intermediate.dense.weight", "bert.encoder.layer.6.intermediate.dense.bias", "bert.encoder.layer.6.output.dense.weight", "bert.encoder.layer.6.output.dense.bias", "bert.encoder.layer.6.output.LayerNorm.weight", "bert.encoder.layer.6.output.LayerNorm.bias", "bert.encoder.layer.7.attention.self.query.weight", "bert.encoder.layer.7.attention.self.query.bias", "bert.encoder.layer.7.attention.self.key.weight", "bert.encoder.layer.7.attention.self.key.bias", "bert.encoder.layer.7.attention.self.value.weight", "bert.encoder.layer.7.attention.self.value.bias", "bert.encoder.layer.7.attention.output.dense.weight", "bert.encoder.layer.7.attention.output.dense.bias", "bert.encoder.layer.7.attention.output.LayerNorm.weight", "bert.encoder.layer.7.attention.output.LayerNorm.bias", "bert.encoder.layer.7.intermediate.dense.weight", "bert.encoder.layer.7.intermediate.dense.bias", "bert.encoder.layer.7.output.dense.weight", "bert.encoder.layer.7.output.dense.bias", "bert.encoder.layer.7.output.LayerNorm.weight", "bert.encoder.layer.7.output.LayerNorm.bias", "bert.encoder.layer.8.attention.self.query.weight", "bert.encoder.layer.8.attention.self.query.bias", "bert.encoder.layer.8.attention.self.key.weight", "bert.encoder.layer.8.attention.self.key.bias", "bert.encoder.layer.8.attention.self.value.weight", "bert.encoder.layer.8.attention.self.value.bias", "bert.encoder.layer.8.attention.output.dense.weight", "bert.encoder.layer.8.attention.output.dense.bias", "bert.encoder.layer.8.attention.output.LayerNorm.weight", "bert.encoder.layer.8.attention.output.LayerNorm.bias", "bert.encoder.layer.8.intermediate.dense.weight", "bert.encoder.layer.8.intermediate.dense.bias", "bert.encoder.layer.8.output.dense.weight", "bert.encoder.layer.8.output.dense.bias", "bert.encoder.layer.8.output.LayerNorm.weight", "bert.encoder.layer.8.output.LayerNorm.bias", "bert.encoder.layer.9.attention.self.query.weight", "bert.encoder.layer.9.attention.self.query.bias", "bert.encoder.layer.9.attention.self.key.weight", "bert.encoder.layer.9.attention.self.key.bias", "bert.encoder.layer.9.attention.self.value.weight", "bert.encoder.layer.9.attention.self.value.bias", "bert.encoder.layer.9.attention.output.dense.weight", "bert.encoder.layer.9.attention.output.dense.bias", "bert.encoder.layer.9.attention.output.LayerNorm.weight", "bert.encoder.layer.9.attention.output.LayerNorm.bias", "bert.encoder.layer.9.intermediate.dense.weight", "bert.encoder.layer.9.intermediate.dense.bias", "bert.encoder.layer.9.output.dense.weight", "bert.encoder.layer.9.output.dense.bias", "bert.encoder.layer.9.output.LayerNorm.weight", "bert.encoder.layer.9.output.LayerNorm.bias", "bert.encoder.layer.10.attention.self.query.weight", "bert.encoder.layer.10.attention.self.query.bias", "bert.encoder.layer.10.attention.self.key.weight", "bert.encoder.layer.10.attention.self.key.bias", "bert.encoder.layer.10.attention.self.value.weight", "bert.encoder.layer.10.attention.self.value.bias", "bert.encoder.layer.10.attention.output.dense.weight", "bert.encoder.layer.10.attention.output.dense.bias", "bert.encoder.layer.10.attention.output.LayerNorm.weight", "bert.encoder.layer.10.attention.output.LayerNorm.bias", "bert.encoder.layer.10.intermediate.dense.weight", "bert.encoder.layer.10.intermediate.dense.bias", "bert.encoder.layer.10.output.dense.weight", "bert.encoder.layer.10.output.dense.bias", "bert.encoder.layer.10.output.LayerNorm.weight", "bert.encoder.layer.10.output.LayerNorm.bias", "bert.encoder.layer.11.attention.self.query.weight", "bert.encoder.layer.11.attention.self.query.bias", "bert.encoder.layer.11.attention.self.key.weight", "bert.encoder.layer.11.attention.self.key.bias", "bert.encoder.layer.11.attention.self.value.weight", "bert.encoder.layer.11.attention.self.value.bias", "bert.encoder.layer.11.attention.output.dense.weight", "bert.encoder.layer.11.attention.output.dense.bias", "bert.encoder.layer.11.attention.output.LayerNorm.weight", "bert.encoder.layer.11.attention.output.LayerNorm.bias", "bert.encoder.layer.11.intermediate.dense.weight", "bert.encoder.layer.11.intermediate.dense.bias", "bert.encoder.layer.11.output.dense.weight", "bert.encoder.layer.11.output.dense.bias", "bert.encoder.layer.11.output.LayerNorm.weight", "bert.encoder.layer.11.output.LayerNorm.bias", "bert.encoder.layer.12.attention.self.query.weight", "bert.encoder.layer.12.attention.self.query.bias", "bert.encoder.layer.12.attention.self.key.weight", "bert.encoder.layer.12.attention.self.key.bias", "bert.encoder.layer.12.attention.self.value.weight", "bert.encoder.layer.12.attention.self.value.bias", "bert.encoder.layer.12.attention.output.dense.weight", "bert.encoder.layer.12.attention.output.dense.bias", "bert.encoder.layer.12.attention.output.LayerNorm.weight", "bert.encoder.layer.12.attention.output.LayerNorm.bias", "bert.encoder.layer.12.intermediate.dense.weight", "bert.encoder.layer.12.intermediate.dense.bias", "bert.encoder.layer.12.output.dense.weight", "bert.encoder.layer.12.output.dense.bias", "bert.encoder.layer.12.output.LayerNorm.weight", "bert.encoder.layer.12.output.LayerNorm.bias", "bert.encoder.layer.13.attention.self.query.weight", "bert.encoder.layer.13.attention.self.query.bias", "bert.encoder.layer.13.attention.self.key.weight", "bert.encoder.layer.13.attention.self.key.bias", "bert.encoder.layer.13.attention.self.value.weight", "bert.encoder.layer.13.attention.self.value.bias", "bert.encoder.layer.13.attention.output.dense.weight", "bert.encoder.layer.13.attention.output.dense.bias", "bert.encoder.layer.13.attention.output.LayerNorm.weight", "bert.encoder.layer.13.attention.output.LayerNorm.bias", "bert.encoder.layer.13.intermediate.dense.weight", "bert.encoder.layer.13.intermediate.dense.bias", "bert.encoder.layer.13.output.dense.weight", "bert.encoder.layer.13.output.dense.bias", "bert.encoder.layer.13.output.LayerNorm.weight", "bert.encoder.layer.13.output.LayerNorm.bias", "bert.encoder.layer.14.attention.self.query.weight", "bert.encoder.layer.14.attention.self.query.bias", "bert.encoder.layer.14.attention.self.key.weight", "bert.encoder.layer.14.attention.self.key.bias", "bert.encoder.layer.14.attention.self.value.weight", "bert.encoder.layer.14.attention.self.value.bias", "bert.encoder.layer.14.attention.output.dense.weight", "bert.encoder.layer.14.attention.output.dense.bias", "bert.encoder.layer.14.attention.output.LayerNorm.weight", "bert.encoder.layer.14.attention.output.LayerNorm.bias", "bert.encoder.layer.14.intermediate.dense.weight", "bert.encoder.layer.14.intermediate.dense.bias", "bert.encoder.layer.14.output.dense.weight", "bert.encoder.layer.14.output.dense.bias", "bert.encoder.layer.14.output.LayerNorm.weight", "bert.encoder.layer.14.output.LayerNorm.bias", "bert.encoder.layer.15.attention.self.query.weight", "bert.encoder.layer.15.attention.self.query.bias", "bert.encoder.layer.15.attention.self.key.weight", "bert.encoder.layer.15.attention.self.key.bias", "bert.encoder.layer.15.attention.self.value.weight", "bert.encoder.layer.15.attention.self.value.bias", "bert.encoder.layer.15.attention.output.dense.weight", "bert.encoder.layer.15.attention.output.dense.bias", "bert.encoder.layer.15.attention.output.LayerNorm.weight", "bert.encoder.layer.15.attention.output.LayerNorm.bias", "bert.encoder.layer.15.intermediate.dense.weight", "bert.encoder.layer.15.intermediate.dense.bias", "bert.encoder.layer.15.output.dense.weight", "bert.encoder.layer.15.output.dense.bias", "bert.encoder.layer.15.output.LayerNorm.weight", "bert.encoder.layer.15.output.LayerNorm.bias", "bert.encoder.layer.16.attention.self.query.weight", "bert.encoder.layer.16.attention.self.query.bias", "bert.encoder.layer.16.attention.self.key.weight", "bert.encoder.layer.16.attention.self.key.bias", "bert.encoder.layer.16.attention.self.value.weight", "bert.encoder.layer.16.attention.self.value.bias", "bert.encoder.layer.16.attention.output.dense.weight", "bert.encoder.layer.16.attention.output.dense.bias", "bert.encoder.layer.16.attention.output.LayerNorm.weight", "bert.encoder.layer.16.attention.output.LayerNorm.bias", "bert.encoder.layer.16.intermediate.dense.weight", "bert.encoder.layer.16.intermediate.dense.bias", "bert.encoder.layer.16.output.dense.weight", "bert.encoder.layer.16.output.dense.bias", "bert.encoder.layer.16.output.LayerNorm.weight", "bert.encoder.layer.16.output.LayerNorm.bias", "bert.encoder.layer.17.attention.self.query.weight", "bert.encoder.layer.17.attention.self.query.bias", "bert.encoder.layer.17.attention.self.key.weight", "bert.encoder.layer.17.attention.self.key.bias", "bert.encoder.layer.17.attention.self.value.weight", "bert.encoder.layer.17.attention.self.value.bias", "bert.encoder.layer.17.attention.output.dense.weight", "bert.encoder.layer.17.attention.output.dense.bias", "bert.encoder.layer.17.attention.output.LayerNorm.weight", "bert.encoder.layer.17.attention.output.LayerNorm.bias", "bert.encoder.layer.17.intermediate.dense.weight", "bert.encoder.layer.17.intermediate.dense.bias", "bert.encoder.layer.17.output.dense.weight", "bert.encoder.layer.17.output.dense.bias", "bert.encoder.layer.17.output.LayerNorm.weight", "bert.encoder.layer.17.output.LayerNorm.bias", "bert.encoder.layer.18.attention.self.query.weight", "bert.encoder.layer.18.attention.self.query.bias", "bert.encoder.layer.18.attention.self.key.weight", "bert.encoder.layer.18.attention.self.key.bias", "bert.encoder.layer.18.attention.self.value.weight", "bert.encoder.layer.18.attention.self.value.bias", "bert.encoder.layer.18.attention.output.dense.weight", "bert.encoder.layer.18.attention.output.dense.bias", "bert.encoder.layer.18.attention.output.LayerNorm.weight", "bert.encoder.layer.18.attention.output.LayerNorm.bias", "bert.encoder.layer.18.intermediate.dense.weight", "bert.encoder.layer.18.intermediate.dense.bias", "bert.encoder.layer.18.output.dense.weight", "bert.encoder.layer.18.output.dense.bias", "bert.encoder.layer.18.output.LayerNorm.weight", "bert.encoder.layer.18.output.LayerNorm.bias", "bert.encoder.layer.19.attention.self.query.weight", "bert.encoder.layer.19.attention.self.query.bias", "bert.encoder.layer.19.attention.self.key.weight", "bert.encoder.layer.19.attention.self.key.bias", "bert.encoder.layer.19.attention.self.value.weight", "bert.encoder.layer.19.attention.self.value.bias", "bert.encoder.layer.19.attention.output.dense.weight", "bert.encoder.layer.19.attention.output.dense.bias", "bert.encoder.layer.19.attention.output.LayerNorm.weight", "bert.encoder.layer.19.attention.output.LayerNorm.bias", "bert.encoder.layer.19.intermediate.dense.weight", "bert.encoder.layer.19.intermediate.dense.bias", "bert.encoder.layer.19.output.dense.weight", "bert.encoder.layer.19.output.dense.bias", "bert.encoder.layer.19.output.LayerNorm.weight", "bert.encoder.layer.19.output.LayerNorm.bias", "bert.encoder.layer.20.attention.self.query.weight", "bert.encoder.layer.20.attention.self.query.bias", "bert.encoder.layer.20.attention.self.key.weight", "bert.encoder.layer.20.attention.self.key.bias", "bert.encoder.layer.20.attention.self.value.weight", "bert.encoder.layer.20.attention.self.value.bias", "bert.encoder.layer.20.attention.output.dense.weight", "bert.encoder.layer.20.attention.output.dense.bias", "bert.encoder.layer.20.attention.output.LayerNorm.weight", "bert.encoder.layer.20.attention.output.LayerNorm.bias", "bert.encoder.layer.20.intermediate.dense.weight", "bert.encoder.layer.20.intermediate.dense.bias", "bert.encoder.layer.20.output.dense.weight", "bert.encoder.layer.20.output.dense.bias", "bert.encoder.layer.20.output.LayerNorm.weight", "bert.encoder.layer.20.output.LayerNorm.bias", "bert.encoder.layer.21.attention.self.query.weight", "bert.encoder.layer.21.attention.self.query.bias", "bert.encoder.layer.21.attention.self.key.weight", "bert.encoder.layer.21.attention.self.key.bias", "bert.encoder.layer.21.attention.self.value.weight", "bert.encoder.layer.21.attention.self.value.bias", "bert.encoder.layer.21.attention.output.dense.weight", "bert.encoder.layer.21.attention.output.dense.bias", "bert.encoder.layer.21.attention.output.LayerNorm.weight", "bert.encoder.layer.21.attention.output.LayerNorm.bias", "bert.encoder.layer.21.intermediate.dense.weight", "bert.encoder.layer.21.intermediate.dense.bias", "bert.encoder.layer.21.output.dense.weight", "bert.encoder.layer.21.output.dense.bias", "bert.encoder.layer.21.output.LayerNorm.weight", "bert.encoder.layer.21.output.LayerNorm.bias", "bert.encoder.layer.22.attention.self.query.weight", "bert.encoder.layer.22.attention.self.query.bias", "bert.encoder.layer.22.attention.self.key.weight", "bert.encoder.layer.22.attention.self.key.bias", "bert.encoder.layer.22.attention.self.value.weight", "bert.encoder.layer.22.attention.self.value.bias", "bert.encoder.layer.22.attention.output.dense.weight", "bert.encoder.layer.22.attention.output.dense.bias", "bert.encoder.layer.22.attention.output.LayerNorm.weight", "bert.encoder.layer.22.attention.output.LayerNorm.bias", "bert.encoder.layer.22.intermediate.dense.weight", "bert.encoder.layer.22.intermediate.dense.bias", "bert.encoder.layer.22.output.dense.weight", "bert.encoder.layer.22.output.dense.bias", "bert.encoder.layer.22.output.LayerNorm.weight", "bert.encoder.layer.22.output.LayerNorm.bias", "bert.encoder.layer.23.attention.self.query.weight", "bert.encoder.layer.23.attention.self.query.bias", "bert.encoder.layer.23.attention.self.key.weight", "bert.encoder.layer.23.attention.self.key.bias", "bert.encoder.layer.23.attention.self.value.weight", "bert.encoder.layer.23.attention.self.value.bias", "bert.encoder.layer.23.attention.output.dense.weight", "bert.encoder.layer.23.attention.output.dense.bias", "bert.encoder.layer.23.attention.output.LayerNorm.weight", "bert.encoder.layer.23.attention.output.LayerNorm.bias", "bert.encoder.layer.23.intermediate.dense.weight", "bert.encoder.layer.23.intermediate.dense.bias", "bert.encoder.layer.23.output.dense.weight", "bert.encoder.layer.23.output.dense.bias", "bert.encoder.layer.23.output.LayerNorm.weight", "bert.encoder.layer.23.output.LayerNorm.bias", "classifier.layers.0.weight", "classifier.layers.0.bias", "classifier.layers.1.projection.weight", "classifier.layers.1.projection.bias", "classifier.layers.3.weight", "classifier.layers.3.bias", "classifier.layers.4.projection.weight", "classifier.layers.4.projection.bias", "classifier.layers.6.weight", "classifier.layers.6.bias". 
	Unexpected key(s) in state_dict: "layers.0.weight", "layers.0.bias", "layers.1.projection.weight", "layers.1.projection.bias", "layers.3.weight", "layers.3.bias", "layers.4.projection.weight", "layers.4.projection.bias", "layers.6.weight", "layers.6.bias". 
RuntimeError: Error(s) in loading state_dict for BERTClassifier:
	Missing key(s) in state_dict: "bert.embeddings.word_embeddings.weight", "bert.embeddings.position_embeddings.weight", "bert.embeddings.token_type_embeddings.weight", "bert.embeddings.LayerNorm.weight", "bert.embeddings.LayerNorm.bias", "bert.encoder.layer.0.attention.self.query.weight", "bert.encoder.layer.0.attention.self.query.bias", "bert.encoder.layer.0.attention.self.key.weight", "bert.encoder.layer.0.attention.self.key.bias", "bert.encoder.layer.0.attention.self.value.weight", "bert.encoder.layer.0.attention.self.value.bias", "bert.encoder.layer.0.attention.output.dense.weight", "bert.encoder.layer.0.attention.output.dense.bias", "bert.encoder.layer.0.attention.output.LayerNorm.weight", "bert.encoder.layer.0.attention.output.LayerNorm.bias", "bert.encoder.layer.0.intermediate.dense.weight", "bert.encoder.layer.0.intermediate.dense.bias", "bert.encoder.layer.0.output.dense.weight", "bert.encoder.layer.0.output.dense.bias", "bert.encoder.layer.0.output.LayerNorm.weight", "bert.encoder.layer.0.output.LayerNorm.bias", "bert.encoder.layer.1.attention.self.query.weight", "bert.encoder.layer.1.attention.self.query.bias", "bert.encoder.layer.1.attention.self.key.weight", "bert.encoder.layer.1.attention.self.key.bias", "bert.encoder.layer.1.attention.self.value.weight", "bert.encoder.layer.1.attention.self.value.bias", "bert.encoder.layer.1.attention.output.dense.weight", "bert.encoder.layer.1.attention.output.dense.bias", "bert.encoder.layer.1.attention.output.LayerNorm.weight", "bert.encoder.layer.1.attention.output.LayerNorm.bias", "bert.encoder.layer.1.intermediate.dense.weight", "bert.encoder.layer.1.intermediate.dense.bias", "bert.encoder.layer.1.output.dense.weight", "bert.encoder.layer.1.output.dense.bias", "bert.encoder.layer.1.output.LayerNorm.weight", "bert.encoder.layer.1.output.LayerNorm.bias", "bert.encoder.layer.2.attention.self.query.weight", "bert.encoder.layer.2.attention.self.query.bias", "bert.encoder.layer.2.attention.self.key.weight", "bert.encoder.layer.2.attention.self.key.bias", "bert.encoder.layer.2.attention.self.value.weight", "bert.encoder.layer.2.attention.self.value.bias", "bert.encoder.layer.2.attention.output.dense.weight", "bert.encoder.layer.2.attention.output.dense.bias", "bert.encoder.layer.2.attention.output.LayerNorm.weight", "bert.encoder.layer.2.attention.output.LayerNorm.bias", "bert.encoder.layer.2.intermediate.dense.weight", "bert.encoder.layer.2.intermediate.dense.bias", "bert.encoder.layer.2.output.dense.weight", "bert.encoder.layer.2.output.dense.bias", "bert.encoder.layer.2.output.LayerNorm.weight", "bert.encoder.layer.2.output.LayerNorm.bias", "bert.encoder.layer.3.attention.self.query.weight", "bert.encoder.layer.3.attention.self.query.bias", "bert.encoder.layer.3.attention.self.key.weight", "bert.encoder.layer.3.attention.self.key.bias", "bert.encoder.layer.3.attention.self.value.weight", "bert.encoder.layer.3.attention.self.value.bias", "bert.encoder.layer.3.attention.output.dense.weight", "bert.encoder.layer.3.attention.output.dense.bias", "bert.encoder.layer.3.attention.output.LayerNorm.weight", "bert.encoder.layer.3.attention.output.LayerNorm.bias", "bert.encoder.layer.3.intermediate.dense.weight", "bert.encoder.layer.3.intermediate.dense.bias", "bert.encoder.layer.3.output.dense.weight", "bert.encoder.layer.3.output.dense.bias", "bert.encoder.layer.3.output.LayerNorm.weight", "bert.encoder.layer.3.output.LayerNorm.bias", "bert.encoder.layer.4.attention.self.query.weight", "bert.encoder.layer.4.attention.self.query.bias", "bert.encoder.layer.4.attention.self.key.weight", "bert.encoder.layer.4.attention.self.key.bias", "bert.encoder.layer.4.attention.self.value.weight", "bert.encoder.layer.4.attention.self.value.bias", "bert.encoder.layer.4.attention.output.dense.weight", "bert.encoder.layer.4.attention.output.dense.bias", "bert.encoder.layer.4.attention.output.LayerNorm.weight", "bert.encoder.layer.4.attention.output.LayerNorm.bias", "bert.encoder.layer.4.intermediate.dense.weight", "bert.encoder.layer.4.intermediate.dense.bias", "bert.encoder.layer.4.output.dense.weight", "bert.encoder.layer.4.output.dense.bias", "bert.encoder.layer.4.output.LayerNorm.weight", "bert.encoder.layer.4.output.LayerNorm.bias", "bert.encoder.layer.5.attention.self.query.weight", "bert.encoder.layer.5.attention.self.query.bias", "bert.encoder.layer.5.attention.self.key.weight", "bert.encoder.layer.5.attention.self.key.bias", "bert.encoder.layer.5.attention.self.value.weight", "bert.encoder.layer.5.attention.self.value.bias", "bert.encoder.layer.5.attention.output.dense.weight", "bert.encoder.layer.5.attention.output.dense.bias", "bert.encoder.layer.5.attention.output.LayerNorm.weight", "bert.encoder.layer.5.attention.output.LayerNorm.bias", "bert.encoder.layer.5.intermediate.dense.weight", "bert.encoder.layer.5.intermediate.dense.bias", "bert.encoder.layer.5.output.dense.weight", "bert.encoder.layer.5.output.dense.bias", "bert.encoder.layer.5.output.LayerNorm.weight", "bert.encoder.layer.5.output.LayerNorm.bias", "bert.encoder.layer.6.attention.self.query.weight", "bert.encoder.layer.6.attention.self.query.bias", "bert.encoder.layer.6.attention.self.key.weight", "bert.encoder.layer.6.attention.self.key.bias", "bert.encoder.layer.6.attention.self.value.weight", "bert.encoder.layer.6.attention.self.value.bias", "bert.encoder.layer.6.attention.output.dense.weight", "bert.encoder.layer.6.attention.output.dense.bias", "bert.encoder.layer.6.attention.output.LayerNorm.weight", "bert.encoder.layer.6.attention.output.LayerNorm.bias", "bert.encoder.layer.6.intermediate.dense.weight", "bert.encoder.layer.6.intermediate.dense.bias", "bert.encoder.layer.6.output.dense.weight", "bert.encoder.layer.6.output.dense.bias", "bert.encoder.layer.6.output.LayerNorm.weight", "bert.encoder.layer.6.output.LayerNorm.bias", "bert.encoder.layer.7.attention.self.query.weight", "bert.encoder.layer.7.attention.self.query.bias", "bert.encoder.layer.7.attention.self.key.weight", "bert.encoder.layer.7.attention.self.key.bias", "bert.encoder.layer.7.attention.self.value.weight", "bert.encoder.layer.7.attention.self.value.bias", "bert.encoder.layer.7.attention.output.dense.weight", "bert.encoder.layer.7.attention.output.dense.bias", "bert.encoder.layer.7.attention.output.LayerNorm.weight", "bert.encoder.layer.7.attention.output.LayerNorm.bias", "bert.encoder.layer.7.intermediate.dense.weight", "bert.encoder.layer.7.intermediate.dense.bias", "bert.encoder.layer.7.output.dense.weight", "bert.encoder.layer.7.output.dense.bias", "bert.encoder.layer.7.output.LayerNorm.weight", "bert.encoder.layer.7.output.LayerNorm.bias", "bert.encoder.layer.8.attention.self.query.weight", "bert.encoder.layer.8.attention.self.query.bias", "bert.encoder.layer.8.attention.self.key.weight", "bert.encoder.layer.8.attention.self.key.bias", "bert.encoder.layer.8.attention.self.value.weight", "bert.encoder.layer.8.attention.self.value.bias", "bert.encoder.layer.8.attention.output.dense.weight", "bert.encoder.layer.8.attention.output.dense.bias", "bert.encoder.layer.8.attention.output.LayerNorm.weight", "bert.encoder.layer.8.attention.output.LayerNorm.bias", "bert.encoder.layer.8.intermediate.dense.weight", "bert.encoder.layer.8.intermediate.dense.bias", "bert.encoder.layer.8.output.dense.weight", "bert.encoder.layer.8.output.dense.bias", "bert.encoder.layer.8.output.LayerNorm.weight", "bert.encoder.layer.8.output.LayerNorm.bias", "bert.encoder.layer.9.attention.self.query.weight", "bert.encoder.layer.9.attention.self.query.bias", "bert.encoder.layer.9.attention.self.key.weight", "bert.encoder.layer.9.attention.self.key.bias", "bert.encoder.layer.9.attention.self.value.weight", "bert.encoder.layer.9.attention.self.value.bias", "bert.encoder.layer.9.attention.output.dense.weight", "bert.encoder.layer.9.attention.output.dense.bias", "bert.encoder.layer.9.attention.output.LayerNorm.weight", "bert.encoder.layer.9.attention.output.LayerNorm.bias", "bert.encoder.layer.9.intermediate.dense.weight", "bert.encoder.layer.9.intermediate.dense.bias", "bert.encoder.layer.9.output.dense.weight", "bert.encoder.layer.9.output.dense.bias", "bert.encoder.layer.9.output.LayerNorm.weight", "bert.encoder.layer.9.output.LayerNorm.bias", "bert.encoder.layer.10.attention.self.query.weight", "bert.encoder.layer.10.attention.self.query.bias", "bert.encoder.layer.10.attention.self.key.weight", "bert.encoder.layer.10.attention.self.key.bias", "bert.encoder.layer.10.attention.self.value.weight", "bert.encoder.layer.10.attention.self.value.bias", "bert.encoder.layer.10.attention.output.dense.weight", "bert.encoder.layer.10.attention.output.dense.bias", "bert.encoder.layer.10.attention.output.LayerNorm.weight", "bert.encoder.layer.10.attention.output.LayerNorm.bias", "bert.encoder.layer.10.intermediate.dense.weight", "bert.encoder.layer.10.intermediate.dense.bias", "bert.encoder.layer.10.output.dense.weight", "bert.encoder.layer.10.output.dense.bias", "bert.encoder.layer.10.output.LayerNorm.weight", "bert.encoder.layer.10.output.LayerNorm.bias", "bert.encoder.layer.11.attention.self.query.weight", "bert.encoder.layer.11.attention.self.query.bias", "bert.encoder.layer.11.attention.self.key.weight", "bert.encoder.layer.11.attention.self.key.bias", "bert.encoder.layer.11.attention.self.value.weight", "bert.encoder.layer.11.attention.self.value.bias", "bert.encoder.layer.11.attention.output.dense.weight", "bert.encoder.layer.11.attention.output.dense.bias", "bert.encoder.layer.11.attention.output.LayerNorm.weight", "bert.encoder.layer.11.attention.output.LayerNorm.bias", "bert.encoder.layer.11.intermediate.dense.weight", "bert.encoder.layer.11.intermediate.dense.bias", "bert.encoder.layer.11.output.dense.weight", "bert.encoder.layer.11.output.dense.bias", "bert.encoder.layer.11.output.LayerNorm.weight", "bert.encoder.layer.11.output.LayerNorm.bias", "bert.encoder.layer.12.attention.self.query.weight", "bert.encoder.layer.12.attention.self.query.bias", "bert.encoder.layer.12.attention.self.key.weight", "bert.encoder.layer.12.attention.self.key.bias", "bert.encoder.layer.12.attention.self.value.weight", "bert.encoder.layer.12.attention.self.value.bias", "bert.encoder.layer.12.attention.output.dense.weight", "bert.encoder.layer.12.attention.output.dense.bias", "bert.encoder.layer.12.attention.output.LayerNorm.weight", "bert.encoder.layer.12.attention.output.LayerNorm.bias", "bert.encoder.layer.12.intermediate.dense.weight", "bert.encoder.layer.12.intermediate.dense.bias", "bert.encoder.layer.12.output.dense.weight", "bert.encoder.layer.12.output.dense.bias", "bert.encoder.layer.12.output.LayerNorm.weight", "bert.encoder.layer.12.output.LayerNorm.bias", "bert.encoder.layer.13.attention.self.query.weight", "bert.encoder.layer.13.attention.self.query.bias", "bert.encoder.layer.13.attention.self.key.weight", "bert.encoder.layer.13.attention.self.key.bias", "bert.encoder.layer.13.attention.self.value.weight", "bert.encoder.layer.13.attention.self.value.bias", "bert.encoder.layer.13.attention.output.dense.weight", "bert.encoder.layer.13.attention.output.dense.bias", "bert.encoder.layer.13.attention.output.LayerNorm.weight", "bert.encoder.layer.13.attention.output.LayerNorm.bias", "bert.encoder.layer.13.intermediate.dense.weight", "bert.encoder.layer.13.intermediate.dense.bias", "bert.encoder.layer.13.output.dense.weight", "bert.encoder.layer.13.output.dense.bias", "bert.encoder.layer.13.output.LayerNorm.weight", "bert.encoder.layer.13.output.LayerNorm.bias", "bert.encoder.layer.14.attention.self.query.weight", "bert.encoder.layer.14.attention.self.query.bias", "bert.encoder.layer.14.attention.self.key.weight", "bert.encoder.layer.14.attention.self.key.bias", "bert.encoder.layer.14.attention.self.value.weight", "bert.encoder.layer.14.attention.self.value.bias", "bert.encoder.layer.14.attention.output.dense.weight", "bert.encoder.layer.14.attention.output.dense.bias", "bert.encoder.layer.14.attention.output.LayerNorm.weight", "bert.encoder.layer.14.attention.output.LayerNorm.bias", "bert.encoder.layer.14.intermediate.dense.weight", "bert.encoder.layer.14.intermediate.dense.bias", "bert.encoder.layer.14.output.dense.weight", "bert.encoder.layer.14.output.dense.bias", "bert.encoder.layer.14.output.LayerNorm.weight", "bert.encoder.layer.14.output.LayerNorm.bias", "bert.encoder.layer.15.attention.self.query.weight", "bert.encoder.layer.15.attention.self.query.bias", "bert.encoder.layer.15.attention.self.key.weight", "bert.encoder.layer.15.attention.self.key.bias", "bert.encoder.layer.15.attention.self.value.weight", "bert.encoder.layer.15.attention.self.value.bias", "bert.encoder.layer.15.attention.output.dense.weight", "bert.encoder.layer.15.attention.output.dense.bias", "bert.encoder.layer.15.attention.output.LayerNorm.weight", "bert.encoder.layer.15.attention.output.LayerNorm.bias", "bert.encoder.layer.15.intermediate.dense.weight", "bert.encoder.layer.15.intermediate.dense.bias", "bert.encoder.layer.15.output.dense.weight", "bert.encoder.layer.15.output.dense.bias", "bert.encoder.layer.15.output.LayerNorm.weight", "bert.encoder.layer.15.output.LayerNorm.bias", "bert.encoder.layer.16.attention.self.query.weight", "bert.encoder.layer.16.attention.self.query.bias", "bert.encoder.layer.16.attention.self.key.weight", "bert.encoder.layer.16.attention.self.key.bias", "bert.encoder.layer.16.attention.self.value.weight", "bert.encoder.layer.16.attention.self.value.bias", "bert.encoder.layer.16.attention.output.dense.weight", "bert.encoder.layer.16.attention.output.dense.bias", "bert.encoder.layer.16.attention.output.LayerNorm.weight", "bert.encoder.layer.16.attention.output.LayerNorm.bias", "bert.encoder.layer.16.intermediate.dense.weight", "bert.encoder.layer.16.intermediate.dense.bias", "bert.encoder.layer.16.output.dense.weight", "bert.encoder.layer.16.output.dense.bias", "bert.encoder.layer.16.output.LayerNorm.weight", "bert.encoder.layer.16.output.LayerNorm.bias", "bert.encoder.layer.17.attention.self.query.weight", "bert.encoder.layer.17.attention.self.query.bias", "bert.encoder.layer.17.attention.self.key.weight", "bert.encoder.layer.17.attention.self.key.bias", "bert.encoder.layer.17.attention.self.value.weight", "bert.encoder.layer.17.attention.self.value.bias", "bert.encoder.layer.17.attention.output.dense.weight", "bert.encoder.layer.17.attention.output.dense.bias", "bert.encoder.layer.17.attention.output.LayerNorm.weight", "bert.encoder.layer.17.attention.output.LayerNorm.bias", "bert.encoder.layer.17.intermediate.dense.weight", "bert.encoder.layer.17.intermediate.dense.bias", "bert.encoder.layer.17.output.dense.weight", "bert.encoder.layer.17.output.dense.bias", "bert.encoder.layer.17.output.LayerNorm.weight", "bert.encoder.layer.17.output.LayerNorm.bias", "bert.encoder.layer.18.attention.self.query.weight", "bert.encoder.layer.18.attention.self.query.bias", "bert.encoder.layer.18.attention.self.key.weight", "bert.encoder.layer.18.attention.self.key.bias", "bert.encoder.layer.18.attention.self.value.weight", "bert.encoder.layer.18.attention.self.value.bias", "bert.encoder.layer.18.attention.output.dense.weight", "bert.encoder.layer.18.attention.output.dense.bias", "bert.encoder.layer.18.attention.output.LayerNorm.weight", "bert.encoder.layer.18.attention.output.LayerNorm.bias", "bert.encoder.layer.18.intermediate.dense.weight", "bert.encoder.layer.18.intermediate.dense.bias", "bert.encoder.layer.18.output.dense.weight", "bert.encoder.layer.18.output.dense.bias", "bert.encoder.layer.18.output.LayerNorm.weight", "bert.encoder.layer.18.output.LayerNorm.bias", "bert.encoder.layer.19.attention.self.query.weight", "bert.encoder.layer.19.attention.self.query.bias", "bert.encoder.layer.19.attention.self.key.weight", "bert.encoder.layer.19.attention.self.key.bias", "bert.encoder.layer.19.attention.self.value.weight", "bert.encoder.layer.19.attention.self.value.bias", "bert.encoder.layer.19.attention.output.dense.weight", "bert.encoder.layer.19.attention.output.dense.bias", "bert.encoder.layer.19.attention.output.LayerNorm.weight", "bert.encoder.layer.19.attention.output.LayerNorm.bias", "bert.encoder.layer.19.intermediate.dense.weight", "bert.encoder.layer.19.intermediate.dense.bias", "bert.encoder.layer.19.output.dense.weight", "bert.encoder.layer.19.output.dense.bias", "bert.encoder.layer.19.output.LayerNorm.weight", "bert.encoder.layer.19.output.LayerNorm.bias", "bert.encoder.layer.20.attention.self.query.weight", "bert.encoder.layer.20.attention.self.query.bias", "bert.encoder.layer.20.attention.self.key.weight", "bert.encoder.layer.20.attention.self.key.bias", "bert.encoder.layer.20.attention.self.value.weight", "bert.encoder.layer.20.attention.self.value.bias", "bert.encoder.layer.20.attention.output.dense.weight", "bert.encoder.layer.20.attention.output.dense.bias", "bert.encoder.layer.20.attention.output.LayerNorm.weight", "bert.encoder.layer.20.attention.output.LayerNorm.bias", "bert.encoder.layer.20.intermediate.dense.weight", "bert.encoder.layer.20.intermediate.dense.bias", "bert.encoder.layer.20.output.dense.weight", "bert.encoder.layer.20.output.dense.bias", "bert.encoder.layer.20.output.LayerNorm.weight", "bert.encoder.layer.20.output.LayerNorm.bias", "bert.encoder.layer.21.attention.self.query.weight", "bert.encoder.layer.21.attention.self.query.bias", "bert.encoder.layer.21.attention.self.key.weight", "bert.encoder.layer.21.attention.self.key.bias", "bert.encoder.layer.21.attention.self.value.weight", "bert.encoder.layer.21.attention.self.value.bias", "bert.encoder.layer.21.attention.output.dense.weight", "bert.encoder.layer.21.attention.output.dense.bias", "bert.encoder.layer.21.attention.output.LayerNorm.weight", "bert.encoder.layer.21.attention.output.LayerNorm.bias", "bert.encoder.layer.21.intermediate.dense.weight", "bert.encoder.layer.21.intermediate.dense.bias", "bert.encoder.layer.21.output.dense.weight", "bert.encoder.layer.21.output.dense.bias", "bert.encoder.layer.21.output.LayerNorm.weight", "bert.encoder.layer.21.output.LayerNorm.bias", "bert.encoder.layer.22.attention.self.query.weight", "bert.encoder.layer.22.attention.self.query.bias", "bert.encoder.layer.22.attention.self.key.weight", "bert.encoder.layer.22.attention.self.key.bias", "bert.encoder.layer.22.attention.self.value.weight", "bert.encoder.layer.22.attention.self.value.bias", "bert.encoder.layer.22.attention.output.dense.weight", "bert.encoder.layer.22.attention.output.dense.bias", "bert.encoder.layer.22.attention.output.LayerNorm.weight", "bert.encoder.layer.22.attention.output.LayerNorm.bias", "bert.encoder.layer.22.intermediate.dense.weight", "bert.encoder.layer.22.intermediate.dense.bias", "bert.encoder.layer.22.output.dense.weight", "bert.encoder.layer.22.output.dense.bias", "bert.encoder.layer.22.output.LayerNorm.weight", "bert.encoder.layer.22.output.LayerNorm.bias", "bert.encoder.layer.23.attention.self.query.weight", "bert.encoder.layer.23.attention.self.query.bias", "bert.encoder.layer.23.attention.self.key.weight", "bert.encoder.layer.23.attention.self.key.bias", "bert.encoder.layer.23.attention.self.value.weight", "bert.encoder.layer.23.attention.self.value.bias", "bert.encoder.layer.23.attention.output.dense.weight", "bert.encoder.layer.23.attention.output.dense.bias", "bert.encoder.layer.23.attention.output.LayerNorm.weight", "bert.encoder.layer.23.attention.output.LayerNorm.bias", "bert.encoder.layer.23.intermediate.dense.weight", "bert.encoder.layer.23.intermediate.dense.bias", "bert.encoder.layer.23.output.dense.weight", "bert.encoder.layer.23.output.dense.bias", "bert.encoder.layer.23.output.LayerNorm.weight", "bert.encoder.layer.23.output.LayerNorm.bias", "classifier.layers.0.weight", "classifier.layers.0.bias", "classifier.layers.1.projection.weight", "classifier.layers.1.projection.bias", "classifier.layers.3.weight", "classifier.layers.3.bias", "classifier.layers.4.projection.weight", "classifier.layers.4.projection.bias", "classifier.layers.6.weight", "classifier.layers.6.bias". 
	Unexpected key(s) in state_dict: "layers.0.weight", "layers.0.bias", "layers.1.projection.weight", "layers.1.projection.bias", "layers.3.weight", "layers.3.bias", "layers.4.projection.weight", "layers.4.projection.bias", "layers.6.weight", "layers.6.bias". 
wandb: ðŸš€ View run run_2_merged_ft6 at: https://wandb.ai/jimbeno/Electra Large/runs/0qeu00ne
wandb: Find logs at: wandb/run-20241024_003211-0qeu00ne/logs
^C
Ctrl+C received. Terminating all processes...
Rank 0 - Current process: MainProcess cleaning up...
Terminating all child processes of MainProcess...
Terminated child process: SpawnProcess-1
Rank 0 - Exiting program...
Exception ignored in atexit callback: <function _exit_function at 0x78a17e4c6e60>
Traceback (most recent call last):
  File "/usr/lib/python3.10/multiprocessing/util.py", line 357, in _exit_function
    p.join()
  File "/usr/lib/python3.10/multiprocessing/process.py", line 149, in join
    res = self._popen.wait(timeout)
  File "/usr/lib/python3.10/multiprocessing/popen_fork.py", line 43, in wait
    return self.poll(os.WNOHANG if timeout == 0.0 else 0)
  File "/usr/lib/python3.10/multiprocessing/popen_fork.py", line 27, in poll
    pid, sts = os.waitpid(self.pid, flag)
  File "/home/ubuntu/nlp-osaka/sentiment/utils.py", line 159, in signal_handler
    cleanup_and_exit(0, True) 
  File "/home/ubuntu/nlp-osaka/sentiment/utils.py", line 205, in cleanup_and_exit
    sys.exit(0)
SystemExit: 0
Exception ignored in: <Finalize object, dead>
Traceback (most recent call last):
  File "/usr/lib/python3.10/multiprocessing/util.py", line 224, in __call__
  File "/usr/lib/python3.10/multiprocessing/heap.py", line 278, in free
AttributeError: 'NoneType' object has no attribute 'getpid'
Exception ignored in: <Finalize object, dead>
Traceback (most recent call last):
  File "/usr/lib/python3.10/multiprocessing/util.py", line 224, in __call__
  File "/usr/lib/python3.10/multiprocessing/util.py", line 464, in close_fds
AttributeError: 'NoneType' object has no attribute 'close'
Exception ignored in: <Finalize object, dead>
Traceback (most recent call last):
  File "/usr/lib/python3.10/multiprocessing/util.py", line 224, in __call__
  File "/usr/lib/python3.10/multiprocessing/util.py", line 464, in close_fds
AttributeError: 'NoneType' object has no attribute 'close'
Exception ignored in: <Finalize object, dead>
Traceback (most recent call last):
  File "/usr/lib/python3.10/multiprocessing/util.py", line 224, in __call__
  File "/usr/lib/python3.10/multiprocessing/util.py", line 464, in close_fds
AttributeError: 'NoneType' object has no attribute 'close'
Exception ignored in: <Finalize object, dead>
Traceback (most recent call last):
  File "/usr/lib/python3.10/multiprocessing/util.py", line 224, in __call__
  File "/usr/lib/python3.10/multiprocessing/util.py", line 464, in close_fds
AttributeError: 'NoneType' object has no attribute 'close'
Exception ignored in: <Finalize object, dead>
Traceback (most recent call last):
  File "/usr/lib/python3.10/multiprocessing/util.py", line 224, in __call__
  File "/usr/lib/python3.10/multiprocessing/util.py", line 464, in close_fds
AttributeError: 'NoneType' object has no attribute 'close'
Exception ignored in: <Finalize object, dead>
Traceback (most recent call last):
  File "/usr/lib/python3.10/multiprocessing/util.py", line 224, in __call__
  File "/usr/lib/python3.10/multiprocessing/util.py", line 464, in close_fds
AttributeError: 'NoneType' object has no attribute 'close'
Exception ignored in: <Finalize object, dead>
Traceback (most recent call last):
  File "/usr/lib/python3.10/multiprocessing/util.py", line 224, in __call__
  File "/usr/lib/python3.10/multiprocessing/util.py", line 464, in close_fds
AttributeError: 'NoneType' object has no attribute 'close'
^C(nlp) ubuntu@138-2-58-218:~/nlp-osaka/sentimentpython ./ddp_sentiment_finetune.py --dataset 'merged_local' --weights_name 'google/electra-large-discriminator' --save_data --save_model --save_pickle --save_preds --lr 0.0002 --lr_decay 0.95 --epochs 100 --pooling 'mean' --dropout_rate 0.3 --num_layers 2 --hidden_dim 1024 --hidden_activation 'swishglu' --batch_size 512 --finetune_bert --finetune_layers 0 --l2_strength 0.0001 --checkpoint_interval 5 --use_zero --optimizer 'adamw' --scheduler 'cosine_warmup' --scheduler_kwargs '{"T_0":5, "T_mult":1, "eta_min":1e-7}' --decimal 6 --use_val_split --eval_split 'test' --early_stop 'score' --n_iter_no_change 20 --wandb --wandb_project 'Electra Large' --wandb_run 'run_1_merged_class's'

Starting DDP PyTorch Training...
Device: cuda, Number of GPUs: 8
Spawning 8 processes...
Rank 6 - Device: cuda:6
Rank 4 - Device: cuda:4
Rank 5 - Device: cuda:5
Rank 7 - Device: cuda:7
Rank 1 - Device: cuda:1
Rank 3 - Device: cuda:3
Rank 2 - Device: cuda:2
Rank 0 - Device: cuda:0
8 process groups initialized with 'nccl' backend on localhost:12355
NCCL Timeout: 1 hr 0 min. NCCL Blocking Wait: Enabled
wandb: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: jbeno (jimbeno). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.5
wandb: Run data is saved locally in /home/ubuntu/nlp-osaka/sentiment/wandb/run-20241024_003527-tq1ae55n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run run_1_merged_class
wandb: â­ï¸ View project at https://wandb.ai/jimbeno/Electra%20Large
wandb: ðŸš€ View run at https://wandb.ai/jimbeno/Electra%20Large/runs/tq1ae55n
Wand run initialized.

Initializing 'google/electra-large-discriminator' tokenizer and model...
Checking for local files...
Found all files in cache, skipping download
All ranks loading tokenizer from local files...
All ranks loading model from local files...
Tokenizer and model initialized (6s)

Loading data...
Using the same dataset for training and evaluation
Splits:
- Train: Using merged_local 'train' split
- Validation: Using merged_local 'validation' split
- Evaluation: Using merged_local 'test' split
Train Data: Merged DynaSent Round 1, Round 2 and SST from Local: 'data/merged'
Validation Data: Merged DynaSent Round 1, Round 2 and SST from Local: 'data/merged'
Evaluation Data: Merged DynaSent Round 1, Round 2 and SST from Local: 'data/merged'
Train size: 102097
Validation size: 5421
Evaluation size: 5421
Train label distribution:
	      Negative: 21910
	       Neutral: 49148
	      Positive: 31039
Validation label distribution:
	      Negative: 1868
	       Neutral: 1669
	      Positive: 1884
Evaluation label distribution:
	      Negative: 1868
	       Neutral: 1669
	      Positive: 1884
Data loaded (2s)

Processing data...
(Batch size: 512, Pooling: Mean, Fine Tune BERT: True, Chunk size: None)...
Extracting sentences and labels...

Data saved to: saves/data_8_gpu_20241024-003537.npz
X Train shape: [102097], X Validation shape: [5421], X Test shape: [5421]
y Train shape: [102097], y Validation shape: [5421], y Test shape: [5421]
Data processed (846ms)

Initializing DDP Neural Classifier...
Layers: 2, Hidden Dim: 1024, Hidden Act: SwishGLU, Dropout: 0.3, Optimizer: AdamW, L2 Strength: 0.0001, Pooling: MEAN, Accumulation Steps: 1, Max Grad Norm: None
Batch Size: 512, Max Epochs: 100, LR: 0.0002, Early Stop: score, Fine-tune BERT: True, Fine-tune Layers: 0, Freeze BERT: False, Target Score: None, Interactive: False
Classifier initialized (26ms)

Fitting DDP Neural Classifier on training data...
Num Workers: 0, Prefetch: None
Score-based early stopping enabled (macro average F1 score against validation set). Validation fraction: 0.1
Training will stop early if the score does not improve by at least 0.00001 for 20 iterations.
Using provided validation set for early stopping.
Building dataset and dataloader...
Initializing model, graph, optimizer...
BERT's original pooler removed. Using custom pooling type: mean
BERT has 0 trainable parameters and 334,092,288 non-trainable parameters
Number of BERT layers requiring gradients: 0 out of 24
All BERT layers are frozen

Model Architecture Summary:
BERTClassifier(
  (bert): ElectraModel(
    (embeddings): ElectraEmbeddings(
      (word_embeddings): Embedding(30522, 1024, padding_idx=0)
      (position_embeddings): Embedding(512, 1024)
      (token_type_embeddings): Embedding(2, 1024)
      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): ElectraEncoder(
      (layer): ModuleList(
        (0-23): 24 x ElectraLayer(
          (attention): ElectraAttention(
            (self): ElectraSelfAttention(
              (query): Linear(in_features=1024, out_features=1024, bias=True)
              (key): Linear(in_features=1024, out_features=1024, bias=True)
              (value): Linear(in_features=1024, out_features=1024, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): ElectraSelfOutput(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): ElectraIntermediate(
            (dense): Linear(in_features=1024, out_features=4096, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): ElectraOutput(
            (dense): Linear(in_features=4096, out_features=1024, bias=True)
            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
  (custom_pooling): PoolingLayer()
  (classifier): Classifier(
    (layers): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): SwishGLU(
        (projection): Linear(in_features=1024, out_features=2048, bias=True)
        (activation): SiLU()
      )
      (2): Dropout(p=0.3, inplace=False)
      (3): Linear(in_features=1024, out_features=1024, bias=True)
      (4): SwishGLU(
        (projection): Linear(in_features=1024, out_features=2048, bias=True)
        (activation): SiLU()
      )
      (5): Dropout(p=0.3, inplace=False)
      (6): Linear(in_features=1024, out_features=3, bias=True)
    )
  )
)

Model Parameters:
  bert.embeddings.word_embeddings: 31,254,528 (frozen)
  bert.embeddings.position_embeddings: 524,288 (frozen)
  bert.embeddings.token_type_embeddings: 2,048 (frozen)
  bert.embeddings.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.0.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.0.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.0.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.0.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.0.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.0.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.0.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.0.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.1.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.1.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.1.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.1.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.1.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.1.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.1.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.1.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.2.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.2.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.2.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.2.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.2.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.2.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.2.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.2.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.3.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.3.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.3.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.3.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.3.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.3.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.3.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.3.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.4.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.4.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.4.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.4.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.4.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.4.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.4.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.4.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.5.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.5.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.5.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.5.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.5.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.5.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.5.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.5.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.6.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.6.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.6.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.6.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.6.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.6.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.6.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.6.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.7.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.7.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.7.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.7.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.7.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.7.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.7.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.7.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.8.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.8.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.8.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.8.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.8.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.8.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.8.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.8.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.9.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.9.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.9.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.9.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.9.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.9.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.9.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.9.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.10.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.10.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.10.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.10.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.10.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.10.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.10.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.10.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.11.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.11.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.11.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.11.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.11.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.11.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.11.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.11.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.12.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.12.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.12.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.12.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.12.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.12.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.12.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.12.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.13.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.13.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.13.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.13.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.13.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.13.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.13.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.13.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.14.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.14.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.14.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.14.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.14.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.14.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.14.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.14.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.15.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.15.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.15.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.15.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.15.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.15.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.15.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.15.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.16.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.16.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.16.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.16.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.16.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.16.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.16.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.16.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.17.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.17.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.17.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.17.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.17.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.17.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.17.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.17.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.18.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.18.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.18.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.18.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.18.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.18.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.18.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.18.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.19.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.19.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.19.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.19.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.19.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.19.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.19.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.19.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.20.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.20.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.20.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.20.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.20.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.20.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.20.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.20.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.21.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.21.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.21.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.21.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.21.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.21.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.21.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.21.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.22.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.22.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.22.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.22.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.22.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.22.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.22.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.22.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.23.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.23.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.23.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.23.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.23.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.23.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.23.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.23.output.LayerNorm: 2,048 (frozen)
  classifier.layers.0: 1,049,600 (trainable)
  classifier.layers.1.projection: 2,099,200 (trainable)
  classifier.layers.3: 1,049,600 (trainable)
  classifier.layers.6: 3,075 (trainable)

Total layers: 200
Trainable layers: 4
Total parameters: 338,293,763
Trainable parameters: 4,201,475
Percentage of trainable parameters: 1.24%
Using optimizer: AdamW, Use Zero: True, Base Learning Rate: 0.0002, L2 strength: 0.0001
Layer-wise decay factor: 0.95
Using scheduler: CosineAnnealingWarmRestarts
Scheduler arguments:
- T_0: 5
- T_mult: 1
- eta_min: 1e-07

Starting training loop...
Start epoch: 1, Max Iterations: 100, Early Stop: score, Tolerance: 0.00001, Number Iterations No Change: 20
^C
Ctrl+C received. Terminating all processes...
Rank 0 - Current process: MainProcess cleaning up...
Terminating all child processes of MainProcess...
Terminated child process: SpawnProcess-8
Terminated child process: SpawnProcess-1
Terminated child process: SpawnProcess-2
Terminated child process: SpawnProcess-3
Terminated child process: SpawnProcess-7
Terminated child process: SpawnProcess-6
Terminated child process: SpawnProcess-5
Terminated child process: SpawnProcess-4
Rank 0 - Exiting program...
(nlp) ubuntu@138-2-58-218:~/nlp-osaka/sentiment$ python ./ddp_sentiment_finetune.py --dataset 'merged_local' --weights_name 'google/electra-large-discriminator' --save_data --save_model --save_pickle --save_preds --lr 0.0002 --lr_decay 0.95 --epochs 50 --pooling 'mean' --dropout_rate 0.3 --num_layers 2 --hidden_dim 1024 --hidden_activation 'swishglu' --batch_size 512 --finetune_bert --finetune_layers 0 --l2_strength 0.0001 --checkpoint_interval 5 --use_zero --optimizer 'adamw' --scheduler 'cosine_warmup' --scheduler_kwargs '{"T_0":5, "T_mult":1, "eta_min":1e-7}' --decimal 6 --use_val_split --eval_split 'test' --early_stop 'score' --n_iter_no_change 50 --wandb --wandb_project 'Electra Large' --wandb_run 'run_1_merged_class' --show_progress

Starting DDP PyTorch Training...
Device: cuda, Number of GPUs: 8
Spawning 8 processes...
Rank 1 - Device: cuda:1
Rank 7 - Device: cuda:7
Rank 6 - Device: cuda:6
Rank 5 - Device: cuda:5
Rank 2 - Device: cuda:2
Rank 4 - Device: cuda:4
Rank 3 - Device: cuda:3
Rank 0 - Device: cuda:0
8 process groups initialized with 'nccl' backend on localhost:12355
NCCL Timeout: 1 hr 0 min. NCCL Blocking Wait: Enabled
wandb: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: jbeno (jimbeno). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.5
wandb: Run data is saved locally in /home/ubuntu/nlp-osaka/sentiment/wandb/run-20241024_003753-4o23t0h3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run run_1_merged_class
wandb: â­ï¸ View project at https://wandb.ai/jimbeno/Electra%20Large
wandb: ðŸš€ View run at https://wandb.ai/jimbeno/Electra%20Large/runs/4o23t0h3
Wand run initialized.

Initializing 'google/electra-large-discriminator' tokenizer and model...
Checking for local files...
Found all files in cache, skipping download
All ranks loading tokenizer from local files...
All ranks loading model from local files...
Tokenizer and model initialized (6s)

Loading data...
Using the same dataset for training and evaluation
Splits:
- Train: Using merged_local 'train' split
- Validation: Using merged_local 'validation' split
- Evaluation: Using merged_local 'test' split
Train Data: Merged DynaSent Round 1, Round 2 and SST from Local: 'data/merged'
Validation Data: Merged DynaSent Round 1, Round 2 and SST from Local: 'data/merged'
Evaluation Data: Merged DynaSent Round 1, Round 2 and SST from Local: 'data/merged'
Train size: 102097
Validation size: 5421
Evaluation size: 5421
Train label distribution:
	      Negative: 21910
	       Neutral: 49148
	      Positive: 31039
Validation label distribution:
	      Negative: 1868
	       Neutral: 1669
	      Positive: 1884
Evaluation label distribution:
	      Negative: 1868
	       Neutral: 1669
	      Positive: 1884
Data loaded (2s)

Processing data...
(Batch size: 512, Pooling: Mean, Fine Tune BERT: True, Chunk size: None)...
Extracting sentences and labels...

Data saved to: saves/data_8_gpu_20241024-003804.npz
X Train shape: [102097], X Validation shape: [5421], X Test shape: [5421]
y Train shape: [102097], y Validation shape: [5421], y Test shape: [5421]
Data processed (915ms)

Initializing DDP Neural Classifier...
Layers: 2, Hidden Dim: 1024, Hidden Act: SwishGLU, Dropout: 0.3, Optimizer: AdamW, L2 Strength: 0.0001, Pooling: MEAN, Accumulation Steps: 1, Max Grad Norm: None
Batch Size: 512, Max Epochs: 50, LR: 0.0002, Early Stop: score, Fine-tune BERT: True, Fine-tune Layers: 0, Freeze BERT: False, Target Score: None, Interactive: False
Classifier initialized (26ms)

Fitting DDP Neural Classifier on training data...
Num Workers: 0, Prefetch: None
Score-based early stopping enabled (macro average F1 score against validation set). Validation fraction: 0.1
Training will stop early if the score does not improve by at least 0.00001 for 50 iterations.
Using provided validation set for early stopping.
Building dataset and dataloader...
Initializing model, graph, optimizer...
BERT's original pooler removed. Using custom pooling type: mean
BERT has 0 trainable parameters and 334,092,288 non-trainable parameters
Number of BERT layers requiring gradients: 0 out of 24
All BERT layers are frozen

Model Architecture Summary:
BERTClassifier(
  (bert): ElectraModel(
    (embeddings): ElectraEmbeddings(
      (word_embeddings): Embedding(30522, 1024, padding_idx=0)
      (position_embeddings): Embedding(512, 1024)
      (token_type_embeddings): Embedding(2, 1024)
      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): ElectraEncoder(
      (layer): ModuleList(
        (0-23): 24 x ElectraLayer(
          (attention): ElectraAttention(
            (self): ElectraSelfAttention(
              (query): Linear(in_features=1024, out_features=1024, bias=True)
              (key): Linear(in_features=1024, out_features=1024, bias=True)
              (value): Linear(in_features=1024, out_features=1024, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): ElectraSelfOutput(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): ElectraIntermediate(
            (dense): Linear(in_features=1024, out_features=4096, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): ElectraOutput(
            (dense): Linear(in_features=4096, out_features=1024, bias=True)
            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
  (custom_pooling): PoolingLayer()
  (classifier): Classifier(
    (layers): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): SwishGLU(
        (projection): Linear(in_features=1024, out_features=2048, bias=True)
        (activation): SiLU()
      )
      (2): Dropout(p=0.3, inplace=False)
      (3): Linear(in_features=1024, out_features=1024, bias=True)
      (4): SwishGLU(
        (projection): Linear(in_features=1024, out_features=2048, bias=True)
        (activation): SiLU()
      )
      (5): Dropout(p=0.3, inplace=False)
      (6): Linear(in_features=1024, out_features=3, bias=True)
    )
  )
)

Model Parameters:
  bert.embeddings.word_embeddings: 31,254,528 (frozen)
  bert.embeddings.position_embeddings: 524,288 (frozen)
  bert.embeddings.token_type_embeddings: 2,048 (frozen)
  bert.embeddings.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.0.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.0.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.0.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.0.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.0.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.0.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.0.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.0.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.1.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.1.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.1.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.1.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.1.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.1.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.1.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.1.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.2.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.2.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.2.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.2.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.2.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.2.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.2.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.2.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.3.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.3.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.3.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.3.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.3.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.3.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.3.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.3.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.4.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.4.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.4.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.4.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.4.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.4.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.4.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.4.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.5.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.5.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.5.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.5.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.5.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.5.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.5.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.5.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.6.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.6.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.6.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.6.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.6.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.6.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.6.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.6.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.7.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.7.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.7.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.7.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.7.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.7.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.7.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.7.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.8.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.8.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.8.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.8.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.8.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.8.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.8.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.8.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.9.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.9.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.9.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.9.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.9.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.9.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.9.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.9.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.10.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.10.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.10.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.10.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.10.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.10.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.10.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.10.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.11.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.11.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.11.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.11.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.11.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.11.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.11.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.11.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.12.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.12.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.12.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.12.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.12.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.12.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.12.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.12.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.13.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.13.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.13.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.13.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.13.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.13.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.13.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.13.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.14.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.14.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.14.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.14.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.14.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.14.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.14.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.14.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.15.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.15.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.15.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.15.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.15.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.15.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.15.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.15.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.16.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.16.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.16.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.16.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.16.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.16.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.16.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.16.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.17.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.17.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.17.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.17.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.17.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.17.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.17.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.17.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.18.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.18.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.18.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.18.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.18.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.18.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.18.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.18.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.19.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.19.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.19.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.19.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.19.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.19.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.19.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.19.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.20.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.20.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.20.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.20.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.20.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.20.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.20.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.20.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.21.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.21.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.21.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.21.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.21.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.21.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.21.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.21.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.22.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.22.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.22.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.22.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.22.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.22.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.22.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.22.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.23.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.23.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.23.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.23.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.23.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.23.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.23.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.23.output.LayerNorm: 2,048 (frozen)
  classifier.layers.0: 1,049,600 (trainable)
  classifier.layers.1.projection: 2,099,200 (trainable)
  classifier.layers.3: 1,049,600 (trainable)
  classifier.layers.6: 3,075 (trainable)

Total layers: 200
Trainable layers: 4
Total parameters: 338,293,763
Trainable parameters: 4,201,475
Percentage of trainable parameters: 1.24%
Using optimizer: AdamW, Use Zero: True, Base Learning Rate: 0.0002, L2 strength: 0.0001
Layer-wise decay factor: 0.95
Using scheduler: CosineAnnealingWarmRestarts
Scheduler arguments:
- T_0: 5
- T_mult: 1
- eta_min: 1e-07

Starting training loop...
Start epoch: 1, Max Iterations: 50, Early Stop: score, Tolerance: 0.00001, Number Iterations No Change: 50
Epoch 1/50:  28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                    | 7/25 [01:24<03:31, 11.76s/it, loss=1.0885, lr=1.99e-04, grad=M:0.0381]^C
Ctrl+C received. Terminating all processes...
Rank 0 - Current process: MainProcess cleaning up...
Terminating all child processes of MainProcess...
Terminated child process: SpawnProcess-6
Terminated child process: SpawnProcess-2
Terminated child process: SpawnProcess-7
Terminated child process: SpawnProcess-5
Terminated child process: SpawnProcess-4
Terminated child process: SpawnProcess-8
Terminated child process: SpawnProcess-1
Terminated child process: SpawnProcess-3
Rank 0 - Exiting program...
/usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
(nlp) ubuntu@138-2-58-218:~/nlp-osaka/sentiment$ python ./ddp_sentiment_finetune.py --dataset 'merged_local' --weights_name 'google/electra-large-discriminator' --save_data --save_model --save_pickle --save_preds --lr 0.0002 --lr_decay 0.95 --epochs 50 --pooling 'mean' --dropout_rate 0.3 --num_layers 2 --hidden_dim 1024 --hidden_activation 'swishglu' --batch_size 128 --finetune_bert --finetune_layers 0 --l2_strength 0.0001 --checkpoint_interval 5 --use_zero --optimizer 'adamw' --scheduler 'cosine_warmup' --scheduler_kwargs '{"T_0":5, "T_mult":1, "eta_min":1e-7}' --decimal 6 --use_val_split --eval_split 'test' --early_stop 'score' --n_iter_no_change 50 --wandb --wandb_project 'Electra Large' --wandb_run 'run_1_merged_class' --show_progress

Starting DDP PyTorch Training...
Device: cuda, Number of GPUs: 8
Spawning 8 processes...
Rank 3 - Device: cuda:3
Rank 5 - Device: cuda:5
Rank 7 - Device: cuda:7
Rank 1 - Device: cuda:1
Rank 6 - Device: cuda:6
Rank 2 - Device: cuda:2
Rank 4 - Device: cuda:4
Rank 0 - Device: cuda:0
8 process groups initialized with 'nccl' backend on localhost:12355
NCCL Timeout: 1 hr 0 min. NCCL Blocking Wait: Enabled
wandb: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: jbeno (jimbeno). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.5
wandb: Run data is saved locally in /home/ubuntu/nlp-osaka/sentiment/wandb/run-20241024_004122-gqxalb5r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run run_1_merged_class
wandb: â­ï¸ View project at https://wandb.ai/jimbeno/Electra%20Large
wandb: ðŸš€ View run at https://wandb.ai/jimbeno/Electra%20Large/runs/gqxalb5r
Wand run initialized.

Initializing 'google/electra-large-discriminator' tokenizer and model...
Checking for local files...
Found all files in cache, skipping download
All ranks loading tokenizer from local files...
All ranks loading model from local files...
Tokenizer and model initialized (4s)

Loading data...
Using the same dataset for training and evaluation
Splits:
- Train: Using merged_local 'train' split
- Validation: Using merged_local 'validation' split
- Evaluation: Using merged_local 'test' split
Train Data: Merged DynaSent Round 1, Round 2 and SST from Local: 'data/merged'
Validation Data: Merged DynaSent Round 1, Round 2 and SST from Local: 'data/merged'
Evaluation Data: Merged DynaSent Round 1, Round 2 and SST from Local: 'data/merged'
Train size: 102097
Validation size: 5421
Evaluation size: 5421
Train label distribution:
	      Negative: 21910
	       Neutral: 49148
	      Positive: 31039
Validation label distribution:
	      Negative: 1868
	       Neutral: 1669
	      Positive: 1884
Evaluation label distribution:
	      Negative: 1868
	       Neutral: 1669
	      Positive: 1884
Data loaded (1s)

Processing data...
(Batch size: 128, Pooling: Mean, Fine Tune BERT: True, Chunk size: None)...
Extracting sentences and labels...

Data saved to: saves/data_8_gpu_20241024-004131.npz
X Train shape: [102097], X Validation shape: [5421], X Test shape: [5421]
y Train shape: [102097], y Validation shape: [5421], y Test shape: [5421]
Data processed (876ms)

Initializing DDP Neural Classifier...
Layers: 2, Hidden Dim: 1024, Hidden Act: SwishGLU, Dropout: 0.3, Optimizer: AdamW, L2 Strength: 0.0001, Pooling: MEAN, Accumulation Steps: 1, Max Grad Norm: None
Batch Size: 128, Max Epochs: 50, LR: 0.0002, Early Stop: score, Fine-tune BERT: True, Fine-tune Layers: 0, Freeze BERT: False, Target Score: None, Interactive: False
Classifier initialized (16ms)

Fitting DDP Neural Classifier on training data...
Num Workers: 0, Prefetch: None
Score-based early stopping enabled (macro average F1 score against validation set). Validation fraction: 0.1
Training will stop early if the score does not improve by at least 0.00001 for 50 iterations.
Using provided validation set for early stopping.
Building dataset and dataloader...
Initializing model, graph, optimizer...
BERT's original pooler removed. Using custom pooling type: mean
BERT has 0 trainable parameters and 334,092,288 non-trainable parameters
Number of BERT layers requiring gradients: 0 out of 24
All BERT layers are frozen

Model Architecture Summary:
BERTClassifier(
  (bert): ElectraModel(
    (embeddings): ElectraEmbeddings(
      (word_embeddings): Embedding(30522, 1024, padding_idx=0)
      (position_embeddings): Embedding(512, 1024)
      (token_type_embeddings): Embedding(2, 1024)
      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): ElectraEncoder(
      (layer): ModuleList(
        (0-23): 24 x ElectraLayer(
          (attention): ElectraAttention(
            (self): ElectraSelfAttention(
              (query): Linear(in_features=1024, out_features=1024, bias=True)
              (key): Linear(in_features=1024, out_features=1024, bias=True)
              (value): Linear(in_features=1024, out_features=1024, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): ElectraSelfOutput(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): ElectraIntermediate(
            (dense): Linear(in_features=1024, out_features=4096, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): ElectraOutput(
            (dense): Linear(in_features=4096, out_features=1024, bias=True)
            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
  (custom_pooling): PoolingLayer()
  (classifier): Classifier(
    (layers): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): SwishGLU(
        (projection): Linear(in_features=1024, out_features=2048, bias=True)
        (activation): SiLU()
      )
      (2): Dropout(p=0.3, inplace=False)
      (3): Linear(in_features=1024, out_features=1024, bias=True)
      (4): SwishGLU(
        (projection): Linear(in_features=1024, out_features=2048, bias=True)
        (activation): SiLU()
      )
      (5): Dropout(p=0.3, inplace=False)
      (6): Linear(in_features=1024, out_features=3, bias=True)
    )
  )
)

Model Parameters:
  bert.embeddings.word_embeddings: 31,254,528 (frozen)
  bert.embeddings.position_embeddings: 524,288 (frozen)
  bert.embeddings.token_type_embeddings: 2,048 (frozen)
  bert.embeddings.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.0.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.0.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.0.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.0.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.0.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.0.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.0.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.0.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.1.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.1.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.1.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.1.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.1.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.1.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.1.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.1.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.2.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.2.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.2.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.2.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.2.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.2.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.2.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.2.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.3.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.3.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.3.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.3.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.3.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.3.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.3.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.3.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.4.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.4.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.4.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.4.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.4.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.4.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.4.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.4.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.5.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.5.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.5.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.5.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.5.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.5.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.5.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.5.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.6.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.6.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.6.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.6.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.6.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.6.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.6.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.6.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.7.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.7.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.7.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.7.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.7.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.7.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.7.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.7.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.8.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.8.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.8.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.8.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.8.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.8.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.8.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.8.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.9.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.9.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.9.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.9.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.9.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.9.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.9.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.9.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.10.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.10.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.10.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.10.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.10.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.10.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.10.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.10.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.11.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.11.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.11.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.11.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.11.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.11.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.11.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.11.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.12.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.12.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.12.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.12.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.12.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.12.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.12.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.12.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.13.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.13.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.13.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.13.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.13.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.13.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.13.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.13.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.14.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.14.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.14.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.14.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.14.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.14.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.14.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.14.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.15.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.15.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.15.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.15.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.15.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.15.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.15.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.15.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.16.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.16.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.16.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.16.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.16.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.16.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.16.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.16.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.17.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.17.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.17.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.17.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.17.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.17.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.17.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.17.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.18.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.18.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.18.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.18.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.18.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.18.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.18.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.18.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.19.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.19.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.19.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.19.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.19.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.19.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.19.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.19.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.20.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.20.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.20.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.20.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.20.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.20.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.20.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.20.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.21.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.21.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.21.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.21.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.21.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.21.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.21.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.21.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.22.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.22.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.22.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.22.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.22.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.22.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.22.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.22.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.23.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.23.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.23.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.23.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.23.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.23.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.23.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.23.output.LayerNorm: 2,048 (frozen)
  classifier.layers.0: 1,049,600 (trainable)
  classifier.layers.1.projection: 2,099,200 (trainable)
  classifier.layers.3: 1,049,600 (trainable)
  classifier.layers.6: 3,075 (trainable)

Total layers: 200
Trainable layers: 4
Total parameters: 338,293,763
Trainable parameters: 4,201,475
Percentage of trainable parameters: 1.24%
Using optimizer: AdamW, Use Zero: True, Base Learning Rate: 0.0002, L2 strength: 0.0001
Layer-wise decay factor: 0.95
Using scheduler: CosineAnnealingWarmRestarts
Scheduler arguments:
- T_0: 5
- T_mult: 1
- eta_min: 1e-07

Starting training loop...
Start epoch: 1, Max Iterations: 50, Early Stop: score, Tolerance: 0.00001, Number Iterations No Change: 50
Epoch 1/50:  22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                        | 22/100 [01:07<03:46,  2.90s/it, loss=1.0409, lr=1.99e-04, grad=M:0.0640]^C
Ctrl+C received. Terminating all processes...
Rank 0 - Current process: MainProcess cleaning up...
Terminating all child processes of MainProcess...
Terminated child process: SpawnProcess-1
Terminated child process: SpawnProcess-3
Terminated child process: SpawnProcess-7

KeyboardInterrupt received. Terminating all processes...

KeyboardInterrupt received. Terminating all processes...
Terminated child process: SpawnProcess-6

KeyboardInterrupt received. Terminating all processes...
Terminated child process: SpawnProcess-2

KeyboardInterrupt received. Terminating all processes...
Terminated child process: SpawnProcess-5
Terminated child process: SpawnProcess-4
Terminated child process: SpawnProcess-8
Rank 0 - Exiting program...
/usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
(nlp) ubuntu@138-2-58-218:~/nlp-osaka/sentiment$ python ./ddp_sentiment_finetune.py --dataset 'merged_local' --weights_name 'google/electra-large-discriminator' --save_data --save_model --save_pickle --save_preds --lr 0.0002 --lr_decay 0.95 --epochs 50 --pooling 'mean' --dropout_rate 0.3 --num_layers 2 --hidden_dim 1024 --hidden_activation 'swishglu' --batch_size 512 --finetune_bert --finetune_layers 0 --l2_strength 0.0001 --checkpoint_interval 5 --use_zero --optimizer 'adamw' --scheduler 'cosine_warmup' --scheduler_kwargs '{"T_0":5, "T_mult":1, "eta_min":1e-7}' --decimal 6 --use_val_split --eval_split 'test' --early_stop 'score' --n_iter_no_change 50 --wandb --wandb_project 'Electra Large' --wandb_run 'run_1_merged_class' --show_progress

Starting DDP PyTorch Training...
Device: cuda, Number of GPUs: 8
Spawning 8 processes...
Rank 3 - Device: cuda:3
Rank 1 - Device: cuda:1
Rank 4 - Device: cuda:4
Rank 7 - Device: cuda:7
Rank 6 - Device: cuda:6
Rank 5 - Device: cuda:5
Rank 2 - Device: cuda:2
Rank 0 - Device: cuda:0
8 process groups initialized with 'nccl' backend on localhost:12355
NCCL Timeout: 1 hr 0 min. NCCL Blocking Wait: Enabled
wandb: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: jbeno (jimbeno). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.5
wandb: Run data is saved locally in /home/ubuntu/nlp-osaka/sentiment/wandb/run-20241024_004445-r509siq2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run run_1_merged_class
wandb: â­ï¸ View project at https://wandb.ai/jimbeno/Electra%20Large
wandb: ðŸš€ View run at https://wandb.ai/jimbeno/Electra%20Large/runs/r509siq2
Wand run initialized.

Initializing 'google/electra-large-discriminator' tokenizer and model...
Checking for local files...
Found all files in cache, skipping download
All ranks loading tokenizer from local files...
All ranks loading model from local files...
Tokenizer and model initialized (5s)

Loading data...
Using the same dataset for training and evaluation
Splits:
- Train: Using merged_local 'train' split
- Validation: Using merged_local 'validation' split
- Evaluation: Using merged_local 'test' split
Train Data: Merged DynaSent Round 1, Round 2 and SST from Local: 'data/merged'
Validation Data: Merged DynaSent Round 1, Round 2 and SST from Local: 'data/merged'
Evaluation Data: Merged DynaSent Round 1, Round 2 and SST from Local: 'data/merged'
Train size: 102097
Validation size: 5421
Evaluation size: 5421
Train label distribution:
	      Negative: 21910
	       Neutral: 49148
	      Positive: 31039
Validation label distribution:
	      Negative: 1868
	       Neutral: 1669
	      Positive: 1884
Evaluation label distribution:
	      Negative: 1868
	       Neutral: 1669
	      Positive: 1884
Data loaded (2s)

Processing data...
(Batch size: 512, Pooling: Mean, Fine Tune BERT: True, Chunk size: None)...
Extracting sentences and labels...

Data saved to: saves/data_8_gpu_20241024-004455.npz
X Train shape: [102097], X Validation shape: [5421], X Test shape: [5421]
y Train shape: [102097], y Validation shape: [5421], y Test shape: [5421]
Data processed (872ms)

Initializing DDP Neural Classifier...
Layers: 2, Hidden Dim: 1024, Hidden Act: SwishGLU, Dropout: 0.3, Optimizer: AdamW, L2 Strength: 0.0001, Pooling: MEAN, Accumulation Steps: 1, Max Grad Norm: None
Batch Size: 512, Max Epochs: 50, LR: 0.0002, Early Stop: score, Fine-tune BERT: True, Fine-tune Layers: 0, Freeze BERT: False, Target Score: None, Interactive: False
Classifier initialized (17ms)

Fitting DDP Neural Classifier on training data...
Num Workers: 0, Prefetch: None
Score-based early stopping enabled (macro average F1 score against validation set). Validation fraction: 0.1
Training will stop early if the score does not improve by at least 0.00001 for 50 iterations.
Using provided validation set for early stopping.
Building dataset and dataloader...
Initializing model, graph, optimizer...
BERT's original pooler removed. Using custom pooling type: mean
BERT has 0 trainable parameters and 334,092,288 non-trainable parameters
Number of BERT layers requiring gradients: 0 out of 24
All BERT layers are frozen

Model Architecture Summary:
BERTClassifier(
  (bert): ElectraModel(
    (embeddings): ElectraEmbeddings(
      (word_embeddings): Embedding(30522, 1024, padding_idx=0)
      (position_embeddings): Embedding(512, 1024)
      (token_type_embeddings): Embedding(2, 1024)
      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): ElectraEncoder(
      (layer): ModuleList(
        (0-23): 24 x ElectraLayer(
          (attention): ElectraAttention(
            (self): ElectraSelfAttention(
              (query): Linear(in_features=1024, out_features=1024, bias=True)
              (key): Linear(in_features=1024, out_features=1024, bias=True)
              (value): Linear(in_features=1024, out_features=1024, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): ElectraSelfOutput(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): ElectraIntermediate(
            (dense): Linear(in_features=1024, out_features=4096, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): ElectraOutput(
            (dense): Linear(in_features=4096, out_features=1024, bias=True)
            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
  (custom_pooling): PoolingLayer()
  (classifier): Classifier(
    (layers): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): SwishGLU(
        (projection): Linear(in_features=1024, out_features=2048, bias=True)
        (activation): SiLU()
      )
      (2): Dropout(p=0.3, inplace=False)
      (3): Linear(in_features=1024, out_features=1024, bias=True)
      (4): SwishGLU(
        (projection): Linear(in_features=1024, out_features=2048, bias=True)
        (activation): SiLU()
      )
      (5): Dropout(p=0.3, inplace=False)
      (6): Linear(in_features=1024, out_features=3, bias=True)
    )
  )
)

Model Parameters:
  bert.embeddings.word_embeddings: 31,254,528 (frozen)
  bert.embeddings.position_embeddings: 524,288 (frozen)
  bert.embeddings.token_type_embeddings: 2,048 (frozen)
  bert.embeddings.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.0.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.0.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.0.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.0.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.0.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.0.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.0.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.0.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.1.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.1.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.1.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.1.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.1.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.1.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.1.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.1.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.2.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.2.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.2.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.2.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.2.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.2.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.2.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.2.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.3.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.3.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.3.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.3.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.3.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.3.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.3.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.3.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.4.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.4.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.4.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.4.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.4.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.4.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.4.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.4.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.5.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.5.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.5.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.5.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.5.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.5.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.5.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.5.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.6.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.6.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.6.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.6.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.6.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.6.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.6.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.6.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.7.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.7.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.7.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.7.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.7.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.7.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.7.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.7.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.8.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.8.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.8.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.8.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.8.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.8.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.8.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.8.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.9.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.9.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.9.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.9.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.9.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.9.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.9.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.9.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.10.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.10.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.10.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.10.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.10.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.10.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.10.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.10.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.11.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.11.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.11.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.11.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.11.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.11.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.11.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.11.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.12.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.12.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.12.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.12.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.12.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.12.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.12.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.12.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.13.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.13.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.13.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.13.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.13.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.13.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.13.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.13.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.14.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.14.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.14.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.14.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.14.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.14.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.14.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.14.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.15.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.15.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.15.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.15.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.15.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.15.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.15.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.15.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.16.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.16.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.16.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.16.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.16.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.16.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.16.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.16.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.17.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.17.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.17.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.17.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.17.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.17.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.17.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.17.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.18.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.18.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.18.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.18.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.18.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.18.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.18.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.18.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.19.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.19.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.19.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.19.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.19.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.19.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.19.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.19.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.20.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.20.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.20.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.20.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.20.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.20.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.20.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.20.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.21.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.21.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.21.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.21.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.21.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.21.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.21.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.21.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.22.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.22.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.22.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.22.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.22.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.22.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.22.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.22.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.23.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.23.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.23.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.23.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.23.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.23.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.23.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.23.output.LayerNorm: 2,048 (frozen)
  classifier.layers.0: 1,049,600 (trainable)
  classifier.layers.1.projection: 2,099,200 (trainable)
  classifier.layers.3: 1,049,600 (trainable)
  classifier.layers.6: 3,075 (trainable)

Total layers: 200
Trainable layers: 4
Total parameters: 338,293,763
Trainable parameters: 4,201,475
Percentage of trainable parameters: 1.24%
Using optimizer: AdamW, Use Zero: True, Base Learning Rate: 0.0002, L2 strength: 0.0001
Layer-wise decay factor: 0.95
Using scheduler: CosineAnnealingWarmRestarts
Scheduler arguments:
- T_0: 5
- T_mult: 1
- eta_min: 1e-07

Starting training loop...
Start epoch: 1, Max Iterations: 50, Early Stop: score, Tolerance: 0.00001, Number Iterations No Change: 50
Epoch 1/50:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                      | 19/25 [03:42<01:09, 11.58s/it, loss=1.0419, lr=1.90e-04, grad=M:0.0792]Epoch 1/50:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 20/25 [03:54<00:58, 11.61s/it, loss=1.0244, lr=1.89e-04, grad=M:0.0383]^C
Ctrl+C received. Terminating all processes...
Rank 0 - Current process: MainProcess cleaning up...
Terminating all child processes of MainProcess...
Terminated child process: SpawnProcess-1
Terminated child process: SpawnProcess-3
Terminated child process: SpawnProcess-7
Terminated child process: SpawnProcess-6
Terminated child process: SpawnProcess-2
Terminated child process: SpawnProcess-5
Terminated child process: SpawnProcess-4
Terminated child process: SpawnProcess-8
Rank 0 - Exiting program...
^C
Ctrl+C received. Terminating all processes...
Rank 0 - Current process: MainProcess cleaning up...
Terminating all child processes of MainProcess...
Terminated child process: SpawnProcess-1
Terminated child process: SpawnProcess-3
Terminated child process: SpawnProcess-7
Terminated child process: SpawnProcess-6
Terminated child process: SpawnProcess-2
Terminated child process: SpawnProcess-5
Terminated child process: SpawnProcess-4
Terminated child process: SpawnProcess-8
Rank 0 - Exiting program...
Exception ignored in atexit callback: <function _exit_function at 0x798268bd2e60>
Traceback (most recent call last):
  File "/usr/lib/python3.10/multiprocessing/util.py", line 357, in _exit_function
    p.join()
  File "/usr/lib/python3.10/multiprocessing/process.py", line 149, in join
    res = self._popen.wait(timeout)
  File "/usr/lib/python3.10/multiprocessing/popen_fork.py", line 43, in wait
    return self.poll(os.WNOHANG if timeout == 0.0 else 0)
  File "/usr/lib/python3.10/multiprocessing/popen_fork.py", line 27, in poll
    pid, sts = os.waitpid(self.pid, flag)
  File "/home/ubuntu/nlp-osaka/sentiment/utils.py", line 159, in signal_handler
    cleanup_and_exit(0, True) 
  File "/home/ubuntu/nlp-osaka/sentiment/utils.py", line 205, in cleanup_and_exit
    sys.exit(0)
SystemExit: 0
Exception ignored in: <Finalize object, dead>
Traceback (most recent call last):
  File "/usr/lib/python3.10/multiprocessing/util.py", line 224, in __call__
  File "/usr/lib/python3.10/multiprocessing/heap.py", line 278, in free
AttributeError: 'NoneType' object has no attribute 'getpid'
/usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
(nlp) ubuntu@138-2-58-218:~/nlp-osaka/sentiment$ git pull
Username for 'https://github.com': jim@jimbeno.net
Password for 'https://jim@jimbeno.net@github.com': 
remote: Enumerating objects: 5, done.
remote: Counting objects: 100% (5/5), done.
remote: Compressing objects: 100% (1/1), done.
remote: Total 3 (delta 2), reused 3 (delta 2), pack-reused 0 (from 0)
Unpacking objects: 100% (3/3), 478 bytes | 8.00 KiB/s, done.
From https://github.com/jbeno/sentiment
   e962be3..a14fb4f  main       -> origin/main
Updating e962be3..a14fb4f
Fast-forward
 ddp_sentiment_finetune.py | 11 +++++++++--
 1 file changed, 9 insertions(+), 2 deletions(-)
(nlp) ubuntu@138-2-58-218:~/nlp-osaka/sentiment$ python ./ddp_sentiment_finetune.py --dataset 'merged_local' --weights_name 'google/electra-large-discriminator' --save_data --save_model --save_pickle --save_preds --lr 0.0002 --lr_decay 0.95 --epochs 50 --pooling 'mean' --dropout_rate 0.3 --num_layers 2 --hidden_dim 1024 --hidden_activation 'swishglu' --batch_size 32 --finetune_bert --finetune_layers 0 --l2_strength 0.0001 --checkpoint_interval 5 --use_zero --optimizer 'adamw' --scheduler 'cosine_warmup' --scheduler_kwargs '{"T_0":5, "T_mult":1, "eta_min":1e-7}' --decimal 6 --use_val_split --eval_split 'test' --early_stop 'score' --n_iter_no_change 50 --wandb --wandb_project 'Electra Large' --wandb_run 'run_1_merged_class' --show_progress --wandb_alerts

Starting DDP PyTorch Training...
Device: cuda, Number of GPUs: 8
Spawning 8 processes...
Rank 1 - Device: cuda:1
Rank 4 - Device: cuda:4
Rank 6 - Device: cuda:6
Rank 7 - Device: cuda:7
Rank 5 - Device: cuda:5
Rank 2 - Device: cuda:2
Rank 3 - Device: cuda:3
Rank 0 - Device: cuda:0
8 process groups initialized with 'nccl' backend on localhost:12355
NCCL Timeout: 1 hr 0 min. NCCL Blocking Wait: Enabled
wandb: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: jbeno (jimbeno). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.5
wandb: Run data is saved locally in /home/ubuntu/nlp-osaka/sentiment/wandb/run-20241024_005629-r8nfpaz1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run run_1_merged_class
wandb: â­ï¸ View project at https://wandb.ai/jimbeno/Electra%20Large
wandb: ðŸš€ View run at https://wandb.ai/jimbeno/Electra%20Large/runs/r8nfpaz1
Wand run initialized.
An error occurred during training: module 'wandb' has no attribute 'alerts'
Traceback (most recent call last):
  File "/home/ubuntu/nlp-osaka/sentiment/ddp_sentiment_finetune.py", line 1180, in main
    wandb.alerts()
AttributeError: module 'wandb' has no attribute 'alerts'. Did you mean: 'alert'?
wandb: ðŸš€ View run run_1_merged_class at: https://wandb.ai/jimbeno/Electra Large/runs/r8nfpaz1
wandb: Find logs at: wandb/run-20241024_005629-r8nfpaz1/logs
(nlp) ubuntu@138-2-58-218:~/nlp-osaka/sentiment$ git pull
Username for 'https://github.com': jim@jimbeno.net
Password for 'https://jim@jimbeno.net@github.com': 
remote: Enumerating objects: 5, done.
remote: Counting objects: 100% (5/5), done.
remote: Compressing objects: 100% (1/1), done.
remote: Total 3 (delta 2), reused 3 (delta 2), pack-reused 0 (from 0)
Unpacking objects: 100% (3/3), 369 bytes | 0 bytes/s, done.
From https://github.com/jbeno/sentiment
   a14fb4f..9755466  main       -> origin/main
Updating a14fb4f..9755466
Fast-forward
 ddp_sentiment_finetune.py | 8 +++-----
 1 file changed, 3 insertions(+), 5 deletions(-)
(nlp) ubuntu@138-2-58-218:~/nlp-osaka/sentiment$ python ./ddp_sentiment_finetune.py --dataset 'merged_local' --weights_name 'google/electra-large-discriminator' --save_data --save_model --save_pickle --save_preds --lr 0.0002 --lr_decay 0.95 --epochs 50 --pooling 'mean' --dropout_rate 0.3 --num_layers 2 --hidden_dim 1024 --hidden_activation 'swishglu' --batch_size 32 --finetune_bert --finetune_layers 0 --l2_strength 0.0001 --checkpoint_interval 5 --use_zero --optimizer 'adamw' --scheduler 'cosine_warmup' --scheduler_kwargs '{"T_0":5, "T_mult":1, "eta_min":1e-7}' --decimal 6 --use_val_split --eval_split 'test' --early_stop 'score' --n_iter_no_change 50 --wandb --wandb_project 'Electra Large' --wandb_run 'run_1_merged_class' --show_progress --wandb_alerts

Starting DDP PyTorch Training...
Device: cuda, Number of GPUs: 8
Spawning 8 processes...
Rank 3 - Device: cuda:3
Rank 2 - Device: cuda:2
Rank 1 - Device: cuda:1
Rank 5 - Device: cuda:5
Rank 4 - Device: cuda:4
Rank 6 - Device: cuda:6
Rank 7 - Device: cuda:7
Rank 0 - Device: cuda:0
8 process groups initialized with 'nccl' backend on localhost:12355
NCCL Timeout: 1 hr 0 min. NCCL Blocking Wait: Enabled
wandb: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: jbeno (jimbeno). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.5
wandb: Run data is saved locally in /home/ubuntu/nlp-osaka/sentiment/wandb/run-20241024_010845-ho8o4i5f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run run_1_merged_class
wandb: â­ï¸ View project at https://wandb.ai/jimbeno/Electra%20Large
wandb: ðŸš€ View run at https://wandb.ai/jimbeno/Electra%20Large/runs/ho8o4i5f
Wand run initialized.

Initializing 'google/electra-large-discriminator' tokenizer and model...
Checking for local files...
Found all files in cache, skipping download
All ranks loading tokenizer from local files...
All ranks loading model from local files...
Tokenizer and model initialized (6s)

Loading data...
Using the same dataset for training and evaluation
Splits:
- Train: Using merged_local 'train' split
- Validation: Using merged_local 'validation' split
- Evaluation: Using merged_local 'test' split
Train Data: Merged DynaSent Round 1, Round 2 and SST from Local: 'data/merged'
Validation Data: Merged DynaSent Round 1, Round 2 and SST from Local: 'data/merged'
Evaluation Data: Merged DynaSent Round 1, Round 2 and SST from Local: 'data/merged'
Train size: 102097
Validation size: 5421
Evaluation size: 5421
Train label distribution:
	      Negative: 21910
	       Neutral: 49148
	      Positive: 31039
Validation label distribution:
	      Negative: 1868
	       Neutral: 1669
	      Positive: 1884
Evaluation label distribution:
	      Negative: 1868
	       Neutral: 1669
	      Positive: 1884
Data loaded (1s)

Processing data...
(Batch size: 32, Pooling: Mean, Fine Tune BERT: True, Chunk size: None)...
Extracting sentences and labels...

Data saved to: saves/data_8_gpu_20241024-010855.npz
X Train shape: [102097], X Validation shape: [5421], X Test shape: [5421]
y Train shape: [102097], y Validation shape: [5421], y Test shape: [5421]
Data processed (863ms)

Initializing DDP Neural Classifier...
Layers: 2, Hidden Dim: 1024, Hidden Act: SwishGLU, Dropout: 0.3, Optimizer: AdamW, L2 Strength: 0.0001, Pooling: MEAN, Accumulation Steps: 1, Max Grad Norm: None
Batch Size: 32, Max Epochs: 50, LR: 0.0002, Early Stop: score, Fine-tune BERT: True, Fine-tune Layers: 0, Freeze BERT: False, Target Score: None, Interactive: False
Classifier initialized (17ms)

Fitting DDP Neural Classifier on training data...
Num Workers: 0, Prefetch: None
Score-based early stopping enabled (macro average F1 score against validation set). Validation fraction: 0.1
Training will stop early if the score does not improve by at least 0.00001 for 50 iterations.
Using provided validation set for early stopping.
Building dataset and dataloader...
Initializing model, graph, optimizer...
BERT's original pooler removed. Using custom pooling type: mean
BERT has 0 trainable parameters and 334,092,288 non-trainable parameters
Number of BERT layers requiring gradients: 0 out of 24
All BERT layers are frozen

Model Architecture Summary:
BERTClassifier(
  (bert): ElectraModel(
    (embeddings): ElectraEmbeddings(
      (word_embeddings): Embedding(30522, 1024, padding_idx=0)
      (position_embeddings): Embedding(512, 1024)
      (token_type_embeddings): Embedding(2, 1024)
      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): ElectraEncoder(
      (layer): ModuleList(
        (0-23): 24 x ElectraLayer(
          (attention): ElectraAttention(
            (self): ElectraSelfAttention(
              (query): Linear(in_features=1024, out_features=1024, bias=True)
              (key): Linear(in_features=1024, out_features=1024, bias=True)
              (value): Linear(in_features=1024, out_features=1024, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): ElectraSelfOutput(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): ElectraIntermediate(
            (dense): Linear(in_features=1024, out_features=4096, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): ElectraOutput(
            (dense): Linear(in_features=4096, out_features=1024, bias=True)
            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
  (custom_pooling): PoolingLayer()
  (classifier): Classifier(
    (layers): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): SwishGLU(
        (projection): Linear(in_features=1024, out_features=2048, bias=True)
        (activation): SiLU()
      )
      (2): Dropout(p=0.3, inplace=False)
      (3): Linear(in_features=1024, out_features=1024, bias=True)
      (4): SwishGLU(
        (projection): Linear(in_features=1024, out_features=2048, bias=True)
        (activation): SiLU()
      )
      (5): Dropout(p=0.3, inplace=False)
      (6): Linear(in_features=1024, out_features=3, bias=True)
    )
  )
)

Model Parameters:
  bert.embeddings.word_embeddings: 31,254,528 (frozen)
  bert.embeddings.position_embeddings: 524,288 (frozen)
  bert.embeddings.token_type_embeddings: 2,048 (frozen)
  bert.embeddings.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.0.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.0.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.0.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.0.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.0.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.0.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.0.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.0.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.1.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.1.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.1.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.1.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.1.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.1.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.1.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.1.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.2.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.2.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.2.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.2.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.2.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.2.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.2.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.2.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.3.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.3.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.3.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.3.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.3.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.3.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.3.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.3.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.4.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.4.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.4.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.4.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.4.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.4.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.4.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.4.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.5.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.5.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.5.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.5.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.5.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.5.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.5.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.5.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.6.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.6.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.6.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.6.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.6.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.6.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.6.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.6.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.7.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.7.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.7.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.7.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.7.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.7.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.7.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.7.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.8.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.8.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.8.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.8.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.8.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.8.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.8.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.8.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.9.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.9.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.9.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.9.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.9.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.9.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.9.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.9.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.10.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.10.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.10.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.10.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.10.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.10.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.10.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.10.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.11.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.11.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.11.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.11.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.11.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.11.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.11.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.11.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.12.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.12.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.12.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.12.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.12.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.12.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.12.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.12.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.13.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.13.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.13.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.13.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.13.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.13.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.13.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.13.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.14.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.14.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.14.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.14.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.14.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.14.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.14.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.14.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.15.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.15.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.15.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.15.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.15.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.15.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.15.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.15.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.16.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.16.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.16.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.16.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.16.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.16.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.16.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.16.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.17.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.17.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.17.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.17.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.17.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.17.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.17.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.17.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.18.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.18.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.18.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.18.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.18.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.18.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.18.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.18.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.19.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.19.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.19.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.19.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.19.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.19.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.19.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.19.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.20.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.20.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.20.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.20.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.20.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.20.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.20.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.20.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.21.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.21.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.21.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.21.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.21.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.21.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.21.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.21.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.22.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.22.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.22.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.22.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.22.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.22.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.22.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.22.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.23.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.23.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.23.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.23.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.23.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.23.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.23.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.23.output.LayerNorm: 2,048 (frozen)
  classifier.layers.0: 1,049,600 (trainable)
  classifier.layers.1.projection: 2,099,200 (trainable)
  classifier.layers.3: 1,049,600 (trainable)
  classifier.layers.6: 3,075 (trainable)

Total layers: 200
Trainable layers: 4
Total parameters: 338,293,763
Trainable parameters: 4,201,475
Percentage of trainable parameters: 1.24%
Using optimizer: AdamW, Use Zero: True, Base Learning Rate: 0.0002, L2 strength: 0.0001
Layer-wise decay factor: 0.95
Using scheduler: CosineAnnealingWarmRestarts
Scheduler arguments:
- T_0: 5
- T_mult: 1
- eta_min: 1e-07

Starting training loop...
Start epoch: 1, Max Iterations: 50, Early Stop: score, Tolerance: 0.00001, Number Iterations No Change: 50
Epoch 1/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 399/399 [05:00<00:00,  1.42it/s, loss=0.9359, lr=1.81e-04, grad=M:0.2296, status=Computing train metrics...]^C
Ctrl+C received. Terminating all processes...
Rank 0 - Current process: MainProcess cleaning up...
Terminating all child processes of MainProcess...
Terminated child process: SpawnProcess-2
Terminated child process: SpawnProcess-8
Terminated child process: SpawnProcess-1
Terminated child process: SpawnProcess-3
Terminated child process: SpawnProcess-7
Terminated child process: SpawnProcess-6
Terminated child process: SpawnProcess-5
Terminated child process: SpawnProcess-4
Rank 0 - Exiting program...
/usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
(nlp) ubuntu@138-2-58-218:~/nlp-osaka/sentiment$ python ./ddp_sentiment_finetune.py --dataset 'merged_local' --weights_name 'google/electra-large-discriminator' --save_data --save_model --save_pickle --save_preds --lr 0.0002 --lr_decay 0.95 --epochs 50 --pooling 'mean' --dropout_rate 0.3 --num_layers 2 --hidden_dim 1024 --hidden_activation 'swishglu' --batch_size 128 --finetune_bert --finetune_layers 0 --l2_strength 0.0001 --checkpoint_interval 5 --use_zero --optimizer 'adamw' --scheduler 'cosine_warmup' --scheduler_kwargs '{"T_0":5, "T_mult":1, "eta_min":1e-7}' --decimal 6 --use_val_split --eval_split 'test' --early_stop 'score' --n_iter_no_change 50 --wandb --wandb_project 'Electra Large' --wandb_run 'run_1_merged_class' --show_progress --wandb_alerts

Starting DDP PyTorch Training...
Device: cuda, Number of GPUs: 8
Spawning 8 processes...
Rank 3 - Device: cuda:3
Rank 4 - Device: cuda:4
Rank 6 - Device: cuda:6
Rank 5 - Device: cuda:5
Rank 7 - Device: cuda:7
Rank 2 - Device: cuda:2
Rank 1 - Device: cuda:1
Rank 0 - Device: cuda:0
8 process groups initialized with 'nccl' backend on localhost:12355
NCCL Timeout: 1 hr 0 min. NCCL Blocking Wait: Enabled
wandb: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: jbeno (jimbeno). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.5
wandb: Run data is saved locally in /home/ubuntu/nlp-osaka/sentiment/wandb/run-20241024_011627-n62n8xx6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run run_1_merged_class
wandb: â­ï¸ View project at https://wandb.ai/jimbeno/Electra%20Large
wandb: ðŸš€ View run at https://wandb.ai/jimbeno/Electra%20Large/runs/n62n8xx6
Wand run initialized.

Initializing 'google/electra-large-discriminator' tokenizer and model...
Checking for local files...
Found all files in cache, skipping download
All ranks loading tokenizer from local files...
All ranks loading model from local files...
Tokenizer and model initialized (5s)

Loading data...
Using the same dataset for training and evaluation
Splits:
- Train: Using merged_local 'train' split
- Validation: Using merged_local 'validation' split
- Evaluation: Using merged_local 'test' split
Train Data: Merged DynaSent Round 1, Round 2 and SST from Local: 'data/merged'
Validation Data: Merged DynaSent Round 1, Round 2 and SST from Local: 'data/merged'
Evaluation Data: Merged DynaSent Round 1, Round 2 and SST from Local: 'data/merged'
Train size: 102097
Validation size: 5421
Evaluation size: 5421
Train label distribution:
	      Negative: 21910
	       Neutral: 49148
	      Positive: 31039
Validation label distribution:
	      Negative: 1868
	       Neutral: 1669
	      Positive: 1884
Evaluation label distribution:
	      Negative: 1868
	       Neutral: 1669
	      Positive: 1884
Data loaded (289ms)

Processing data...
(Batch size: 128, Pooling: Mean, Fine Tune BERT: True, Chunk size: None)...
Extracting sentences and labels...

Data saved to: saves/data_8_gpu_20241024-011635.npz
X Train shape: [102097], X Validation shape: [5421], X Test shape: [5421]
y Train shape: [102097], y Validation shape: [5421], y Test shape: [5421]
Data processed (866ms)

Initializing DDP Neural Classifier...
Layers: 2, Hidden Dim: 1024, Hidden Act: SwishGLU, Dropout: 0.3, Optimizer: AdamW, L2 Strength: 0.0001, Pooling: MEAN, Accumulation Steps: 1, Max Grad Norm: None
Batch Size: 128, Max Epochs: 50, LR: 0.0002, Early Stop: score, Fine-tune BERT: True, Fine-tune Layers: 0, Freeze BERT: False, Target Score: None, Interactive: False
Classifier initialized (17ms)

Fitting DDP Neural Classifier on training data...
Num Workers: 0, Prefetch: None
Score-based early stopping enabled (macro average F1 score against validation set). Validation fraction: 0.1
Training will stop early if the score does not improve by at least 0.00001 for 50 iterations.
Using provided validation set for early stopping.
Building dataset and dataloader...
Initializing model, graph, optimizer...
BERT's original pooler removed. Using custom pooling type: mean
BERT has 0 trainable parameters and 334,092,288 non-trainable parameters
Number of BERT layers requiring gradients: 0 out of 24
All BERT layers are frozen

Model Architecture Summary:
BERTClassifier(
  (bert): ElectraModel(
    (embeddings): ElectraEmbeddings(
      (word_embeddings): Embedding(30522, 1024, padding_idx=0)
      (position_embeddings): Embedding(512, 1024)
      (token_type_embeddings): Embedding(2, 1024)
      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): ElectraEncoder(
      (layer): ModuleList(
        (0-23): 24 x ElectraLayer(
          (attention): ElectraAttention(
            (self): ElectraSelfAttention(
              (query): Linear(in_features=1024, out_features=1024, bias=True)
              (key): Linear(in_features=1024, out_features=1024, bias=True)
              (value): Linear(in_features=1024, out_features=1024, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): ElectraSelfOutput(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): ElectraIntermediate(
            (dense): Linear(in_features=1024, out_features=4096, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): ElectraOutput(
            (dense): Linear(in_features=4096, out_features=1024, bias=True)
            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
  (custom_pooling): PoolingLayer()
  (classifier): Classifier(
    (layers): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): SwishGLU(
        (projection): Linear(in_features=1024, out_features=2048, bias=True)
        (activation): SiLU()
      )
      (2): Dropout(p=0.3, inplace=False)
      (3): Linear(in_features=1024, out_features=1024, bias=True)
      (4): SwishGLU(
        (projection): Linear(in_features=1024, out_features=2048, bias=True)
        (activation): SiLU()
      )
      (5): Dropout(p=0.3, inplace=False)
      (6): Linear(in_features=1024, out_features=3, bias=True)
    )
  )
)

Model Parameters:
  bert.embeddings.word_embeddings: 31,254,528 (frozen)
  bert.embeddings.position_embeddings: 524,288 (frozen)
  bert.embeddings.token_type_embeddings: 2,048 (frozen)
  bert.embeddings.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.0.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.0.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.0.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.0.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.0.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.0.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.0.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.0.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.1.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.1.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.1.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.1.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.1.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.1.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.1.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.1.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.2.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.2.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.2.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.2.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.2.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.2.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.2.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.2.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.3.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.3.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.3.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.3.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.3.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.3.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.3.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.3.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.4.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.4.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.4.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.4.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.4.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.4.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.4.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.4.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.5.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.5.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.5.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.5.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.5.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.5.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.5.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.5.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.6.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.6.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.6.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.6.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.6.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.6.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.6.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.6.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.7.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.7.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.7.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.7.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.7.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.7.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.7.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.7.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.8.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.8.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.8.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.8.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.8.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.8.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.8.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.8.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.9.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.9.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.9.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.9.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.9.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.9.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.9.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.9.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.10.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.10.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.10.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.10.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.10.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.10.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.10.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.10.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.11.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.11.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.11.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.11.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.11.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.11.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.11.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.11.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.12.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.12.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.12.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.12.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.12.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.12.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.12.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.12.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.13.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.13.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.13.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.13.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.13.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.13.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.13.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.13.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.14.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.14.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.14.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.14.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.14.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.14.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.14.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.14.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.15.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.15.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.15.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.15.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.15.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.15.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.15.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.15.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.16.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.16.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.16.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.16.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.16.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.16.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.16.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.16.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.17.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.17.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.17.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.17.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.17.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.17.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.17.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.17.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.18.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.18.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.18.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.18.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.18.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.18.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.18.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.18.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.19.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.19.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.19.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.19.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.19.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.19.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.19.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.19.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.20.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.20.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.20.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.20.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.20.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.20.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.20.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.20.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.21.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.21.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.21.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.21.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.21.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.21.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.21.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.21.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.22.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.22.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.22.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.22.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.22.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.22.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.22.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.22.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.23.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.23.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.23.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.23.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.23.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.23.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.23.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.23.output.LayerNorm: 2,048 (frozen)
  classifier.layers.0: 1,049,600 (trainable)
  classifier.layers.1.projection: 2,099,200 (trainable)
  classifier.layers.3: 1,049,600 (trainable)
  classifier.layers.6: 3,075 (trainable)

Total layers: 200
Trainable layers: 4
Total parameters: 338,293,763
Trainable parameters: 4,201,475
Percentage of trainable parameters: 1.24%
Using optimizer: AdamW, Use Zero: True, Base Learning Rate: 0.0002, L2 strength: 0.0001
Layer-wise decay factor: 0.95
Using scheduler: CosineAnnealingWarmRestarts
Scheduler arguments:
- T_0: 5
- T_mult: 1
- eta_min: 1e-07

Starting training loop...
Start epoch: 1, Max Iterations: 50, Early Stop: score, Tolerance: 0.00001, Number Iterations No Change: 50
Epoch 1/50:  15%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                                               | 15/100 [00:46<04:07,  2.91s/it, loss=1.0651, lr=2.00e-04, grad=M:0.0457]^C
Ctrl+C received. Terminating all processes...
Rank 0 - Current process: MainProcess cleaning up...
Terminating all child processes of MainProcess...
Terminated child process: SpawnProcess-3
Terminated child process: SpawnProcess-7
Terminated child process: SpawnProcess-6
Terminated child process: SpawnProcess-5
Terminated child process: SpawnProcess-4
Terminated child process: SpawnProcess-2
Terminated child process: SpawnProcess-8
Terminated child process: SpawnProcess-1
Rank 0 - Exiting program...
/usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
(nlp) ubuntu@138-2-58-218:~/nlp-osaka/sentiment$ python ./ddp_sentiment_finetune.py --dataset 'merged_local' --weights_name 'google/electra-large-discriminator' --save_data --save_model --save_pickle --save_preds --lr 0.0002 --lr_decay 0.95 --epochs 50 --pooling 'mean' --dropout_rate 0.3 --num_layers 2 --hidden_dim 1024 --hidden_activation 'swishglu' --batch_size 512 --finetune_bert --finetune_layers 0 --l2_strength 0.0001 --checkpoint_interval 5 --use_zero --optimizer 'adamw' --scheduler 'cosine_warmup' --scheduler_kwargs '{"T_0":5, "T_mult":1, "eta_min":1e-7}' --decimal 6 --use_val_split --eval_split 'test' --early_stop 'score' --n_iter_no_change 50 --wandb --wandb_project 'Electra Large' --wandb_run 'run_1_merged_class' --show_progress --wandb_alerts

Starting DDP PyTorch Training...
Device: cuda, Number of GPUs: 8
Spawning 8 processes...
Rank 7 - Device: cuda:7
Rank 1 - Device: cuda:1
Rank 4 - Device: cuda:4
Rank 3 - Device: cuda:3
Rank 2 - Device: cuda:2
Rank 6 - Device: cuda:6
Rank 5 - Device: cuda:5
Rank 0 - Device: cuda:0
8 process groups initialized with 'nccl' backend on localhost:12355
NCCL Timeout: 1 hr 0 min. NCCL Blocking Wait: Enabled
wandb: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: jbeno (jimbeno). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.5
wandb: Run data is saved locally in /home/ubuntu/nlp-osaka/sentiment/wandb/run-20241024_011904-zjlro0ta
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run run_1_merged_class
wandb: â­ï¸ View project at https://wandb.ai/jimbeno/Electra%20Large
wandb: ðŸš€ View run at https://wandb.ai/jimbeno/Electra%20Large/runs/zjlro0ta
Wand run initialized.

Initializing 'google/electra-large-discriminator' tokenizer and model...
Checking for local files...
Found all files in cache, skipping download
All ranks loading tokenizer from local files...
All ranks loading model from local files...
Tokenizer and model initialized (4s)

Loading data...
Using the same dataset for training and evaluation
Splits:
- Train: Using merged_local 'train' split
- Validation: Using merged_local 'validation' split
- Evaluation: Using merged_local 'test' split
Train Data: Merged DynaSent Round 1, Round 2 and SST from Local: 'data/merged'
Validation Data: Merged DynaSent Round 1, Round 2 and SST from Local: 'data/merged'
Evaluation Data: Merged DynaSent Round 1, Round 2 and SST from Local: 'data/merged'
Train size: 102097
Validation size: 5421
Evaluation size: 5421
Train label distribution:
	      Negative: 21910
	       Neutral: 49148
	      Positive: 31039
Validation label distribution:
	      Negative: 1868
	       Neutral: 1669
	      Positive: 1884
Evaluation label distribution:
	      Negative: 1868
	       Neutral: 1669
	      Positive: 1884
Data loaded (1s)

Processing data...
(Batch size: 512, Pooling: Mean, Fine Tune BERT: True, Chunk size: None)...
Extracting sentences and labels...

Data saved to: saves/data_8_gpu_20241024-011912.npz
X Train shape: [102097], X Validation shape: [5421], X Test shape: [5421]
y Train shape: [102097], y Validation shape: [5421], y Test shape: [5421]
Data processed (850ms)

Initializing DDP Neural Classifier...
Layers: 2, Hidden Dim: 1024, Hidden Act: SwishGLU, Dropout: 0.3, Optimizer: AdamW, L2 Strength: 0.0001, Pooling: MEAN, Accumulation Steps: 1, Max Grad Norm: None
Batch Size: 512, Max Epochs: 50, LR: 0.0002, Early Stop: score, Fine-tune BERT: True, Fine-tune Layers: 0, Freeze BERT: False, Target Score: None, Interactive: False
Classifier initialized (18ms)

Fitting DDP Neural Classifier on training data...
Num Workers: 0, Prefetch: None
Score-based early stopping enabled (macro average F1 score against validation set). Validation fraction: 0.1
Training will stop early if the score does not improve by at least 0.00001 for 50 iterations.
Using provided validation set for early stopping.
Building dataset and dataloader...
Initializing model, graph, optimizer...
BERT's original pooler removed. Using custom pooling type: mean
BERT has 0 trainable parameters and 334,092,288 non-trainable parameters
Number of BERT layers requiring gradients: 0 out of 24
All BERT layers are frozen

Model Architecture Summary:
BERTClassifier(
  (bert): ElectraModel(
    (embeddings): ElectraEmbeddings(
      (word_embeddings): Embedding(30522, 1024, padding_idx=0)
      (position_embeddings): Embedding(512, 1024)
      (token_type_embeddings): Embedding(2, 1024)
      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): ElectraEncoder(
      (layer): ModuleList(
        (0-23): 24 x ElectraLayer(
          (attention): ElectraAttention(
            (self): ElectraSelfAttention(
              (query): Linear(in_features=1024, out_features=1024, bias=True)
              (key): Linear(in_features=1024, out_features=1024, bias=True)
              (value): Linear(in_features=1024, out_features=1024, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): ElectraSelfOutput(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): ElectraIntermediate(
            (dense): Linear(in_features=1024, out_features=4096, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): ElectraOutput(
            (dense): Linear(in_features=4096, out_features=1024, bias=True)
            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
  (custom_pooling): PoolingLayer()
  (classifier): Classifier(
    (layers): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): SwishGLU(
        (projection): Linear(in_features=1024, out_features=2048, bias=True)
        (activation): SiLU()
      )
      (2): Dropout(p=0.3, inplace=False)
      (3): Linear(in_features=1024, out_features=1024, bias=True)
      (4): SwishGLU(
        (projection): Linear(in_features=1024, out_features=2048, bias=True)
        (activation): SiLU()
      )
      (5): Dropout(p=0.3, inplace=False)
      (6): Linear(in_features=1024, out_features=3, bias=True)
    )
  )
)

Model Parameters:
  bert.embeddings.word_embeddings: 31,254,528 (frozen)
  bert.embeddings.position_embeddings: 524,288 (frozen)
  bert.embeddings.token_type_embeddings: 2,048 (frozen)
  bert.embeddings.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.0.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.0.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.0.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.0.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.0.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.0.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.0.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.0.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.1.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.1.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.1.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.1.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.1.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.1.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.1.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.1.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.2.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.2.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.2.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.2.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.2.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.2.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.2.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.2.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.3.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.3.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.3.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.3.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.3.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.3.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.3.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.3.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.4.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.4.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.4.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.4.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.4.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.4.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.4.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.4.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.5.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.5.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.5.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.5.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.5.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.5.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.5.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.5.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.6.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.6.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.6.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.6.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.6.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.6.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.6.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.6.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.7.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.7.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.7.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.7.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.7.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.7.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.7.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.7.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.8.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.8.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.8.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.8.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.8.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.8.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.8.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.8.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.9.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.9.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.9.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.9.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.9.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.9.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.9.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.9.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.10.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.10.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.10.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.10.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.10.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.10.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.10.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.10.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.11.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.11.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.11.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.11.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.11.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.11.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.11.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.11.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.12.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.12.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.12.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.12.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.12.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.12.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.12.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.12.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.13.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.13.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.13.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.13.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.13.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.13.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.13.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.13.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.14.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.14.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.14.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.14.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.14.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.14.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.14.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.14.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.15.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.15.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.15.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.15.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.15.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.15.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.15.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.15.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.16.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.16.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.16.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.16.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.16.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.16.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.16.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.16.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.17.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.17.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.17.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.17.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.17.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.17.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.17.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.17.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.18.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.18.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.18.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.18.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.18.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.18.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.18.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.18.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.19.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.19.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.19.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.19.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.19.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.19.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.19.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.19.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.20.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.20.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.20.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.20.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.20.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.20.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.20.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.20.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.21.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.21.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.21.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.21.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.21.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.21.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.21.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.21.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.22.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.22.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.22.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.22.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.22.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.22.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.22.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.22.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.23.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.23.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.23.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.23.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.23.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.23.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.23.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.23.output.LayerNorm: 2,048 (frozen)
  classifier.layers.0: 1,049,600 (trainable)
  classifier.layers.1.projection: 2,099,200 (trainable)
  classifier.layers.3: 1,049,600 (trainable)
  classifier.layers.6: 3,075 (trainable)

Total layers: 200
Trainable layers: 4
Total parameters: 338,293,763
Trainable parameters: 4,201,475
Percentage of trainable parameters: 1.24%
Using optimizer: AdamW, Use Zero: True, Base Learning Rate: 0.0002, L2 strength: 0.0001
Layer-wise decay factor: 0.95
Using scheduler: CosineAnnealingWarmRestarts
Scheduler arguments:
- T_0: 5
- T_mult: 1
- eta_min: 1e-07

Starting training loop...
Start epoch: 1, Max Iterations: 50, Early Stop: score, Tolerance: 0.00001, Number Iterations No Change: 50
Epoch 1/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [09:39<00:00, 23.17s/it, loss=1.0611, lr=1.82e-04, grad=M:0.0203, status=Epoch complete]
â–ˆ Epoch  1: Loss T 1.061091 V 1.175930 | F1 T 0.216630 V 0.157012 B 0.157012 SC 0/50 | Acc T 0.481362 V 0.308075 | LR 1.82e-04 | Grad â†“ 0.002931 â†‘ 0.048101 M 0.020267 | 9m 39s
Epoch 2/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [09:35<00:00, 23.03s/it, loss=1.0051, lr=1.33e-04, grad=M:0.0627, status=Epoch complete]
â–ˆ Epoch  2: Loss T 1.005102 V 1.082971 | F1 T 0.226234 V 0.171957 B 0.171957 SC 0/50 | Acc T 0.483977 V 0.312131 | LR 1.33e-04 | Grad â†“ 0.005034 â†‘ 0.205692 M 0.062736 | 9m 35s
Epoch 3/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [09:34<00:00, 23.00s/it, loss=0.9531, lr=7.16e-05, grad=M:0.0408, status=Epoch complete]
â–ˆ Epoch  3: Loss T 0.953098 V 1.076062 | F1 T 0.339917 V 0.286274 B 0.286274 SC 0/50 | Acc T 0.528657 V 0.375000 | LR 7.16e-05 | Grad â†“ 0.002379 â†‘ 0.124627 M 0.040764 | 9m 34s
Epoch 4/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [09:35<00:00, 23.03s/it, loss=0.9365, lr=2.07e-05, grad=M:0.0702, status=Epoch complete]
â–ˆ Epoch  4: Loss T 0.936497 V 1.058967 | F1 T 0.368858 V 0.314983 B 0.314983 SC 0/50 | Acc T 0.548353 V 0.401180 | LR 2.07e-05 | Grad â†“ 0.003738 â†‘ 0.295007 M 0.070159 | 9m 35s
Epoch 5/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [09:35<00:00, 23.01s/it, loss=0.9311, lr=1.32e-07, grad=M:0.0711, status=Epoch complete]
â–ˆ Epoch  5: Loss T 0.931065 V 1.064449 | F1 T 0.372463 V 0.319033 B 0.319033 SC 0/50 | Acc T 0.550919 V 0.405236 | LR 1.32e-07 | Grad â†“ 0.005823 â†‘ 0.313312 M 0.071072 | 9m 35s
Saved model state: checkpoints/checkpoint_epoch_5_20241024-020715.pth
Epoch 6/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [09:35<00:00, 23.00s/it, loss=0.9259, lr=1.82e-04, grad=M:0.1515, status=Epoch complete]
â–ˆ Epoch  6: Loss T 0.925867 V 1.007099 | F1 T 0.422848 V 0.378367 B 0.378367 SC 0/50 | Acc T 0.582494 V 0.466814 | LR 1.82e-04 | Grad â†“ 0.010247 â†‘ 0.743729 M 0.151469 | 9m 35s
Epoch 7/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [04:50<00:00, 11.33s/it, loss=0.8841, lr=1.33e-04, grad=M:0.1100, status=Computing train metrics...]^C
Ctrl+C received. Terminating all processes...
Rank 0 - Current process: MainProcess cleaning up...
Terminating all child processes of MainProcess...
Terminated child process: SpawnProcess-2
Terminated child process: SpawnProcess-8
Terminated child process: SpawnProcess-1
Terminated child process: SpawnProcess-3
Terminated child process: SpawnProcess-7
Terminated child process: SpawnProcess-6
Terminated child process: SpawnProcess-5
Terminated child process: SpawnProcess-4
Rank 0 - Exiting program...
/usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
(nlp) ubuntu@138-2-58-218:~/nlp-osaka/sentiment$ git pull
Username for 'https://github.com': jim@jimbeno.net
Password for 'https://jim@jimbeno.net@github.com': 
remote: Enumerating objects: 7, done.
remote: Counting objects: 100% (7/7), done.
remote: Compressing objects: 100% (1/1), done.
remote: Total 4 (delta 3), reused 4 (delta 3), pack-reused 0 (from 0)
Unpacking objects: 100% (4/4), 1.51 KiB | 20.00 KiB/s, done.
From https://github.com/jbeno/sentiment
   9755466..d4ce292  main       -> origin/main
Updating 9755466..d4ce292
Fast-forward
 ddp_sentiment_finetune.py               | 12 +++++++-----
 torch_ddp_finetune_neural_classifier.py | 57 +++++++++++++++++++++++++++++++++++++++++++++++++++------
 2 files changed, 58 insertions(+), 11 deletions(-)
(nlp) ubuntu@138-2-58-218:~/nlp-osaka/sentiment$ python ./ddp_sentiment_finetune.py --dataset 'merged_local' --weights_name 'google/electra-large-discriminator' --save_data --save_model --save_pickle --save_preds --lr 0.0001 --lr_decay 0.95 --epochs 25 --pooling 'mean' --dropout_rate 0.3 --num_layers 2 --hidden_dim 1024 --hidden_activation 'swishglu' --batch_size 64 --finetune_bert --finetune_layers 6 --l2_strength 0.0001 --checkpoint_interval 5 --use_zero --optimizer 'adamw' --scheduler 'cosine_warmup' --scheduler_kwargs '{"T_0":5, "T_mult":1, "eta_min":1e-7}' --decimal 6 --use_val_split --eval_split 'test' --early_stop 'score' --n_iter_no_change 25 --show_progress --wandb --wandb_project 'Electra Large' --wandb_run 'run_2_merged_ft6' --model_file 'checkpoint_epoch_100_20241024-002635.pth'
^CTraceback (most recent call last):
  File "/home/ubuntu/nlp-osaka/sentiment/./ddp_sentiment_finetune.py", line 28, in <module>
    from torch.distributed.optim import ZeroRedundancyOptimizer
  File "/home/ubuntu/nlp-osaka/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/optim/__init__.py", line 24, in <module>
    from .named_optimizer import _NamedOptimizer
  File "/home/ubuntu/nlp-osaka/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/optim/named_optimizer.py", line 11, in <module>
    from torch.distributed.fsdp import FullyShardedDataParallel as FSDP
  File "/home/ubuntu/nlp-osaka/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/fsdp/__init__.py", line 1, in <module>
    from .flat_param import FlatParameter
  File "/home/ubuntu/nlp-osaka/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/fsdp/flat_param.py", line 30, in <module>
    from torch.distributed.fsdp._common_utils import (
  File "/home/ubuntu/nlp-osaka/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/fsdp/_common_utils.py", line 31, in <module>
    from torch.distributed._tensor.device_mesh import DeviceMesh
  File "/home/ubuntu/nlp-osaka/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/_tensor/__init__.py", line 6, in <module>
    import torch.distributed._tensor.ops
  File "/home/ubuntu/nlp-osaka/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/_tensor/ops/__init__.py", line 2, in <module>
    from .embedding_ops import *  # noqa: F403
  File "/home/ubuntu/nlp-osaka/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/_tensor/ops/embedding_ops.py", line 5, in <module>
    from torch.distributed._tensor.op_schema import OpSchema, OutputSharding
  File "/home/ubuntu/nlp-osaka/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/_tensor/op_schema.py", line 5, in <module>
    from torch.distributed._tensor.placement_types import DTensorSpec
  File "/home/ubuntu/nlp-osaka/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/_tensor/placement_types.py", line 7, in <module>
    import torch.distributed._functional_collectives as funcol
  File "/home/ubuntu/nlp-osaka/sentiment/nlp/lib/python3.10/site-packages/torch/distributed/_functional_collectives.py", line 20, in <module>
    from torch._dynamo.external_utils import is_compiling as is_torchdynamo_compiling
  File "/home/ubuntu/nlp-osaka/sentiment/nlp/lib/python3.10/site-packages/torch/_dynamo/__init__.py", line 2, in <module>
    from . import allowed_functions, convert_frame, eval_frame, resume_execution
  File "/home/ubuntu/nlp-osaka/sentiment/nlp/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 44, in <module>
    from .guards import CheckFunctionManager, GuardedCode
  File "/home/ubuntu/nlp-osaka/sentiment/nlp/lib/python3.10/site-packages/torch/_dynamo/guards.py", line 28, in <module>
    from torch._dynamo.source import (
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1002, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 945, in _find_spec
  File "<frozen importlib._bootstrap_external>", line 1439, in find_spec
  File "<frozen importlib._bootstrap_external>", line 1411, in _get_spec
  File "<frozen importlib._bootstrap_external>", line 1544, in find_spec
  File "<frozen importlib._bootstrap_external>", line 147, in _path_stat
KeyboardInterrupt
^C
(nlp) ubuntu@138-2-58-218:~/nlp-osaka/sentiment$ ^C
(nlp) ubuntu@138-2-58-218:~/nlp-osaka/sentiment$ python ./ddp_sentiment_finetune.py --dataset 'merged_local' --weights_name 'google/electra-large-discriminator' --save_data --save_model --save_pickle --save_preds --lr 0.0001 --lr_decay 0.95 --epochs 25 --pooling 'mean' --dropout_rate 0.3 --num_layers 2 --hidden_dim 1024 --hidden_activation 'swishglu' --batch_size 64 --finetune_bert --finetune_layers 6 --l2_strength 0.0001 --checkpoint_interval 5 --use_zero --optimizer 'adamw' --scheduler 'cosine_warmup' --scheduler_kwargs '{"T_0":5, "T_mult":1, "eta_min":1e-7}' --decimal 6 --use_val_split --eval_split 'test' --early_stop 'score' --n_iter_no_change 25 --show_progress --wandb --wandb_project 'Electra Large' --wandb_run 'run_2_merged_ft6' --model_file 'checkpoint_epoch_100_20241024-002635.pth' --load_classifier_only

Starting DDP PyTorch Training...
Device: cuda, Number of GPUs: 8
Spawning 8 processes...
Rank 3 - Device: cuda:3
Rank 1 - Device: cuda:1
Rank 2 - Device: cuda:2
Rank 5 - Device: cuda:5
Rank 7 - Device: cuda:7
Rank 4 - Device: cuda:4
Rank 6 - Device: cuda:6
Rank 0 - Device: cuda:0
8 process groups initialized with 'nccl' backend on localhost:12355
NCCL Timeout: 1 hr 0 min. NCCL Blocking Wait: Enabled
wandb: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: jbeno (jimbeno). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.5
wandb: Run data is saved locally in /home/ubuntu/nlp-osaka/sentiment/wandb/run-20241024_022758-gcobol3t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run run_2_merged_ft6
wandb: â­ï¸ View project at https://wandb.ai/jimbeno/Electra%20Large
wandb: ðŸš€ View run at https://wandb.ai/jimbeno/Electra%20Large/runs/gcobol3t
Wand run initialized.

Initializing 'google/electra-large-discriminator' tokenizer and model...
Checking for local files...
Found all files in cache, skipping download
All ranks loading tokenizer from local files...
All ranks loading model from local files...
Tokenizer and model initialized (6s)

Loading data...
Using the same dataset for training and evaluation
Splits:
- Train: Using merged_local 'train' split
- Validation: Using merged_local 'validation' split
- Evaluation: Using merged_local 'test' split
Train Data: Merged DynaSent Round 1, Round 2 and SST from Local: 'data/merged'
Validation Data: Merged DynaSent Round 1, Round 2 and SST from Local: 'data/merged'
Evaluation Data: Merged DynaSent Round 1, Round 2 and SST from Local: 'data/merged'
Train size: 102097
Validation size: 5421
Evaluation size: 5421
Train label distribution:
	      Negative: 21910
	       Neutral: 49148
	      Positive: 31039
Validation label distribution:
	      Negative: 1868
	       Neutral: 1669
	      Positive: 1884
Evaluation label distribution:
	      Negative: 1868
	       Neutral: 1669
	      Positive: 1884
Data loaded (2s)

Processing data...
(Batch size: 64, Pooling: Mean, Fine Tune BERT: True, Chunk size: None)...
Extracting sentences and labels...

Data saved to: saves/data_8_gpu_20241024-022809.npz
X Train shape: [102097], X Validation shape: [5421], X Test shape: [5421]
y Train shape: [102097], y Validation shape: [5421], y Test shape: [5421]
Data processed (865ms)

Initializing DDP Neural Classifier...
Layers: 2, Hidden Dim: 1024, Hidden Act: SwishGLU, Dropout: 0.3, Optimizer: AdamW, L2 Strength: 0.0001, Pooling: MEAN, Accumulation Steps: 1, Max Grad Norm: None
Batch Size: 64, Max Epochs: 25, LR: 0.0001, Early Stop: score, Fine-tune BERT: True, Fine-tune Layers: 6, Freeze BERT: False, Target Score: None, Interactive: False
Loading model from: checkpoints/checkpoint_epoch_100_20241024-002635.pth...
Loaded checkpoint: checkpoints/checkpoint_epoch_100_20241024-002635.pth
Retrieved model state dictionary.
Retrieved optimizer state dictionary.
Classifier initialized (1s)

Fitting DDP Neural Classifier on training data...
Num Workers: 0, Prefetch: None
Score-based early stopping enabled (macro average F1 score against validation set). Validation fraction: 0.1
Training will stop early if the score does not improve by at least 0.00001 for 25 iterations.
Using provided validation set for early stopping.
Building dataset and dataloader...
Initializing model, graph, optimizer...
BERT's original pooler removed. Using custom pooling type: mean
BERT has 75,577,344 trainable parameters and 258,514,944 non-trainable parameters
Number of BERT layers requiring gradients: 6 out of 24
Fine-tuning the last 6 out of 24 BERT layers

Model Architecture Summary:
BERTClassifier(
  (bert): ElectraModel(
    (embeddings): ElectraEmbeddings(
      (word_embeddings): Embedding(30522, 1024, padding_idx=0)
      (position_embeddings): Embedding(512, 1024)
      (token_type_embeddings): Embedding(2, 1024)
      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): ElectraEncoder(
      (layer): ModuleList(
        (0-23): 24 x ElectraLayer(
          (attention): ElectraAttention(
            (self): ElectraSelfAttention(
              (query): Linear(in_features=1024, out_features=1024, bias=True)
              (key): Linear(in_features=1024, out_features=1024, bias=True)
              (value): Linear(in_features=1024, out_features=1024, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): ElectraSelfOutput(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): ElectraIntermediate(
            (dense): Linear(in_features=1024, out_features=4096, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): ElectraOutput(
            (dense): Linear(in_features=4096, out_features=1024, bias=True)
            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
  (custom_pooling): PoolingLayer()
  (classifier): Classifier(
    (layers): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): SwishGLU(
        (projection): Linear(in_features=1024, out_features=2048, bias=True)
        (activation): SiLU()
      )
      (2): Dropout(p=0.3, inplace=False)
      (3): Linear(in_features=1024, out_features=1024, bias=True)
      (4): SwishGLU(
        (projection): Linear(in_features=1024, out_features=2048, bias=True)
        (activation): SiLU()
      )
      (5): Dropout(p=0.3, inplace=False)
      (6): Linear(in_features=1024, out_features=3, bias=True)
    )
  )
)

Model Parameters:
  bert.embeddings.word_embeddings: 31,254,528 (frozen)
  bert.embeddings.position_embeddings: 524,288 (frozen)
  bert.embeddings.token_type_embeddings: 2,048 (frozen)
  bert.embeddings.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.0.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.0.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.0.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.0.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.0.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.0.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.0.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.0.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.1.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.1.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.1.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.1.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.1.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.1.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.1.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.1.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.2.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.2.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.2.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.2.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.2.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.2.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.2.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.2.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.3.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.3.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.3.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.3.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.3.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.3.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.3.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.3.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.4.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.4.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.4.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.4.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.4.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.4.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.4.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.4.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.5.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.5.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.5.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.5.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.5.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.5.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.5.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.5.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.6.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.6.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.6.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.6.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.6.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.6.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.6.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.6.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.7.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.7.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.7.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.7.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.7.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.7.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.7.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.7.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.8.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.8.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.8.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.8.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.8.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.8.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.8.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.8.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.9.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.9.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.9.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.9.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.9.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.9.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.9.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.9.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.10.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.10.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.10.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.10.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.10.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.10.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.10.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.10.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.11.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.11.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.11.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.11.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.11.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.11.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.11.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.11.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.12.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.12.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.12.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.12.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.12.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.12.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.12.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.12.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.13.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.13.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.13.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.13.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.13.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.13.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.13.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.13.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.14.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.14.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.14.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.14.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.14.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.14.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.14.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.14.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.15.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.15.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.15.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.15.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.15.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.15.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.15.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.15.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.16.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.16.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.16.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.16.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.16.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.16.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.16.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.16.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.17.attention.self.query: 1,049,600 (frozen)
  bert.encoder.layer.17.attention.self.key: 1,049,600 (frozen)
  bert.encoder.layer.17.attention.self.value: 1,049,600 (frozen)
  bert.encoder.layer.17.attention.output.dense: 1,049,600 (frozen)
  bert.encoder.layer.17.attention.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.17.intermediate.dense: 4,198,400 (frozen)
  bert.encoder.layer.17.output.dense: 4,195,328 (frozen)
  bert.encoder.layer.17.output.LayerNorm: 2,048 (frozen)
  bert.encoder.layer.18.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.18.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.18.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.18.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.18.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.18.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.18.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.18.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.19.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.19.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.19.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.19.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.19.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.19.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.19.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.19.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.20.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.20.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.20.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.20.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.20.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.20.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.20.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.20.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.21.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.21.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.21.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.21.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.21.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.21.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.21.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.21.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.22.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.22.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.22.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.22.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.22.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.22.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.22.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.22.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.23.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.23.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.23.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.23.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.23.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.23.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.23.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.23.output.LayerNorm: 2,048 (trainable)
  classifier.layers.0: 1,049,600 (trainable)
  classifier.layers.1.projection: 2,099,200 (trainable)
  classifier.layers.3: 1,049,600 (trainable)
  classifier.layers.6: 3,075 (trainable)

Total layers: 200
Trainable layers: 52
Total parameters: 338,293,763
Trainable parameters: 79,778,819
Percentage of trainable parameters: 23.58%
Using optimizer: AdamW, Use Zero: True, Base Learning Rate: 0.0001, L2 strength: 0.0001
Layer-wise decay factor: 0.95
Using scheduler: CosineAnnealingWarmRestarts
Scheduler arguments:
- T_0: 5
- T_mult: 1
- eta_min: 1e-07
An error occurred during training: Error(s) in loading state_dict for BERTClassifier:
	Missing key(s) in state_dict: "bert.embeddings.word_embeddings.weight", "bert.embeddings.position_embeddings.weight", "bert.embeddings.token_type_embeddings.weight", "bert.embeddings.LayerNorm.weight", "bert.embeddings.LayerNorm.bias", "bert.encoder.layer.0.attention.self.query.weight", "bert.encoder.layer.0.attention.self.query.bias", "bert.encoder.layer.0.attention.self.key.weight", "bert.encoder.layer.0.attention.self.key.bias", "bert.encoder.layer.0.attention.self.value.weight", "bert.encoder.layer.0.attention.self.value.bias", "bert.encoder.layer.0.attention.output.dense.weight", "bert.encoder.layer.0.attention.output.dense.bias", "bert.encoder.layer.0.attention.output.LayerNorm.weight", "bert.encoder.layer.0.attention.output.LayerNorm.bias", "bert.encoder.layer.0.intermediate.dense.weight", "bert.encoder.layer.0.intermediate.dense.bias", "bert.encoder.layer.0.output.dense.weight", "bert.encoder.layer.0.output.dense.bias", "bert.encoder.layer.0.output.LayerNorm.weight", "bert.encoder.layer.0.output.LayerNorm.bias", "bert.encoder.layer.1.attention.self.query.weight", "bert.encoder.layer.1.attention.self.query.bias", "bert.encoder.layer.1.attention.self.key.weight", "bert.encoder.layer.1.attention.self.key.bias", "bert.encoder.layer.1.attention.self.value.weight", "bert.encoder.layer.1.attention.self.value.bias", "bert.encoder.layer.1.attention.output.dense.weight", "bert.encoder.layer.1.attention.output.dense.bias", "bert.encoder.layer.1.attention.output.LayerNorm.weight", "bert.encoder.layer.1.attention.output.LayerNorm.bias", "bert.encoder.layer.1.intermediate.dense.weight", "bert.encoder.layer.1.intermediate.dense.bias", "bert.encoder.layer.1.output.dense.weight", "bert.encoder.layer.1.output.dense.bias", "bert.encoder.layer.1.output.LayerNorm.weight", "bert.encoder.layer.1.output.LayerNorm.bias", "bert.encoder.layer.2.attention.self.query.weight", "bert.encoder.layer.2.attention.self.query.bias", "bert.encoder.layer.2.attention.self.key.weight", "bert.encoder.layer.2.attention.self.key.bias", "bert.encoder.layer.2.attention.self.value.weight", "bert.encoder.layer.2.attention.self.value.bias", "bert.encoder.layer.2.attention.output.dense.weight", "bert.encoder.layer.2.attention.output.dense.bias", "bert.encoder.layer.2.attention.output.LayerNorm.weight", "bert.encoder.layer.2.attention.output.LayerNorm.bias", "bert.encoder.layer.2.intermediate.dense.weight", "bert.encoder.layer.2.intermediate.dense.bias", "bert.encoder.layer.2.output.dense.weight", "bert.encoder.layer.2.output.dense.bias", "bert.encoder.layer.2.output.LayerNorm.weight", "bert.encoder.layer.2.output.LayerNorm.bias", "bert.encoder.layer.3.attention.self.query.weight", "bert.encoder.layer.3.attention.self.query.bias", "bert.encoder.layer.3.attention.self.key.weight", "bert.encoder.layer.3.attention.self.key.bias", "bert.encoder.layer.3.attention.self.value.weight", "bert.encoder.layer.3.attention.self.value.bias", "bert.encoder.layer.3.attention.output.dense.weight", "bert.encoder.layer.3.attention.output.dense.bias", "bert.encoder.layer.3.attention.output.LayerNorm.weight", "bert.encoder.layer.3.attention.output.LayerNorm.bias", "bert.encoder.layer.3.intermediate.dense.weight", "bert.encoder.layer.3.intermediate.dense.bias", "bert.encoder.layer.3.output.dense.weight", "bert.encoder.layer.3.output.dense.bias", "bert.encoder.layer.3.output.LayerNorm.weight", "bert.encoder.layer.3.output.LayerNorm.bias", "bert.encoder.layer.4.attention.self.query.weight", "bert.encoder.layer.4.attention.self.query.bias", "bert.encoder.layer.4.attention.self.key.weight", "bert.encoder.layer.4.attention.self.key.bias", "bert.encoder.layer.4.attention.self.value.weight", "bert.encoder.layer.4.attention.self.value.bias", "bert.encoder.layer.4.attention.output.dense.weight", "bert.encoder.layer.4.attention.output.dense.bias", "bert.encoder.layer.4.attention.output.LayerNorm.weight", "bert.encoder.layer.4.attention.output.LayerNorm.bias", "bert.encoder.layer.4.intermediate.dense.weight", "bert.encoder.layer.4.intermediate.dense.bias", "bert.encoder.layer.4.output.dense.weight", "bert.encoder.layer.4.output.dense.bias", "bert.encoder.layer.4.output.LayerNorm.weight", "bert.encoder.layer.4.output.LayerNorm.bias", "bert.encoder.layer.5.attention.self.query.weight", "bert.encoder.layer.5.attention.self.query.bias", "bert.encoder.layer.5.attention.self.key.weight", "bert.encoder.layer.5.attention.self.key.bias", "bert.encoder.layer.5.attention.self.value.weight", "bert.encoder.layer.5.attention.self.value.bias", "bert.encoder.layer.5.attention.output.dense.weight", "bert.encoder.layer.5.attention.output.dense.bias", "bert.encoder.layer.5.attention.output.LayerNorm.weight", "bert.encoder.layer.5.attention.output.LayerNorm.bias", "bert.encoder.layer.5.intermediate.dense.weight", "bert.encoder.layer.5.intermediate.dense.bias", "bert.encoder.layer.5.output.dense.weight", "bert.encoder.layer.5.output.dense.bias", "bert.encoder.layer.5.output.LayerNorm.weight", "bert.encoder.layer.5.output.LayerNorm.bias", "bert.encoder.layer.6.attention.self.query.weight", "bert.encoder.layer.6.attention.self.query.bias", "bert.encoder.layer.6.attention.self.key.weight", "bert.encoder.layer.6.attention.self.key.bias", "bert.encoder.layer.6.attention.self.value.weight", "bert.encoder.layer.6.attention.self.value.bias", "bert.encoder.layer.6.attention.output.dense.weight", "bert.encoder.layer.6.attention.output.dense.bias", "bert.encoder.layer.6.attention.output.LayerNorm.weight", "bert.encoder.layer.6.attention.output.LayerNorm.bias", "bert.encoder.layer.6.intermediate.dense.weight", "bert.encoder.layer.6.intermediate.dense.bias", "bert.encoder.layer.6.output.dense.weight", "bert.encoder.layer.6.output.dense.bias", "bert.encoder.layer.6.output.LayerNorm.weight", "bert.encoder.layer.6.output.LayerNorm.bias", "bert.encoder.layer.7.attention.self.query.weight", "bert.encoder.layer.7.attention.self.query.bias", "bert.encoder.layer.7.attention.self.key.weight", "bert.encoder.layer.7.attention.self.key.bias", "bert.encoder.layer.7.attention.self.value.weight", "bert.encoder.layer.7.attention.self.value.bias", "bert.encoder.layer.7.attention.output.dense.weight", "bert.encoder.layer.7.attention.output.dense.bias", "bert.encoder.layer.7.attention.output.LayerNorm.weight", "bert.encoder.layer.7.attention.output.LayerNorm.bias", "bert.encoder.layer.7.intermediate.dense.weight", "bert.encoder.layer.7.intermediate.dense.bias", "bert.encoder.layer.7.output.dense.weight", "bert.encoder.layer.7.output.dense.bias", "bert.encoder.layer.7.output.LayerNorm.weight", "bert.encoder.layer.7.output.LayerNorm.bias", "bert.encoder.layer.8.attention.self.query.weight", "bert.encoder.layer.8.attention.self.query.bias", "bert.encoder.layer.8.attention.self.key.weight", "bert.encoder.layer.8.attention.self.key.bias", "bert.encoder.layer.8.attention.self.value.weight", "bert.encoder.layer.8.attention.self.value.bias", "bert.encoder.layer.8.attention.output.dense.weight", "bert.encoder.layer.8.attention.output.dense.bias", "bert.encoder.layer.8.attention.output.LayerNorm.weight", "bert.encoder.layer.8.attention.output.LayerNorm.bias", "bert.encoder.layer.8.intermediate.dense.weight", "bert.encoder.layer.8.intermediate.dense.bias", "bert.encoder.layer.8.output.dense.weight", "bert.encoder.layer.8.output.dense.bias", "bert.encoder.layer.8.output.LayerNorm.weight", "bert.encoder.layer.8.output.LayerNorm.bias", "bert.encoder.layer.9.attention.self.query.weight", "bert.encoder.layer.9.attention.self.query.bias", "bert.encoder.layer.9.attention.self.key.weight", "bert.encoder.layer.9.attention.self.key.bias", "bert.encoder.layer.9.attention.self.value.weight", "bert.encoder.layer.9.attention.self.value.bias", "bert.encoder.layer.9.attention.output.dense.weight", "bert.encoder.layer.9.attention.output.dense.bias", "bert.encoder.layer.9.attention.output.LayerNorm.weight", "bert.encoder.layer.9.attention.output.LayerNorm.bias", "bert.encoder.layer.9.intermediate.dense.weight", "bert.encoder.layer.9.intermediate.dense.bias", "bert.encoder.layer.9.output.dense.weight", "bert.encoder.layer.9.output.dense.bias", "bert.encoder.layer.9.output.LayerNorm.weight", "bert.encoder.layer.9.output.LayerNorm.bias", "bert.encoder.layer.10.attention.self.query.weight", "bert.encoder.layer.10.attention.self.query.bias", "bert.encoder.layer.10.attention.self.key.weight", "bert.encoder.layer.10.attention.self.key.bias", "bert.encoder.layer.10.attention.self.value.weight", "bert.encoder.layer.10.attention.self.value.bias", "bert.encoder.layer.10.attention.output.dense.weight", "bert.encoder.layer.10.attention.output.dense.bias", "bert.encoder.layer.10.attention.output.LayerNorm.weight", "bert.encoder.layer.10.attention.output.LayerNorm.bias", "bert.encoder.layer.10.intermediate.dense.weight", "bert.encoder.layer.10.intermediate.dense.bias", "bert.encoder.layer.10.output.dense.weight", "bert.encoder.layer.10.output.dense.bias", "bert.encoder.layer.10.output.LayerNorm.weight", "bert.encoder.layer.10.output.LayerNorm.bias", "bert.encoder.layer.11.attention.self.query.weight", "bert.encoder.layer.11.attention.self.query.bias", "bert.encoder.layer.11.attention.self.key.weight", "bert.encoder.layer.11.attention.self.key.bias", "bert.encoder.layer.11.attention.self.value.weight", "bert.encoder.layer.11.attention.self.value.bias", "bert.encoder.layer.11.attention.output.dense.weight", "bert.encoder.layer.11.attention.output.dense.bias", "bert.encoder.layer.11.attention.output.LayerNorm.weight", "bert.encoder.layer.11.attention.output.LayerNorm.bias", "bert.encoder.layer.11.intermediate.dense.weight", "bert.encoder.layer.11.intermediate.dense.bias", "bert.encoder.layer.11.output.dense.weight", "bert.encoder.layer.11.output.dense.bias", "bert.encoder.layer.11.output.LayerNorm.weight", "bert.encoder.layer.11.output.LayerNorm.bias", "bert.encoder.layer.12.attention.self.query.weight", "bert.encoder.layer.12.attention.self.query.bias", "bert.encoder.layer.12.attention.self.key.weight", "bert.encoder.layer.12.attention.self.key.bias", "bert.encoder.layer.12.attention.self.value.weight", "bert.encoder.layer.12.attention.self.value.bias", "bert.encoder.layer.12.attention.output.dense.weight", "bert.encoder.layer.12.attention.output.dense.bias", "bert.encoder.layer.12.attention.output.LayerNorm.weight", "bert.encoder.layer.12.attention.output.LayerNorm.bias", "bert.encoder.layer.12.intermediate.dense.weight", "bert.encoder.layer.12.intermediate.dense.bias", "bert.encoder.layer.12.output.dense.weight", "bert.encoder.layer.12.output.dense.bias", "bert.encoder.layer.12.output.LayerNorm.weight", "bert.encoder.layer.12.output.LayerNorm.bias", "bert.encoder.layer.13.attention.self.query.weight", "bert.encoder.layer.13.attention.self.query.bias", "bert.encoder.layer.13.attention.self.key.weight", "bert.encoder.layer.13.attention.self.key.bias", "bert.encoder.layer.13.attention.self.value.weight", "bert.encoder.layer.13.attention.self.value.bias", "bert.encoder.layer.13.attention.output.dense.weight", "bert.encoder.layer.13.attention.output.dense.bias", "bert.encoder.layer.13.attention.output.LayerNorm.weight", "bert.encoder.layer.13.attention.output.LayerNorm.bias", "bert.encoder.layer.13.intermediate.dense.weight", "bert.encoder.layer.13.intermediate.dense.bias", "bert.encoder.layer.13.output.dense.weight", "bert.encoder.layer.13.output.dense.bias", "bert.encoder.layer.13.output.LayerNorm.weight", "bert.encoder.layer.13.output.LayerNorm.bias", "bert.encoder.layer.14.attention.self.query.weight", "bert.encoder.layer.14.attention.self.query.bias", "bert.encoder.layer.14.attention.self.key.weight", "bert.encoder.layer.14.attention.self.key.bias", "bert.encoder.layer.14.attention.self.value.weight", "bert.encoder.layer.14.attention.self.value.bias", "bert.encoder.layer.14.attention.output.dense.weight", "bert.encoder.layer.14.attention.output.dense.bias", "bert.encoder.layer.14.attention.output.LayerNorm.weight", "bert.encoder.layer.14.attention.output.LayerNorm.bias", "bert.encoder.layer.14.intermediate.dense.weight", "bert.encoder.layer.14.intermediate.dense.bias", "bert.encoder.layer.14.output.dense.weight", "bert.encoder.layer.14.output.dense.bias", "bert.encoder.layer.14.output.LayerNorm.weight", "bert.encoder.layer.14.output.LayerNorm.bias", "bert.encoder.layer.15.attention.self.query.weight", "bert.encoder.layer.15.attention.self.query.bias", "bert.encoder.layer.15.attention.self.key.weight", "bert.encoder.layer.15.attention.self.key.bias", "bert.encoder.layer.15.attention.self.value.weight", "bert.encoder.layer.15.attention.self.value.bias", "bert.encoder.layer.15.attention.output.dense.weight", "bert.encoder.layer.15.attention.output.dense.bias", "bert.encoder.layer.15.attention.output.LayerNorm.weight", "bert.encoder.layer.15.attention.output.LayerNorm.bias", "bert.encoder.layer.15.intermediate.dense.weight", "bert.encoder.layer.15.intermediate.dense.bias", "bert.encoder.layer.15.output.dense.weight", "bert.encoder.layer.15.output.dense.bias", "bert.encoder.layer.15.output.LayerNorm.weight", "bert.encoder.layer.15.output.LayerNorm.bias", "bert.encoder.layer.16.attention.self.query.weight", "bert.encoder.layer.16.attention.self.query.bias", "bert.encoder.layer.16.attention.self.key.weight", "bert.encoder.layer.16.attention.self.key.bias", "bert.encoder.layer.16.attention.self.value.weight", "bert.encoder.layer.16.attention.self.value.bias", "bert.encoder.layer.16.attention.output.dense.weight", "bert.encoder.layer.16.attention.output.dense.bias", "bert.encoder.layer.16.attention.output.LayerNorm.weight", "bert.encoder.layer.16.attention.output.LayerNorm.bias", "bert.encoder.layer.16.intermediate.dense.weight", "bert.encoder.layer.16.intermediate.dense.bias", "bert.encoder.layer.16.output.dense.weight", "bert.encoder.layer.16.output.dense.bias", "bert.encoder.layer.16.output.LayerNorm.weight", "bert.encoder.layer.16.output.LayerNorm.bias", "bert.encoder.layer.17.attention.self.query.weight", "bert.encoder.layer.17.attention.self.query.bias", "bert.encoder.layer.17.attention.self.key.weight", "bert.encoder.layer.17.attention.self.key.bias", "bert.encoder.layer.17.attention.self.value.weight", "bert.encoder.layer.17.attention.self.value.bias", "bert.encoder.layer.17.attention.output.dense.weight", "bert.encoder.layer.17.attention.output.dense.bias", "bert.encoder.layer.17.attention.output.LayerNorm.weight", "bert.encoder.layer.17.attention.output.LayerNorm.bias", "bert.encoder.layer.17.intermediate.dense.weight", "bert.encoder.layer.17.intermediate.dense.bias", "bert.encoder.layer.17.output.dense.weight", "bert.encoder.layer.17.output.dense.bias", "bert.encoder.layer.17.output.LayerNorm.weight", "bert.encoder.layer.17.output.LayerNorm.bias", "bert.encoder.layer.18.attention.self.query.weight", "bert.encoder.layer.18.attention.self.query.bias", "bert.encoder.layer.18.attention.self.key.weight", "bert.encoder.layer.18.attention.self.key.bias", "bert.encoder.layer.18.attention.self.value.weight", "bert.encoder.layer.18.attention.self.value.bias", "bert.encoder.layer.18.attention.output.dense.weight", "bert.encoder.layer.18.attention.output.dense.bias", "bert.encoder.layer.18.attention.output.LayerNorm.weight", "bert.encoder.layer.18.attention.output.LayerNorm.bias", "bert.encoder.layer.18.intermediate.dense.weight", "bert.encoder.layer.18.intermediate.dense.bias", "bert.encoder.layer.18.output.dense.weight", "bert.encoder.layer.18.output.dense.bias", "bert.encoder.layer.18.output.LayerNorm.weight", "bert.encoder.layer.18.output.LayerNorm.bias", "bert.encoder.layer.19.attention.self.query.weight", "bert.encoder.layer.19.attention.self.query.bias", "bert.encoder.layer.19.attention.self.key.weight", "bert.encoder.layer.19.attention.self.key.bias", "bert.encoder.layer.19.attention.self.value.weight", "bert.encoder.layer.19.attention.self.value.bias", "bert.encoder.layer.19.attention.output.dense.weight", "bert.encoder.layer.19.attention.output.dense.bias", "bert.encoder.layer.19.attention.output.LayerNorm.weight", "bert.encoder.layer.19.attention.output.LayerNorm.bias", "bert.encoder.layer.19.intermediate.dense.weight", "bert.encoder.layer.19.intermediate.dense.bias", "bert.encoder.layer.19.output.dense.weight", "bert.encoder.layer.19.output.dense.bias", "bert.encoder.layer.19.output.LayerNorm.weight", "bert.encoder.layer.19.output.LayerNorm.bias", "bert.encoder.layer.20.attention.self.query.weight", "bert.encoder.layer.20.attention.self.query.bias", "bert.encoder.layer.20.attention.self.key.weight", "bert.encoder.layer.20.attention.self.key.bias", "bert.encoder.layer.20.attention.self.value.weight", "bert.encoder.layer.20.attention.self.value.bias", "bert.encoder.layer.20.attention.output.dense.weight", "bert.encoder.layer.20.attention.output.dense.bias", "bert.encoder.layer.20.attention.output.LayerNorm.weight", "bert.encoder.layer.20.attention.output.LayerNorm.bias", "bert.encoder.layer.20.intermediate.dense.weight", "bert.encoder.layer.20.intermediate.dense.bias", "bert.encoder.layer.20.output.dense.weight", "bert.encoder.layer.20.output.dense.bias", "bert.encoder.layer.20.output.LayerNorm.weight", "bert.encoder.layer.20.output.LayerNorm.bias", "bert.encoder.layer.21.attention.self.query.weight", "bert.encoder.layer.21.attention.self.query.bias", "bert.encoder.layer.21.attention.self.key.weight", "bert.encoder.layer.21.attention.self.key.bias", "bert.encoder.layer.21.attention.self.value.weight", "bert.encoder.layer.21.attention.self.value.bias", "bert.encoder.layer.21.attention.output.dense.weight", "bert.encoder.layer.21.attention.output.dense.bias", "bert.encoder.layer.21.attention.output.LayerNorm.weight", "bert.encoder.layer.21.attention.output.LayerNorm.bias", "bert.encoder.layer.21.intermediate.dense.weight", "bert.encoder.layer.21.intermediate.dense.bias", "bert.encoder.layer.21.output.dense.weight", "bert.encoder.layer.21.output.dense.bias", "bert.encoder.layer.21.output.LayerNorm.weight", "bert.encoder.layer.21.output.LayerNorm.bias", "bert.encoder.layer.22.attention.self.query.weight", "bert.encoder.layer.22.attention.self.query.bias", "bert.encoder.layer.22.attention.self.key.weight", "bert.encoder.layer.22.attention.self.key.bias", "bert.encoder.layer.22.attention.self.value.weight", "bert.encoder.layer.22.attention.self.value.bias", "bert.encoder.layer.22.attention.output.dense.weight", "bert.encoder.layer.22.attention.output.dense.bias", "bert.encoder.layer.22.attention.output.LayerNorm.weight", "bert.encoder.layer.22.attention.output.LayerNorm.bias", "bert.encoder.layer.22.intermediate.dense.weight", "bert.encoder.layer.22.intermediate.dense.bias", "bert.encoder.layer.22.output.dense.weight", "bert.encoder.layer.22.output.dense.bias", "bert.encoder.layer.22.output.LayerNorm.weight", "bert.encoder.layer.22.output.LayerNorm.bias", "bert.encoder.layer.23.attention.self.query.weight", "bert.encoder.layer.23.attention.self.query.bias", "bert.encoder.layer.23.attention.self.key.weight", "bert.encoder.layer.23.attention.self.key.bias", "bert.encoder.layer.23.attention.self.value.weight", "bert.encoder.layer.23.attention.self.value.bias", "bert.encoder.layer.23.attention.output.dense.weight", "bert.encoder.layer.23.attention.output.dense.bias", "bert.encoder.layer.23.attention.output.LayerNorm.weight", "bert.encoder.layer.23.attention.output.LayerNorm.bias", "bert.encoder.layer.23.intermediate.dense.weight", "bert.encoder.layer.23.intermediate.dense.bias", "bert.encoder.layer.23.output.dense.weight", "bert.encoder.layer.23.output.dense.bias", "bert.encoder.layer.23.output.LayerNorm.weight", "bert.encoder.layer.23.output.LayerNorm.bias". An error occurred during training: Error(s) in loading state_dict for BERTClassifier:
	Missing key(s) in state_dict: "bert.embeddings.word_embeddings.weight", "bert.embeddings.position_embeddings.weight", "bert.embeddings.token_type_embeddings.weight", "bert.embeddings.LayerNorm.weight", "bert.embeddings.LayerNorm.bias", "bert.encoder.layer.0.attention.self.query.weight", "bert.encoder.layer.0.attention.self.query.bias", "bert.encoder.layer.0.attention.self.key.weight", "bert.encoder.layer.0.attention.self.key.bias", "bert.encoder.layer.0.attention.self.value.weight", "bert.encoder.layer.0.attention.self.value.bias", "bert.encoder.layer.0.attention.output.dense.weight", "bert.encoder.layer.0.attention.output.dense.bias", "bert.encoder.layer.0.attention.output.LayerNorm.weight", "bert.encoder.layer.0.attention.output.LayerNorm.bias", "bert.encoder.layer.0.intermediate.dense.weight", "bert.encoder.layer.0.intermediate.dense.bias", "bert.encoder.layer.0.output.dense.weight", "bert.encoder.layer.0.output.dense.bias", "bert.encoder.layer.0.output.LayerNorm.weight", "bert.encoder.layer.0.output.LayerNorm.bias", "bert.encoder.layer.1.attention.self.query.weight", "bert.encoder.layer.1.attention.self.query.bias", "bert.encoder.layer.1.attention.self.key.weight", "bert.encoder.layer.1.attention.self.key.bias", "bert.encoder.layer.1.attention.self.value.weight", "bert.encoder.layer.1.attention.self.value.bias", "bert.encoder.layer.1.attention.output.dense.weight", "bert.encoder.layer.1.attention.output.dense.bias", "bert.encoder.layer.1.attention.output.LayerNorm.weight", "bert.encoder.layer.1.attention.output.LayerNorm.bias", "bert.encoder.layer.1.intermediate.dense.weight", "bert.encoder.layer.1.intermediate.dense.bias", "bert.encoder.layer.1.output.dense.weight", "bert.encoder.layer.1.output.dense.bias", "bert.encoder.layer.1.output.LayerNorm.weight", "bert.encoder.layer.1.output.LayerNorm.bias", "bert.encoder.layer.2.attention.self.query.weight", "bert.encoder.layer.2.attention.self.query.bias", "bert.encoder.layer.2.attention.self.key.weight", "bert.encoder.layer.2.attention.self.key.bias", "bert.encoder.layer.2.attention.self.value.weight", "bert.encoder.layer.2.attention.self.value.bias", "bert.encoder.layer.2.attention.output.dense.weight", "bert.encoder.layer.2.attention.output.dense.bias", "bert.encoder.layer.2.attention.output.LayerNorm.weight", "bert.encoder.layer.2.attention.output.LayerNorm.bias", "bert.encoder.layer.2.intermediate.dense.weight", "bert.encoder.layer.2.intermediate.dense.bias", "bert.encoder.layer.2.output.dense.weight", "bert.encoder.layer.2.output.dense.bias", "bert.encoder.layer.2.output.LayerNorm.weight", "bert.encoder.layer.2.output.LayerNorm.bias", "bert.encoder.layer.3.attention.self.query.weight", "bert.encoder.layer.3.attention.self.query.bias", "bert.encoder.layer.3.attention.self.key.weight", "bert.encoder.layer.3.attention.self.key.bias", "bert.encoder.layer.3.attention.self.value.weight", "bert.encoder.layer.3.attention.self.value.bias", "bert.encoder.layer.3.attention.output.dense.weight", "bert.encoder.layer.3.attention.output.dense.bias", "bert.encoder.layer.3.attention.output.LayerNorm.weight", "bert.encoder.layer.3.attention.output.LayerNorm.bias", "bert.encoder.layer.3.intermediate.dense.weight", "bert.encoder.layer.3.intermediate.dense.bias", "bert.encoder.layer.3.output.dense.weight", "bert.encoder.layer.3.output.dense.bias", "bert.encoder.layer.3.output.LayerNorm.weight", "bert.encoder.layer.3.output.LayerNorm.bias", "bert.encoder.layer.4.attention.self.query.weight", "bert.encoder.layer.4.attention.self.query.bias", "bert.encoder.layer.4.attention.self.key.weight", "bert.encoder.layer.4.attention.self.key.bias", "bert.encoder.layer.4.attention.self.value.weight", "bert.encoder.layer.4.attention.self.value.bias", "bert.encoder.layer.4.attention.output.dense.weight", "bert.encoder.layer.4.attention.output.dense.bias", "bert.encoder.layer.4.attention.output.LayerNorm.weight", "bert.encoder.layer.4.attention.output.LayerNorm.bias", "bert.encoder.layer.4.intermediate.dense.weight", "bert.encoder.layer.4.intermediate.dense.bias", "bert.encoder.layer.4.output.dense.weight", "bert.encoder.layer.4.output.dense.bias", "bert.encoder.layer.4.output.LayerNorm.weight", "bert.encoder.layer.4.output.LayerNorm.bias", "bert.encoder.layer.5.attention.self.query.weight", "bert.encoder.layer.5.attention.self.query.bias", "bert.encoder.layer.5.attention.self.key.weight", "bert.encoder.layer.5.attention.self.key.bias", "bert.encoder.layer.5.attention.self.value.weight", "bert.encoder.layer.5.attention.self.value.bias", "bert.encoder.layer.5.attention.output.dense.weight", "bert.encoder.layer.5.attention.output.dense.bias", "bert.encoder.layer.5.attention.output.LayerNorm.weight", "bert.encoder.layer.5.attention.output.LayerNorm.bias", "bert.encoder.layer.5.intermediate.dense.weight", "bert.encoder.layer.5.intermediate.dense.bias", "bert.encoder.layer.5.output.dense.weight", "bert.encoder.layer.5.output.dense.bias", "bert.encoder.layer.5.output.LayerNorm.weight", "bert.encoder.layer.5.output.LayerNorm.bias", "bert.encoder.layer.6.attention.self.query.weight", "bert.encoder.layer.6.attention.self.query.bias", "bert.encoder.layer.6.attention.self.key.weight", "bert.encoder.layer.6.attention.self.key.bias", "bert.encoder.layer.6.attention.self.value.weight", "bert.encoder.layer.6.attention.self.value.bias", "bert.encoder.layer.6.attention.output.dense.weight", "bert.encoder.layer.6.attention.output.dense.bias", "bert.encoder.layer.6.attention.output.LayerNorm.weight", "bert.encoder.layer.6.attention.output.LayerNorm.bias", "bert.encoder.layer.6.intermediate.dense.weight", "bert.encoder.layer.6.intermediate.dense.bias", "bert.encoder.layer.6.output.dense.weight", "bert.encoder.layer.6.output.dense.bias", "bert.encoder.layer.6.output.LayerNorm.weight", "bert.encoder.layer.6.output.LayerNorm.bias", "bert.encoder.layer.7.attention.self.query.weight", "bert.encoder.layer.7.attention.self.query.bias", "bert.encoder.layer.7.attention.self.key.weight", "bert.encoder.layer.7.attention.self.key.bias", "bert.encoder.layer.7.attention.self.value.weight", "bert.encoder.layer.7.attention.self.value.bias", "bert.encoder.layer.7.attention.output.dense.weight", "bert.encoder.layer.7.attention.output.dense.bias", "bert.encoder.layer.7.attention.output.LayerNorm.weight", "bert.encoder.layer.7.attention.output.LayerNorm.bias", "bert.encoder.layer.7.intermediate.dense.weight", "bert.encoder.layer.7.intermediate.dense.bias", "bert.encoder.layer.7.output.dense.weight", "bert.encoder.layer.7.output.dense.bias", "bert.encoder.layer.7.output.LayerNorm.weight", "bert.encoder.layer.7.output.LayerNorm.bias", "bert.encoder.layer.8.attention.self.query.weight", "bert.encoder.layer.8.attention.self.query.bias", "bert.encoder.layer.8.attention.self.key.weight", "bert.encoder.layer.8.attention.self.key.bias", "bert.encoder.layer.8.attention.self.value.weight", "bert.encoder.layer.8.attention.self.value.bias", "bert.encoder.layer.8.attention.output.dense.weight", "bert.encoder.layer.8.attention.output.dense.bias", "bert.encoder.layer.8.attention.output.LayerNorm.weight", "bert.encoder.layer.8.attention.output.LayerNorm.bias", "bert.encoder.layer.8.intermediate.dense.weight", "bert.encoder.layer.8.intermediate.dense.bias", "bert.encoder.layer.8.output.dense.weight", "bert.encoder.layer.8.output.dense.bias", "bert.encoder.layer.8.output.LayerNorm.weight", "bert.encoder.layer.8.output.LayerNorm.bias", "bert.encoder.layer.9.attention.self.query.weight", "bert.encoder.layer.9.attention.self.query.bias", "bert.encoder.layer.9.attention.self.key.weight", "bert.encoder.layer.9.attention.self.key.bias", "bert.encoder.layer.9.attention.self.value.weight", "bert.encoder.layer.9.attention.self.value.bias", "bert.encoder.layer.9.attention.output.dense.weight", "bert.encoder.layer.9.attention.output.dense.bias", "bert.encoder.layer.9.attention.output.LayerNorm.weight", "bert.encoder.layer.9.attention.output.LayerNorm.bias", "bert.encoder.layer.9.intermediate.dense.weight", "bert.encoder.layer.9.intermediate.dense.bias", "bert.encoder.layer.9.output.dense.weight", "bert.encoder.layer.9.output.dense.bias", "bert.encoder.layer.9.output.LayerNorm.weight", "bert.encoder.layer.9.output.LayerNorm.bias", "bert.encoder.layer.10.attention.self.query.weight", "bert.encoder.layer.10.attention.self.query.bias", "bert.encoder.layer.10.attention.self.key.weight", "bert.encoder.layer.10.attention.self.key.bias", "bert.encoder.layer.10.attention.self.value.weight", "bert.encoder.layer.10.attention.self.value.bias", "bert.encoder.layer.10.attention.output.dense.weight", "bert.encoder.layer.10.attention.output.dense.bias", "bert.encoder.layer.10.attention.output.LayerNorm.weight", "bert.encoder.layer.10.attention.output.LayerNorm.bias", "bert.encoder.layer.10.intermediate.dense.weight", "bert.encoder.layer.10.intermediate.dense.bias", "bert.encoder.layer.10.output.dense.weight", "bert.encoder.layer.10.output.dense.bias", "bert.encoder.layer.10.output.LayerNorm.weight", "bert.encoder.layer.10.output.LayerNorm.bias", "bert.encoder.layer.11.attention.self.query.weight", "bert.encoder.layer.11.attention.self.query.bias", "bert.encoder.layer.11.attention.self.key.weight", "bert.encoder.layer.11.attention.self.key.bias", "bert.encoder.layer.11.attention.self.value.weight", "bert.encoder.layer.11.attention.self.value.bias", "bert.encoder.layer.11.attention.output.dense.weight", "bert.encoder.layer.11.attention.output.dense.bias", "bert.encoder.layer.11.attention.output.LayerNorm.weight", "bert.encoder.layer.11.attention.output.LayerNorm.bias", "bert.encoder.layer.11.intermediate.dense.weight", "bert.encoder.layer.11.intermediate.dense.bias", "bert.encoder.layer.11.output.dense.weight", "bert.encoder.layer.11.output.dense.bias", "bert.encoder.layer.11.output.LayerNorm.weight", "bert.encoder.layer.11.output.LayerNorm.bias", "bert.encoder.layer.12.attention.self.query.weight", "bert.encoder.layer.12.attention.self.query.bias", "bert.encoder.layer.12.attention.self.key.weight", "bert.encoder.layer.12.attention.self.key.bias", "bert.encoder.layer.12.attention.self.value.weight", "bert.encoder.layer.12.attention.self.value.bias", "bert.encoder.layer.12.attention.output.dense.weight", "bert.encoder.layer.12.attention.output.dense.bias", "bert.encoder.layer.12.attention.output.LayerNorm.weight", "bert.encoder.layer.12.attention.output.LayerNorm.bias", "bert.encoder.layer.12.intermediate.dense.weight", "bert.encoder.layer.12.intermediate.dense.bias", "bert.encoder.layer.12.output.dense.weight", "bert.encoder.layer.12.output.dense.bias", "bert.encoder.layer.12.output.LayerNorm.weight", "bert.encoder.layer.12.output.LayerNorm.bias", "bert.encoder.layer.13.attention.self.query.weight", "bert.encoder.layer.13.attention.self.query.bias", "bert.encoder.layer.13.attention.self.key.weight", "bert.encoder.layer.13.attention.self.key.bias", "bert.encoder.layer.13.attention.self.value.weight", "bert.encoder.layer.13.attention.self.value.bias", "bert.encoder.layer.13.attention.output.dense.weight", "bert.encoder.layer.13.attention.output.dense.bias", "bert.encoder.layer.13.attention.output.LayerNorm.weight", "bert.encoder.layer.13.attention.output.LayerNorm.bias", "bert.encoder.layer.13.intermediate.dense.weight", "bert.encoder.layer.13.intermediate.dense.bias", "bert.encoder.layer.13.output.dense.weight", "bert.encoder.layer.13.output.dense.bias", "bert.encoder.layer.13.output.LayerNorm.weight", "bert.encoder.layer.13.output.LayerNorm.bias", "bert.encoder.layer.14.attention.self.query.weight", "bert.encoder.layer.14.attention.self.query.bias", "bert.encoder.layer.14.attention.self.key.weight", "bert.encoder.layer.14.attention.self.key.bias", "bert.encoder.layer.14.attention.self.value.weight", "bert.encoder.layer.14.attention.self.value.bias", "bert.encoder.layer.14.attention.output.dense.weight", "bert.encoder.layer.14.attention.output.dense.bias", "bert.encoder.layer.14.attention.output.LayerNorm.weight", "bert.encoder.layer.14.attention.output.LayerNorm.bias", "bert.encoder.layer.14.intermediate.dense.weight", "bert.encoder.layer.14.intermediate.dense.bias", "bert.encoder.layer.14.output.dense.weight", "bert.encoder.layer.14.output.dense.bias", "bert.encoder.layer.14.output.LayerNorm.weight", "bert.encoder.layer.14.output.LayerNorm.bias", "bert.encoder.layer.15.attention.self.query.weight", "bert.encoder.layer.15.attention.self.query.bias", "bert.encoder.layer.15.attention.self.key.weight", "bert.encoder.layer.15.attention.self.key.bias", "bert.encoder.layer.15.attention.self.value.weight", "bert.encoder.layer.15.attention.self.value.bias", "bert.encoder.layer.15.attention.output.dense.weight", "bert.encoder.layer.15.attention.output.dense.bias", "bert.encoder.layer.15.attention.output.LayerNorm.weight", "bert.encoder.layer.15.attention.output.LayerNorm.bias", "bert.encoder.layer.15.intermediate.dense.weight", "bert.encoder.layer.15.intermediate.dense.bias", "bert.encoder.layer.15.output.dense.weight", "bert.encoder.layer.15.output.dense.bias", "bert.encoder.layer.15.output.LayerNorm.weight", "bert.encoder.layer.15.output.LayerNorm.bias", "bert.encoder.layer.16.attention.self.query.weight", "bert.encoder.layer.16.attention.self.query.bias", "bert.encoder.layer.16.attention.self.key.weight", "bert.encoder.layer.16.attention.self.key.bias", "bert.encoder.layer.16.attention.self.value.weight", "bert.encoder.layer.16.attention.self.value.bias", "bert.encoder.layer.16.attention.output.dense.weight", "bert.encoder.layer.16.attention.output.dense.bias", "bert.encoder.layer.16.attention.output.LayerNorm.weight", "bert.encoder.layer.16.attention.output.LayerNorm.bias", "bert.encoder.layer.16.intermediate.dense.weight", "bert.encoder.layer.16.intermediate.dense.bias", "bert.encoder.layer.16.output.dense.weight", "bert.encoder.layer.16.output.dense.bias", "bert.encoder.layer.16.output.LayerNorm.weight", "bert.encoder.layer.16.output.LayerNorm.bias", "bert.encoder.layer.17.attention.self.query.weight", "bert.encoder.layer.17.attention.self.query.bias", "bert.encoder.layer.17.attention.self.key.weight", "bert.encoder.layer.17.attention.self.key.bias", "bert.encoder.layer.17.attention.self.value.weight", "bert.encoder.layer.17.attention.self.value.bias", "bert.encoder.layer.17.attention.output.dense.weight", "bert.encoder.layer.17.attention.output.dense.bias", "bert.encoder.layer.17.attention.output.LayerNorm.weight", "bert.encoder.layer.17.attention.output.LayerNorm.bias", "bert.encoder.layer.17.intermediate.dense.weight", "bert.encoder.layer.17.intermediate.dense.bias", "bert.encoder.layer.17.output.dense.weight", "bert.encoder.layer.17.output.dense.bias", "bert.encoder.layer.17.output.LayerNorm.weight", "bert.encoder.layer.17.output.LayerNorm.bias", "bert.encoder.layer.18.attention.self.query.weight", "bert.encoder.layer.18.attention.self.query.bias", "bert.encoder.layer.18.attention.self.key.weight", "bert.encoder.layer.18.attention.self.key.bias", "bert.encoder.layer.18.attention.self.value.weight", "bert.encoder.layer.18.attention.self.value.bias", "bert.encoder.layer.18.attention.output.dense.weight", "bert.encoder.layer.18.attention.output.dense.bias", "bert.encoder.layer.18.attention.output.LayerNorm.weight", "bert.encoder.layer.18.attention.output.LayerNorm.bias", "bert.encoder.layer.18.intermediate.dense.weight", "bert.encoder.layer.18.intermediate.dense.bias", "bert.encoder.layer.18.output.dense.weight", "bert.encoder.layer.18.output.dense.bias", "bert.encoder.layer.18.output.LayerNorm.weight", "bert.encoder.layer.18.output.LayerNorm.bias", "bert.encoder.layer.19.attention.self.query.weight", "bert.encoder.layer.19.attention.self.query.bias", "bert.encoder.layer.19.attention.self.key.weight", "bert.encoder.layer.19.attention.self.key.bias", "bert.encoder.layer.19.attention.self.value.weight", "bert.encoder.layer.19.attention.self.value.bias", "bert.encoder.layer.19.attention.output.dense.weight", "bert.encoder.layer.19.attention.output.dense.bias", "bert.encoder.layer.19.attention.output.LayerNorm.weight", "bert.encoder.layer.19.attention.output.LayerNorm.bias", "bert.encoder.layer.19.intermediate.dense.weight", "bert.encoder.layer.19.intermediate.dense.bias", "bert.encoder.layer.19.output.dense.weight", "bert.encoder.layer.19.output.dense.bias", "bert.encoder.layer.19.output.LayerNorm.weight", "bert.encoder.layer.19.output.LayerNorm.bias", "bert.encoder.layer.20.attention.self.query.weight", "bert.encoder.layer.20.attention.self.query.bias", "bert.encoder.layer.20.attention.self.key.weight", "bert.encoder.layer.20.attention.self.key.bias", "bert.encoder.layer.20.attention.self.value.weight", "bert.encoder.layer.20.attention.self.value.bias", "bert.encoder.layer.20.attention.output.dense.weight", "bert.encoder.layer.20.attention.output.dense.bias", "bert.encoder.layer.20.attention.output.LayerNorm.weight", "bert.encoder.layer.20.attention.output.LayerNorm.bias", "bert.encoder.layer.20.intermediate.dense.weight", "bert.encoder.layer.20.intermediate.dense.bias", "bert.encoder.layer.20.output.dense.weight", "bert.encoder.layer.20.output.dense.bias", "bert.encoder.layer.20.output.LayerNorm.weight", "bert.encoder.layer.20.output.LayerNorm.bias", "bert.encoder.layer.21.attention.self.query.weight", "bert.encoder.layer.21.attention.self.query.bias", "bert.encoder.layer.21.attention.self.key.weight", "bert.encoder.layer.21.attention.self.key.bias", "bert.encoder.layer.21.attention.self.value.weight", "bert.encoder.layer.21.attention.self.value.bias", "bert.encoder.layer.21.attention.output.dense.weight", "bert.encoder.layer.21.attention.output.dense.bias", "bert.encoder.layer.21.attention.output.LayerNorm.weight", "bert.encoder.layer.21.attention.output.LayerNorm.bias", "bert.encoder.layer.21.intermediate.dense.weight", "bert.encoder.layer.21.intermediate.dense.bias", "bert.encoder.layer.21.output.dense.weight", "bert.encoder.layer.21.output.dense.bias", "bert.encoder.layer.21.output.LayerNorm.weight", "bert.encoder.layer.21.output.LayerNorm.bias", "bert.encoder.layer.22.attention.self.query.weight", "bert.encoder.layer.22.attention.self.query.bias", "bert.encoder.layer.22.attention.self.key.weight", "bert.encoder.layer.22.attention.self.key.bias", "bert.encoder.layer.22.attention.self.value.weight", "bert.encoder.layer.22.attention.self.value.bias", "bert.encoder.layer.22.attention.output.dense.weight", "bert.encoder.layer.22.attention.output.dense.bias", "bert.encoder.layer.22.attention.output.LayerNorm.weight", "bert.encoder.layer.22.attention.output.LayerNorm.bias", "bert.encoder.layer.22.intermediate.dense.weight", "bert.encoder.layer.22.intermediate.dense.bias", "bert.encoder.layer.22.output.dense.weight", "bert.encoder.layer.22.output.dense.bias", "bert.encoder.layer.22.output.LayerNorm.weight", "bert.encoder.layer.22.output.LayerNorm.bias", "bert.encoder.layer.23.attention.self.query.weight", "bert.encoder.layer.23.attention.self.query.bias", "bert.encoder.layer.23.attention.self.key.weight", "bert.encoder.layer.23.attention.self.key.bias", "bert.encoder.layer.23.attention.self.value.weight", "bert.encoder.layer.23.attention.self.value.bias", "bert.encoder.layer.23.attention.output.dense.weight", "bert.encoder.layer.23.attention.output.dense.bias", "bert.encoder.layer.23.attention.output.LayerNorm.weight", "bert.encoder.layer.23.attention.output.LayerNorm.bias", "bert.encoder.layer.23.intermediate.dense.weight", "bert.encoder.layer.23.intermediate.dense.bias", "bert.encoder.layer.23.output.dense.weight", "bert.encoder.layer.23.output.dense.bias", "bert.encoder.layer.23.output.LayerNorm.weight", "bert.encoder.layer.23.output.LayerNorm.bias". An error occurred during training: Error(s) in loading state_dict for BERTClassifier:
	Missing key(s) in state_dict: "bert.embeddings.word_embeddings.weight", "bert.embeddings.position_embeddings.weight", "bert.embeddings.token_type_embeddings.weight", "bert.embeddings.LayerNorm.weight", "bert.embeddings.LayerNorm.bias", "bert.encoder.layer.0.attention.self.query.weight", "bert.encoder.layer.0.attention.self.query.bias", "bert.encoder.layer.0.attention.self.key.weight", "bert.encoder.layer.0.attention.self.key.bias", "bert.encoder.layer.0.attention.self.value.weight", "bert.encoder.layer.0.attention.self.value.bias", "bert.encoder.layer.0.attention.output.dense.weight", "bert.encoder.layer.0.attention.output.dense.bias", "bert.encoder.layer.0.attention.output.LayerNorm.weight", "bert.encoder.layer.0.attention.output.LayerNorm.bias", "bert.encoder.layer.0.intermediate.dense.weight", "bert.encoder.layer.0.intermediate.dense.bias", "bert.encoder.layer.0.output.dense.weight", "bert.encoder.layer.0.output.dense.bias", "bert.encoder.layer.0.output.LayerNorm.weight", "bert.encoder.layer.0.output.LayerNorm.bias", "bert.encoder.layer.1.attention.self.query.weight", "bert.encoder.layer.1.attention.self.query.bias", "bert.encoder.layer.1.attention.self.key.weight", "bert.encoder.layer.1.attention.self.key.bias", "bert.encoder.layer.1.attention.self.value.weight", "bert.encoder.layer.1.attention.self.value.bias", "bert.encoder.layer.1.attention.output.dense.weight", "bert.encoder.layer.1.attention.output.dense.bias", "bert.encoder.layer.1.attention.output.LayerNorm.weight", "bert.encoder.layer.1.attention.output.LayerNorm.bias", "bert.encoder.layer.1.intermediate.dense.weight", "bert.encoder.layer.1.intermediate.dense.bias", "bert.encoder.layer.1.output.dense.weight", "bert.encoder.layer.1.output.dense.bias", "bert.encoder.layer.1.output.LayerNorm.weight", "bert.encoder.layer.1.output.LayerNorm.bias", "bert.encoder.layer.2.attention.self.query.weight", "bert.encoder.layer.2.attention.self.query.bias", "bert.encoder.layer.2.attention.self.key.weight", "bert.encoder.layer.2.attention.self.key.bias", "bert.encoder.layer.2.attention.self.value.weight", "bert.encoder.layer.2.attention.self.value.bias", "bert.encoder.layer.2.attention.output.dense.weight", "bert.encoder.layer.2.attention.output.dense.bias", "bert.encoder.layer.2.attention.output.LayerNorm.weight", "bert.encoder.layer.2.attention.output.LayerNorm.bias", "bert.encoder.layer.2.intermediate.dense.weight", "bert.encoder.layer.2.intermediate.dense.bias", "bert.encoder.layer.2.output.dense.weight", "bert.encoder.layer.2.output.dense.bias", "bert.encoder.layer.2.output.LayerNorm.weight", "bert.encoder.layer.2.output.LayerNorm.bias", "bert.encoder.layer.3.attention.self.query.weight", "bert.encoder.layer.3.attention.self.query.bias", "bert.encoder.layer.3.attention.self.key.weight", "bert.encoder.layer.3.attention.self.key.bias", "bert.encoder.layer.3.attention.self.value.weight", "bert.encoder.layer.3.attention.self.value.bias", "bert.encoder.layer.3.attention.output.dense.weight", "bert.encoder.layer.3.attention.output.dense.bias", "bert.encoder.layer.3.attention.output.LayerNorm.weight", "bert.encoder.layer.3.attention.output.LayerNorm.bias", "bert.encoder.layer.3.intermediate.dense.weight", "bert.encoder.layer.3.intermediate.dense.bias", "bert.encoder.layer.3.output.dense.weight", "bert.encoder.layer.3.output.dense.bias", "bert.encoder.layer.3.output.LayerNorm.weight", "bert.encoder.layer.3.output.LayerNorm.bias", "bert.encoder.layer.4.attention.self.query.weight", "bert.encoder.layer.4.attention.self.query.bias", "bert.encoder.layer.4.attention.self.key.weight", "bert.encoder.layer.4.attention.self.key.bias", "bert.encoder.layer.4.attention.self.value.weight", "bert.encoder.layer.4.attention.self.value.bias", "bert.encoder.layer.4.attention.output.dense.weight", "bert.encoder.layer.4.attention.output.dense.bias", "bert.encoder.layer.4.attention.output.LayerNorm.weight", "bert.encoder.layer.4.attention.output.LayerNorm.bias", "bert.encoder.layer.4.intermediate.dense.weight", "bert.encoder.layer.4.intermediate.dense.bias", "bert.encoder.layer.4.output.dense.weight", "bert.encoder.layer.4.output.dense.bias", "bert.encoder.layer.4.output.LayerNorm.weight", "bert.encoder.layer.4.output.LayerNorm.bias", "bert.encoder.layer.5.attention.self.query.weight", "bert.encoder.layer.5.attention.self.query.bias", "bert.encoder.layer.5.attention.self.key.weight", "bert.encoder.layer.5.attention.self.key.bias", "bert.encoder.layer.5.attention.self.value.weight", "bert.encoder.layer.5.attention.self.value.bias", "bert.encoder.layer.5.attention.output.dense.weight", "bert.encoder.layer.5.attention.output.dense.bias", "bert.encoder.layer.5.attention.output.LayerNorm.weight", "bert.encoder.layer.5.attention.output.LayerNorm.bias", "bert.encoder.layer.5.intermediate.dense.weight", "bert.encoder.layer.5.intermediate.dense.bias", "bert.encoder.layer.5.output.dense.weight", "bert.encoder.layer.5.output.dense.bias", "bert.encoder.layer.5.output.LayerNorm.weight", "bert.encoder.layer.5.output.LayerNorm.bias", "bert.encoder.layer.6.attention.self.query.weight", "bert.encoder.layer.6.attention.self.query.bias", "bert.encoder.layer.6.attention.self.key.weight", "bert.encoder.layer.6.attention.self.key.bias", "bert.encoder.layer.6.attention.self.value.weight", "bert.encoder.layer.6.attention.self.value.bias", "bert.encoder.layer.6.attention.output.dense.weight", "bert.encoder.layer.6.attention.output.dense.bias", "bert.encoder.layer.6.attention.output.LayerNorm.weight", "bert.encoder.layer.6.attention.output.LayerNorm.bias", "bert.encoder.layer.6.intermediate.dense.weight", "bert.encoder.layer.6.intermediate.dense.bias", "bert.encoder.layer.6.output.dense.weight", "bert.encoder.layer.6.output.dense.bias", "bert.encoder.layer.6.output.LayerNorm.weight", "bert.encoder.layer.6.output.LayerNorm.bias", "bert.encoder.layer.7.attention.self.query.weight", "bert.encoder.layer.7.attention.self.query.bias", "bert.encoder.layer.7.attention.self.key.weight", "bert.encoder.layer.7.attention.self.key.bias", "bert.encoder.layer.7.attention.self.value.weight", "bert.encoder.layer.7.attention.self.value.bias", "bert.encoder.layer.7.attention.output.dense.weight", "bert.encoder.layer.7.attention.output.dense.bias", "bert.encoder.layer.7.attention.output.LayerNorm.weight", "bert.encoder.layer.7.attention.output.LayerNorm.bias", "bert.encoder.layer.7.intermediate.dense.weight", "bert.encoder.layer.7.intermediate.dense.bias", "bert.encoder.layer.7.output.dense.weight", "bert.encoder.layer.7.output.dense.bias", "bert.encoder.layer.7.output.LayerNorm.weight", "bert.encoder.layer.7.output.LayerNorm.bias", "bert.encoder.layer.8.attention.self.query.weight", "bert.encoder.layer.8.attention.self.query.bias", "bert.encoder.layer.8.attention.self.key.weight", "bert.encoder.layer.8.attention.self.key.bias", "bert.encoder.layer.8.attention.self.value.weight", "bert.encoder.layer.8.attention.self.value.bias", "bert.encoder.layer.8.attention.output.dense.weight", "bert.encoder.layer.8.attention.output.dense.bias", "bert.encoder.layer.8.attention.output.LayerNorm.weight", "bert.encoder.layer.8.attention.output.LayerNorm.bias", "bert.encoder.layer.8.intermediate.dense.weight", "bert.encoder.layer.8.intermediate.dense.bias", "bert.encoder.layer.8.output.dense.weight", "bert.encoder.layer.8.output.dense.bias", "bert.encoder.layer.8.output.LayerNorm.weight", "bert.encoder.layer.8.output.LayerNorm.bias", "bert.encoder.layer.9.attention.self.query.weight", "bert.encoder.layer.9.attention.self.query.bias", "bert.encoder.layer.9.attention.self.key.weight", "bert.encoder.layer.9.attention.self.key.bias", "bert.encoder.layer.9.attention.self.value.weight", "bert.encoder.layer.9.attention.self.value.bias", "bert.encoder.layer.9.attention.output.dense.weight", "bert.encoder.layer.9.attention.output.dense.bias", "bert.encoder.layer.9.attention.output.LayerNorm.weight", "bert.encoder.layer.9.attention.output.LayerNorm.bias", "bert.encoder.layer.9.intermediate.dense.weight", "bert.encoder.layer.9.intermediate.dense.bias", "bert.encoder.layer.9.output.dense.weight", "bert.encoder.layer.9.output.dense.bias", "bert.encoder.layer.9.output.LayerNorm.weight", "bert.encoder.layer.9.output.LayerNorm.bias", "bert.encoder.layer.10.attention.self.query.weight", "bert.encoder.layer.10.attention.self.query.bias", "bert.encoder.layer.10.attention.self.key.weight", "bert.encoder.layer.10.attention.self.key.bias", "bert.encoder.layer.10.attention.self.value.weight", "bert.encoder.layer.10.attention.self.value.bias", "bert.encoder.layer.10.attention.output.dense.weight", "bert.encoder.layer.10.attention.output.dense.bias", "bert.encoder.layer.10.attention.output.LayerNorm.weight", "bert.encoder.layer.10.attention.output.LayerNorm.bias", "bert.encoder.layer.10.intermediate.dense.weight", "bert.encoder.layer.10.intermediate.dense.bias", "bert.encoder.layer.10.output.dense.weight", "bert.encoder.layer.10.output.dense.bias", "bert.encoder.layer.10.output.LayerNorm.weight", "bert.encoder.layer.10.output.LayerNorm.bias", "bert.encoder.layer.11.attention.self.query.weight", "bert.encoder.layer.11.attention.self.query.bias", "bert.encoder.layer.11.attention.self.key.weight", "bert.encoder.layer.11.attention.self.key.bias", "bert.encoder.layer.11.attention.self.value.weight", "bert.encoder.layer.11.attention.self.value.bias", "bert.encoder.layer.11.attention.output.dense.weight", "bert.encoder.layer.11.attention.output.dense.bias", "bert.encoder.layer.11.attention.output.LayerNorm.weight", "bert.encoder.layer.11.attention.output.LayerNorm.bias", "bert.encoder.layer.11.intermediate.dense.weight", "bert.encoder.layer.11.intermediate.dense.bias", "bert.encoder.layer.11.output.dense.weight", "bert.encoder.layer.11.output.dense.bias", "bert.encoder.layer.11.output.LayerNorm.weight", "bert.encoder.layer.11.output.LayerNorm.bias", "bert.encoder.layer.12.attention.self.query.weight", "bert.encoder.layer.12.attention.self.query.bias", "bert.encoder.layer.12.attention.self.key.weight", "bert.encoder.layer.12.attention.self.key.bias", "bert.encoder.layer.12.attention.self.value.weight", "bert.encoder.layer.12.attention.self.value.bias", "bert.encoder.layer.12.attention.output.dense.weight", "bert.encoder.layer.12.attention.output.dense.bias", "bert.encoder.layer.12.attention.output.LayerNorm.weight", "bert.encoder.layer.12.attention.output.LayerNorm.bias", "bert.encoder.layer.12.intermediate.dense.weight", "bert.encoder.layer.12.intermediate.dense.bias", "bert.encoder.layer.12.output.dense.weight", "bert.encoder.layer.12.output.dense.bias", "bert.encoder.layer.12.output.LayerNorm.weight", "bert.encoder.layer.12.output.LayerNorm.bias", "bert.encoder.layer.13.attention.self.query.weight", "bert.encoder.layer.13.attention.self.query.bias", "bert.encoder.layer.13.attention.self.key.weight", "bert.encoder.layer.13.attention.self.key.bias", "bert.encoder.layer.13.attention.self.value.weight", "bert.encoder.layer.13.attention.self.value.bias", "bert.encoder.layer.13.attention.output.dense.weight", "bert.encoder.layer.13.attention.output.dense.bias", "bert.encoder.layer.13.attention.output.LayerNorm.weight", "bert.encoder.layer.13.attention.output.LayerNorm.bias", "bert.encoder.layer.13.intermediate.dense.weight", "bert.encoder.layer.13.intermediate.dense.bias", "bert.encoder.layer.13.output.dense.weight", "bert.encoder.layer.13.output.dense.bias", "bert.encoder.layer.13.output.LayerNorm.weight", "bert.encoder.layer.13.output.LayerNorm.bias", "bert.encoder.layer.14.attention.self.query.weight", "bert.encoder.layer.14.attention.self.query.bias", "bert.encoder.layer.14.attention.self.key.weight", "bert.encoder.layer.14.attention.self.key.bias", "bert.encoder.layer.14.attention.self.value.weight", "bert.encoder.layer.14.attention.self.value.bias", "bert.encoder.layer.14.attention.output.dense.weight", "bert.encoder.layer.14.attention.output.dense.bias", "bert.encoder.layer.14.attention.output.LayerNorm.weight", "bert.encoder.layer.14.attention.output.LayerNorm.bias", "bert.encoder.layer.14.intermediate.dense.weight", "bert.encoder.layer.14.intermediate.dense.bias", "bert.encoder.layer.14.output.dense.weight", "bert.encoder.layer.14.output.dense.bias", "bert.encoder.layer.14.output.LayerNorm.weight", "bert.encoder.layer.14.output.LayerNorm.bias", "bert.encoder.layer.15.attention.self.query.weight", "bert.encoder.layer.15.attention.self.query.bias", "bert.encoder.layer.15.attention.self.key.weight", "bert.encoder.layer.15.attention.self.key.bias", "bert.encoder.layer.15.attention.self.value.weight", "bert.encoder.layer.15.attention.self.value.bias", "bert.encoder.layer.15.attention.output.dense.weight", "bert.encoder.layer.15.attention.output.dense.bias", "bert.encoder.layer.15.attention.output.LayerNorm.weight", "bert.encoder.layer.15.attention.output.LayerNorm.bias", "bert.encoder.layer.15.intermediate.dense.weight", "bert.encoder.layer.15.intermediate.dense.bias", "bert.encoder.layer.15.output.dense.weight", "bert.encoder.layer.15.output.dense.bias", "bert.encoder.layer.15.output.LayerNorm.weight", "bert.encoder.layer.15.output.LayerNorm.bias", "bert.encoder.layer.16.attention.self.query.weight", "bert.encoder.layer.16.attention.self.query.bias", "bert.encoder.layer.16.attention.self.key.weight", "bert.encoder.layer.16.attention.self.key.bias", "bert.encoder.layer.16.attention.self.value.weight", "bert.encoder.layer.16.attention.self.value.bias", "bert.encoder.layer.16.attention.output.dense.weight", "bert.encoder.layer.16.attention.output.dense.bias", "bert.encoder.layer.16.attention.output.LayerNorm.weight", "bert.encoder.layer.16.attention.output.LayerNorm.bias", "bert.encoder.layer.16.intermediate.dense.weight", "bert.encoder.layer.16.intermediate.dense.bias", "bert.encoder.layer.16.output.dense.weight", "bert.encoder.layer.16.output.dense.bias", "bert.encoder.layer.16.output.LayerNorm.weight", "bert.encoder.layer.16.output.LayerNorm.bias", "bert.encoder.layer.17.attention.self.query.weight", "bert.encoder.layer.17.attention.self.query.bias", "bert.encoder.layer.17.attention.self.key.weight", "bert.encoder.layer.17.attention.self.key.bias", "bert.encoder.layer.17.attention.self.value.weight", "bert.encoder.layer.17.attention.self.value.bias", "bert.encoder.layer.17.attention.output.dense.weight", "bert.encoder.layer.17.attention.output.dense.bias", "bert.encoder.layer.17.attention.output.LayerNorm.weight", "bert.encoder.layer.17.attention.output.LayerNorm.bias", "bert.encoder.layer.17.intermediate.dense.weight", "bert.encoder.layer.17.intermediate.dense.bias", "bert.encoder.layer.17.output.dense.weight", "bert.encoder.layer.17.output.dense.bias", "bert.encoder.layer.17.output.LayerNorm.weight", "bert.encoder.layer.17.output.LayerNorm.bias", "bert.encoder.layer.18.attention.self.query.weight", "bert.encoder.layer.18.attention.self.query.bias", "bert.encoder.layer.18.attention.self.key.weight", "bert.encoder.layer.18.attention.self.key.bias", "bert.encoder.layer.18.attention.self.value.weight", "bert.encoder.layer.18.attention.self.value.bias", "bert.encoder.layer.18.attention.output.dense.weight", "bert.encoder.layer.18.attention.output.dense.bias", "bert.encoder.layer.18.attention.output.LayerNorm.weight", "bert.encoder.layer.18.attention.output.LayerNorm.bias", "bert.encoder.layer.18.intermediate.dense.weight", "bert.encoder.layer.18.intermediate.dense.bias", "bert.encoder.layer.18.output.dense.weight", "bert.encoder.layer.18.output.dense.bias", "bert.encoder.layer.18.output.LayerNorm.weight", "bert.encoder.layer.18.output.LayerNorm.bias", "bert.encoder.layer.19.attention.self.query.weight", "bert.encoder.layer.19.attention.self.query.bias", "bert.encoder.layer.19.attention.self.key.weight", "bert.encoder.layer.19.attention.self.key.bias", "bert.encoder.layer.19.attention.self.value.weight", "bert.encoder.layer.19.attention.self.value.bias", "bert.encoder.layer.19.attention.output.dense.weight", "bert.encoder.layer.19.attention.output.dense.bias", "bert.encoder.layer.19.attention.output.LayerNorm.weight", "bert.encoder.layer.19.attention.output.LayerNorm.bias", "bert.encoder.layer.19.intermediate.dense.weight", "bert.encoder.layer.19.intermediate.dense.bias", "bert.encoder.layer.19.output.dense.weight", "bert.encoder.layer.19.output.dense.bias", "bert.encoder.layer.19.output.LayerNorm.weight", "bert.encoder.layer.19.output.LayerNorm.bias", "bert.encoder.layer.20.attention.self.query.weight", "bert.encoder.layer.20.attention.self.query.bias", "bert.encoder.layer.20.attention.self.key.weight", "bert.encoder.layer.20.attention.self.key.bias", "bert.encoder.layer.20.attention.self.value.weight", "bert.encoder.layer.20.attention.self.value.bias", "bert.encoder.layer.20.attention.output.dense.weight", "bert.encoder.layer.20.attention.output.dense.bias", "bert.encoder.layer.20.attention.output.LayerNorm.weight", "bert.encoder.layer.20.attention.output.LayerNorm.bias", "bert.encoder.layer.20.intermediate.dense.weight", "bert.encoder.layer.20.intermediate.dense.bias", "bert.encoder.layer.20.output.dense.weight", "bert.encoder.layer.20.output.dense.bias", "bert.encoder.layer.20.output.LayerNorm.weight", "bert.encoder.layer.20.output.LayerNorm.bias", "bert.encoder.layer.21.attention.self.query.weight", "bert.encoder.layer.21.attention.self.query.bias", "bert.encoder.layer.21.attention.self.key.weight", "bert.encoder.layer.21.attention.self.key.bias", "bert.encoder.layer.21.attention.self.value.weight", "bert.encoder.layer.21.attention.self.value.bias", "bert.encoder.layer.21.attention.output.dense.weight", "bert.encoder.layer.21.attention.output.dense.bias", "bert.encoder.layer.21.attention.output.LayerNorm.weight", "bert.encoder.layer.21.attention.output.LayerNorm.bias", "bert.encoder.layer.21.intermediate.dense.weight", "bert.encoder.layer.21.intermediate.dense.bias", "bert.encoder.layer.21.output.dense.weight", "bert.encoder.layer.21.output.dense.bias", "bert.encoder.layer.21.output.LayerNorm.weight", "bert.encoder.layer.21.output.LayerNorm.bias", "bert.encoder.layer.22.attention.self.query.weight", "bert.encoder.layer.22.attention.self.query.bias", "bert.encoder.layer.22.attention.self.key.weight", "bert.encoder.layer.22.attention.self.key.bias", "bert.encoder.layer.22.attention.self.value.weight", "bert.encoder.layer.22.attention.self.value.bias", "bert.encoder.layer.22.attention.output.dense.weight", "bert.encoder.layer.22.attention.output.dense.bias", "bert.encoder.layer.22.attention.output.LayerNorm.weight", "bert.encoder.layer.22.attention.output.LayerNorm.bias", "bert.encoder.layer.22.intermediate.dense.weight", "bert.encoder.layer.22.intermediate.dense.bias", "bert.encoder.layer.22.output.dense.weight", "bert.encoder.layer.22.output.dense.bias", "bert.encoder.layer.22.output.LayerNorm.weight", "bert.encoder.layer.22.output.LayerNorm.bias", "bert.encoder.layer.23.attention.self.query.weight", "bert.encoder.layer.23.attention.self.query.bias", "bert.encoder.layer.23.attention.self.key.weight", "bert.encoder.layer.23.attention.self.key.bias", "bert.encoder.layer.23.attention.self.value.weight", "bert.encoder.layer.23.attention.self.value.bias", "bert.encoder.layer.23.attention.output.dense.weight", "bert.encoder.layer.23.attention.output.dense.bias", "bert.encoder.layer.23.attention.output.LayerNorm.weight", "bert.encoder.layer.23.attention.output.LayerNorm.bias", "bert.encoder.layer.23.intermediate.dense.weight", "bert.encoder.layer.23.intermediate.dense.bias", "bert.encoder.layer.23.output.dense.weight", "bert.encoder.layer.23.output.dense.bias", "bert.encoder.layer.23.output.LayerNorm.weight", "bert.encoder.layer.23.output.LayerNorm.bias". 
An error occurred during training: Error(s) in loading state_dict for BERTClassifier:
	Missing key(s) in state_dict: "bert.embeddings.word_embeddings.weight", "bert.embeddings.position_embeddings.weight", "bert.embeddings.token_type_embeddings.weight", "bert.embeddings.LayerNorm.weight", "bert.embeddings.LayerNorm.bias", "bert.encoder.layer.0.attention.self.query.weight", "bert.encoder.layer.0.attention.self.query.bias", "bert.encoder.layer.0.attention.self.key.weight", "bert.encoder.layer.0.attention.self.key.bias", "bert.encoder.layer.0.attention.self.value.weight", "bert.encoder.layer.0.attention.self.value.bias", "bert.encoder.layer.0.attention.output.dense.weight", "bert.encoder.layer.0.attention.output.dense.bias", "bert.encoder.layer.0.attention.output.LayerNorm.weight", "bert.encoder.layer.0.attention.output.LayerNorm.bias", "bert.encoder.layer.0.intermediate.dense.weight", "bert.encoder.layer.0.intermediate.dense.bias", "bert.encoder.layer.0.output.dense.weight", "bert.encoder.layer.0.output.dense.bias", "bert.encoder.layer.0.output.LayerNorm.weight", "bert.encoder.layer.0.output.LayerNorm.bias", "bert.encoder.layer.1.attention.self.query.weight", "bert.encoder.layer.1.attention.self.query.bias", "bert.encoder.layer.1.attention.self.key.weight", "bert.encoder.layer.1.attention.self.key.bias", "bert.encoder.layer.1.attention.self.value.weight", "bert.encoder.layer.1.attention.self.value.bias", "bert.encoder.layer.1.attention.output.dense.weight", "bert.encoder.layer.1.attention.output.dense.bias", "bert.encoder.layer.1.attention.output.LayerNorm.weight", "bert.encoder.layer.1.attention.output.LayerNorm.bias", "bert.encoder.layer.1.intermediate.dense.weight", "bert.encoder.layer.1.intermediate.dense.bias", "bert.encoder.layer.1.output.dense.weight", "bert.encoder.layer.1.output.dense.bias", "bert.encoder.layer.1.output.LayerNorm.weight", "bert.encoder.layer.1.output.LayerNorm.bias", "bert.encoder.layer.2.attention.self.query.weight", "bert.encoder.layer.2.attention.self.query.bias", "bert.encoder.layer.2.attention.self.key.weight", "bert.encoder.layer.2.attention.self.key.bias", "bert.encoder.layer.2.attention.self.value.weight", "bert.encoder.layer.2.attention.self.value.bias", "bert.encoder.layer.2.attention.output.dense.weight", "bert.encoder.layer.2.attention.output.dense.bias", "bert.encoder.layer.2.attention.output.LayerNorm.weight", "bert.encoder.layer.2.attention.output.LayerNorm.bias", "bert.encoder.layer.2.intermediate.dense.weight", "bert.encoder.layer.2.intermediate.dense.bias", "bert.encoder.layer.2.output.dense.weight", "bert.encoder.layer.2.output.dense.bias", "bert.encoder.layer.2.output.LayerNorm.weight", "bert.encoder.layer.2.output.LayerNorm.bias", "bert.encoder.layer.3.attention.self.query.weight", "bert.encoder.layer.3.attention.self.query.bias", "bert.encoder.layer.3.attention.self.key.weight", "bert.encoder.layer.3.attention.self.key.bias", "bert.encoder.layer.3.attention.self.value.weight", "bert.encoder.layer.3.attention.self.value.bias", "bert.encoder.layer.3.attention.output.dense.weight", "bert.encoder.layer.3.attention.output.dense.bias", "bert.encoder.layer.3.attention.output.LayerNorm.weight", "bert.encoder.layer.3.attention.output.LayerNorm.bias", "bert.encoder.layer.3.intermediate.dense.weight", "bert.encoder.layer.3.intermediate.dense.bias", "bert.encoder.layer.3.output.dense.weight", "bert.encoder.layer.3.output.dense.bias", "bert.encoder.layer.3.output.LayerNorm.weight", "bert.encoder.layer.3.output.LayerNorm.bias", "bert.encoder.layer.4.attention.self.query.weight", "bert.encoder.layer.4.attention.self.query.bias", "bert.encoder.layer.4.attention.self.key.weight", "bert.encoder.layer.4.attention.self.key.bias", "bert.encoder.layer.4.attention.self.value.weight", "bert.encoder.layer.4.attention.self.value.bias", "bert.encoder.layer.4.attention.output.dense.weight", "bert.encoder.layer.4.attention.output.dense.bias", "bert.encoder.layer.4.attention.output.LayerNorm.weight", "bert.encoder.layer.4.attention.output.LayerNorm.bias", "bert.encoder.layer.4.intermediate.dense.weight", "bert.encoder.layer.4.intermediate.dense.bias", "bert.encoder.layer.4.output.dense.weight", "bert.encoder.layer.4.output.dense.bias", "bert.encoder.layer.4.output.LayerNorm.weight", "bert.encoder.layer.4.output.LayerNorm.bias", "bert.encoder.layer.5.attention.self.query.weight", "bert.encoder.layer.5.attention.self.query.bias", "bert.encoder.layer.5.attention.self.key.weight", "bert.encoder.layer.5.attention.self.key.bias", "bert.encoder.layer.5.attention.self.value.weight", "bert.encoder.layer.5.attention.self.value.bias", "bert.encoder.layer.5.attention.output.dense.weight", "bert.encoder.layer.5.attention.output.dense.bias", "bert.encoder.layer.5.attention.output.LayerNorm.weight", "bert.encoder.layer.5.attention.output.LayerNorm.bias", "bert.encoder.layer.5.intermediate.dense.weight", "bert.encoder.layer.5.intermediate.dense.bias", "bert.encoder.layer.5.output.dense.weight", "bert.encoder.layer.5.output.dense.bias", "bert.encoder.layer.5.output.LayerNorm.weight", "bert.encoder.layer.5.output.LayerNorm.bias", "bert.encoder.layer.6.attention.self.query.weight", "bert.encoder.layer.6.attention.self.query.bias", "bert.encoder.layer.6.attention.self.key.weight", "bert.encoder.layer.6.attention.self.key.bias", "bert.encoder.layer.6.attention.self.value.weight", "bert.encoder.layer.6.attention.self.value.bias", "bert.encoder.layer.6.attention.output.dense.weight", "bert.encoder.layer.6.attention.output.dense.bias", "bert.encoder.layer.6.attention.output.LayerNorm.weight", "bert.encoder.layer.6.attention.output.LayerNorm.bias", "bert.encoder.layer.6.intermediate.dense.weight", "bert.encoder.layer.6.intermediate.dense.bias", "bert.encoder.layer.6.output.dense.weight", "bert.encoder.layer.6.output.dense.bias", "bert.encoder.layer.6.output.LayerNorm.weight", "bert.encoder.layer.6.output.LayerNorm.bias", "bert.encoder.layer.7.attention.self.query.weight", "bert.encoder.layer.7.attention.self.query.bias", "bert.encoder.layer.7.attention.self.key.weight", "bert.encoder.layer.7.attention.self.key.bias", "bert.encoder.layer.7.attention.self.value.weight", "bert.encoder.layer.7.attention.self.value.bias", "bert.encoder.layer.7.attention.output.dense.weight", "bert.encoder.layer.7.attention.output.dense.bias", "bert.encoder.layer.7.attention.output.LayerNorm.weight", "bert.encoder.layer.7.attention.output.LayerNorm.bias", "bert.encoder.layer.7.intermediate.dense.weight", "bert.encoder.layer.7.intermediate.dense.bias", "bert.encoder.layer.7.output.dense.weight", "bert.encoder.layer.7.output.dense.bias", "bert.encoder.layer.7.output.LayerNorm.weight", "bert.encoder.layer.7.output.LayerNorm.bias", "bert.encoder.layer.8.attention.self.query.weight", "bert.encoder.layer.8.attention.self.query.bias", "bert.encoder.layer.8.attention.self.key.weight", "bert.encoder.layer.8.attention.self.key.bias", "bert.encoder.layer.8.attention.self.value.weight", "bert.encoder.layer.8.attention.self.value.bias", "bert.encoder.layer.8.attention.output.dense.weight", "bert.encoder.layer.8.attention.output.dense.bias", "bert.encoder.layer.8.attention.output.LayerNorm.weight", "bert.encoder.layer.8.attention.output.LayerNorm.bias", "bert.encoder.layer.8.intermediate.dense.weight", "bert.encoder.layer.8.intermediate.dense.bias", "bert.encoder.layer.8.output.dense.weight", "bert.encoder.layer.8.output.dense.bias", "bert.encoder.layer.8.output.LayerNorm.weight", "bert.encoder.layer.8.output.LayerNorm.bias", "bert.encoder.layer.9.attention.self.query.weight", "bert.encoder.layer.9.attention.self.query.bias", "bert.encoder.layer.9.attention.self.key.weight", "bert.encoder.layer.9.attention.self.key.bias", "bert.encoder.layer.9.attention.self.value.weight", "bert.encoder.layer.9.attention.self.value.bias", "bert.encoder.layer.9.attention.output.dense.weight", "bert.encoder.layer.9.attention.output.dense.bias", "bert.encoder.layer.9.attention.output.LayerNorm.weight", "bert.encoder.layer.9.attention.output.LayerNorm.bias", "bert.encoder.layer.9.intermediate.dense.weight", "bert.encoder.layer.9.intermediate.dense.bias", "bert.encoder.layer.9.output.dense.weight", "bert.encoder.layer.9.output.dense.bias", "bert.encoder.layer.9.output.LayerNorm.weight", "bert.encoder.layer.9.output.LayerNorm.bias", "bert.encoder.layer.10.attention.self.query.weight", "bert.encoder.layer.10.attention.self.query.bias", "bert.encoder.layer.10.attention.self.key.weight", "bert.encoder.layer.10.attention.self.key.bias", "bert.encoder.layer.10.attention.self.value.weight", "bert.encoder.layer.10.attention.self.value.bias", "bert.encoder.layer.10.attention.output.dense.weight", "bert.encoder.layer.10.attention.output.dense.bias", "bert.encoder.layer.10.attention.output.LayerNorm.weight", "bert.encoder.layer.10.attention.output.LayerNorm.bias", "bert.encoder.layer.10.intermediate.dense.weight", "bert.encoder.layer.10.intermediate.dense.bias", "bert.encoder.layer.10.output.dense.weight", "bert.encoder.layer.10.output.dense.bias", "bert.encoder.layer.10.output.LayerNorm.weight", "bert.encoder.layer.10.output.LayerNorm.bias", "bert.encoder.layer.11.attention.self.query.weight", "bert.encoder.layer.11.attention.self.query.bias", "bert.encoder.layer.11.attention.self.key.weight", "bert.encoder.layer.11.attention.self.key.bias", "bert.encoder.layer.11.attention.self.value.weight", "bert.encoder.layer.11.attention.self.value.bias", "bert.encoder.layer.11.attention.output.dense.weight", "bert.encoder.layer.11.attention.output.dense.bias", "bert.encoder.layer.11.attention.output.LayerNorm.weight", "bert.encoder.layer.11.attention.output.LayerNorm.bias", "bert.encoder.layer.11.intermediate.dense.weight", "bert.encoder.layer.11.intermediate.dense.bias", "bert.encoder.layer.11.output.dense.weight", "bert.encoder.layer.11.output.dense.bias", "bert.encoder.layer.11.output.LayerNorm.weight", "bert.encoder.layer.11.output.LayerNorm.bias", "bert.encoder.layer.12.attention.self.query.weight", "bert.encoder.layer.12.attention.self.query.bias", "bert.encoder.layer.12.attention.self.key.weight", "bert.encoder.layer.12.attention.self.key.bias", "bert.encoder.layer.12.attention.self.value.weight", "bert.encoder.layer.12.attention.self.value.bias", "bert.encoder.layer.12.attention.output.dense.weight", "bert.encoder.layer.12.attention.output.dense.bias", "bert.encoder.layer.12.attention.output.LayerNorm.weight", "bert.encoder.layer.12.attention.output.LayerNorm.bias", "bert.encoder.layer.12.intermediate.dense.weight", "bert.encoder.layer.12.intermediate.dense.bias", "bert.encoder.layer.12.output.dense.weight", "bert.encoder.layer.12.output.dense.bias", "bert.encoder.layer.12.output.LayerNorm.weight", "bert.encoder.layer.12.output.LayerNorm.bias", "bert.encoder.layer.13.attention.self.query.weight", "bert.encoder.layer.13.attention.self.query.bias", "bert.encoder.layer.13.attention.self.key.weight", "bert.encoder.layer.13.attention.self.key.bias", "bert.encoder.layer.13.attention.self.value.weight", "bert.encoder.layer.13.attention.self.value.bias", "bert.encoder.layer.13.attention.output.dense.weight", "bert.encoder.layer.13.attention.output.dense.bias", "bert.encoder.layer.13.attention.output.LayerNorm.weight", "bert.encoder.layer.13.attention.output.LayerNorm.bias", "bert.encoder.layer.13.intermediate.dense.weight", "bert.encoder.layer.13.intermediate.dense.bias", "bert.encoder.layer.13.output.dense.weight", "bert.encoder.layer.13.output.dense.bias", "bert.encoder.layer.13.output.LayerNorm.weight", "bert.encoder.layer.13.output.LayerNorm.bias", "bert.encoder.layer.14.attention.self.query.weight", "bert.encoder.layer.14.attention.self.query.bias", "bert.encoder.layer.14.attention.self.key.weight", "bert.encoder.layer.14.attention.self.key.bias", "bert.encoder.layer.14.attention.self.value.weight", "bert.encoder.layer.14.attention.self.value.bias", "bert.encoder.layer.14.attention.output.dense.weight", "bert.encoder.layer.14.attention.output.dense.bias", "bert.encoder.layer.14.attention.output.LayerNorm.weight", "bert.encoder.layer.14.attention.output.LayerNorm.bias", "bert.encoder.layer.14.intermediate.dense.weight", "bert.encoder.layer.14.intermediate.dense.bias", "bert.encoder.layer.14.output.dense.weight", "bert.encoder.layer.14.output.dense.bias", "bert.encoder.layer.14.output.LayerNorm.weight", "bert.encoder.layer.14.output.LayerNorm.bias", "bert.encoder.layer.15.attention.self.query.weight", "bert.encoder.layer.15.attention.self.query.bias", "bert.encoder.layer.15.attention.self.key.weight", "bert.encoder.layer.15.attention.self.key.bias", "bert.encoder.layer.15.attention.self.value.weight", "bert.encoder.layer.15.attention.self.value.bias", "bert.encoder.layer.15.attention.output.dense.weight", "bert.encoder.layer.15.attention.output.dense.bias", "bert.encoder.layer.15.attention.output.LayerNorm.weight", "bert.encoder.layer.15.attention.output.LayerNorm.bias", "bert.encoder.layer.15.intermediate.dense.weight", "bert.encoder.layer.15.intermediate.dense.bias", "bert.encoder.layer.15.output.dense.weight", "bert.encoder.layer.15.output.dense.bias", "bert.encoder.layer.15.output.LayerNorm.weight", "bert.encoder.layer.15.output.LayerNorm.bias", "bert.encoder.layer.16.attention.self.query.weight", "bert.encoder.layer.16.attention.self.query.bias", "bert.encoder.layer.16.attention.self.key.weight", "bert.encoder.layer.16.attention.self.key.bias", "bert.encoder.layer.16.attention.self.value.weight", "bert.encoder.layer.16.attention.self.value.bias", "bert.encoder.layer.16.attention.output.dense.weight", "bert.encoder.layer.16.attention.output.dense.bias", "bert.encoder.layer.16.attention.output.LayerNorm.weight", "bert.encoder.layer.16.attention.output.LayerNorm.bias", "bert.encoder.layer.16.intermediate.dense.weight", "bert.encoder.layer.16.intermediate.dense.bias", "bert.encoder.layer.16.output.dense.weight", "bert.encoder.layer.16.output.dense.bias", "bert.encoder.layer.16.output.LayerNorm.weight", "bert.encoder.layer.16.output.LayerNorm.bias", "bert.encoder.layer.17.attention.self.query.weight", "bert.encoder.layer.17.attention.self.query.bias", "bert.encoder.layer.17.attention.self.key.weight", "bert.encoder.layer.17.attention.self.key.bias", "bert.encoder.layer.17.attention.self.value.weight", "bert.encoder.layer.17.attention.self.value.bias", "bert.encoder.layer.17.attention.output.dense.weight", "bert.encoder.layer.17.attention.output.dense.bias", "bert.encoder.layer.17.attention.output.LayerNorm.weight", "bert.encoder.layer.17.attention.output.LayerNorm.bias", "bert.encoder.layer.17.intermediate.dense.weight", "bert.encoder.layer.17.intermediate.dense.bias", "bert.encoder.layer.17.output.dense.weight", "bert.encoder.layer.17.output.dense.bias", "bert.encoder.layer.17.output.LayerNorm.weight", "bert.encoder.layer.17.output.LayerNorm.bias", "bert.encoder.layer.18.attention.self.query.weight", "bert.encoder.layer.18.attention.self.query.bias", "bert.encoder.layer.18.attention.self.key.weight", "bert.encoder.layer.18.attention.self.key.bias", "bert.encoder.layer.18.attention.self.value.weight", "bert.encoder.layer.18.attention.self.value.bias", "bert.encoder.layer.18.attention.output.dense.weight", "bert.encoder.layer.18.attention.output.dense.bias", "bert.encoder.layer.18.attention.output.LayerNorm.weight", "bert.encoder.layer.18.attention.output.LayerNorm.bias", "bert.encoder.layer.18.intermediate.dense.weight", "bert.encoder.layer.18.intermediate.dense.bias", "bert.encoder.layer.18.output.dense.weight", "bert.encoder.layer.18.output.dense.bias", "bert.encoder.layer.18.output.LayerNorm.weight", "bert.encoder.layer.18.output.LayerNorm.bias", "bert.encoder.layer.19.attention.self.query.weight", "bert.encoder.layer.19.attention.self.query.bias", "bert.encoder.layer.19.attention.self.key.weight", "bert.encoder.layer.19.attention.self.key.bias", "bert.encoder.layer.19.attention.self.value.weight", "bert.encoder.layer.19.attention.self.value.bias", "bert.encoder.layer.19.attention.output.dense.weight", "bert.encoder.layer.19.attention.output.dense.bias", "bert.encoder.layer.19.attention.output.LayerNorm.weight", "bert.encoder.layer.19.attention.output.LayerNorm.bias", "bert.encoder.layer.19.intermediate.dense.weight", "bert.encoder.layer.19.intermediate.dense.bias", "bert.encoder.layer.19.output.dense.weight", "bert.encoder.layer.19.output.dense.bias", "bert.encoder.layer.19.output.LayerNorm.weight", "bert.encoder.layer.19.output.LayerNorm.bias", "bert.encoder.layer.20.attention.self.query.weight", "bert.encoder.layer.20.attention.self.query.bias", "bert.encoder.layer.20.attention.self.key.weight", "bert.encoder.layer.20.attention.self.key.bias", "bert.encoder.layer.20.attention.self.value.weight", "bert.encoder.layer.20.attention.self.value.bias", "bert.encoder.layer.20.attention.output.dense.weight", "bert.encoder.layer.20.attention.output.dense.bias", "bert.encoder.layer.20.attention.output.LayerNorm.weight", "bert.encoder.layer.20.attention.output.LayerNorm.bias", "bert.encoder.layer.20.intermediate.dense.weight", "bert.encoder.layer.20.intermediate.dense.bias", "bert.encoder.layer.20.output.dense.weight", "bert.encoder.layer.20.output.dense.bias", "bert.encoder.layer.20.output.LayerNorm.weight", "bert.encoder.layer.20.output.LayerNorm.bias", "bert.encoder.layer.21.attention.self.query.weight", "bert.encoder.layer.21.attention.self.query.bias", "bert.encoder.layer.21.attention.self.key.weight", "bert.encoder.layer.21.attention.self.key.bias", "bert.encoder.layer.21.attention.self.value.weight", "bert.encoder.layer.21.attention.self.value.bias", "bert.encoder.layer.21.attention.output.dense.weight", "bert.encoder.layer.21.attention.output.dense.bias", "bert.encoder.layer.21.attention.output.LayerNorm.weight", "bert.encoder.layer.21.attention.output.LayerNorm.bias", "bert.encoder.layer.21.intermediate.dense.weight", "bert.encoder.layer.21.intermediate.dense.bias", "bert.encoder.layer.21.output.dense.weight", "bert.encoder.layer.21.output.dense.bias", "bert.encoder.layer.21.output.LayerNorm.weight", "bert.encoder.layer.21.output.LayerNorm.bias", "bert.encoder.layer.22.attention.self.query.weight", "bert.encoder.layer.22.attention.self.query.bias", "bert.encoder.layer.22.attention.self.key.weight", "bert.encoder.layer.22.attention.self.key.bias", "bert.encoder.layer.22.attention.self.value.weight", "bert.encoder.layer.22.attention.self.value.bias", "bert.encoder.layer.22.attention.output.dense.weight", "bert.encoder.layer.22.attention.output.dense.bias", "bert.encoder.layer.22.attention.output.LayerNorm.weight", "bert.encoder.layer.22.attention.output.LayerNorm.bias", "bert.encoder.layer.22.intermediate.dense.weight", "bert.encoder.layer.22.intermediate.dense.bias", "bert.encoder.layer.22.output.dense.weight", "bert.encoder.layer.22.output.dense.bias", "bert.encoder.layer.22.output.LayerNorm.weight", "bert.encoder.layer.22.output.LayerNorm.bias", "bert.encoder.layer.23.attention.self.query.weight", "bert.encoder.layer.23.attention.self.query.bias", "bert.encoder.layer.23.attention.self.key.weight", "bert.encoder.layer.23.attention.self.key.bias", "bert.encoder.layer.23.attention.self.value.weight", "bert.encoder.layer.23.attention.self.value.bias", "bert.encoder.layer.23.attention.output.dense.weight", "bert.encoder.layer.23.attention.output.dense.bias", "bert.encoder.layer.23.attention.output.LayerNorm.weight", "bert.encoder.layer.23.attention.output.LayerNorm.bias", "bert.encoder.layer.23.intermediate.dense.weight", "bert.encoder.layer.23.intermediate.dense.bias", "bert.encoder.layer.23.output.dense.weight", "bert.encoder.layer.23.output.dense.bias", "bert.encoder.layer.23.output.LayerNorm.weight", "bert.encoder.layer.23.output.LayerNorm.bias". 
An error occurred during training: Error(s) in loading state_dict for BERTClassifier:
	Missing key(s) in state_dict: "bert.embeddings.word_embeddings.weight", "bert.embeddings.position_embeddings.weight", "bert.embeddings.token_type_embeddings.weight", "bert.embeddings.LayerNorm.weight", "bert.embeddings.LayerNorm.bias", "bert.encoder.layer.0.attention.self.query.weight", "bert.encoder.layer.0.attention.self.query.bias", "bert.encoder.layer.0.attention.self.key.weight", "bert.encoder.layer.0.attention.self.key.bias", "bert.encoder.layer.0.attention.self.value.weight", "bert.encoder.layer.0.attention.self.value.bias", "bert.encoder.layer.0.attention.output.dense.weight", "bert.encoder.layer.0.attention.output.dense.bias", "bert.encoder.layer.0.attention.output.LayerNorm.weight", "bert.encoder.layer.0.attention.output.LayerNorm.bias", "bert.encoder.layer.0.intermediate.dense.weight", "bert.encoder.layer.0.intermediate.dense.bias", "bert.encoder.layer.0.output.dense.weight", "bert.encoder.layer.0.output.dense.bias", "bert.encoder.layer.0.output.LayerNorm.weight", "bert.encoder.layer.0.output.LayerNorm.bias", "bert.encoder.layer.1.attention.self.query.weight", "bert.encoder.layer.1.attention.self.query.bias", "bert.encoder.layer.1.attention.self.key.weight", "bert.encoder.layer.1.attention.self.key.bias", "bert.encoder.layer.1.attention.self.value.weight", "bert.encoder.layer.1.attention.self.value.bias", "bert.encoder.layer.1.attention.output.dense.weight", "bert.encoder.layer.1.attention.output.dense.bias", "bert.encoder.layer.1.attention.output.LayerNorm.weight", "bert.encoder.layer.1.attention.output.LayerNorm.bias", "bert.encoder.layer.1.intermediate.dense.weight", "bert.encoder.layer.1.intermediate.dense.bias", "bert.encoder.layer.1.output.dense.weight", "bert.encoder.layer.1.output.dense.bias", "bert.encoder.layer.1.output.LayerNorm.weight", "bert.encoder.layer.1.output.LayerNorm.bias", "bert.encoder.layer.2.attention.self.query.weight", "bert.encoder.layer.2.attention.self.query.bias", "bert.encoder.layer.2.attention.self.key.weight", "bert.encoder.layer.2.attention.self.key.bias", "bert.encoder.layer.2.attention.self.value.weight", "bert.encoder.layer.2.attention.self.value.bias", "bert.encoder.layer.2.attention.output.dense.weight", "bert.encoder.layer.2.attention.output.dense.bias", "bert.encoder.layer.2.attention.output.LayerNorm.weight", "bert.encoder.layer.2.attention.output.LayerNorm.bias", "bert.encoder.layer.2.intermediate.dense.weight", "bert.encoder.layer.2.intermediate.dense.bias", "bert.encoder.layer.2.output.dense.weight", "bert.encoder.layer.2.output.dense.bias", "bert.encoder.layer.2.output.LayerNorm.weight", "bert.encoder.layer.2.output.LayerNorm.bias", "bert.encoder.layer.3.attention.self.query.weight", "bert.encoder.layer.3.attention.self.query.bias", "bert.encoder.layer.3.attention.self.key.weight", "bert.encoder.layer.3.attention.self.key.bias", "bert.encoder.layer.3.attention.self.value.weight", "bert.encoder.layer.3.attention.self.value.bias", "bert.encoder.layer.3.attention.output.dense.weight", "bert.encoder.layer.3.attention.output.dense.bias", "bert.encoder.layer.3.attention.output.LayerNorm.weight", "bert.encoder.layer.3.attention.output.LayerNorm.bias", "bert.encoder.layer.3.intermediate.dense.weight", "bert.encoder.layer.3.intermediate.dense.bias", "bert.encoder.layer.3.output.dense.weight", "bert.encoder.layer.3.output.dense.bias", "bert.encoder.layer.3.output.LayerNorm.weight", "bert.encoder.layer.3.output.LayerNorm.bias", "bert.encoder.layer.4.attention.self.query.weight", "bert.encoder.layer.4.attention.self.query.bias", "bert.encoder.layer.4.attention.self.key.weight", "bert.encoder.layer.4.attention.self.key.bias", "bert.encoder.layer.4.attention.self.value.weight", "bert.encoder.layer.4.attention.self.value.bias", "bert.encoder.layer.4.attention.output.dense.weight", "bert.encoder.layer.4.attention.output.dense.bias", "bert.encoder.layer.4.attention.output.LayerNorm.weight", "bert.encoder.layer.4.attention.output.LayerNorm.bias", "bert.encoder.layer.4.intermediate.dense.weight", "bert.encoder.layer.4.intermediate.dense.bias", "bert.encoder.layer.4.output.dense.weight", "bert.encoder.layer.4.output.dense.bias", "bert.encoder.layer.4.output.LayerNorm.weight", "bert.encoder.layer.4.output.LayerNorm.bias", "bert.encoder.layer.5.attention.self.query.weight", "bert.encoder.layer.5.attention.self.query.bias", "bert.encoder.layer.5.attention.self.key.weight", "bert.encoder.layer.5.attention.self.key.bias", "bert.encoder.layer.5.attention.self.value.weight", "bert.encoder.layer.5.attention.self.value.bias", "bert.encoder.layer.5.attention.output.dense.weight", "bert.encoder.layer.5.attention.output.dense.bias", "bert.encoder.layer.5.attention.output.LayerNorm.weight", "bert.encoder.layer.5.attention.output.LayerNorm.bias", "bert.encoder.layer.5.intermediate.dense.weight", "bert.encoder.layer.5.intermediate.dense.bias", "bert.encoder.layer.5.output.dense.weight", "bert.encoder.layer.5.output.dense.bias", "bert.encoder.layer.5.output.LayerNorm.weight", "bert.encoder.layer.5.output.LayerNorm.bias", "bert.encoder.layer.6.attention.self.query.weight", "bert.encoder.layer.6.attention.self.query.bias", "bert.encoder.layer.6.attention.self.key.weight", "bert.encoder.layer.6.attention.self.key.bias", "bert.encoder.layer.6.attention.self.value.weight", "bert.encoder.layer.6.attention.self.value.bias", "bert.encoder.layer.6.attention.output.dense.weight", "bert.encoder.layer.6.attention.output.dense.bias", "bert.encoder.layer.6.attention.output.LayerNorm.weight", "bert.encoder.layer.6.attention.output.LayerNorm.bias", "bert.encoder.layer.6.intermediate.dense.weight", "bert.encoder.layer.6.intermediate.dense.bias", "bert.encoder.layer.6.output.dense.weight", "bert.encoder.layer.6.output.dense.bias", "bert.encoder.layer.6.output.LayerNorm.weight", "bert.encoder.layer.6.output.LayerNorm.bias", "bert.encoder.layer.7.attention.self.query.weight", "bert.encoder.layer.7.attention.self.query.bias", "bert.encoder.layer.7.attention.self.key.weight", "bert.encoder.layer.7.attention.self.key.bias", "bert.encoder.layer.7.attention.self.value.weight", "bert.encoder.layer.7.attention.self.value.bias", "bert.encoder.layer.7.attention.output.dense.weight", "bert.encoder.layer.7.attention.output.dense.bias", "bert.encoder.layer.7.attention.output.LayerNorm.weight", "bert.encoder.layer.7.attention.output.LayerNorm.bias", "bert.encoder.layer.7.intermediate.dense.weight", "bert.encoder.layer.7.intermediate.dense.bias", "bert.encoder.layer.7.output.dense.weight", "bert.encoder.layer.7.output.dense.bias", "bert.encoder.layer.7.output.LayerNorm.weight", "bert.encoder.layer.7.output.LayerNorm.bias", "bert.encoder.layer.8.attention.self.query.weight", "bert.encoder.layer.8.attention.self.query.bias", "bert.encoder.layer.8.attention.self.key.weight", "bert.encoder.layer.8.attention.self.key.bias", "bert.encoder.layer.8.attention.self.value.weight", "bert.encoder.layer.8.attention.self.value.bias", "bert.encoder.layer.8.attention.output.dense.weight", "bert.encoder.layer.8.attention.output.dense.bias", "bert.encoder.layer.8.attention.output.LayerNorm.weight", "bert.encoder.layer.8.attention.output.LayerNorm.bias", "bert.encoder.layer.8.intermediate.dense.weight", "bert.encoder.layer.8.intermediate.dense.bias", "bert.encoder.layer.8.output.dense.weight", "bert.encoder.layer.8.output.dense.bias", "bert.encoder.layer.8.output.LayerNorm.weight", "bert.encoder.layer.8.output.LayerNorm.bias", "bert.encoder.layer.9.attention.self.query.weight", "bert.encoder.layer.9.attention.self.query.bias", "bert.encoder.layer.9.attention.self.key.weight", "bert.encoder.layer.9.attention.self.key.bias", "bert.encoder.layer.9.attention.self.value.weight", "bert.encoder.layer.9.attention.self.value.bias", "bert.encoder.layer.9.attention.output.dense.weight", "bert.encoder.layer.9.attention.output.dense.bias", "bert.encoder.layer.9.attention.output.LayerNorm.weight", "bert.encoder.layer.9.attention.output.LayerNorm.bias", "bert.encoder.layer.9.intermediate.dense.weight", "bert.encoder.layer.9.intermediate.dense.bias", "bert.encoder.layer.9.output.dense.weight", "bert.encoder.layer.9.output.dense.bias", "bert.encoder.layer.9.output.LayerNorm.weight", "bert.encoder.layer.9.output.LayerNorm.bias", "bert.encoder.layer.10.attention.self.query.weight", "bert.encoder.layer.10.attention.self.query.bias", "bert.encoder.layer.10.attention.self.key.weight", "bert.encoder.layer.10.attention.self.key.bias", "bert.encoder.layer.10.attention.self.value.weight", "bert.encoder.layer.10.attention.self.value.bias", "bert.encoder.layer.10.attention.output.dense.weight", "bert.encoder.layer.10.attention.output.dense.bias", "bert.encoder.layer.10.attention.output.LayerNorm.weight", "bert.encoder.layer.10.attention.output.LayerNorm.bias", "bert.encoder.layer.10.intermediate.dense.weight", "bert.encoder.layer.10.intermediate.dense.bias", "bert.encoder.layer.10.output.dense.weight", "bert.encoder.layer.10.output.dense.bias", "bert.encoder.layer.10.output.LayerNorm.weight", "bert.encoder.layer.10.output.LayerNorm.bias", "bert.encoder.layer.11.attention.self.query.weight", "bert.encoder.layer.11.attention.self.query.bias", "bert.encoder.layer.11.attention.self.key.weight", "bert.encoder.layer.11.attention.self.key.bias", "bert.encoder.layer.11.attention.self.value.weight", "bert.encoder.layer.11.attention.self.value.bias", "bert.encoder.layer.11.attention.output.dense.weight", "bert.encoder.layer.11.attention.output.dense.bias", "bert.encoder.layer.11.attention.output.LayerNorm.weight", "bert.encoder.layer.11.attention.output.LayerNorm.bias", "bert.encoder.layer.11.intermediate.dense.weight", "bert.encoder.layer.11.intermediate.dense.bias", "bert.encoder.layer.11.output.dense.weight", "bert.encoder.layer.11.output.dense.bias", "bert.encoder.layer.11.output.LayerNorm.weight", "bert.encoder.layer.11.output.LayerNorm.bias", "bert.encoder.layer.12.attention.self.query.weight", "bert.encoder.layer.12.attention.self.query.bias", "bert.encoder.layer.12.attention.self.key.weight", "bert.encoder.layer.12.attention.self.key.bias", "bert.encoder.layer.12.attention.self.value.weight", "bert.encoder.layer.12.attention.self.value.bias", "bert.encoder.layer.12.attention.output.dense.weight", "bert.encoder.layer.12.attention.output.dense.bias", "bert.encoder.layer.12.attention.output.LayerNorm.weight", "bert.encoder.layer.12.attention.output.LayerNorm.bias", "bert.encoder.layer.12.intermediate.dense.weight", "bert.encoder.layer.12.intermediate.dense.bias", "bert.encoder.layer.12.output.dense.weight", "bert.encoder.layer.12.output.dense.bias", "bert.encoder.layer.12.output.LayerNorm.weight", "bert.encoder.layer.12.output.LayerNorm.bias", "bert.encoder.layer.13.attention.self.query.weight", "bert.encoder.layer.13.attention.self.query.bias", "bert.encoder.layer.13.attention.self.key.weight", "bert.encoder.layer.13.attention.self.key.bias", "bert.encoder.layer.13.attention.self.value.weight", "bert.encoder.layer.13.attention.self.value.bias", "bert.encoder.layer.13.attention.output.dense.weight", "bert.encoder.layer.13.attention.output.dense.bias", "bert.encoder.layer.13.attention.output.LayerNorm.weight", "bert.encoder.layer.13.attention.output.LayerNorm.bias", "bert.encoder.layer.13.intermediate.dense.weight", "bert.encoder.layer.13.intermediate.dense.bias", "bert.encoder.layer.13.output.dense.weight", "bert.encoder.layer.13.output.dense.bias", "bert.encoder.layer.13.output.LayerNorm.weight", "bert.encoder.layer.13.output.LayerNorm.bias", "bert.encoder.layer.14.attention.self.query.weight", "bert.encoder.layer.14.attention.self.query.bias", "bert.encoder.layer.14.attention.self.key.weight", "bert.encoder.layer.14.attention.self.key.bias", "bert.encoder.layer.14.attention.self.value.weight", "bert.encoder.layer.14.attention.self.value.bias", "bert.encoder.layer.14.attention.output.dense.weight", "bert.encoder.layer.14.attention.output.dense.bias", "bert.encoder.layer.14.attention.output.LayerNorm.weight", "bert.encoder.layer.14.attention.output.LayerNorm.bias", "bert.encoder.layer.14.intermediate.dense.weight", "bert.encoder.layer.14.intermediate.dense.bias", "bert.encoder.layer.14.output.dense.weight", "bert.encoder.layer.14.output.dense.bias", "bert.encoder.layer.14.output.LayerNorm.weight", "bert.encoder.layer.14.output.LayerNorm.bias", "bert.encoder.layer.15.attention.self.query.weight", "bert.encoder.layer.15.attention.self.query.bias", "bert.encoder.layer.15.attention.self.key.weight", "bert.encoder.layer.15.attention.self.key.bias", "bert.encoder.layer.15.attention.self.value.weight", "bert.encoder.layer.15.attention.self.value.bias", "bert.encoder.layer.15.attention.output.dense.weight", "bert.encoder.layer.15.attention.output.dense.bias", "bert.encoder.layer.15.attention.output.LayerNorm.weight", "bert.encoder.layer.15.attention.output.LayerNorm.bias", "bert.encoder.layer.15.intermediate.dense.weight", "bert.encoder.layer.15.intermediate.dense.bias", "bert.encoder.layer.15.output.dense.weight", "bert.encoder.layer.15.output.dense.bias", "bert.encoder.layer.15.output.LayerNorm.weight", "bert.encoder.layer.15.output.LayerNorm.bias", "bert.encoder.layer.16.attention.self.query.weight", "bert.encoder.layer.16.attention.self.query.bias", "bert.encoder.layer.16.attention.self.key.weight", "bert.encoder.layer.16.attention.self.key.bias", "bert.encoder.layer.16.attention.self.value.weight", "bert.encoder.layer.16.attention.self.value.bias", "bert.encoder.layer.16.attention.output.dense.weight", "bert.encoder.layer.16.attention.output.dense.bias", "bert.encoder.layer.16.attention.output.LayerNorm.weight", "bert.encoder.layer.16.attention.output.LayerNorm.bias", "bert.encoder.layer.16.intermediate.dense.weight", "bert.encoder.layer.16.intermediate.dense.bias", "bert.encoder.layer.16.output.dense.weight", "bert.encoder.layer.16.output.dense.bias", "bert.encoder.layer.16.output.LayerNorm.weight", "bert.encoder.layer.16.output.LayerNorm.bias", "bert.encoder.layer.17.attention.self.query.weight", "bert.encoder.layer.17.attention.self.query.bias", "bert.encoder.layer.17.attention.self.key.weight", "bert.encoder.layer.17.attention.self.key.bias", "bert.encoder.layer.17.attention.self.value.weight", "bert.encoder.layer.17.attention.self.value.bias", "bert.encoder.layer.17.attention.output.dense.weight", "bert.encoder.layer.17.attention.output.dense.bias", "bert.encoder.layer.17.attention.output.LayerNorm.weight", "bert.encoder.layer.17.attention.output.LayerNorm.bias", "bert.encoder.layer.17.intermediate.dense.weight", "bert.encoder.layer.17.intermediate.dense.bias", "bert.encoder.layer.17.output.dense.weight", "bert.encoder.layer.17.output.dense.bias", "bert.encoder.layer.17.output.LayerNorm.weight", "bert.encoder.layer.17.output.LayerNorm.bias", "bert.encoder.layer.18.attention.self.query.weight", "bert.encoder.layer.18.attention.self.query.bias", "bert.encoder.layer.18.attention.self.key.weight", "bert.encoder.layer.18.attention.self.key.bias", "bert.encoder.layer.18.attention.self.value.weight", "bert.encoder.layer.18.attention.self.value.bias", "bert.encoder.layer.18.attention.output.dense.weight", "bert.encoder.layer.18.attention.output.dense.bias", "bert.encoder.layer.18.attention.output.LayerNorm.weight", "bert.encoder.layer.18.attention.output.LayerNorm.bias", "bert.encoder.layer.18.intermediate.dense.weight", "bert.encoder.layer.18.intermediate.dense.bias", "bert.encoder.layer.18.output.dense.weight", "bert.encoder.layer.18.output.dense.bias", "bert.encoder.layer.18.output.LayerNorm.weight", "bert.encoder.layer.18.output.LayerNorm.bias", "bert.encoder.layer.19.attention.self.query.weight", "bert.encoder.layer.19.attention.self.query.bias", "bert.encoder.layer.19.attention.self.key.weight", "bert.encoder.layer.19.attention.self.key.bias", "bert.encoder.layer.19.attention.self.value.weight", "bert.encoder.layer.19.attention.self.value.bias", "bert.encoder.layer.19.attention.output.dense.weight", "bert.encoder.layer.19.attention.output.dense.bias", "bert.encoder.layer.19.attention.output.LayerNorm.weight", "bert.encoder.layer.19.attention.output.LayerNorm.bias", "bert.encoder.layer.19.intermediate.dense.weight", "bert.encoder.layer.19.intermediate.dense.bias", "bert.encoder.layer.19.output.dense.weight", "bert.encoder.layer.19.output.dense.bias", "bert.encoder.layer.19.output.LayerNorm.weight", "bert.encoder.layer.19.output.LayerNorm.bias", "bert.encoder.layer.20.attention.self.query.weight", "bert.encoder.layer.20.attention.self.query.bias", "bert.encoder.layer.20.attention.self.key.weight", "bert.encoder.layer.20.attention.self.key.bias", "bert.encoder.layer.20.attention.self.value.weight", "bert.encoder.layer.20.attention.self.value.bias", "bert.encoder.layer.20.attention.output.dense.weight", "bert.encoder.layer.20.attention.output.dense.bias", "bert.encoder.layer.20.attention.output.LayerNorm.weight", "bert.encoder.layer.20.attention.output.LayerNorm.bias", "bert.encoder.layer.20.intermediate.dense.weight", "bert.encoder.layer.20.intermediate.dense.bias", "bert.encoder.layer.20.output.dense.weight", "bert.encoder.layer.20.output.dense.bias", "bert.encoder.layer.20.output.LayerNorm.weight", "bert.encoder.layer.20.output.LayerNorm.bias", "bert.encoder.layer.21.attention.self.query.weight", "bert.encoder.layer.21.attention.self.query.bias", "bert.encoder.layer.21.attention.self.key.weight", "bert.encoder.layer.21.attention.self.key.bias", "bert.encoder.layer.21.attention.self.value.weight", "bert.encoder.layer.21.attention.self.value.bias", "bert.encoder.layer.21.attention.output.dense.weight", "bert.encoder.layer.21.attention.output.dense.bias", "bert.encoder.layer.21.attention.output.LayerNorm.weight", "bert.encoder.layer.21.attention.output.LayerNorm.bias", "bert.encoder.layer.21.intermediate.dense.weight", "bert.encoder.layer.21.intermediate.dense.bias", "bert.encoder.layer.21.output.dense.weight", "bert.encoder.layer.21.output.dense.bias", "bert.encoder.layer.21.output.LayerNorm.weight", "bert.encoder.layer.21.output.LayerNorm.bias", "bert.encoder.layer.22.attention.self.query.weight", "bert.encoder.layer.22.attention.self.query.bias", "bert.encoder.layer.22.attention.self.key.weight", "bert.encoder.layer.22.attention.self.key.bias", "bert.encoder.layer.22.attention.self.value.weight", "bert.encoder.layer.22.attention.self.value.bias", "bert.encoder.layer.22.attention.output.dense.weight", "bert.encoder.layer.22.attention.output.dense.bias", "bert.encoder.layer.22.attention.output.LayerNorm.weight", "bert.encoder.layer.22.attention.output.LayerNorm.bias", "bert.encoder.layer.22.intermediate.dense.weight", "bert.encoder.layer.22.intermediate.dense.bias", "bert.encoder.layer.22.output.dense.weight", "bert.encoder.layer.22.output.dense.bias", "bert.encoder.layer.22.output.LayerNorm.weight", "bert.encoder.layer.22.output.LayerNorm.bias", "bert.encoder.layer.23.attention.self.query.weight", "bert.encoder.layer.23.attention.self.query.bias", "bert.encoder.layer.23.attention.self.key.weight", "bert.encoder.layer.23.attention.self.key.bias", "bert.encoder.layer.23.attention.self.value.weight", "bert.encoder.layer.23.attention.self.value.bias", "bert.encoder.layer.23.attention.output.dense.weight", "bert.encoder.layer.23.attention.output.dense.bias", "bert.encoder.layer.23.attention.output.LayerNorm.weight", "bert.encoder.layer.23.attention.output.LayerNorm.bias", "bert.encoder.layer.23.intermediate.dense.weight", "bert.encoder.layer.23.intermediate.dense.bias", "bert.encoder.layer.23.output.dense.weight", "bert.encoder.layer.23.output.dense.bias", "bert.encoder.layer.23.output.LayerNorm.weight", "bert.encoder.layer.23.output.LayerNorm.bias". 

An error occurred during training: Error(s) in loading state_dict for BERTClassifier:
	Missing key(s) in state_dict: "bert.embeddings.word_embeddings.weight", "bert.embeddings.position_embeddings.weight", "bert.embeddings.token_type_embeddings.weight", "bert.embeddings.LayerNorm.weight", "bert.embeddings.LayerNorm.bias", "bert.encoder.layer.0.attention.self.query.weight", "bert.encoder.layer.0.attention.self.query.bias", "bert.encoder.layer.0.attention.self.key.weight", "bert.encoder.layer.0.attention.self.key.bias", "bert.encoder.layer.0.attention.self.value.weight", "bert.encoder.layer.0.attention.self.value.bias", "bert.encoder.layer.0.attention.output.dense.weight", "bert.encoder.layer.0.attention.output.dense.bias", "bert.encoder.layer.0.attention.output.LayerNorm.weight", "bert.encoder.layer.0.attention.output.LayerNorm.bias", "bert.encoder.layer.0.intermediate.dense.weight", "bert.encoder.layer.0.intermediate.dense.bias", "bert.encoder.layer.0.output.dense.weight", "bert.encoder.layer.0.output.dense.bias", "bert.encoder.layer.0.output.LayerNorm.weight", "bert.encoder.layer.0.output.LayerNorm.bias", "bert.encoder.layer.1.attention.self.query.weight", "bert.encoder.layer.1.attention.self.query.bias", "bert.encoder.layer.1.attention.self.key.weight", "bert.encoder.layer.1.attention.self.key.bias", "bert.encoder.layer.1.attention.self.value.weight", "bert.encoder.layer.1.attention.self.value.bias", "bert.encoder.layer.1.attention.output.dense.weight", "bert.encoder.layer.1.attention.output.dense.bias", "bert.encoder.layer.1.attention.output.LayerNorm.weight", "bert.encoder.layer.1.attention.output.LayerNorm.bias", "bert.encoder.layer.1.intermediate.dense.weight", "bert.encoder.layer.1.intermediate.dense.bias", "bert.encoder.layer.1.output.dense.weight", "bert.encoder.layer.1.output.dense.bias", "bert.encoder.layer.1.output.LayerNorm.weight", "bert.encoder.layer.1.output.LayerNorm.bias", "bert.encoder.layer.2.attention.self.query.weight", "bert.encoder.layer.2.attention.self.query.bias", "bert.encoder.layer.2.attention.self.key.weight", "bert.encoder.layer.2.attention.self.key.bias", "bert.encoder.layer.2.attention.self.value.weight", "bert.encoder.layer.2.attention.self.value.bias", "bert.encoder.layer.2.attention.output.dense.weight", "bert.encoder.layer.2.attention.output.dense.bias", "bert.encoder.layer.2.attention.output.LayerNorm.weight", "bert.encoder.layer.2.attention.output.LayerNorm.bias", "bert.encoder.layer.2.intermediate.dense.weight", "bert.encoder.layer.2.intermediate.dense.bias", "bert.encoder.layer.2.output.dense.weight", "bert.encoder.layer.2.output.dense.bias", "bert.encoder.layer.2.output.LayerNorm.weight", "bert.encoder.layer.2.output.LayerNorm.bias", "bert.encoder.layer.3.attention.self.query.weight", "bert.encoder.layer.3.attention.self.query.bias", "bert.encoder.layer.3.attention.self.key.weight", "bert.encoder.layer.3.attention.self.key.bias", "bert.encoder.layer.3.attention.self.value.weight", "bert.encoder.layer.3.attention.self.value.bias", "bert.encoder.layer.3.attention.output.dense.weight", "bert.encoder.layer.3.attention.output.dense.bias", "bert.encoder.layer.3.attention.output.LayerNorm.weight", "bert.encoder.layer.3.attention.output.LayerNorm.bias", "bert.encoder.layer.3.intermediate.dense.weight", "bert.encoder.layer.3.intermediate.dense.bias", "bert.encoder.layer.3.output.dense.weight", "bert.encoder.layer.3.output.dense.bias", "bert.encoder.layer.3.output.LayerNorm.weight", "bert.encoder.layer.3.output.LayerNorm.bias", "bert.encoder.layer.4.attention.self.query.weight", "bert.encoder.layer.4.attention.self.query.bias", "bert.encoder.layer.4.attention.self.key.weight", "bert.encoder.layer.4.attention.self.key.bias", "bert.encoder.layer.4.attention.self.value.weight", "bert.encoder.layer.4.attention.self.value.bias", "bert.encoder.layer.4.attention.output.dense.weight", "bert.encoder.layer.4.attention.output.dense.bias", "bert.encoder.layer.4.attention.output.LayerNorm.weight", "bert.encoder.layer.4.attention.output.LayerNorm.bias", "bert.encoder.layer.4.intermediate.dense.weight", "bert.encoder.layer.4.intermediate.dense.bias", "bert.encoder.layer.4.output.dense.weight", "bert.encoder.layer.4.output.dense.bias", "bert.encoder.layer.4.output.LayerNorm.weight", "bert.encoder.layer.4.output.LayerNorm.bias", "bert.encoder.layer.5.attention.self.query.weight", "bert.encoder.layer.5.attention.self.query.bias", "bert.encoder.layer.5.attention.self.key.weight", "bert.encoder.layer.5.attention.self.key.bias", "bert.encoder.layer.5.attention.self.value.weight", "bert.encoder.layer.5.attention.self.value.bias", "bert.encoder.layer.5.attention.output.dense.weight", "bert.encoder.layer.5.attention.output.dense.bias", "bert.encoder.layer.5.attention.output.LayerNorm.weight", "bert.encoder.layer.5.attention.output.LayerNorm.bias", "bert.encoder.layer.5.intermediate.dense.weight", "bert.encoder.layer.5.intermediate.dense.bias", "bert.encoder.layer.5.output.dense.weight", "bert.encoder.layer.5.output.dense.bias", "bert.encoder.layer.5.output.LayerNorm.weight", "bert.encoder.layer.5.output.LayerNorm.bias", "bert.encoder.layer.6.attention.self.query.weight", "bert.encoder.layer.6.attention.self.query.bias", "bert.encoder.layer.6.attention.self.key.weight", "bert.encoder.layer.6.attention.self.key.bias", "bert.encoder.layer.6.attention.self.value.weight", "bert.encoder.layer.6.attention.self.value.bias", "bert.encoder.layer.6.attention.output.dense.weight", "bert.encoder.layer.6.attention.output.dense.bias", "bert.encoder.layer.6.attention.output.LayerNorm.weight", "bert.encoder.layer.6.attention.output.LayerNorm.bias", "bert.encoder.layer.6.intermediate.dense.weight", "bert.encoder.layer.6.intermediate.dense.bias", "bert.encoder.layer.6.output.dense.weight", "bert.encoder.layer.6.output.dense.bias", "bert.encoder.layer.6.output.LayerNorm.weight", "bert.encoder.layer.6.output.LayerNorm.bias", "bert.encoder.layer.7.attention.self.query.weight", "bert.encoder.layer.7.attention.self.query.bias", "bert.encoder.layer.7.attention.self.key.weight", "bert.encoder.layer.7.attention.self.key.bias", "bert.encoder.layer.7.attention.self.value.weight", "bert.encoder.layer.7.attention.self.value.bias", "bert.encoder.layer.7.attention.output.dense.weight", "bert.encoder.layer.7.attention.output.dense.bias", "bert.encoder.layer.7.attention.output.LayerNorm.weight", "bert.encoder.layer.7.attention.output.LayerNorm.bias", "bert.encoder.layer.7.intermediate.dense.weight", "bert.encoder.layer.7.intermediate.dense.bias", "bert.encoder.layer.7.output.dense.weight", "bert.encoder.layer.7.output.dense.bias", "bert.encoder.layer.7.output.LayerNorm.weight", "bert.encoder.layer.7.output.LayerNorm.bias", "bert.encoder.layer.8.attention.self.query.weight", "bert.encoder.layer.8.attention.self.query.bias", "bert.encoder.layer.8.attention.self.key.weight", "bert.encoder.layer.8.attention.self.key.bias", "bert.encoder.layer.8.attention.self.value.weight", "bert.encoder.layer.8.attention.self.value.bias", "bert.encoder.layer.8.attention.output.dense.weight", "bert.encoder.layer.8.attention.output.dense.bias", "bert.encoder.layer.8.attention.output.LayerNorm.weight", "bert.encoder.layer.8.attention.output.LayerNorm.bias", "bert.encoder.layer.8.intermediate.dense.weight", "bert.encoder.layer.8.intermediate.dense.bias", "bert.encoder.layer.8.output.dense.weight", "bert.encoder.layer.8.output.dense.bias", "bert.encoder.layer.8.output.LayerNorm.weight", "bert.encoder.layer.8.output.LayerNorm.bias", "bert.encoder.layer.9.attention.self.query.weight", "bert.encoder.layer.9.attention.self.query.bias", "bert.encoder.layer.9.attention.self.key.weight", "bert.encoder.layer.9.attention.self.key.bias", "bert.encoder.layer.9.attention.self.value.weight", "bert.encoder.layer.9.attention.self.value.bias", "bert.encoder.layer.9.attention.output.dense.weight", "bert.encoder.layer.9.attention.output.dense.bias", "bert.encoder.layer.9.attention.output.LayerNorm.weight", "bert.encoder.layer.9.attention.output.LayerNorm.bias", "bert.encoder.layer.9.intermediate.dense.weight", "bert.encoder.layer.9.intermediate.dense.bias", "bert.encoder.layer.9.output.dense.weight", "bert.encoder.layer.9.output.dense.bias", "bert.encoder.layer.9.output.LayerNorm.weight", "bert.encoder.layer.9.output.LayerNorm.bias", "bert.encoder.layer.10.attention.self.query.weight", "bert.encoder.layer.10.attention.self.query.bias", "bert.encoder.layer.10.attention.self.key.weight", "bert.encoder.layer.10.attention.self.key.bias", "bert.encoder.layer.10.attention.self.value.weight", "bert.encoder.layer.10.attention.self.value.bias", "bert.encoder.layer.10.attention.output.dense.weight", "bert.encoder.layer.10.attention.output.dense.bias", "bert.encoder.layer.10.attention.output.LayerNorm.weight", "bert.encoder.layer.10.attention.output.LayerNorm.bias", "bert.encoder.layer.10.intermediate.dense.weight", "bert.encoder.layer.10.intermediate.dense.bias", "bert.encoder.layer.10.output.dense.weight", "bert.encoder.layer.10.output.dense.bias", "bert.encoder.layer.10.output.LayerNorm.weight", "bert.encoder.layer.10.output.LayerNorm.bias", "bert.encoder.layer.11.attention.self.query.weight", "bert.encoder.layer.11.attention.self.query.bias", "bert.encoder.layer.11.attention.self.key.weight", "bert.encoder.layer.11.attention.self.key.bias", "bert.encoder.layer.11.attention.self.value.weight", "bert.encoder.layer.11.attention.self.value.bias", "bert.encoder.layer.11.attention.output.dense.weight", "bert.encoder.layer.11.attention.output.dense.bias", "bert.encoder.layer.11.attention.output.LayerNorm.weight", "bert.encoder.layer.11.attention.output.LayerNorm.bias", "bert.encoder.layer.11.intermediate.dense.weight", "bert.encoder.layer.11.intermediate.dense.bias", "bert.encoder.layer.11.output.dense.weight", "bert.encoder.layer.11.output.dense.bias", "bert.encoder.layer.11.output.LayerNorm.weight", "bert.encoder.layer.11.output.LayerNorm.bias", "bert.encoder.layer.12.attention.self.query.weight", "bert.encoder.layer.12.attention.self.query.bias", "bert.encoder.layer.12.attention.self.key.weight", "bert.encoder.layer.12.attention.self.key.bias", "bert.encoder.layer.12.attention.self.value.weight", "bert.encoder.layer.12.attention.self.value.bias", "bert.encoder.layer.12.attention.output.dense.weight", "bert.encoder.layer.12.attention.output.dense.bias", "bert.encoder.layer.12.attention.output.LayerNorm.weight", "bert.encoder.layer.12.attention.output.LayerNorm.bias", "bert.encoder.layer.12.intermediate.dense.weight", "bert.encoder.layer.12.intermediate.dense.bias", "bert.encoder.layer.12.output.dense.weight", "bert.encoder.layer.12.output.dense.bias", "bert.encoder.layer.12.output.LayerNorm.weight", "bert.encoder.layer.12.output.LayerNorm.bias", "bert.encoder.layer.13.attention.self.query.weight", "bert.encoder.layer.13.attention.self.query.bias", "bert.encoder.layer.13.attention.self.key.weight", "bert.encoder.layer.13.attention.self.key.bias", "bert.encoder.layer.13.attention.self.value.weight", "bert.encoder.layer.13.attention.self.value.bias", "bert.encoder.layer.13.attention.output.dense.weight", "bert.encoder.layer.13.attention.output.dense.bias", "bert.encoder.layer.13.attention.output.LayerNorm.weight", "bert.encoder.layer.13.attention.output.LayerNorm.bias", "bert.encoder.layer.13.intermediate.dense.weight", "bert.encoder.layer.13.intermediate.dense.bias", "bert.encoder.layer.13.output.dense.weight", "bert.encoder.layer.13.output.dense.bias", "bert.encoder.layer.13.output.LayerNorm.weight", "bert.encoder.layer.13.output.LayerNorm.bias", "bert.encoder.layer.14.attention.self.query.weight", "bert.encoder.layer.14.attention.self.query.bias", "bert.encoder.layer.14.attention.self.key.weight", "bert.encoder.layer.14.attention.self.key.bias", "bert.encoder.layer.14.attention.self.value.weight", "bert.encoder.layer.14.attention.self.value.bias", "bert.encoder.layer.14.attention.output.dense.weight", "bert.encoder.layer.14.attention.output.dense.bias", "bert.encoder.layer.14.attention.output.LayerNorm.weight", "bert.encoder.layer.14.attention.output.LayerNorm.bias", "bert.encoder.layer.14.intermediate.dense.weight", "bert.encoder.layer.14.intermediate.dense.bias", "bert.encoder.layer.14.output.dense.weight", "bert.encoder.layer.14.output.dense.bias", "bert.encoder.layer.14.output.LayerNorm.weight", "bert.encoder.layer.14.output.LayerNorm.bias", "bert.encoder.layer.15.attention.self.query.weight", "bert.encoder.layer.15.attention.self.query.bias", "bert.encoder.layer.15.attention.self.key.weight", "bert.encoder.layer.15.attention.self.key.bias", "bert.encoder.layer.15.attention.self.value.weight", "bert.encoder.layer.15.attention.self.value.bias", "bert.encoder.layer.15.attention.output.dense.weight", "bert.encoder.layer.15.attention.output.dense.bias", "bert.encoder.layer.15.attention.output.LayerNorm.weight", "bert.encoder.layer.15.attention.output.LayerNorm.bias", "bert.encoder.layer.15.intermediate.dense.weight", "bert.encoder.layer.15.intermediate.dense.bias", "bert.encoder.layer.15.output.dense.weight", "bert.encoder.layer.15.output.dense.bias", "bert.encoder.layer.15.output.LayerNorm.weight", "bert.encoder.layer.15.output.LayerNorm.bias", "bert.encoder.layer.16.attention.self.query.weight", "bert.encoder.layer.16.attention.self.query.bias", "bert.encoder.layer.16.attention.self.key.weight", "bert.encoder.layer.16.attention.self.key.bias", "bert.encoder.layer.16.attention.self.value.weight", "bert.encoder.layer.16.attention.self.value.bias", "bert.encoder.layer.16.attention.output.dense.weight", "bert.encoder.layer.16.attention.output.dense.bias", "bert.encoder.layer.16.attention.output.LayerNorm.weight", "bert.encoder.layer.16.attention.output.LayerNorm.bias", "bert.encoder.layer.16.intermediate.dense.weight", "bert.encoder.layer.16.intermediate.dense.bias", "bert.encoder.layer.16.output.dense.weight", "bert.encoder.layer.16.output.dense.bias", "bert.encoder.layer.16.output.LayerNorm.weight", "bert.encoder.layer.16.output.LayerNorm.bias", "bert.encoder.layer.17.attention.self.query.weight", "bert.encoder.layer.17.attention.self.query.bias", "bert.encoder.layer.17.attention.self.key.weight", "bert.encoder.layer.17.attention.self.key.bias", "bert.encoder.layer.17.attention.self.value.weight", "bert.encoder.layer.17.attention.self.value.bias", "bert.encoder.layer.17.attention.output.dense.weight", "bert.encoder.layer.17.attention.output.dense.bias", "bert.encoder.layer.17.attention.output.LayerNorm.weight", "bert.encoder.layer.17.attention.output.LayerNorm.bias", "bert.encoder.layer.17.intermediate.dense.weight", "bert.encoder.layer.17.intermediate.dense.bias", "bert.encoder.layer.17.output.dense.weight", "bert.encoder.layer.17.output.dense.bias", "bert.encoder.layer.17.output.LayerNorm.weight", "bert.encoder.layer.17.output.LayerNorm.bias", "bert.encoder.layer.18.attention.self.query.weight", "bert.encoder.layer.18.attention.self.query.bias", "bert.encoder.layer.18.attention.self.key.weight", "bert.encoder.layer.18.attention.self.key.bias", "bert.encoder.layer.18.attention.self.value.weight", "bert.encoder.layer.18.attention.self.value.bias", "bert.encoder.layer.18.attention.output.dense.weight", "bert.encoder.layer.18.attention.output.dense.bias", "bert.encoder.layer.18.attention.output.LayerNorm.weight", "bert.encoder.layer.18.attention.output.LayerNorm.bias", "bert.encoder.layer.18.intermediate.dense.weight", "bert.encoder.layer.18.intermediate.dense.bias", "bert.encoder.layer.18.output.dense.weight", "bert.encoder.layer.18.output.dense.bias", "bert.encoder.layer.18.output.LayerNorm.weight", "bert.encoder.layer.18.output.LayerNorm.bias", "bert.encoder.layer.19.attention.self.query.weight", "bert.encoder.layer.19.attention.self.query.bias", "bert.encoder.layer.19.attention.self.key.weight", "bert.encoder.layer.19.attention.self.key.bias", "bert.encoder.layer.19.attention.self.value.weight", "bert.encoder.layer.19.attention.self.value.bias", "bert.encoder.layer.19.attention.output.dense.weight", "bert.encoder.layer.19.attention.output.dense.bias", "bert.encoder.layer.19.attention.output.LayerNorm.weight", "bert.encoder.layer.19.attention.output.LayerNorm.bias", "bert.encoder.layer.19.intermediate.dense.weight", "bert.encoder.layer.19.intermediate.dense.bias", "bert.encoder.layer.19.output.dense.weight", "bert.encoder.layer.19.output.dense.bias", "bert.encoder.layer.19.output.LayerNorm.weight", "bert.encoder.layer.19.output.LayerNorm.bias", "bert.encoder.layer.20.attention.self.query.weight", "bert.encoder.layer.20.attention.self.query.bias", "bert.encoder.layer.20.attention.self.key.weight", "bert.encoder.layer.20.attention.self.key.bias", "bert.encoder.layer.20.attention.self.value.weight", "bert.encoder.layer.20.attention.self.value.bias", "bert.encoder.layer.20.attention.output.dense.weight", "bert.encoder.layer.20.attention.output.dense.bias", "bert.encoder.layer.20.attention.output.LayerNorm.weight", "bert.encoder.layer.20.attention.output.LayerNorm.bias", "bert.encoder.layer.20.intermediate.dense.weight", "bert.encoder.layer.20.intermediate.dense.bias", "bert.encoder.layer.20.output.dense.weight", "bert.encoder.layer.20.output.dense.bias", "bert.encoder.layer.20.output.LayerNorm.weight", "bert.encoder.layer.20.output.LayerNorm.bias", "bert.encoder.layer.21.attention.self.query.weight", "bert.encoder.layer.21.attention.self.query.bias", "bert.encoder.layer.21.attention.self.key.weight", "bert.encoder.layer.21.attention.self.key.bias", "bert.encoder.layer.21.attention.self.value.weight", "bert.encoder.layer.21.attention.self.value.bias", "bert.encoder.layer.21.attention.output.dense.weight", "bert.encoder.layer.21.attention.output.dense.bias", "bert.encoder.layer.21.attention.output.LayerNorm.weight", "bert.encoder.layer.21.attention.output.LayerNorm.bias", "bert.encoder.layer.21.intermediate.dense.weight", "bert.encoder.layer.21.intermediate.dense.bias", "bert.encoder.layer.21.output.dense.weight", "bert.encoder.layer.21.output.dense.bias", "bert.encoder.layer.21.output.LayerNorm.weight", "bert.encoder.layer.21.output.LayerNorm.bias", "bert.encoder.layer.22.attention.self.query.weight", "bert.encoder.layer.22.attention.self.query.bias", "bert.encoder.layer.22.attention.self.key.weight", "bert.encoder.layer.22.attention.self.key.bias", "bert.encoder.layer.22.attention.self.value.weight", "bert.encoder.layer.22.attention.self.value.bias", "bert.encoder.layer.22.attention.output.dense.weight", "bert.encoder.layer.22.attention.output.dense.bias", "bert.encoder.layer.22.attention.output.LayerNorm.weight", "bert.encoder.layer.22.attention.output.LayerNorm.bias", "bert.encoder.layer.22.intermediate.dense.weight", "bert.encoder.layer.22.intermediate.dense.bias", "bert.encoder.layer.22.output.dense.weight", "bert.encoder.layer.22.output.dense.bias", "bert.encoder.layer.22.output.LayerNorm.weight", "bert.encoder.layer.22.output.LayerNorm.bias", "bert.encoder.layer.23.attention.self.query.weight", "bert.encoder.layer.23.attention.self.query.bias", "bert.encoder.layer.23.attention.self.key.weight", "bert.encoder.layer.23.attention.self.key.bias", "bert.encoder.layer.23.attention.self.value.weight", "bert.encoder.layer.23.attention.self.value.bias", "bert.encoder.layer.23.attention.output.dense.weight", "bert.encoder.layer.23.attention.output.dense.bias", "bert.encoder.layer.23.attention.output.LayerNorm.weight", "bert.encoder.layer.23.attention.output.LayerNorm.bias", "bert.encoder.layer.23.intermediate.dense.weight", "bert.encoder.layer.23.intermediate.dense.bias", "bert.encoder.layer.23.output.dense.weight", "bert.encoder.layer.23.output.dense.bias", "bert.encoder.layer.23.output.LayerNorm.weight", "bert.encoder.layer.23.output.LayerNorm.bias". 
An error occurred during training: Error(s) in loading state_dict for BERTClassifier:
	Missing key(s) in state_dict: "bert.embeddings.word_embeddings.weight", "bert.embeddings.position_embeddings.weight", "bert.embeddings.token_type_embeddings.weight", "bert.embeddings.LayerNorm.weight", "bert.embeddings.LayerNorm.bias", "bert.encoder.layer.0.attention.self.query.weight", "bert.encoder.layer.0.attention.self.query.bias", "bert.encoder.layer.0.attention.self.key.weight", "bert.encoder.layer.0.attention.self.key.bias", "bert.encoder.layer.0.attention.self.value.weight", "bert.encoder.layer.0.attention.self.value.bias", "bert.encoder.layer.0.attention.output.dense.weight", "bert.encoder.layer.0.attention.output.dense.bias", "bert.encoder.layer.0.attention.output.LayerNorm.weight", "bert.encoder.layer.0.attention.output.LayerNorm.bias", "bert.encoder.layer.0.intermediate.dense.weight", "bert.encoder.layer.0.intermediate.dense.bias", "bert.encoder.layer.0.output.dense.weight", "bert.encoder.layer.0.output.dense.bias", "bert.encoder.layer.0.output.LayerNorm.weight", "bert.encoder.layer.0.output.LayerNorm.bias", "bert.encoder.layer.1.attention.self.query.weight", "bert.encoder.layer.1.attention.self.query.bias", "bert.encoder.layer.1.attention.self.key.weight", "bert.encoder.layer.1.attention.self.key.bias", "bert.encoder.layer.1.attention.self.value.weight", "bert.encoder.layer.1.attention.self.value.bias", "bert.encoder.layer.1.attention.output.dense.weight", "bert.encoder.layer.1.attention.output.dense.bias", "bert.encoder.layer.1.attention.output.LayerNorm.weight", "bert.encoder.layer.1.attention.output.LayerNorm.bias", "bert.encoder.layer.1.intermediate.dense.weight", "bert.encoder.layer.1.intermediate.dense.bias", "bert.encoder.layer.1.output.dense.weight", "bert.encoder.layer.1.output.dense.bias", "bert.encoder.layer.1.output.LayerNorm.weight", "bert.encoder.layer.1.output.LayerNorm.bias", "bert.encoder.layer.2.attention.self.query.weight", "bert.encoder.layer.2.attention.self.query.bias", "bert.encoder.layer.2.attention.self.key.weight", "bert.encoder.layer.2.attention.self.key.bias", "bert.encoder.layer.2.attention.self.value.weight", "bert.encoder.layer.2.attention.self.value.bias", "bert.encoder.layer.2.attention.output.dense.weight", "bert.encoder.layer.2.attention.output.dense.bias", "bert.encoder.layer.2.attention.output.LayerNorm.weight", "bert.encoder.layer.2.attention.output.LayerNorm.bias", "bert.encoder.layer.2.intermediate.dense.weight", "bert.encoder.layer.2.intermediate.dense.bias", "bert.encoder.layer.2.output.dense.weight", "bert.encoder.layer.2.output.dense.bias", "bert.encoder.layer.2.output.LayerNorm.weight", "bert.encoder.layer.2.output.LayerNorm.bias", "bert.encoder.layer.3.attention.self.query.weight", "bert.encoder.layer.3.attention.self.query.bias", "bert.encoder.layer.3.attention.self.key.weight", "bert.encoder.layer.3.attention.self.key.bias", "bert.encoder.layer.3.attention.self.value.weight", "bert.encoder.layer.3.attention.self.value.bias", "bert.encoder.layer.3.attention.output.dense.weight", "bert.encoder.layer.3.attention.output.dense.bias", "bert.encoder.layer.3.attention.output.LayerNorm.weight", "bert.encoder.layer.3.attention.output.LayerNorm.bias", "bert.encoder.layer.3.intermediate.dense.weight", "bert.encoder.layer.3.intermediate.dense.bias", "bert.encoder.layer.3.output.dense.weight", "bert.encoder.layer.3.output.dense.bias", "bert.encoder.layer.3.output.LayerNorm.weight", "bert.encoder.layer.3.output.LayerNorm.bias", "bert.encoder.layer.4.attention.self.query.weight", "bert.encoder.layer.4.attention.self.query.bias", "bert.encoder.layer.4.attention.self.key.weight", "bert.encoder.layer.4.attention.self.key.bias", "bert.encoder.layer.4.attention.self.value.weight", "bert.encoder.layer.4.attention.self.value.bias", "bert.encoder.layer.4.attention.output.dense.weight", "bert.encoder.layer.4.attention.output.dense.bias", "bert.encoder.layer.4.attention.output.LayerNorm.weight", "bert.encoder.layer.4.attention.output.LayerNorm.bias", "bert.encoder.layer.4.intermediate.dense.weight", "bert.encoder.layer.4.intermediate.dense.bias", "bert.encoder.layer.4.output.dense.weight", "bert.encoder.layer.4.output.dense.bias", "bert.encoder.layer.4.output.LayerNorm.weight", "bert.encoder.layer.4.output.LayerNorm.bias", "bert.encoder.layer.5.attention.self.query.weight", "bert.encoder.layer.5.attention.self.query.bias", "bert.encoder.layer.5.attention.self.key.weight", "bert.encoder.layer.5.attention.self.key.bias", "bert.encoder.layer.5.attention.self.value.weight", "bert.encoder.layer.5.attention.self.value.bias", "bert.encoder.layer.5.attention.output.dense.weight", "bert.encoder.layer.5.attention.output.dense.bias", "bert.encoder.layer.5.attention.output.LayerNorm.weight", "bert.encoder.layer.5.attention.output.LayerNorm.bias", "bert.encoder.layer.5.intermediate.dense.weight", "bert.encoder.layer.5.intermediate.dense.bias", "bert.encoder.layer.5.output.dense.weight", "bert.encoder.layer.5.output.dense.bias", "bert.encoder.layer.5.output.LayerNorm.weight", "bert.encoder.layer.5.output.LayerNorm.bias", "bert.encoder.layer.6.attention.self.query.weight", "bert.encoder.layer.6.attention.self.query.bias", "bert.encoder.layer.6.attention.self.key.weight", "bert.encoder.layer.6.attention.self.key.bias", "bert.encoder.layer.6.attention.self.value.weight", "bert.encoder.layer.6.attention.self.value.bias", "bert.encoder.layer.6.attention.output.dense.weight", "bert.encoder.layer.6.attention.output.dense.bias", "bert.encoder.layer.6.attention.output.LayerNorm.weight", "bert.encoder.layer.6.attention.output.LayerNorm.bias", "bert.encoder.layer.6.intermediate.dense.weight", "bert.encoder.layer.6.intermediate.dense.bias", "bert.encoder.layer.6.output.dense.weight", "bert.encoder.layer.6.output.dense.bias", "bert.encoder.layer.6.output.LayerNorm.weight", "bert.encoder.layer.6.output.LayerNorm.bias", "bert.encoder.layer.7.attention.self.query.weight", "bert.encoder.layer.7.attention.self.query.bias", "bert.encoder.layer.7.attention.self.key.weight", "bert.encoder.layer.7.attention.self.key.bias", "bert.encoder.layer.7.attention.self.value.weight", "bert.encoder.layer.7.attention.self.value.bias", "bert.encoder.layer.7.attention.output.dense.weight", "bert.encoder.layer.7.attention.output.dense.bias", "bert.encoder.layer.7.attention.output.LayerNorm.weight", "bert.encoder.layer.7.attention.output.LayerNorm.bias", "bert.encoder.layer.7.intermediate.dense.weight", "bert.encoder.layer.7.intermediate.dense.bias", "bert.encoder.layer.7.output.dense.weight", "bert.encoder.layer.7.output.dense.bias", "bert.encoder.layer.7.output.LayerNorm.weight", "bert.encoder.layer.7.output.LayerNorm.bias", "bert.encoder.layer.8.attention.self.query.weight", "bert.encoder.layer.8.attention.self.query.bias", "bert.encoder.layer.8.attention.self.key.weight", "bert.encoder.layer.8.attention.self.key.bias", "bert.encoder.layer.8.attention.self.value.weight", "bert.encoder.layer.8.attention.self.value.bias", "bert.encoder.layer.8.attention.output.dense.weight", "bert.encoder.layer.8.attention.output.dense.bias", "bert.encoder.layer.8.attention.output.LayerNorm.weight", "bert.encoder.layer.8.attention.output.LayerNorm.bias", "bert.encoder.layer.8.intermediate.dense.weight", "bert.encoder.layer.8.intermediate.dense.bias", "bert.encoder.layer.8.output.dense.weight", "bert.encoder.layer.8.output.dense.bias", "bert.encoder.layer.8.output.LayerNorm.weight", "bert.encoder.layer.8.output.LayerNorm.bias", "bert.encoder.layer.9.attention.self.query.weight", "bert.encoder.layer.9.attention.self.query.bias", "bert.encoder.layer.9.attention.self.key.weight", "bert.encoder.layer.9.attention.self.key.bias", "bert.encoder.layer.9.attention.self.value.weight", "bert.encoder.layer.9.attention.self.value.bias", "bert.encoder.layer.9.attention.output.dense.weight", "bert.encoder.layer.9.attention.output.dense.bias", "bert.encoder.layer.9.attention.output.LayerNorm.weight", "bert.encoder.layer.9.attention.output.LayerNorm.bias", "bert.encoder.layer.9.intermediate.dense.weight", "bert.encoder.layer.9.intermediate.dense.bias", "bert.encoder.layer.9.output.dense.weight", "bert.encoder.layer.9.output.dense.bias", "bert.encoder.layer.9.output.LayerNorm.weight", "bert.encoder.layer.9.output.LayerNorm.bias", "bert.encoder.layer.10.attention.self.query.weight", "bert.encoder.layer.10.attention.self.query.bias", "bert.encoder.layer.10.attention.self.key.weight", "bert.encoder.layer.10.attention.self.key.bias", "bert.encoder.layer.10.attention.self.value.weight", "bert.encoder.layer.10.attention.self.value.bias", "bert.encoder.layer.10.attention.output.dense.weight", "bert.encoder.layer.10.attention.output.dense.bias", "bert.encoder.layer.10.attention.output.LayerNorm.weight", "bert.encoder.layer.10.attention.output.LayerNorm.bias", "bert.encoder.layer.10.intermediate.dense.weight", "bert.encoder.layer.10.intermediate.dense.bias", "bert.encoder.layer.10.output.dense.weight", "bert.encoder.layer.10.output.dense.bias", "bert.encoder.layer.10.output.LayerNorm.weight", "bert.encoder.layer.10.output.LayerNorm.bias", "bert.encoder.layer.11.attention.self.query.weight", "bert.encoder.layer.11.attention.self.query.bias", "bert.encoder.layer.11.attention.self.key.weight", "bert.encoder.layer.11.attention.self.key.bias", "bert.encoder.layer.11.attention.self.value.weight", "bert.encoder.layer.11.attention.self.value.bias", "bert.encoder.layer.11.attention.output.dense.weight", "bert.encoder.layer.11.attention.output.dense.bias", "bert.encoder.layer.11.attention.output.LayerNorm.weight", "bert.encoder.layer.11.attention.output.LayerNorm.bias", "bert.encoder.layer.11.intermediate.dense.weight", "bert.encoder.layer.11.intermediate.dense.bias", "bert.encoder.layer.11.output.dense.weight", "bert.encoder.layer.11.output.dense.bias", "bert.encoder.layer.11.output.LayerNorm.weight", "bert.encoder.layer.11.output.LayerNorm.bias", "bert.encoder.layer.12.attention.self.query.weight", "bert.encoder.layer.12.attention.self.query.bias", "bert.encoder.layer.12.attention.self.key.weight", "bert.encoder.layer.12.attention.self.key.bias", "bert.encoder.layer.12.attention.self.value.weight", "bert.encoder.layer.12.attention.self.value.bias", "bert.encoder.layer.12.attention.output.dense.weight", "bert.encoder.layer.12.attention.output.dense.bias", "bert.encoder.layer.12.attention.output.LayerNorm.weight", "bert.encoder.layer.12.attention.output.LayerNorm.bias", "bert.encoder.layer.12.intermediate.dense.weight", "bert.encoder.layer.12.intermediate.dense.bias", "bert.encoder.layer.12.output.dense.weight", "bert.encoder.layer.12.output.dense.bias", "bert.encoder.layer.12.output.LayerNorm.weight", "bert.encoder.layer.12.output.LayerNorm.bias", "bert.encoder.layer.13.attention.self.query.weight", "bert.encoder.layer.13.attention.self.query.bias", "bert.encoder.layer.13.attention.self.key.weight", "bert.encoder.layer.13.attention.self.key.bias", "bert.encoder.layer.13.attention.self.value.weight", "bert.encoder.layer.13.attention.self.value.bias", "bert.encoder.layer.13.attention.output.dense.weight", "bert.encoder.layer.13.attention.output.dense.bias", "bert.encoder.layer.13.attention.output.LayerNorm.weight", "bert.encoder.layer.13.attention.output.LayerNorm.bias", "bert.encoder.layer.13.intermediate.dense.weight", "bert.encoder.layer.13.intermediate.dense.bias", "bert.encoder.layer.13.output.dense.weight", "bert.encoder.layer.13.output.dense.bias", "bert.encoder.layer.13.output.LayerNorm.weight", "bert.encoder.layer.13.output.LayerNorm.bias", "bert.encoder.layer.14.attention.self.query.weight", "bert.encoder.layer.14.attention.self.query.bias", "bert.encoder.layer.14.attention.self.key.weight", "bert.encoder.layer.14.attention.self.key.bias", "bert.encoder.layer.14.attention.self.value.weight", "bert.encoder.layer.14.attention.self.value.bias", "bert.encoder.layer.14.attention.output.dense.weight", "bert.encoder.layer.14.attention.output.dense.bias", "bert.encoder.layer.14.attention.output.LayerNorm.weight", "bert.encoder.layer.14.attention.output.LayerNorm.bias", "bert.encoder.layer.14.intermediate.dense.weight", "bert.encoder.layer.14.intermediate.dense.bias", "bert.encoder.layer.14.output.dense.weight", "bert.encoder.layer.14.output.dense.bias", "bert.encoder.layer.14.output.LayerNorm.weight", "bert.encoder.layer.14.output.LayerNorm.bias", "bert.encoder.layer.15.attention.self.query.weight", "bert.encoder.layer.15.attention.self.query.bias", "bert.encoder.layer.15.attention.self.key.weight", "bert.encoder.layer.15.attention.self.key.bias", "bert.encoder.layer.15.attention.self.value.weight", "bert.encoder.layer.15.attention.self.value.bias", "bert.encoder.layer.15.attention.output.dense.weight", "bert.encoder.layer.15.attention.output.dense.bias", "bert.encoder.layer.15.attention.output.LayerNorm.weight", "bert.encoder.layer.15.attention.output.LayerNorm.bias", "bert.encoder.layer.15.intermediate.dense.weight", "bert.encoder.layer.15.intermediate.dense.bias", "bert.encoder.layer.15.output.dense.weight", "bert.encoder.layer.15.output.dense.bias", "bert.encoder.layer.15.output.LayerNorm.weight", "bert.encoder.layer.15.output.LayerNorm.bias", "bert.encoder.layer.16.attention.self.query.weight", "bert.encoder.layer.16.attention.self.query.bias", "bert.encoder.layer.16.attention.self.key.weight", "bert.encoder.layer.16.attention.self.key.bias", "bert.encoder.layer.16.attention.self.value.weight", "bert.encoder.layer.16.attention.self.value.bias", "bert.encoder.layer.16.attention.output.dense.weight", "bert.encoder.layer.16.attention.output.dense.bias", "bert.encoder.layer.16.attention.output.LayerNorm.weight", "bert.encoder.layer.16.attention.output.LayerNorm.bias", "bert.encoder.layer.16.intermediate.dense.weight", "bert.encoder.layer.16.intermediate.dense.bias", "bert.encoder.layer.16.output.dense.weight", "bert.encoder.layer.16.output.dense.bias", "bert.encoder.layer.16.output.LayerNorm.weight", "bert.encoder.layer.16.output.LayerNorm.bias", "bert.encoder.layer.17.attention.self.query.weight", "bert.encoder.layer.17.attention.self.query.bias", "bert.encoder.layer.17.attention.self.key.weight", "bert.encoder.layer.17.attention.self.key.bias", "bert.encoder.layer.17.attention.self.value.weight", "bert.encoder.layer.17.attention.self.value.bias", "bert.encoder.layer.17.attention.output.dense.weight", "bert.encoder.layer.17.attention.output.dense.bias", "bert.encoder.layer.17.attention.output.LayerNorm.weight", "bert.encoder.layer.17.attention.output.LayerNorm.bias", "bert.encoder.layer.17.intermediate.dense.weight", "bert.encoder.layer.17.intermediate.dense.bias", "bert.encoder.layer.17.output.dense.weight", "bert.encoder.layer.17.output.dense.bias", "bert.encoder.layer.17.output.LayerNorm.weight", "bert.encoder.layer.17.output.LayerNorm.bias", "bert.encoder.layer.18.attention.self.query.weight", "bert.encoder.layer.18.attention.self.query.bias", "bert.encoder.layer.18.attention.self.key.weight", "bert.encoder.layer.18.attention.self.key.bias", "bert.encoder.layer.18.attention.self.value.weight", "bert.encoder.layer.18.attention.self.value.bias", "bert.encoder.layer.18.attention.output.dense.weight", "bert.encoder.layer.18.attention.output.dense.bias", "bert.encoder.layer.18.attention.output.LayerNorm.weight", "bert.encoder.layer.18.attention.output.LayerNorm.bias", "bert.encoder.layer.18.intermediate.dense.weight", "bert.encoder.layer.18.intermediate.dense.bias", "bert.encoder.layer.18.output.dense.weight", "bert.encoder.layer.18.output.dense.bias", "bert.encoder.layer.18.output.LayerNorm.weight", "bert.encoder.layer.18.output.LayerNorm.bias", "bert.encoder.layer.19.attention.self.query.weight", "bert.encoder.layer.19.attention.self.query.bias", "bert.encoder.layer.19.attention.self.key.weight", "bert.encoder.layer.19.attention.self.key.bias", "bert.encoder.layer.19.attention.self.value.weight", "bert.encoder.layer.19.attention.self.value.bias", "bert.encoder.layer.19.attention.output.dense.weight", "bert.encoder.layer.19.attention.output.dense.bias", "bert.encoder.layer.19.attention.output.LayerNorm.weight", "bert.encoder.layer.19.attention.output.LayerNorm.bias", "bert.encoder.layer.19.intermediate.dense.weight", "bert.encoder.layer.19.intermediate.dense.bias", "bert.encoder.layer.19.output.dense.weight", "bert.encoder.layer.19.output.dense.bias", "bert.encoder.layer.19.output.LayerNorm.weight", "bert.encoder.layer.19.output.LayerNorm.bias", "bert.encoder.layer.20.attention.self.query.weight", "bert.encoder.layer.20.attention.self.query.bias", "bert.encoder.layer.20.attention.self.key.weight", "bert.encoder.layer.20.attention.self.key.bias", "bert.encoder.layer.20.attention.self.value.weight", "bert.encoder.layer.20.attention.self.value.bias", "bert.encoder.layer.20.attention.output.dense.weight", "bert.encoder.layer.20.attention.output.dense.bias", "bert.encoder.layer.20.attention.output.LayerNorm.weight", "bert.encoder.layer.20.attention.output.LayerNorm.bias", "bert.encoder.layer.20.intermediate.dense.weight", "bert.encoder.layer.20.intermediate.dense.bias", "bert.encoder.layer.20.output.dense.weight", "bert.encoder.layer.20.output.dense.bias", "bert.encoder.layer.20.output.LayerNorm.weight", "bert.encoder.layer.20.output.LayerNorm.bias", "bert.encoder.layer.21.attention.self.query.weight", "bert.encoder.layer.21.attention.self.query.bias", "bert.encoder.layer.21.attention.self.key.weight", "bert.encoder.layer.21.attention.self.key.bias", "bert.encoder.layer.21.attention.self.value.weight", "bert.encoder.layer.21.attention.self.value.bias", "bert.encoder.layer.21.attention.output.dense.weight", "bert.encoder.layer.21.attention.output.dense.bias", "bert.encoder.layer.21.attention.output.LayerNorm.weight", "bert.encoder.layer.21.attention.output.LayerNorm.bias", "bert.encoder.layer.21.intermediate.dense.weight", "bert.encoder.layer.21.intermediate.dense.bias", "bert.encoder.layer.21.output.dense.weight", "bert.encoder.layer.21.output.dense.bias", "bert.encoder.layer.21.output.LayerNorm.weight", "bert.encoder.layer.21.output.LayerNorm.bias", "bert.encoder.layer.22.attention.self.query.weight", "bert.encoder.layer.22.attention.self.query.bias", "bert.encoder.layer.22.attention.self.key.weight", "bert.encoder.layer.22.attention.self.key.bias", "bert.encoder.layer.22.attention.self.value.weight", "bert.encoder.layer.22.attention.self.value.bias", "bert.encoder.layer.22.attention.output.dense.weight", "bert.encoder.layer.22.attention.output.dense.bias", "bert.encoder.layer.22.attention.output.LayerNorm.weight", "bert.encoder.layer.22.attention.output.LayerNorm.bias", "bert.encoder.layer.22.intermediate.dense.weight", "bert.encoder.layer.22.intermediate.dense.bias", "bert.encoder.layer.22.output.dense.weight", "bert.encoder.layer.22.output.dense.bias", "bert.encoder.layer.22.output.LayerNorm.weight", "bert.encoder.layer.22.output.LayerNorm.bias", "bert.encoder.layer.23.attention.self.query.weight", "bert.encoder.layer.23.attention.self.query.bias", "bert.encoder.layer.23.attention.self.key.weight", "bert.encoder.layer.23.attention.self.key.bias", "bert.encoder.layer.23.attention.self.value.weight", "bert.encoder.layer.23.attention.self.value.bias", "bert.encoder.layer.23.attention.output.dense.weight", "bert.encoder.layer.23.attention.output.dense.bias", "bert.encoder.layer.23.attention.output.LayerNorm.weight", "bert.encoder.layer.23.attention.output.LayerNorm.bias", "bert.encoder.layer.23.intermediate.dense.weight", "bert.encoder.layer.23.intermediate.dense.bias", "bert.encoder.layer.23.output.dense.weight", "bert.encoder.layer.23.output.dense.bias", "bert.encoder.layer.23.output.LayerNorm.weight", "bert.encoder.layer.23.output.LayerNorm.bias". 
An error occurred during training: Error(s) in loading state_dict for BERTClassifier:
	Missing key(s) in state_dict: "bert.embeddings.word_embeddings.weight", "bert.embeddings.position_embeddings.weight", "bert.embeddings.token_type_embeddings.weight", "bert.embeddings.LayerNorm.weight", "bert.embeddings.LayerNorm.bias", "bert.encoder.layer.0.attention.self.query.weight", "bert.encoder.layer.0.attention.self.query.bias", "bert.encoder.layer.0.attention.self.key.weight", "bert.encoder.layer.0.attention.self.key.bias", "bert.encoder.layer.0.attention.self.value.weight", "bert.encoder.layer.0.attention.self.value.bias", "bert.encoder.layer.0.attention.output.dense.weight", "bert.encoder.layer.0.attention.output.dense.bias", "bert.encoder.layer.0.attention.output.LayerNorm.weight", "bert.encoder.layer.0.attention.output.LayerNorm.bias", "bert.encoder.layer.0.intermediate.dense.weight", "bert.encoder.layer.0.intermediate.dense.bias", "bert.encoder.layer.0.output.dense.weight", "bert.encoder.layer.0.output.dense.bias", "bert.encoder.layer.0.output.LayerNorm.weight", "bert.encoder.layer.0.output.LayerNorm.bias", "bert.encoder.layer.1.attention.self.query.weight", "bert.encoder.layer.1.attention.self.query.bias", "bert.encoder.layer.1.attention.self.key.weight", "bert.encoder.layer.1.attention.self.key.bias", "bert.encoder.layer.1.attention.self.value.weight", "bert.encoder.layer.1.attention.self.value.bias", "bert.encoder.layer.1.attention.output.dense.weight", "bert.encoder.layer.1.attention.output.dense.bias", "bert.encoder.layer.1.attention.output.LayerNorm.weight", "bert.encoder.layer.1.attention.output.LayerNorm.bias", "bert.encoder.layer.1.intermediate.dense.weight", "bert.encoder.layer.1.intermediate.dense.bias", "bert.encoder.layer.1.output.dense.weight", "bert.encoder.layer.1.output.dense.bias", "bert.encoder.layer.1.output.LayerNorm.weight", "bert.encoder.layer.1.output.LayerNorm.bias", "bert.encoder.layer.2.attention.self.query.weight", "bert.encoder.layer.2.attention.self.query.bias", "bert.encoder.layer.2.attention.self.key.weight", "bert.encoder.layer.2.attention.self.key.bias", "bert.encoder.layer.2.attention.self.value.weight", "bert.encoder.layer.2.attention.self.value.bias", "bert.encoder.layer.2.attention.output.dense.weight", "bert.encoder.layer.2.attention.output.dense.bias", "bert.encoder.layer.2.attention.output.LayerNorm.weight", "bert.encoder.layer.2.attention.output.LayerNorm.bias", "bert.encoder.layer.2.intermediate.dense.weight", "bert.encoder.layer.2.intermediate.dense.bias", "bert.encoder.layer.2.output.dense.weight", "bert.encoder.layer.2.output.dense.bias", "bert.encoder.layer.2.output.LayerNorm.weight", "bert.encoder.layer.2.output.LayerNorm.bias", "bert.encoder.layer.3.attention.self.query.weight", "bert.encoder.layer.3.attention.self.query.bias", "bert.encoder.layer.3.attention.self.key.weight", "bert.encoder.layer.3.attention.self.key.bias", "bert.encoder.layer.3.attention.self.value.weight", "bert.encoder.layer.3.attention.self.value.bias", "bert.encoder.layer.3.attention.output.dense.weight", "bert.encoder.layer.3.attention.output.dense.bias", "bert.encoder.layer.3.attention.output.LayerNorm.weight", "bert.encoder.layer.3.attention.output.LayerNorm.bias", "bert.encoder.layer.3.intermediate.dense.weight", "bert.encoder.layer.3.intermediate.dense.bias", "bert.encoder.layer.3.output.dense.weight", "bert.encoder.layer.3.output.dense.bias", "bert.encoder.layer.3.output.LayerNorm.weight", "bert.encoder.layer.3.output.LayerNorm.bias", "bert.encoder.layer.4.attention.self.query.weight", "bert.encoder.layer.4.attention.self.query.bias", "bert.encoder.layer.4.attention.self.key.weight", "bert.encoder.layer.4.attention.self.key.bias", "bert.encoder.layer.4.attention.self.value.weight", "bert.encoder.layer.4.attention.self.value.bias", "bert.encoder.layer.4.attention.output.dense.weight", "bert.encoder.layer.4.attention.output.dense.bias", "bert.encoder.layer.4.attention.output.LayerNorm.weight", "bert.encoder.layer.4.attention.output.LayerNorm.bias", "bert.encoder.layer.4.intermediate.dense.weight", "bert.encoder.layer.4.intermediate.dense.bias", "bert.encoder.layer.4.output.dense.weight", "bert.encoder.layer.4.output.dense.bias", "bert.encoder.layer.4.output.LayerNorm.weight", "bert.encoder.layer.4.output.LayerNorm.bias", "bert.encoder.layer.5.attention.self.query.weight", "bert.encoder.layer.5.attention.self.query.bias", "bert.encoder.layer.5.attention.self.key.weight", "bert.encoder.layer.5.attention.self.key.bias", "bert.encoder.layer.5.attention.self.value.weight", "bert.encoder.layer.5.attention.self.value.bias", "bert.encoder.layer.5.attention.output.dense.weight", "bert.encoder.layer.5.attention.output.dense.bias", "bert.encoder.layer.5.attention.output.LayerNorm.weight", "bert.encoder.layer.5.attention.output.LayerNorm.bias", "bert.encoder.layer.5.intermediate.dense.weight", "bert.encoder.layer.5.intermediate.dense.bias", "bert.encoder.layer.5.output.dense.weight", "bert.encoder.layer.5.output.dense.bias", "bert.encoder.layer.5.output.LayerNorm.weight", "bert.encoder.layer.5.output.LayerNorm.bias", "bert.encoder.layer.6.attention.self.query.weight", "bert.encoder.layer.6.attention.self.query.bias", "bert.encoder.layer.6.attention.self.key.weight", "bert.encoder.layer.6.attention.self.key.bias", "bert.encoder.layer.6.attention.self.value.weight", "bert.encoder.layer.6.attention.self.value.bias", "bert.encoder.layer.6.attention.output.dense.weight", "bert.encoder.layer.6.attention.output.dense.bias", "bert.encoder.layer.6.attention.output.LayerNorm.weight", "bert.encoder.layer.6.attention.output.LayerNorm.bias", "bert.encoder.layer.6.intermediate.dense.weight", "bert.encoder.layer.6.intermediate.dense.bias", "bert.encoder.layer.6.output.dense.weight", "bert.encoder.layer.6.output.dense.bias", "bert.encoder.layer.6.output.LayerNorm.weight", "bert.encoder.layer.6.output.LayerNorm.bias", "bert.encoder.layer.7.attention.self.query.weight", "bert.encoder.layer.7.attention.self.query.bias", "bert.encoder.layer.7.attention.self.key.weight", "bert.encoder.layer.7.attention.self.key.bias", "bert.encoder.layer.7.attention.self.value.weight", "bert.encoder.layer.7.attention.self.value.bias", "bert.encoder.layer.7.attention.output.dense.weight", "bert.encoder.layer.7.attention.output.dense.bias", "bert.encoder.layer.7.attention.output.LayerNorm.weight", "bert.encoder.layer.7.attention.output.LayerNorm.bias", "bert.encoder.layer.7.intermediate.dense.weight", "bert.encoder.layer.7.intermediate.dense.bias", "bert.encoder.layer.7.output.dense.weight", "bert.encoder.layer.7.output.dense.bias", "bert.encoder.layer.7.output.LayerNorm.weight", "bert.encoder.layer.7.output.LayerNorm.bias", "bert.encoder.layer.8.attention.self.query.weight", "bert.encoder.layer.8.attention.self.query.bias", "bert.encoder.layer.8.attention.self.key.weight", "bert.encoder.layer.8.attention.self.key.bias", "bert.encoder.layer.8.attention.self.value.weight", "bert.encoder.layer.8.attention.self.value.bias", "bert.encoder.layer.8.attention.output.dense.weight", "bert.encoder.layer.8.attention.output.dense.bias", "bert.encoder.layer.8.attention.output.LayerNorm.weight", "bert.encoder.layer.8.attention.output.LayerNorm.bias", "bert.encoder.layer.8.intermediate.dense.weight", "bert.encoder.layer.8.intermediate.dense.bias", "bert.encoder.layer.8.output.dense.weight", "bert.encoder.layer.8.output.dense.bias", "bert.encoder.layer.8.output.LayerNorm.weight", "bert.encoder.layer.8.output.LayerNorm.bias", "bert.encoder.layer.9.attention.self.query.weight", "bert.encoder.layer.9.attention.self.query.bias", "bert.encoder.layer.9.attention.self.key.weight", "bert.encoder.layer.9.attention.self.key.bias", "bert.encoder.layer.9.attention.self.value.weight", "bert.encoder.layer.9.attention.self.value.bias", "bert.encoder.layer.9.attention.output.dense.weight", "bert.encoder.layer.9.attention.output.dense.bias", "bert.encoder.layer.9.attention.output.LayerNorm.weight", "bert.encoder.layer.9.attention.output.LayerNorm.bias", "bert.encoder.layer.9.intermediate.dense.weight", "bert.encoder.layer.9.intermediate.dense.bias", "bert.encoder.layer.9.output.dense.weight", "bert.encoder.layer.9.output.dense.bias", "bert.encoder.layer.9.output.LayerNorm.weight", "bert.encoder.layer.9.output.LayerNorm.bias", "bert.encoder.layer.10.attention.self.query.weight", "bert.encoder.layer.10.attention.self.query.bias", "bert.encoder.layer.10.attention.self.key.weight", "bert.encoder.layer.10.attention.self.key.bias", "bert.encoder.layer.10.attention.self.value.weight", "bert.encoder.layer.10.attention.self.value.bias", "bert.encoder.layer.10.attention.output.dense.weight", "bert.encoder.layer.10.attention.output.dense.bias", "bert.encoder.layer.10.attention.output.LayerNorm.weight", "bert.encoder.layer.10.attention.output.LayerNorm.bias", "bert.encoder.layer.10.intermediate.dense.weight", "bert.encoder.layer.10.intermediate.dense.bias", "bert.encoder.layer.10.output.dense.weight", "bert.encoder.layer.10.output.dense.bias", "bert.encoder.layer.10.output.LayerNorm.weight", "bert.encoder.layer.10.output.LayerNorm.bias", "bert.encoder.layer.11.attention.self.query.weight", "bert.encoder.layer.11.attention.self.query.bias", "bert.encoder.layer.11.attention.self.key.weight", "bert.encoder.layer.11.attention.self.key.bias", "bert.encoder.layer.11.attention.self.value.weight", "bert.encoder.layer.11.attention.self.value.bias", "bert.encoder.layer.11.attention.output.dense.weight", "bert.encoder.layer.11.attention.output.dense.bias", "bert.encoder.layer.11.attention.output.LayerNorm.weight", "bert.encoder.layer.11.attention.output.LayerNorm.bias", "bert.encoder.layer.11.intermediate.dense.weight", "bert.encoder.layer.11.intermediate.dense.bias", "bert.encoder.layer.11.output.dense.weight", "bert.encoder.layer.11.output.dense.bias", "bert.encoder.layer.11.output.LayerNorm.weight", "bert.encoder.layer.11.output.LayerNorm.bias", "bert.encoder.layer.12.attention.self.query.weight", "bert.encoder.layer.12.attention.self.query.bias", "bert.encoder.layer.12.attention.self.key.weight", "bert.encoder.layer.12.attention.self.key.bias", "bert.encoder.layer.12.attention.self.value.weight", "bert.encoder.layer.12.attention.self.value.bias", "bert.encoder.layer.12.attention.output.dense.weight", "bert.encoder.layer.12.attention.output.dense.bias", "bert.encoder.layer.12.attention.output.LayerNorm.weight", "bert.encoder.layer.12.attention.output.LayerNorm.bias", "bert.encoder.layer.12.intermediate.dense.weight", "bert.encoder.layer.12.intermediate.dense.bias", "bert.encoder.layer.12.output.dense.weight", "bert.encoder.layer.12.output.dense.bias", "bert.encoder.layer.12.output.LayerNorm.weight", "bert.encoder.layer.12.output.LayerNorm.bias", "bert.encoder.layer.13.attention.self.query.weight", "bert.encoder.layer.13.attention.self.query.bias", "bert.encoder.layer.13.attention.self.key.weight", "bert.encoder.layer.13.attention.self.key.bias", "bert.encoder.layer.13.attention.self.value.weight", "bert.encoder.layer.13.attention.self.value.bias", "bert.encoder.layer.13.attention.output.dense.weight", "bert.encoder.layer.13.attention.output.dense.bias", "bert.encoder.layer.13.attention.output.LayerNorm.weight", "bert.encoder.layer.13.attention.output.LayerNorm.bias", "bert.encoder.layer.13.intermediate.dense.weight", "bert.encoder.layer.13.intermediate.dense.bias", "bert.encoder.layer.13.output.dense.weight", "bert.encoder.layer.13.output.dense.bias", "bert.encoder.layer.13.output.LayerNorm.weight", "bert.encoder.layer.13.output.LayerNorm.bias", "bert.encoder.layer.14.attention.self.query.weight", "bert.encoder.layer.14.attention.self.query.bias", "bert.encoder.layer.14.attention.self.key.weight", "bert.encoder.layer.14.attention.self.key.bias", "bert.encoder.layer.14.attention.self.value.weight", "bert.encoder.layer.14.attention.self.value.bias", "bert.encoder.layer.14.attention.output.dense.weight", "bert.encoder.layer.14.attention.output.dense.bias", "bert.encoder.layer.14.attention.output.LayerNorm.weight", "bert.encoder.layer.14.attention.output.LayerNorm.bias", "bert.encoder.layer.14.intermediate.dense.weight", "bert.encoder.layer.14.intermediate.dense.bias", "bert.encoder.layer.14.output.dense.weight", "bert.encoder.layer.14.output.dense.bias", "bert.encoder.layer.14.output.LayerNorm.weight", "bert.encoder.layer.14.output.LayerNorm.bias", "bert.encoder.layer.15.attention.self.query.weight", "bert.encoder.layer.15.attention.self.query.bias", "bert.encoder.layer.15.attention.self.key.weight", "bert.encoder.layer.15.attention.self.key.bias", "bert.encoder.layer.15.attention.self.value.weight", "bert.encoder.layer.15.attention.self.value.bias", "bert.encoder.layer.15.attention.output.dense.weight", "bert.encoder.layer.15.attention.output.dense.bias", "bert.encoder.layer.15.attention.output.LayerNorm.weight", "bert.encoder.layer.15.attention.output.LayerNorm.bias", "bert.encoder.layer.15.intermediate.dense.weight", "bert.encoder.layer.15.intermediate.dense.bias", "bert.encoder.layer.15.output.dense.weight", "bert.encoder.layer.15.output.dense.bias", "bert.encoder.layer.15.output.LayerNorm.weight", "bert.encoder.layer.15.output.LayerNorm.bias", "bert.encoder.layer.16.attention.self.query.weight", "bert.encoder.layer.16.attention.self.query.bias", "bert.encoder.layer.16.attention.self.key.weight", "bert.encoder.layer.16.attention.self.key.bias", "bert.encoder.layer.16.attention.self.value.weight", "bert.encoder.layer.16.attention.self.value.bias", "bert.encoder.layer.16.attention.output.dense.weight", "bert.encoder.layer.16.attention.output.dense.bias", "bert.encoder.layer.16.attention.output.LayerNorm.weight", "bert.encoder.layer.16.attention.output.LayerNorm.bias", "bert.encoder.layer.16.intermediate.dense.weight", "bert.encoder.layer.16.intermediate.dense.bias", "bert.encoder.layer.16.output.dense.weight", "bert.encoder.layer.16.output.dense.bias", "bert.encoder.layer.16.output.LayerNorm.weight", "bert.encoder.layer.16.output.LayerNorm.bias", "bert.encoder.layer.17.attention.self.query.weight", "bert.encoder.layer.17.attention.self.query.bias", "bert.encoder.layer.17.attention.self.key.weight", "bert.encoder.layer.17.attention.self.key.bias", "bert.encoder.layer.17.attention.self.value.weight", "bert.encoder.layer.17.attention.self.value.bias", "bert.encoder.layer.17.attention.output.dense.weight", "bert.encoder.layer.17.attention.output.dense.bias", "bert.encoder.layer.17.attention.output.LayerNorm.weight", "bert.encoder.layer.17.attention.output.LayerNorm.bias", "bert.encoder.layer.17.intermediate.dense.weight", "bert.encoder.layer.17.intermediate.dense.bias", "bert.encoder.layer.17.output.dense.weight", "bert.encoder.layer.17.output.dense.bias", "bert.encoder.layer.17.output.LayerNorm.weight", "bert.encoder.layer.17.output.LayerNorm.bias", "bert.encoder.layer.18.attention.self.query.weight", "bert.encoder.layer.18.attention.self.query.bias", "bert.encoder.layer.18.attention.self.key.weight", "bert.encoder.layer.18.attention.self.key.bias", "bert.encoder.layer.18.attention.self.value.weight", "bert.encoder.layer.18.attention.self.value.bias", "bert.encoder.layer.18.attention.output.dense.weight", "bert.encoder.layer.18.attention.output.dense.bias", "bert.encoder.layer.18.attention.output.LayerNorm.weight", "bert.encoder.layer.18.attention.output.LayerNorm.bias", "bert.encoder.layer.18.intermediate.dense.weight", "bert.encoder.layer.18.intermediate.dense.bias", "bert.encoder.layer.18.output.dense.weight", "bert.encoder.layer.18.output.dense.bias", "bert.encoder.layer.18.output.LayerNorm.weight", "bert.encoder.layer.18.output.LayerNorm.bias", "bert.encoder.layer.19.attention.self.query.weight", "bert.encoder.layer.19.attention.self.query.bias", "bert.encoder.layer.19.attention.self.key.weight", "bert.encoder.layer.19.attention.self.key.bias", "bert.encoder.layer.19.attention.self.value.weight", "bert.encoder.layer.19.attention.self.value.bias", "bert.encoder.layer.19.attention.output.dense.weight", "bert.encoder.layer.19.attention.output.dense.bias", "bert.encoder.layer.19.attention.output.LayerNorm.weight", "bert.encoder.layer.19.attention.output.LayerNorm.bias", "bert.encoder.layer.19.intermediate.dense.weight", "bert.encoder.layer.19.intermediate.dense.bias", "bert.encoder.layer.19.output.dense.weight", "bert.encoder.layer.19.output.dense.bias", "bert.encoder.layer.19.output.LayerNorm.weight", "bert.encoder.layer.19.output.LayerNorm.bias", "bert.encoder.layer.20.attention.self.query.weight", "bert.encoder.layer.20.attention.self.query.bias", "bert.encoder.layer.20.attention.self.key.weight", "bert.encoder.layer.20.attention.self.key.bias", "bert.encoder.layer.20.attention.self.value.weight", "bert.encoder.layer.20.attention.self.value.bias", "bert.encoder.layer.20.attention.output.dense.weight", "bert.encoder.layer.20.attention.output.dense.bias", "bert.encoder.layer.20.attention.output.LayerNorm.weight", "bert.encoder.layer.20.attention.output.LayerNorm.bias", "bert.encoder.layer.20.intermediate.dense.weight", "bert.encoder.layer.20.intermediate.dense.bias", "bert.encoder.layer.20.output.dense.weight", "bert.encoder.layer.20.output.dense.bias", "bert.encoder.layer.20.output.LayerNorm.weight", "bert.encoder.layer.20.output.LayerNorm.bias", "bert.encoder.layer.21.attention.self.query.weight", "bert.encoder.layer.21.attention.self.query.bias", "bert.encoder.layer.21.attention.self.key.weight", "bert.encoder.layer.21.attention.self.key.bias", "bert.encoder.layer.21.attention.self.value.weight", "bert.encoder.layer.21.attention.self.value.bias", "bert.encoder.layer.21.attention.output.dense.weight", "bert.encoder.layer.21.attention.output.dense.bias", "bert.encoder.layer.21.attention.output.LayerNorm.weight", "bert.encoder.layer.21.attention.output.LayerNorm.bias", "bert.encoder.layer.21.intermediate.dense.weight", "bert.encoder.layer.21.intermediate.dense.bias", "bert.encoder.layer.21.output.dense.weight", "bert.encoder.layer.21.output.dense.bias", "bert.encoder.layer.21.output.LayerNorm.weight", "bert.encoder.layer.21.output.LayerNorm.bias", "bert.encoder.layer.22.attention.self.query.weight", "bert.encoder.layer.22.attention.self.query.bias", "bert.encoder.layer.22.attention.self.key.weight", "bert.encoder.layer.22.attention.self.key.bias", "bert.encoder.layer.22.attention.self.value.weight", "bert.encoder.layer.22.attention.self.value.bias", "bert.encoder.layer.22.attention.output.dense.weight", "bert.encoder.layer.22.attention.output.dense.bias", "bert.encoder.layer.22.attention.output.LayerNorm.weight", "bert.encoder.layer.22.attention.output.LayerNorm.bias", "bert.encoder.layer.22.intermediate.dense.weight", "bert.encoder.layer.22.intermediate.dense.bias", "bert.encoder.layer.22.output.dense.weight", "bert.encoder.layer.22.output.dense.bias", "bert.encoder.layer.22.output.LayerNorm.weight", "bert.encoder.layer.22.output.LayerNorm.bias", "bert.encoder.layer.23.attention.self.query.weight", "bert.encoder.layer.23.attention.self.query.bias", "bert.encoder.layer.23.attention.self.key.weight", "bert.encoder.layer.23.attention.self.key.bias", "bert.encoder.layer.23.attention.self.value.weight", "bert.encoder.layer.23.attention.self.value.bias", "bert.encoder.layer.23.attention.output.dense.weight", "bert.encoder.layer.23.attention.output.dense.bias", "bert.encoder.layer.23.attention.output.LayerNorm.weight", "bert.encoder.layer.23.attention.output.LayerNorm.bias", "bert.encoder.layer.23.intermediate.dense.weight", "bert.encoder.layer.23.intermediate.dense.bias", "bert.encoder.layer.23.output.dense.weight", "bert.encoder.layer.23.output.dense.bias", "bert.encoder.layer.23.output.LayerNorm.weight", "bert.encoder.layer.23.output.LayerNorm.bias". 

Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
  File "/home/ubuntu/nlp-osaka/sentiment/ddp_sentiment_finetune.py", line 1206, in main
    classifier.fit(X_train, X_val, y_train, y_val, rank, world_size, debug, start_epoch, model_state_dict, optimizer_state_dict,
  File "/home/ubuntu/nlp-osaka/sentiment/torch_ddp_finetune_neural_classifier.py", line 1115, in fit
    self.model.load_state_dict(model_state_dict)
  File "/home/ubuntu/nlp-osaka/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 2152, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
  File "/home/ubuntu/nlp-osaka/sentiment/ddp_sentiment_finetune.py", line 1206, in main
    classifier.fit(X_train, X_val, y_train, y_val, rank, world_size, debug, start_epoch, model_state_dict, optimizer_state_dict,
Traceback (most recent call last):
  File "/home/ubuntu/nlp-osaka/sentiment/torch_ddp_finetune_neural_classifier.py", line 1115, in fit
    self.model.load_state_dict(model_state_dict)
  File "/home/ubuntu/nlp-osaka/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 2152, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
  File "/home/ubuntu/nlp-osaka/sentiment/ddp_sentiment_finetune.py", line 1206, in main
    classifier.fit(X_train, X_val, y_train, y_val, rank, world_size, debug, start_epoch, model_state_dict, optimizer_state_dict,
RuntimeError: Error(s) in loading state_dict for BERTClassifier:
	Missing key(s) in state_dict: "bert.embeddings.word_embeddings.weight", "bert.embeddings.position_embeddings.weight", "bert.embeddings.token_type_embeddings.weight", "bert.embeddings.LayerNorm.weight", "bert.embeddings.LayerNorm.bias", "bert.encoder.layer.0.attention.self.query.weight", "bert.encoder.layer.0.attention.self.query.bias", "bert.encoder.layer.0.attention.self.key.weight", "bert.encoder.layer.0.attention.self.key.bias", "bert.encoder.layer.0.attention.self.value.weight", "bert.encoder.layer.0.attention.self.value.bias", "bert.encoder.layer.0.attention.output.dense.weight", "bert.encoder.layer.0.attention.output.dense.bias", "bert.encoder.layer.0.attention.output.LayerNorm.weight", "bert.encoder.layer.0.attention.output.LayerNorm.bias", "bert.encoder.layer.0.intermediate.dense.weight", "bert.encoder.layer.0.intermediate.dense.bias", "bert.encoder.layer.0.output.dense.weight", "bert.encoder.layer.0.output.dense.bias", "bert.encoder.layer.0.output.LayerNorm.weight", "bert.encoder.layer.0.output.LayerNorm.bias", "bert.encoder.layer.1.attention.self.query.weight", "bert.encoder.layer.1.attention.self.query.bias", "bert.encoder.layer.1.attention.self.key.weight", "bert.encoder.layer.1.attention.self.key.bias", "bert.encoder.layer.1.attention.self.value.weight", "bert.encoder.layer.1.attention.self.value.bias", "bert.encoder.layer.1.attention.output.dense.weight", "bert.encoder.layer.1.attention.output.dense.bias", "bert.encoder.layer.1.attention.output.LayerNorm.weight", "bert.encoder.layer.1.attention.output.LayerNorm.bias", "bert.encoder.layer.1.intermediate.dense.weight", "bert.encoder.layer.1.intermediate.dense.bias", "bert.encoder.layer.1.output.dense.weight", "bert.encoder.layer.1.output.dense.bias", "bert.encoder.layer.1.output.LayerNorm.weight", "bert.encoder.layer.1.output.LayerNorm.bias", "bert.encoder.layer.2.attention.self.query.weight", "bert.encoder.layer.2.attention.self.query.bias", "bert.encoder.layer.2.attention.self.key.weight", "bert.encoder.layer.2.attention.self.key.bias", "bert.encoder.layer.2.attention.self.value.weight", "bert.encoder.layer.2.attention.self.value.bias", "bert.encoder.layer.2.attention.output.dense.weight", "bert.encoder.layer.2.attention.output.dense.bias", "bert.encoder.layer.2.attention.output.LayerNorm.weight", "bert.encoder.layer.2.attention.output.LayerNorm.bias", "bert.encoder.layer.2.intermediate.dense.weight", "bert.encoder.layer.2.intermediate.dense.bias", "bert.encoder.layer.2.output.dense.weight", "bert.encoder.layer.2.output.dense.bias", "bert.encoder.layer.2.output.LayerNorm.weight", "bert.encoder.layer.2.output.LayerNorm.bias", "bert.encoder.layer.3.attention.self.query.weight", "bert.encoder.layer.3.attention.self.query.bias", "bert.encoder.layer.3.attention.self.key.weight", "bert.encoder.layer.3.attention.self.key.bias", "bert.encoder.layer.3.attention.self.value.weight", "bert.encoder.layer.3.attention.self.value.bias", "bert.encoder.layer.3.attention.output.dense.weight", "bert.encoder.layer.3.attention.output.dense.bias", "bert.encoder.layer.3.attention.output.LayerNorm.weight", "bert.encoder.layer.3.attention.output.LayerNorm.bias", "bert.encoder.layer.3.intermediate.dense.weight", "bert.encoder.layer.3.intermediate.dense.bias", "bert.encoder.layer.3.output.dense.weight", "bert.encoder.layer.3.output.dense.bias", "bert.encoder.layer.3.output.LayerNorm.weight", "bert.encoder.layer.3.output.LayerNorm.bias", "bert.encoder.layer.4.attention.self.query.weight", "bert.encoder.layer.4.attention.self.query.bias", "bert.encoder.layer.4.attention.self.key.weight", "bert.encoder.layer.4.attention.self.key.bias", "bert.encoder.layer.4.attention.self.value.weight", "bert.encoder.layer.4.attention.self.value.bias", "bert.encoder.layer.4.attention.output.dense.weight", "bert.encoder.layer.4.attention.output.dense.bias", "bert.encoder.layer.4.attention.output.LayerNorm.weight", "bert.encoder.layer.4.attention.output.LayerNorm.bias", "bert.encoder.layer.4.intermediate.dense.weight", "bert.encoder.layer.4.intermediate.dense.bias", "bert.encoder.layer.4.output.dense.weight", "bert.encoder.layer.4.output.dense.bias", "bert.encoder.layer.4.output.LayerNorm.weight", "bert.encoder.layer.4.output.LayerNorm.bias", "bert.encoder.layer.5.attention.self.query.weight", "bert.encoder.layer.5.attention.self.query.bias", "bert.encoder.layer.5.attention.self.key.weight", "bert.encoder.layer.5.attention.self.key.bias", "bert.encoder.layer.5.attention.self.value.weight", "bert.encoder.layer.5.attention.self.value.bias", "bert.encoder.layer.5.attention.output.dense.weight", "bert.encoder.layer.5.attention.output.dense.bias", "bert.encoder.layer.5.attention.output.LayerNorm.weight", "bert.encoder.layer.5.attention.output.LayerNorm.bias", "bert.encoder.layer.5.intermediate.dense.weight", "bert.encoder.layer.5.intermediate.dense.bias", "bert.encoder.layer.5.output.dense.weight", "bert.encoder.layer.5.output.dense.bias", "bert.encoder.layer.5.output.LayerNorm.weight", "bert.encoder.layer.5.output.LayerNorm.bias", "bert.encoder.layer.6.attention.self.query.weight", "bert.encoder.layer.6.attention.self.query.bias", "bert.encoder.layer.6.attention.self.key.weight", "bert.encoder.layer.6.attention.self.key.bias", "bert.encoder.layer.6.attention.self.value.weight", "bert.encoder.layer.6.attention.self.value.bias", "bert.encoder.layer.6.attention.output.dense.weight", "bert.encoder.layer.6.attention.output.dense.bias", "bert.encoder.layer.6.attention.output.LayerNorm.weight", "bert.encoder.layer.6.attention.output.LayerNorm.bias", "bert.encoder.layer.6.intermediate.dense.weight", "bert.encoder.layer.6.intermediate.dense.bias", "bert.encoder.layer.6.output.dense.weight", "bert.encoder.layer.6.output.dense.bias", "bert.encoder.layer.6.output.LayerNorm.weight", "bert.encoder.layer.6.output.LayerNorm.bias", "bert.encoder.layer.7.attention.self.query.weight", "bert.encoder.layer.7.attention.self.query.bias", "bert.encoder.layer.7.attention.self.key.weight", "bert.encoder.layer.7.attention.self.key.bias", "bert.encoder.layer.7.attention.self.value.weight", "bert.encoder.layer.7.attention.self.value.bias", "bert.encoder.layer.7.attention.output.dense.weight", "bert.encoder.layer.7.attention.output.dense.bias", "bert.encoder.layer.7.attention.output.LayerNorm.weight", "bert.encoder.layer.7.attention.output.LayerNorm.bias", "bert.encoder.layer.7.intermediate.dense.weight", "bert.encoder.layer.7.intermediate.dense.bias", "bert.encoder.layer.7.output.dense.weight", "bert.encoder.layer.7.output.dense.bias", "bert.encoder.layer.7.output.LayerNorm.weight", "bert.encoder.layer.7.output.LayerNorm.bias", "bert.encoder.layer.8.attention.self.query.weight", "bert.encoder.layer.8.attention.self.query.bias", "bert.encoder.layer.8.attention.self.key.weight", "bert.encoder.layer.8.attention.self.key.bias", "bert.encoder.layer.8.attention.self.value.weight", "bert.encoder.layer.8.attention.self.value.bias", "bert.encoder.layer.8.attention.output.dense.weight", "bert.encoder.layer.8.attention.output.dense.bias", "bert.encoder.layer.8.attention.output.LayerNorm.weight", "bert.encoder.layer.8.attention.output.LayerNorm.bias", "bert.encoder.layer.8.intermediate.dense.weight", "bert.encoder.layer.8.intermediate.dense.bias", "bert.encoder.layer.8.output.dense.weight", "bert.encoder.layer.8.output.dense.bias", "bert.encoder.layer.8.output.LayerNorm.weight", "bert.encoder.layer.8.output.LayerNorm.bias", "bert.encoder.layer.9.attention.self.query.weight", "bert.encoder.layer.9.attention.self.query.bias", "bert.encoder.layer.9.attention.self.key.weight", "bert.encoder.layer.9.attention.self.key.bias", "bert.encoder.layer.9.attention.self.value.weight", "bert.encoder.layer.9.attention.self.value.bias", "bert.encoder.layer.9.attention.output.dense.weight", "bert.encoder.layer.9.attention.output.dense.bias", "bert.encoder.layer.9.attention.output.LayerNorm.weight", "bert.encoder.layer.9.attention.output.LayerNorm.bias", "bert.encoder.layer.9.intermediate.dense.weight", "bert.encoder.layer.9.intermediate.dense.bias", "bert.encoder.layer.9.output.dense.weight", "bert.encoder.layer.9.output.dense.bias", "bert.encoder.layer.9.output.LayerNorm.weight", "bert.encoder.layer.9.output.LayerNorm.bias", "bert.encoder.layer.10.attention.self.query.weight", "bert.encoder.layer.10.attention.self.query.bias", "bert.encoder.layer.10.attention.self.key.weight", "bert.encoder.layer.10.attention.self.key.bias", "bert.encoder.layer.10.attention.self.value.weight", "bert.encoder.layer.10.attention.self.value.bias", "bert.encoder.layer.10.attention.output.dense.weight", "bert.encoder.layer.10.attention.output.dense.bias", "bert.encoder.layer.10.attention.output.LayerNorm.weight", "bert.encoder.layer.10.attention.output.LayerNorm.bias", "bert.encoder.layer.10.intermediate.dense.weight", "bert.encoder.layer.10.intermediate.dense.bias", "bert.encoder.layer.10.output.dense.weight", "bert.encoder.layer.10.output.dense.bias", "bert.encoder.layer.10.output.LayerNorm.weight", "bert.encoder.layer.10.output.LayerNorm.bias", "bert.encoder.layer.11.attention.self.query.weight", "bert.encoder.layer.11.attention.self.query.bias", "bert.encoder.layer.11.attention.self.key.weight", "bert.encoder.layer.11.attention.self.key.bias", "bert.encoder.layer.11.attention.self.value.weight", "bert.encoder.layer.11.attention.self.value.bias", "bert.encoder.layer.11.attention.output.dense.weight", "bert.encoder.layer.11.attention.output.dense.bias", "bert.encoder.layer.11.attention.output.LayerNorm.weight", "bert.encoder.layer.11.attention.output.LayerNorm.bias", "bert.encoder.layer.11.intermediate.dense.weight", "bert.encoder.layer.11.intermediate.dense.bias", "bert.encoder.layer.11.output.dense.weight", "bert.encoder.layer.11.output.dense.bias", "bert.encoder.layer.11.output.LayerNorm.weight", "bert.encoder.layer.11.output.LayerNorm.bias", "bert.encoder.layer.12.attention.self.query.weight", "bert.encoder.layer.12.attention.self.query.bias", "bert.encoder.layer.12.attention.self.key.weight", "bert.encoder.layer.12.attention.self.key.bias", "bert.encoder.layer.12.attention.self.value.weight", "bert.encoder.layer.12.attention.self.value.bias", "bert.encoder.layer.12.attention.output.dense.weight", "bert.encoder.layer.12.attention.output.dense.bias", "bert.encoder.layer.12.attention.output.LayerNorm.weight", "bert.encoder.layer.12.attention.output.LayerNorm.bias", "bert.encoder.layer.12.intermediate.dense.weight", "bert.encoder.layer.12.intermediate.dense.bias", "bert.encoder.layer.12.output.dense.weight", "bert.encoder.layer.12.output.dense.bias", "bert.encoder.layer.12.output.LayerNorm.weight", "bert.encoder.layer.12.output.LayerNorm.bias", "bert.encoder.layer.13.attention.self.query.weight", "bert.encoder.layer.13.attention.self.query.bias", "bert.encoder.layer.13.attention.self.key.weight", "bert.encoder.layer.13.attention.self.key.bias", "bert.encoder.layer.13.attention.self.value.weight", "bert.encoder.layer.13.attention.self.value.bias", "bert.encoder.layer.13.attention.output.dense.weight", "bert.encoder.layer.13.attention.output.dense.bias", "bert.encoder.layer.13.attention.output.LayerNorm.weight", "bert.encoder.layer.13.attention.output.LayerNorm.bias", "bert.encoder.layer.13.intermediate.dense.weight", "bert.encoder.layer.13.intermediate.dense.bias", "bert.encoder.layer.13.output.dense.weight", "bert.encoder.layer.13.output.dense.bias", "bert.encoder.layer.13.output.LayerNorm.weight", "bert.encoder.layer.13.output.LayerNorm.bias", "bert.encoder.layer.14.attention.self.query.weight", "bert.encoder.layer.14.attention.self.query.bias", "bert.encoder.layer.14.attention.self.key.weight", "bert.encoder.layer.14.attention.self.key.bias", "bert.encoder.layer.14.attention.self.value.weight", "bert.encoder.layer.14.attention.self.value.bias", "bert.encoder.layer.14.attention.output.dense.weight", "bert.encoder.layer.14.attention.output.dense.bias", "bert.encoder.layer.14.attention.output.LayerNorm.weight", "bert.encoder.layer.14.attention.output.LayerNorm.bias", "bert.encoder.layer.14.intermediate.dense.weight", "bert.encoder.layer.14.intermediate.dense.bias", "bert.encoder.layer.14.output.dense.weight", "bert.encoder.layer.14.output.dense.bias", "bert.encoder.layer.14.output.LayerNorm.weight", "bert.encoder.layer.14.output.LayerNorm.bias", "bert.encoder.layer.15.attention.self.query.weight", "bert.encoder.layer.15.attention.self.query.bias", "bert.encoder.layer.15.attention.self.key.weight", "bert.encoder.layer.15.attention.self.key.bias", "bert.encoder.layer.15.attention.self.value.weight", "bert.encoder.layer.15.attention.self.value.bias", "bert.encoder.layer.15.attention.output.dense.weight", "bert.encoder.layer.15.attention.output.dense.bias", "bert.encoder.layer.15.attention.output.LayerNorm.weight", "bert.encoder.layer.15.attention.output.LayerNorm.bias", "bert.encoder.layer.15.intermediate.dense.weight", "bert.encoder.layer.15.intermediate.dense.bias", "bert.encoder.layer.15.output.dense.weight", "bert.encoder.layer.15.output.dense.bias", "bert.encoder.layer.15.output.LayerNorm.weight", "bert.encoder.layer.15.output.LayerNorm.bias", "bert.encoder.layer.16.attention.self.query.weight", "bert.encoder.layer.16.attention.self.query.bias", "bert.encoder.layer.16.attention.self.key.weight", "bert.encoder.layer.16.attention.self.key.bias", "bert.encoder.layer.16.attention.self.value.weight", "bert.encoder.layer.16.attention.self.value.bias", "bert.encoder.layer.16.attention.output.dense.weight", "bert.encoder.layer.16.attention.output.dense.bias", "bert.encoder.layer.16.attention.output.LayerNorm.weight", "bert.encoder.layer.16.attention.output.LayerNorm.bias", "bert.encoder.layer.16.intermediate.dense.weight", "bert.encoder.layer.16.intermediate.dense.bias", "bert.encoder.layer.16.output.dense.weight", "bert.encoder.layer.16.output.dense.bias", "bert.encoder.layer.16.output.LayerNorm.weight", "bert.encoder.layer.16.output.LayerNorm.bias", "bert.encoder.layer.17.attention.self.query.weight", "bert.encoder.layer.17.attention.self.query.bias", "bert.encoder.layer.17.attention.self.key.weight", "bert.encoder.layer.17.attention.self.key.bias", "bert.encoder.layer.17.attention.self.value.weight", "bert.encoder.layer.17.attention.self.value.bias", "bert.encoder.layer.17.attention.output.dense.weight", "bert.encoder.layer.17.attention.output.dense.bias", "bert.encoder.layer.17.attention.output.LayerNorm.weight", "bert.encoder.layer.17.attention.output.LayerNorm.bias", "bert.encoder.layer.17.intermediate.dense.weight", "bert.encoder.layer.17.intermediate.dense.bias", "bert.encoder.layer.17.output.dense.weight", "bert.encoder.layer.17.output.dense.bias", "bert.encoder.layer.17.output.LayerNorm.weight", "bert.encoder.layer.17.output.LayerNorm.bias", "bert.encoder.layer.18.attention.self.query.weight", "bert.encoder.layer.18.attention.self.query.bias", "bert.encoder.layer.18.attention.self.key.weight", "bert.encoder.layer.18.attention.self.key.bias", "bert.encoder.layer.18.attention.self.value.weight", "bert.encoder.layer.18.attention.self.value.bias", "bert.encoder.layer.18.attention.output.dense.weight", "bert.encoder.layer.18.attention.output.dense.bias", "bert.encoder.layer.18.attention.output.LayerNorm.weight", "bert.encoder.layer.18.attention.output.LayerNorm.bias", "bert.encoder.layer.18.intermediate.dense.weight", "bert.encoder.layer.18.intermediate.dense.bias", "bert.encoder.layer.18.output.dense.weight", "bert.encoder.layer.18.output.dense.bias", "bert.encoder.layer.18.output.LayerNorm.weight", "bert.encoder.layer.18.output.LayerNorm.bias", "bert.encoder.layer.19.attention.self.query.weight", "bert.encoder.layer.19.attention.self.query.bias", "bert.encoder.layer.19.attention.self.key.weight", "bert.encoder.layer.19.attention.self.key.bias", "bert.encoder.layer.19.attention.self.value.weight", "bert.encoder.layer.19.attention.self.value.bias", "bert.encoder.layer.19.attention.output.dense.weight", "bert.encoder.layer.19.attention.output.dense.bias", "bert.encoder.layer.19.attention.output.LayerNorm.weight", "bert.encoder.layer.19.attention.output.LayerNorm.bias", "bert.encoder.layer.19.intermediate.dense.weight", "bert.encoder.layer.19.intermediate.dense.bias", "bert.encoder.layer.19.output.dense.weight", "bert.encoder.layer.19.output.dense.bias", "bert.encoder.layer.19.output.LayerNorm.weight", "bert.encoder.layer.19.output.LayerNorm.bias", "bert.encoder.layer.20.attention.self.query.weight", "bert.encoder.layer.20.attention.self.query.bias", "bert.encoder.layer.20.attention.self.key.weight", "bert.encoder.layer.20.attention.self.key.bias", "bert.encoder.layer.20.attention.self.value.weight", "bert.encoder.layer.20.attention.self.value.bias", "bert.encoder.layer.20.attention.output.dense.weight", "bert.encoder.layer.20.attention.output.dense.bias", "bert.encoder.layer.20.attention.output.LayerNorm.weight", "bert.encoder.layer.20.attention.output.LayerNorm.bias", "bert.encoder.layer.20.intermediate.dense.weight", "bert.encoder.layer.20.intermediate.dense.bias", "bert.encoder.layer.20.output.dense.weight", "bert.encoder.layer.20.output.dense.bias", "bert.encoder.layer.20.output.LayerNorm.weight", "bert.encoder.layer.20.output.LayerNorm.bias", "bert.encoder.layer.21.attention.self.query.weight", "bert.encoder.layer.21.attention.self.query.bias", "bert.encoder.layer.21.attention.self.key.weight", "bert.encoder.layer.21.attention.self.key.bias", "bert.encoder.layer.21.attention.self.value.weight", "bert.encoder.layer.21.attention.self.value.bias", "bert.encoder.layer.21.attention.output.dense.weight", "bert.encoder.layer.21.attention.output.dense.bias", "bert.encoder.layer.21.attention.output.LayerNorm.weight", "bert.encoder.layer.21.attention.output.LayerNorm.bias", "bert.encoder.layer.21.intermediate.dense.weight", "bert.encoder.layer.21.intermediate.dense.bias", "bert.encoder.layer.21.output.dense.weight", "bert.encoder.layer.21.output.dense.bias", "bert.encoder.layer.21.output.LayerNorm.weight", "bert.encoder.layer.21.output.LayerNorm.bias", "bert.encoder.layer.22.attention.self.query.weight", "bert.encoder.layer.22.attention.self.query.bias", "bert.encoder.layer.22.attention.self.key.weight", "bert.encoder.layer.22.attention.self.key.bias", "bert.encoder.layer.22.attention.self.value.weight", "bert.encoder.layer.22.attention.self.value.bias", "bert.encoder.layer.22.attention.output.dense.weight", "bert.encoder.layer.22.attention.output.dense.bias", "bert.encoder.layer.22.attention.output.LayerNorm.weight", "bert.encoder.layer.22.attention.output.LayerNorm.bias", "bert.encoder.layer.22.intermediate.dense.weight", "bert.encoder.layer.22.intermediate.dense.bias", "bert.encoder.layer.22.output.dense.weight", "bert.encoder.layer.22.output.dense.bias", "bert.encoder.layer.22.output.LayerNorm.weight", "bert.encoder.layer.22.output.LayerNorm.bias", "bert.encoder.layer.23.attention.self.query.weight", "bert.encoder.layer.23.attention.self.query.bias", "bert.encoder.layer.23.attention.self.key.weight", "bert.encoder.layer.23.attention.self.key.bias", "bert.encoder.layer.23.attention.self.value.weight", "bert.encoder.layer.23.attention.self.value.bias", "bert.encoder.layer.23.attention.output.dense.weight", "bert.encoder.layer.23.attention.output.dense.bias", "bert.encoder.layer.23.attention.output.LayerNorm.weight", "bert.encoder.layer.23.attention.output.LayerNorm.bias", "bert.encoder.layer.23.intermediate.dense.weight", "bert.encoder.layer.23.intermediate.dense.bias", "bert.encoder.layer.23.output.dense.weight", "bert.encoder.layer.23.output.dense.bias", "bert.encoder.layer.23.output.LayerNorm.weight", "bert.encoder.layer.23.output.LayerNorm.bias". 
  File "/home/ubuntu/nlp-osaka/sentiment/torch_ddp_finetune_neural_classifier.py", line 1115, in fit
    self.model.load_state_dict(model_state_dict)
  File "/home/ubuntu/nlp-osaka/sentiment/ddp_sentiment_finetune.py", line 1206, in main
    classifier.fit(X_train, X_val, y_train, y_val, rank, world_size, debug, start_epoch, model_state_dict, optimizer_state_dict,
  File "/home/ubuntu/nlp-osaka/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 2152, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for BERTClassifier:
	Missing key(s) in state_dict: "bert.embeddings.word_embeddings.weight", "bert.embeddings.position_embeddings.weight", "bert.embeddings.token_type_embeddings.weight", "bert.embeddings.LayerNorm.weight", "bert.embeddings.LayerNorm.bias", "bert.encoder.layer.0.attention.self.query.weight", "bert.encoder.layer.0.attention.self.query.bias", "bert.encoder.layer.0.attention.self.key.weight", "bert.encoder.layer.0.attention.self.key.bias", "bert.encoder.layer.0.attention.self.value.weight", "bert.encoder.layer.0.attention.self.value.bias", "bert.encoder.layer.0.attention.output.dense.weight", "bert.encoder.layer.0.attention.output.dense.bias", "bert.encoder.layer.0.attention.output.LayerNorm.weight", "bert.encoder.layer.0.attention.output.LayerNorm.bias", "bert.encoder.layer.0.intermediate.dense.weight", "bert.encoder.layer.0.intermediate.dense.bias", "bert.encoder.layer.0.output.dense.weight", "bert.encoder.layer.0.output.dense.bias", "bert.encoder.layer.0.output.LayerNorm.weight", "bert.encoder.layer.0.output.LayerNorm.bias", "bert.encoder.layer.1.attention.self.query.weight", "bert.encoder.layer.1.attention.self.query.bias", "bert.encoder.layer.1.attention.self.key.weight", "bert.encoder.layer.1.attention.self.key.bias", "bert.encoder.layer.1.attention.self.value.weight", "bert.encoder.layer.1.attention.self.value.bias", "bert.encoder.layer.1.attention.output.dense.weight", "bert.encoder.layer.1.attention.output.dense.bias", "bert.encoder.layer.1.attention.output.LayerNorm.weight", "bert.encoder.layer.1.attention.output.LayerNorm.bias", "bert.encoder.layer.1.intermediate.dense.weight", "bert.encoder.layer.1.intermediate.dense.bias", "bert.encoder.layer.1.output.dense.weight", "bert.encoder.layer.1.output.dense.bias", "bert.encoder.layer.1.output.LayerNorm.weight", "bert.encoder.layer.1.output.LayerNorm.bias", "bert.encoder.layer.2.attention.self.query.weight", "bert.encoder.layer.2.attention.self.query.bias", "bert.encoder.layer.2.attention.self.key.weight", "bert.encoder.layer.2.attention.self.key.bias", "bert.encoder.layer.2.attention.self.value.weight", "bert.encoder.layer.2.attention.self.value.bias", "bert.encoder.layer.2.attention.output.dense.weight", "bert.encoder.layer.2.attention.output.dense.bias", "bert.encoder.layer.2.attention.output.LayerNorm.weight", "bert.encoder.layer.2.attention.output.LayerNorm.bias", "bert.encoder.layer.2.intermediate.dense.weight", "bert.encoder.layer.2.intermediate.dense.bias", "bert.encoder.layer.2.output.dense.weight", "bert.encoder.layer.2.output.dense.bias", "bert.encoder.layer.2.output.LayerNorm.weight", "bert.encoder.layer.2.output.LayerNorm.bias", "bert.encoder.layer.3.attention.self.query.weight", "bert.encoder.layer.3.attention.self.query.bias", "bert.encoder.layer.3.attention.self.key.weight", "bert.encoder.layer.3.attention.self.key.bias", "bert.encoder.layer.3.attention.self.value.weight", "bert.encoder.layer.3.attention.self.value.bias", "bert.encoder.layer.3.attention.output.dense.weight", "bert.encoder.layer.3.attention.output.dense.bias", "bert.encoder.layer.3.attention.output.LayerNorm.weight", "bert.encoder.layer.3.attention.output.LayerNorm.bias", "bert.encoder.layer.3.intermediate.dense.weight", "bert.encoder.layer.3.intermediate.dense.bias", "bert.encoder.layer.3.output.dense.weight", "bert.encoder.layer.3.output.dense.bias", "bert.encoder.layer.3.output.LayerNorm.weight", "bert.encoder.layer.3.output.LayerNorm.bias", "bert.encoder.layer.4.attention.self.query.weight", "bert.encoder.layer.4.attention.self.query.bias", "bert.encoder.layer.4.attention.self.key.weight", "bert.encoder.layer.4.attention.self.key.bias", "bert.encoder.layer.4.attention.self.value.weight", "bert.encoder.layer.4.attention.self.value.bias", "bert.encoder.layer.4.attention.output.dense.weight", "bert.encoder.layer.4.attention.output.dense.bias", "bert.encoder.layer.4.attention.output.LayerNorm.weight", "bert.encoder.layer.4.attention.output.LayerNorm.bias", "bert.encoder.layer.4.intermediate.dense.weight", "bert.encoder.layer.4.intermediate.dense.bias", "bert.encoder.layer.4.output.dense.weight", "bert.encoder.layer.4.output.dense.bias", "bert.encoder.layer.4.output.LayerNorm.weight", "bert.encoder.layer.4.output.LayerNorm.bias", "bert.encoder.layer.5.attention.self.query.weight", "bert.encoder.layer.5.attention.self.query.bias", "bert.encoder.layer.5.attention.self.key.weight", "bert.encoder.layer.5.attention.self.key.bias", "bert.encoder.layer.5.attention.self.value.weight", "bert.encoder.layer.5.attention.self.value.bias", "bert.encoder.layer.5.attention.output.dense.weight", "bert.encoder.layer.5.attention.output.dense.bias", "bert.encoder.layer.5.attention.output.LayerNorm.weight", "bert.encoder.layer.5.attention.output.LayerNorm.bias", "bert.encoder.layer.5.intermediate.dense.weight", "bert.encoder.layer.5.intermediate.dense.bias", "bert.encoder.layer.5.output.dense.weight", "bert.encoder.layer.5.output.dense.bias", "bert.encoder.layer.5.output.LayerNorm.weight", "bert.encoder.layer.5.output.LayerNorm.bias", "bert.encoder.layer.6.attention.self.query.weight", "bert.encoder.layer.6.attention.self.query.bias", "bert.encoder.layer.6.attention.self.key.weight", "bert.encoder.layer.6.attention.self.key.bias", "bert.encoder.layer.6.attention.self.value.weight", "bert.encoder.layer.6.attention.self.value.bias", "bert.encoder.layer.6.attention.output.dense.weight", "bert.encoder.layer.6.attention.output.dense.bias", "bert.encoder.layer.6.attention.output.LayerNorm.weight", "bert.encoder.layer.6.attention.output.LayerNorm.bias", "bert.encoder.layer.6.intermediate.dense.weight", "bert.encoder.layer.6.intermediate.dense.bias", "bert.encoder.layer.6.output.dense.weight", "bert.encoder.layer.6.output.dense.bias", "bert.encoder.layer.6.output.LayerNorm.weight", "bert.encoder.layer.6.output.LayerNorm.bias", "bert.encoder.layer.7.attention.self.query.weight", "bert.encoder.layer.7.attention.self.query.bias", "bert.encoder.layer.7.attention.self.key.weight", "bert.encoder.layer.7.attention.self.key.bias", "bert.encoder.layer.7.attention.self.value.weight", "bert.encoder.layer.7.attention.self.value.bias", "bert.encoder.layer.7.attention.output.dense.weight", "bert.encoder.layer.7.attention.output.dense.bias", "bert.encoder.layer.7.attention.output.LayerNorm.weight", "bert.encoder.layer.7.attention.output.LayerNorm.bias", "bert.encoder.layer.7.intermediate.dense.weight", "bert.encoder.layer.7.intermediate.dense.bias", "bert.encoder.layer.7.output.dense.weight", "bert.encoder.layer.7.output.dense.bias", "bert.encoder.layer.7.output.LayerNorm.weight", "bert.encoder.layer.7.output.LayerNorm.bias", "bert.encoder.layer.8.attention.self.query.weight", "bert.encoder.layer.8.attention.self.query.bias", "bert.encoder.layer.8.attention.self.key.weight", "bert.encoder.layer.8.attention.self.key.bias", "bert.encoder.layer.8.attention.self.value.weight", "bert.encoder.layer.8.attention.self.value.bias", "bert.encoder.layer.8.attention.output.dense.weight", "bert.encoder.layer.8.attention.output.dense.bias", "bert.encoder.layer.8.attention.output.LayerNorm.weight", "bert.encoder.layer.8.attention.output.LayerNorm.bias", "bert.encoder.layer.8.intermediate.dense.weight", "bert.encoder.layer.8.intermediate.dense.bias", "bert.encoder.layer.8.output.dense.weight", "bert.encoder.layer.8.output.dense.bias", "bert.encoder.layer.8.output.LayerNorm.weight", "bert.encoder.layer.8.output.LayerNorm.bias", "bert.encoder.layer.9.attention.self.query.weight", "bert.encoder.layer.9.attention.self.query.bias", "bert.encoder.layer.9.attention.self.key.weight", "bert.encoder.layer.9.attention.self.key.bias", "bert.encoder.layer.9.attention.self.value.weight", "bert.encoder.layer.9.attention.self.value.bias", "bert.encoder.layer.9.attention.output.dense.weight", "bert.encoder.layer.9.attention.output.dense.bias", "bert.encoder.layer.9.attention.output.LayerNorm.weight", "bert.encoder.layer.9.attention.output.LayerNorm.bias", "bert.encoder.layer.9.intermediate.dense.weight", "bert.encoder.layer.9.intermediate.dense.bias", "bert.encoder.layer.9.output.dense.weight", "bert.encoder.layer.9.output.dense.bias", "bert.encoder.layer.9.output.LayerNorm.weight", "bert.encoder.layer.9.output.LayerNorm.bias", "bert.encoder.layer.10.attention.self.query.weight", "bert.encoder.layer.10.attention.self.query.bias", "bert.encoder.layer.10.attention.self.key.weight", "bert.encoder.layer.10.attention.self.key.bias", "bert.encoder.layer.10.attention.self.value.weight", "bert.encoder.layer.10.attention.self.value.bias", "bert.encoder.layer.10.attention.output.dense.weight", "bert.encoder.layer.10.attention.output.dense.bias", "bert.encoder.layer.10.attention.output.LayerNorm.weight", "bert.encoder.layer.10.attention.output.LayerNorm.bias", "bert.encoder.layer.10.intermediate.dense.weight", "bert.encoder.layer.10.intermediate.dense.bias", "bert.encoder.layer.10.output.dense.weight", "bert.encoder.layer.10.output.dense.bias", "bert.encoder.layer.10.output.LayerNorm.weight", "bert.encoder.layer.10.output.LayerNorm.bias", "bert.encoder.layer.11.attention.self.query.weight", "bert.encoder.layer.11.attention.self.query.bias", "bert.encoder.layer.11.attention.self.key.weight", "bert.encoder.layer.11.attention.self.key.bias", "bert.encoder.layer.11.attention.self.value.weight", "bert.encoder.layer.11.attention.self.value.bias", "bert.encoder.layer.11.attention.output.dense.weight", "bert.encoder.layer.11.attention.output.dense.bias", "bert.encoder.layer.11.attention.output.LayerNorm.weight", "bert.encoder.layer.11.attention.output.LayerNorm.bias", "bert.encoder.layer.11.intermediate.dense.weight", "bert.encoder.layer.11.intermediate.dense.bias", "bert.encoder.layer.11.output.dense.weight", "bert.encoder.layer.11.output.dense.bias", "bert.encoder.layer.11.output.LayerNorm.weight", "bert.encoder.layer.11.output.LayerNorm.bias", "bert.encoder.layer.12.attention.self.query.weight", "bert.encoder.layer.12.attention.self.query.bias", "bert.encoder.layer.12.attention.self.key.weight", "bert.encoder.layer.12.attention.self.key.bias", "bert.encoder.layer.12.attention.self.value.weight", "bert.encoder.layer.12.attention.self.value.bias", "bert.encoder.layer.12.attention.output.dense.weight", "bert.encoder.layer.12.attention.output.dense.bias", "bert.encoder.layer.12.attention.output.LayerNorm.weight", "bert.encoder.layer.12.attention.output.LayerNorm.bias", "bert.encoder.layer.12.intermediate.dense.weight", "bert.encoder.layer.12.intermediate.dense.bias", "bert.encoder.layer.12.output.dense.weight", "bert.encoder.layer.12.output.dense.bias", "bert.encoder.layer.12.output.LayerNorm.weight", "bert.encoder.layer.12.output.LayerNorm.bias", "bert.encoder.layer.13.attention.self.query.weight", "bert.encoder.layer.13.attention.self.query.bias", "bert.encoder.layer.13.attention.self.key.weight", "bert.encoder.layer.13.attention.self.key.bias", "bert.encoder.layer.13.attention.self.value.weight", "bert.encoder.layer.13.attention.self.value.bias", "bert.encoder.layer.13.attention.output.dense.weight", "bert.encoder.layer.13.attention.output.dense.bias", "bert.encoder.layer.13.attention.output.LayerNorm.weight", "bert.encoder.layer.13.attention.output.LayerNorm.bias", "bert.encoder.layer.13.intermediate.dense.weight", "bert.encoder.layer.13.intermediate.dense.bias", "bert.encoder.layer.13.output.dense.weight", "bert.encoder.layer.13.output.dense.bias", "bert.encoder.layer.13.output.LayerNorm.weight", "bert.encoder.layer.13.output.LayerNorm.bias", "bert.encoder.layer.14.attention.self.query.weight", "bert.encoder.layer.14.attention.self.query.bias", "bert.encoder.layer.14.attention.self.key.weight", "bert.encoder.layer.14.attention.self.key.bias", "bert.encoder.layer.14.attention.self.value.weight", "bert.encoder.layer.14.attention.self.value.bias", "bert.encoder.layer.14.attention.output.dense.weight", "bert.encoder.layer.14.attention.output.dense.bias", "bert.encoder.layer.14.attention.output.LayerNorm.weight", "bert.encoder.layer.14.attention.output.LayerNorm.bias", "bert.encoder.layer.14.intermediate.dense.weight", "bert.encoder.layer.14.intermediate.dense.bias", "bert.encoder.layer.14.output.dense.weight", "bert.encoder.layer.14.output.dense.bias", "bert.encoder.layer.14.output.LayerNorm.weight", "bert.encoder.layer.14.output.LayerNorm.bias", "bert.encoder.layer.15.attention.self.query.weight", "bert.encoder.layer.15.attention.self.query.bias", "bert.encoder.layer.15.attention.self.key.weight", "bert.encoder.layer.15.attention.self.key.bias", "bert.encoder.layer.15.attention.self.value.weight", "bert.encoder.layer.15.attention.self.value.bias", "bert.encoder.layer.15.attention.output.dense.weight", "bert.encoder.layer.15.attention.output.dense.bias", "bert.encoder.layer.15.attention.output.LayerNorm.weight", "bert.encoder.layer.15.attention.output.LayerNorm.bias", "bert.encoder.layer.15.intermediate.dense.weight", "bert.encoder.layer.15.intermediate.dense.bias", "bert.encoder.layer.15.output.dense.weight", "bert.encoder.layer.15.output.dense.bias", "bert.encoder.layer.15.output.LayerNorm.weight", "bert.encoder.layer.15.output.LayerNorm.bias", "bert.encoder.layer.16.attention.self.query.weight", "bert.encoder.layer.16.attention.self.query.bias", "bert.encoder.layer.16.attention.self.key.weight", "bert.encoder.layer.16.attention.self.key.bias", "bert.encoder.layer.16.attention.self.value.weight", "bert.encoder.layer.16.attention.self.value.bias", "bert.encoder.layer.16.attention.output.dense.weight", "bert.encoder.layer.16.attention.output.dense.bias", "bert.encoder.layer.16.attention.output.LayerNorm.weight", "bert.encoder.layer.16.attention.output.LayerNorm.bias", "bert.encoder.layer.16.intermediate.dense.weight", "bert.encoder.layer.16.intermediate.dense.bias", "bert.encoder.layer.16.output.dense.weight", "bert.encoder.layer.16.output.dense.bias", "bert.encoder.layer.16.output.LayerNorm.weight", "bert.encoder.layer.16.output.LayerNorm.bias", "bert.encoder.layer.17.attention.self.query.weight", "bert.encoder.layer.17.attention.self.query.bias", "bert.encoder.layer.17.attention.self.key.weight", "bert.encoder.layer.17.attention.self.key.bias", "bert.encoder.layer.17.attention.self.value.weight", "bert.encoder.layer.17.attention.self.value.bias", "bert.encoder.layer.17.attention.output.dense.weight", "bert.encoder.layer.17.attention.output.dense.bias", "bert.encoder.layer.17.attention.output.LayerNorm.weight", "bert.encoder.layer.17.attention.output.LayerNorm.bias", "bert.encoder.layer.17.intermediate.dense.weight", "bert.encoder.layer.17.intermediate.dense.bias", "bert.encoder.layer.17.output.dense.weight", "bert.encoder.layer.17.output.dense.bias", "bert.encoder.layer.17.output.LayerNorm.weight", "bert.encoder.layer.17.output.LayerNorm.bias", "bert.encoder.layer.18.attention.self.query.weight", "bert.encoder.layer.18.attention.self.query.bias", "bert.encoder.layer.18.attention.self.key.weight", "bert.encoder.layer.18.attention.self.key.bias", "bert.encoder.layer.18.attention.self.value.weight", "bert.encoder.layer.18.attention.self.value.bias", "bert.encoder.layer.18.attention.output.dense.weight", "bert.encoder.layer.18.attention.output.dense.bias", "bert.encoder.layer.18.attention.output.LayerNorm.weight", "bert.encoder.layer.18.attention.output.LayerNorm.bias", "bert.encoder.layer.18.intermediate.dense.weight", "bert.encoder.layer.18.intermediate.dense.bias", "bert.encoder.layer.18.output.dense.weight", "bert.encoder.layer.18.output.dense.bias", "bert.encoder.layer.18.output.LayerNorm.weight", "bert.encoder.layer.18.output.LayerNorm.bias", "bert.encoder.layer.19.attention.self.query.weight", "bert.encoder.layer.19.attention.self.query.bias", "bert.encoder.layer.19.attention.self.key.weight", "bert.encoder.layer.19.attention.self.key.bias", "bert.encoder.layer.19.attention.self.value.weight", "bert.encoder.layer.19.attention.self.value.bias", "bert.encoder.layer.19.attention.output.dense.weight", "bert.encoder.layer.19.attention.output.dense.bias", "bert.encoder.layer.19.attention.output.LayerNorm.weight", "bert.encoder.layer.19.attention.output.LayerNorm.bias", "bert.encoder.layer.19.intermediate.dense.weight", "bert.encoder.layer.19.intermediate.dense.bias", "bert.encoder.layer.19.output.dense.weight", "bert.encoder.layer.19.output.dense.bias", "bert.encoder.layer.19.output.LayerNorm.weight", "bert.encoder.layer.19.output.LayerNorm.bias", "bert.encoder.layer.20.attention.self.query.weight", "bert.encoder.layer.20.attention.self.query.bias", "bert.encoder.layer.20.attention.self.key.weight", "bert.encoder.layer.20.attention.self.key.bias", "bert.encoder.layer.20.attention.self.value.weight", "bert.encoder.layer.20.attention.self.value.bias", "bert.encoder.layer.20.attention.output.dense.weight", "bert.encoder.layer.20.attention.output.dense.bias", "bert.encoder.layer.20.attention.output.LayerNorm.weight", "bert.encoder.layer.20.attention.output.LayerNorm.bias", "bert.encoder.layer.20.intermediate.dense.weight", "bert.encoder.layer.20.intermediate.dense.bias", "bert.encoder.layer.20.output.dense.weight", "bert.encoder.layer.20.output.dense.bias", "bert.encoder.layer.20.output.LayerNorm.weight", "bert.encoder.layer.20.output.LayerNorm.bias", "bert.encoder.layer.21.attention.self.query.weight", "bert.encoder.layer.21.attention.self.query.bias", "bert.encoder.layer.21.attention.self.key.weight", "bert.encoder.layer.21.attention.self.key.bias", "bert.encoder.layer.21.attention.self.value.weight", "bert.encoder.layer.21.attention.self.value.bias", "bert.encoder.layer.21.attention.output.dense.weight", "bert.encoder.layer.21.attention.output.dense.bias", "bert.encoder.layer.21.attention.output.LayerNorm.weight", "bert.encoder.layer.21.attention.output.LayerNorm.bias", "bert.encoder.layer.21.intermediate.dense.weight", "bert.encoder.layer.21.intermediate.dense.bias", "bert.encoder.layer.21.output.dense.weight", "bert.encoder.layer.21.output.dense.bias", "bert.encoder.layer.21.output.LayerNorm.weight", "bert.encoder.layer.21.output.LayerNorm.bias", "bert.encoder.layer.22.attention.self.query.weight", "bert.encoder.layer.22.attention.self.query.bias", "bert.encoder.layer.22.attention.self.key.weight", "bert.encoder.layer.22.attention.self.key.bias", "bert.encoder.layer.22.attention.self.value.weight", "bert.encoder.layer.22.attention.self.value.bias", "bert.encoder.layer.22.attention.output.dense.weight", "bert.encoder.layer.22.attention.output.dense.bias", "bert.encoder.layer.22.attention.output.LayerNorm.weight", "bert.encoder.layer.22.attention.output.LayerNorm.bias", "bert.encoder.layer.22.intermediate.dense.weight", "bert.encoder.layer.22.intermediate.dense.bias", "bert.encoder.layer.22.output.dense.weight", "bert.encoder.layer.22.output.dense.bias", "bert.encoder.layer.22.output.LayerNorm.weight", "bert.encoder.layer.22.output.LayerNorm.bias", "bert.encoder.layer.23.attention.self.query.weight", "bert.encoder.layer.23.attention.self.query.bias", "bert.encoder.layer.23.attention.self.key.weight", "bert.encoder.layer.23.attention.self.key.bias", "bert.encoder.layer.23.attention.self.value.weight", "bert.encoder.layer.23.attention.self.value.bias", "bert.encoder.layer.23.attention.output.dense.weight", "bert.encoder.layer.23.attention.output.dense.bias", "bert.encoder.layer.23.attention.output.LayerNorm.weight", "bert.encoder.layer.23.attention.output.LayerNorm.bias", "bert.encoder.layer.23.intermediate.dense.weight", "bert.encoder.layer.23.intermediate.dense.bias", "bert.encoder.layer.23.output.dense.weight", "bert.encoder.layer.23.output.dense.bias", "bert.encoder.layer.23.output.LayerNorm.weight", "bert.encoder.layer.23.output.LayerNorm.bias". 
RuntimeError: Error(s) in loading state_dict for BERTClassifier:
	Missing key(s) in state_dict: "bert.embeddings.word_embeddings.weight", "bert.embeddings.position_embeddings.weight", "bert.embeddings.token_type_embeddings.weight", "bert.embeddings.LayerNorm.weight", "bert.embeddings.LayerNorm.bias", "bert.encoder.layer.0.attention.self.query.weight", "bert.encoder.layer.0.attention.self.query.bias", "bert.encoder.layer.0.attention.self.key.weight", "bert.encoder.layer.0.attention.self.key.bias", "bert.encoder.layer.0.attention.self.value.weight", "bert.encoder.layer.0.attention.self.value.bias", "bert.encoder.layer.0.attention.output.dense.weight", "bert.encoder.layer.0.attention.output.dense.bias", "bert.encoder.layer.0.attention.output.LayerNorm.weight", "bert.encoder.layer.0.attention.output.LayerNorm.bias", "bert.encoder.layer.0.intermediate.dense.weight", "bert.encoder.layer.0.intermediate.dense.bias", "bert.encoder.layer.0.output.dense.weight", "bert.encoder.layer.0.output.dense.bias", "bert.encoder.layer.0.output.LayerNorm.weight", "bert.encoder.layer.0.output.LayerNorm.bias", "bert.encoder.layer.1.attention.self.query.weight", "bert.encoder.layer.1.attention.self.query.bias", "bert.encoder.layer.1.attention.self.key.weight", "bert.encoder.layer.1.attention.self.key.bias", "bert.encoder.layer.1.attention.self.value.weight", "bert.encoder.layer.1.attention.self.value.bias", "bert.encoder.layer.1.attention.output.dense.weight", "bert.encoder.layer.1.attention.output.dense.bias", "bert.encoder.layer.1.attention.output.LayerNorm.weight", "bert.encoder.layer.1.attention.output.LayerNorm.bias", "bert.encoder.layer.1.intermediate.dense.weight", "bert.encoder.layer.1.intermediate.dense.bias", "bert.encoder.layer.1.output.dense.weight", "bert.encoder.layer.1.output.dense.bias", "bert.encoder.layer.1.output.LayerNorm.weight", "bert.encoder.layer.1.output.LayerNorm.bias", "bert.encoder.layer.2.attention.self.query.weight", "bert.encoder.layer.2.attention.self.query.bias", "bert.encoder.layer.2.attention.self.key.weight", "bert.encoder.layer.2.attention.self.key.bias", "bert.encoder.layer.2.attention.self.value.weight", "bert.encoder.layer.2.attention.self.value.bias", "bert.encoder.layer.2.attention.output.dense.weight", "bert.encoder.layer.2.attention.output.dense.bias", "bert.encoder.layer.2.attention.output.LayerNorm.weight", "bert.encoder.layer.2.attention.output.LayerNorm.bias", "bert.encoder.layer.2.intermediate.dense.weight", "bert.encoder.layer.2.intermediate.dense.bias", "bert.encoder.layer.2.output.dense.weight", "bert.encoder.layer.2.output.dense.bias", "bert.encoder.layer.2.output.LayerNorm.weight", "bert.encoder.layer.2.output.LayerNorm.bias", "bert.encoder.layer.3.attention.self.query.weight", "bert.encoder.layer.3.attention.self.query.bias", "bert.encoder.layer.3.attention.self.key.weight", "bert.encoder.layer.3.attention.self.key.bias", "bert.encoder.layer.3.attention.self.value.weight", "bert.encoder.layer.3.attention.self.value.bias", "bert.encoder.layer.3.attention.output.dense.weight", "bert.encoder.layer.3.attention.output.dense.bias", "bert.encoder.layer.3.attention.output.LayerNorm.weight", "bert.encoder.layer.3.attention.output.LayerNorm.bias", "bert.encoder.layer.3.intermediate.dense.weight", "bert.encoder.layer.3.intermediate.dense.bias", "bert.encoder.layer.3.output.dense.weight", "bert.encoder.layer.3.output.dense.bias", "bert.encoder.layer.3.output.LayerNorm.weight", "bert.encoder.layer.3.output.LayerNorm.bias", "bert.encoder.layer.4.attention.self.query.weight", "bert.encoder.layer.4.attention.self.query.bias", "bert.encoder.layer.4.attention.self.key.weight", "bert.encoder.layer.4.attention.self.key.bias", "bert.encoder.layer.4.attention.self.value.weight", "bert.encoder.layer.4.attention.self.value.bias", "bert.encoder.layer.4.attention.output.dense.weight", "bert.encoder.layer.4.attention.output.dense.bias", "bert.encoder.layer.4.attention.output.LayerNorm.weight", "bert.encoder.layer.4.attention.output.LayerNorm.bias", "bert.encoder.layer.4.intermediate.dense.weight", "bert.encoder.layer.4.intermediate.dense.bias", "bert.encoder.layer.4.output.dense.weight", "bert.encoder.layer.4.output.dense.bias", "bert.encoder.layer.4.output.LayerNorm.weight", "bert.encoder.layer.4.output.LayerNorm.bias", "bert.encoder.layer.5.attention.self.query.weight", "bert.encoder.layer.5.attention.self.query.bias", "bert.encoder.layer.5.attention.self.key.weight", "bert.encoder.layer.5.attention.self.key.bias", "bert.encoder.layer.5.attention.self.value.weight", "bert.encoder.layer.5.attention.self.value.bias", "bert.encoder.layer.5.attention.output.dense.weight", "bert.encoder.layer.5.attention.output.dense.bias", "bert.encoder.layer.5.attention.output.LayerNorm.weight", "bert.encoder.layer.5.attention.output.LayerNorm.bias", "bert.encoder.layer.5.intermediate.dense.weight", "bert.encoder.layer.5.intermediate.dense.bias", "bert.encoder.layer.5.output.dense.weight", "bert.encoder.layer.5.output.dense.bias", "bert.encoder.layer.5.output.LayerNorm.weight", "bert.encoder.layer.5.output.LayerNorm.bias", "bert.encoder.layer.6.attention.self.query.weight", "bert.encoder.layer.6.attention.self.query.bias", "bert.encoder.layer.6.attention.self.key.weight", "bert.encoder.layer.6.attention.self.key.bias", "bert.encoder.layer.6.attention.self.value.weight", "bert.encoder.layer.6.attention.self.value.bias", "bert.encoder.layer.6.attention.output.dense.weight", "bert.encoder.layer.6.attention.output.dense.bias", "bert.encoder.layer.6.attention.output.LayerNorm.weight", "bert.encoder.layer.6.attention.output.LayerNorm.bias", "bert.encoder.layer.6.intermediate.dense.weight", "bert.encoder.layer.6.intermediate.dense.bias", "bert.encoder.layer.6.output.dense.weight", "bert.encoder.layer.6.output.dense.bias", "bert.encoder.layer.6.output.LayerNorm.weight", "bert.encoder.layer.6.output.LayerNorm.bias", "bert.encoder.layer.7.attention.self.query.weight", "bert.encoder.layer.7.attention.self.query.bias", "bert.encoder.layer.7.attention.self.key.weight", "bert.encoder.layer.7.attention.self.key.bias", "bert.encoder.layer.7.attention.self.value.weight", "bert.encoder.layer.7.attention.self.value.bias", "bert.encoder.layer.7.attention.output.dense.weight", "bert.encoder.layer.7.attention.output.dense.bias", "bert.encoder.layer.7.attention.output.LayerNorm.weight", "bert.encoder.layer.7.attention.output.LayerNorm.bias", "bert.encoder.layer.7.intermediate.dense.weight", "bert.encoder.layer.7.intermediate.dense.bias", "bert.encoder.layer.7.output.dense.weight", "bert.encoder.layer.7.output.dense.bias", "bert.encoder.layer.7.output.LayerNorm.weight", "bert.encoder.layer.7.output.LayerNorm.bias", "bert.encoder.layer.8.attention.self.query.weight", "bert.encoder.layer.8.attention.self.query.bias", "bert.encoder.layer.8.attention.self.key.weight", "bert.encoder.layer.8.attention.self.key.bias", "bert.encoder.layer.8.attention.self.value.weight", "bert.encoder.layer.8.attention.self.value.bias", "bert.encoder.layer.8.attention.output.dense.weight", "bert.encoder.layer.8.attention.output.dense.bias", "bert.encoder.layer.8.attention.output.LayerNorm.weight", "bert.encoder.layer.8.attention.output.LayerNorm.bias", "bert.encoder.layer.8.intermediate.dense.weight", "bert.encoder.layer.8.intermediate.dense.bias", "bert.encoder.layer.8.output.dense.weight", "bert.encoder.layer.8.output.dense.bias", "bert.encoder.layer.8.output.LayerNorm.weight", "bert.encoder.layer.8.output.LayerNorm.bias", "bert.encoder.layer.9.attention.self.query.weight", "bert.encoder.layer.9.attention.self.query.bias", "bert.encoder.layer.9.attention.self.key.weight", "bert.encoder.layer.9.attention.self.key.bias", "bert.encoder.layer.9.attention.self.value.weight", "bert.encoder.layer.9.attention.self.value.bias", "bert.encoder.layer.9.attention.output.dense.weight", "bert.encoder.layer.9.attention.output.dense.bias", "bert.encoder.layer.9.attention.output.LayerNorm.weight", "bert.encoder.layer.9.attention.output.LayerNorm.bias", "bert.encoder.layer.9.intermediate.dense.weight", "bert.encoder.layer.9.intermediate.dense.bias", "bert.encoder.layer.9.output.dense.weight", "bert.encoder.layer.9.output.dense.bias", "bert.encoder.layer.9.output.LayerNorm.weight", "bert.encoder.layer.9.output.LayerNorm.bias", "bert.encoder.layer.10.attention.self.query.weight", "bert.encoder.layer.10.attention.self.query.bias", "bert.encoder.layer.10.attention.self.key.weight", "bert.encoder.layer.10.attention.self.key.bias", "bert.encoder.layer.10.attention.self.value.weight", "bert.encoder.layer.10.attention.self.value.bias", "bert.encoder.layer.10.attention.output.dense.weight", "bert.encoder.layer.10.attention.output.dense.bias", "bert.encoder.layer.10.attention.output.LayerNorm.weight", "bert.encoder.layer.10.attention.output.LayerNorm.bias", "bert.encoder.layer.10.intermediate.dense.weight", "bert.encoder.layer.10.intermediate.dense.bias", "bert.encoder.layer.10.output.dense.weight", "bert.encoder.layer.10.output.dense.bias", "bert.encoder.layer.10.output.LayerNorm.weight", "bert.encoder.layer.10.output.LayerNorm.bias", "bert.encoder.layer.11.attention.self.query.weight", "bert.encoder.layer.11.attention.self.query.bias", "bert.encoder.layer.11.attention.self.key.weight", "bert.encoder.layer.11.attention.self.key.bias", "bert.encoder.layer.11.attention.self.value.weight", "bert.encoder.layer.11.attention.self.value.bias", "bert.encoder.layer.11.attention.output.dense.weight", "bert.encoder.layer.11.attention.output.dense.bias", "bert.encoder.layer.11.attention.output.LayerNorm.weight", "bert.encoder.layer.11.attention.output.LayerNorm.bias", "bert.encoder.layer.11.intermediate.dense.weight", "bert.encoder.layer.11.intermediate.dense.bias", "bert.encoder.layer.11.output.dense.weight", "bert.encoder.layer.11.output.dense.bias", "bert.encoder.layer.11.output.LayerNorm.weight", "bert.encoder.layer.11.output.LayerNorm.bias", "bert.encoder.layer.12.attention.self.query.weight", "bert.encoder.layer.12.attention.self.query.bias", "bert.encoder.layer.12.attention.self.key.weight", "bert.encoder.layer.12.attention.self.key.bias", "bert.encoder.layer.12.attention.self.value.weight", "bert.encoder.layer.12.attention.self.value.bias", "bert.encoder.layer.12.attention.output.dense.weight", "bert.encoder.layer.12.attention.output.dense.bias", "bert.encoder.layer.12.attention.output.LayerNorm.weight", "bert.encoder.layer.12.attention.output.LayerNorm.bias", "bert.encoder.layer.12.intermediate.dense.weight", "bert.encoder.layer.12.intermediate.dense.bias", "bert.encoder.layer.12.output.dense.weight", "bert.encoder.layer.12.output.dense.bias", "bert.encoder.layer.12.output.LayerNorm.weight", "bert.encoder.layer.12.output.LayerNorm.bias", "bert.encoder.layer.13.attention.self.query.weight", "bert.encoder.layer.13.attention.self.query.bias", "bert.encoder.layer.13.attention.self.key.weight", "bert.encoder.layer.13.attention.self.key.bias", "bert.encoder.layer.13.attention.self.value.weight", "bert.encoder.layer.13.attention.self.value.bias", "bert.encoder.layer.13.attention.output.dense.weight", "bert.encoder.layer.13.attention.output.dense.bias", "bert.encoder.layer.13.attention.output.LayerNorm.weight", "bert.encoder.layer.13.attention.output.LayerNorm.bias", "bert.encoder.layer.13.intermediate.dense.weight", "bert.encoder.layer.13.intermediate.dense.bias", "bert.encoder.layer.13.output.dense.weight", "bert.encoder.layer.13.output.dense.bias", "bert.encoder.layer.13.output.LayerNorm.weight", "bert.encoder.layer.13.output.LayerNorm.bias", "bert.encoder.layer.14.attention.self.query.weight", "bert.encoder.layer.14.attention.self.query.bias", "bert.encoder.layer.14.attention.self.key.weight", "bert.encoder.layer.14.attention.self.key.bias", "bert.encoder.layer.14.attention.self.value.weight", "bert.encoder.layer.14.attention.self.value.bias", "bert.encoder.layer.14.attention.output.dense.weight", "bert.encoder.layer.14.attention.output.dense.bias", "bert.encoder.layer.14.attention.output.LayerNorm.weight", "bert.encoder.layer.14.attention.output.LayerNorm.bias", "bert.encoder.layer.14.intermediate.dense.weight", "bert.encoder.layer.14.intermediate.dense.bias", "bert.encoder.layer.14.output.dense.weight", "bert.encoder.layer.14.output.dense.bias", "bert.encoder.layer.14.output.LayerNorm.weight", "bert.encoder.layer.14.output.LayerNorm.bias", "bert.encoder.layer.15.attention.self.query.weight", "bert.encoder.layer.15.attention.self.query.bias", "bert.encoder.layer.15.attention.self.key.weight", "bert.encoder.layer.15.attention.self.key.bias", "bert.encoder.layer.15.attention.self.value.weight", "bert.encoder.layer.15.attention.self.value.bias", "bert.encoder.layer.15.attention.output.dense.weight", "bert.encoder.layer.15.attention.output.dense.bias", "bert.encoder.layer.15.attention.output.LayerNorm.weight", "bert.encoder.layer.15.attention.output.LayerNorm.bias", "bert.encoder.layer.15.intermediate.dense.weight", "bert.encoder.layer.15.intermediate.dense.bias", "bert.encoder.layer.15.output.dense.weight", "bert.encoder.layer.15.output.dense.bias", "bert.encoder.layer.15.output.LayerNorm.weight", "bert.encoder.layer.15.output.LayerNorm.bias", "bert.encoder.layer.16.attention.self.query.weight", "bert.encoder.layer.16.attention.self.query.bias", "bert.encoder.layer.16.attention.self.key.weight", "bert.encoder.layer.16.attention.self.key.bias", "bert.encoder.layer.16.attention.self.value.weight", "bert.encoder.layer.16.attention.self.value.bias", "bert.encoder.layer.16.attention.output.dense.weight", "bert.encoder.layer.16.attention.output.dense.bias", "bert.encoder.layer.16.attention.output.LayerNorm.weight", "bert.encoder.layer.16.attention.output.LayerNorm.bias", "bert.encoder.layer.16.intermediate.dense.weight", "bert.encoder.layer.16.intermediate.dense.bias", "bert.encoder.layer.16.output.dense.weight", "bert.encoder.layer.16.output.dense.bias", "bert.encoder.layer.16.output.LayerNorm.weight", "bert.encoder.layer.16.output.LayerNorm.bias", "bert.encoder.layer.17.attention.self.query.weight", "bert.encoder.layer.17.attention.self.query.bias", "bert.encoder.layer.17.attention.self.key.weight", "bert.encoder.layer.17.attention.self.key.bias", "bert.encoder.layer.17.attention.self.value.weight", "bert.encoder.layer.17.attention.self.value.bias", "bert.encoder.layer.17.attention.output.dense.weight", "bert.encoder.layer.17.attention.output.dense.bias", "bert.encoder.layer.17.attention.output.LayerNorm.weight", "bert.encoder.layer.17.attention.output.LayerNorm.bias", "bert.encoder.layer.17.intermediate.dense.weight", "bert.encoder.layer.17.intermediate.dense.bias", "bert.encoder.layer.17.output.dense.weight", "bert.encoder.layer.17.output.dense.bias", "bert.encoder.layer.17.output.LayerNorm.weight", "bert.encoder.layer.17.output.LayerNorm.bias", "bert.encoder.layer.18.attention.self.query.weight", "bert.encoder.layer.18.attention.self.query.bias", "bert.encoder.layer.18.attention.self.key.weight", "bert.encoder.layer.18.attention.self.key.bias", "bert.encoder.layer.18.attention.self.value.weight", "bert.encoder.layer.18.attention.self.value.bias", "bert.encoder.layer.18.attention.output.dense.weight", "bert.encoder.layer.18.attention.output.dense.bias", "bert.encoder.layer.18.attention.output.LayerNorm.weight", "bert.encoder.layer.18.attention.output.LayerNorm.bias", "bert.encoder.layer.18.intermediate.dense.weight", "bert.encoder.layer.18.intermediate.dense.bias", "bert.encoder.layer.18.output.dense.weight", "bert.encoder.layer.18.output.dense.bias", "bert.encoder.layer.18.output.LayerNorm.weight", "bert.encoder.layer.18.output.LayerNorm.bias", "bert.encoder.layer.19.attention.self.query.weight", "bert.encoder.layer.19.attention.self.query.bias", "bert.encoder.layer.19.attention.self.key.weight", "bert.encoder.layer.19.attention.self.key.bias", "bert.encoder.layer.19.attention.self.value.weight", "bert.encoder.layer.19.attention.self.value.bias", "bert.encoder.layer.19.attention.output.dense.weight", "bert.encoder.layer.19.attention.output.dense.bias", "bert.encoder.layer.19.attention.output.LayerNorm.weight", "bert.encoder.layer.19.attention.output.LayerNorm.bias", "bert.encoder.layer.19.intermediate.dense.weight", "bert.encoder.layer.19.intermediate.dense.bias", "bert.encoder.layer.19.output.dense.weight", "bert.encoder.layer.19.output.dense.bias", "bert.encoder.layer.19.output.LayerNorm.weight", "bert.encoder.layer.19.output.LayerNorm.bias", "bert.encoder.layer.20.attention.self.query.weight", "bert.encoder.layer.20.attention.self.query.bias", "bert.encoder.layer.20.attention.self.key.weight", "bert.encoder.layer.20.attention.self.key.bias", "bert.encoder.layer.20.attention.self.value.weight", "bert.encoder.layer.20.attention.self.value.bias", "bert.encoder.layer.20.attention.output.dense.weight", "bert.encoder.layer.20.attention.output.dense.bias", "bert.encoder.layer.20.attention.output.LayerNorm.weight", "bert.encoder.layer.20.attention.output.LayerNorm.bias", "bert.encoder.layer.20.intermediate.dense.weight", "bert.encoder.layer.20.intermediate.dense.bias", "bert.encoder.layer.20.output.dense.weight", "bert.encoder.layer.20.output.dense.bias", "bert.encoder.layer.20.output.LayerNorm.weight", "bert.encoder.layer.20.output.LayerNorm.bias", "bert.encoder.layer.21.attention.self.query.weight", "bert.encoder.layer.21.attention.self.query.bias", "bert.encoder.layer.21.attention.self.key.weight", "bert.encoder.layer.21.attention.self.key.bias", "bert.encoder.layer.21.attention.self.value.weight", "bert.encoder.layer.21.attention.self.value.bias", "bert.encoder.layer.21.attention.output.dense.weight", "bert.encoder.layer.21.attention.output.dense.bias", "bert.encoder.layer.21.attention.output.LayerNorm.weight", "bert.encoder.layer.21.attention.output.LayerNorm.bias", "bert.encoder.layer.21.intermediate.dense.weight", "bert.encoder.layer.21.intermediate.dense.bias", "bert.encoder.layer.21.output.dense.weight", "bert.encoder.layer.21.output.dense.bias", "bert.encoder.layer.21.output.LayerNorm.weight", "bert.encoder.layer.21.output.LayerNorm.bias", "bert.encoder.layer.22.attention.self.query.weight", "bert.encoder.layer.22.attention.self.query.bias", "bert.encoder.layer.22.attention.self.key.weight", "bert.encoder.layer.22.attention.self.key.bias", "bert.encoder.layer.22.attention.self.value.weight", "bert.encoder.layer.22.attention.self.value.bias", "bert.encoder.layer.22.attention.output.dense.weight", "bert.encoder.layer.22.attention.output.dense.bias", "bert.encoder.layer.22.attention.output.LayerNorm.weight", "bert.encoder.layer.22.attention.output.LayerNorm.bias", "bert.encoder.layer.22.intermediate.dense.weight", "bert.encoder.layer.22.intermediate.dense.bias", "bert.encoder.layer.22.output.dense.weight", "bert.encoder.layer.22.output.dense.bias", "bert.encoder.layer.22.output.LayerNorm.weight", "bert.encoder.layer.22.output.LayerNorm.bias", "bert.encoder.layer.23.attention.self.query.weight", "bert.encoder.layer.23.attention.self.query.bias", "bert.encoder.layer.23.attention.self.key.weight", "bert.encoder.layer.23.attention.self.key.bias", "bert.encoder.layer.23.attention.self.value.weight", "bert.encoder.layer.23.attention.self.value.bias", "bert.encoder.layer.23.attention.output.dense.weight", "bert.encoder.layer.23.attention.output.dense.bias", "bert.encoder.layer.23.attention.output.LayerNorm.weight", "bert.encoder.layer.23.attention.output.LayerNorm.bias", "bert.encoder.layer.23.intermediate.dense.weight", "bert.encoder.layer.23.intermediate.dense.bias", "bert.encoder.layer.23.output.dense.weight", "bert.encoder.layer.23.output.dense.bias", "bert.encoder.layer.23.output.LayerNorm.weight", "bert.encoder.layer.23.output.LayerNorm.bias". 
Traceback (most recent call last):
  File "/home/ubuntu/nlp-osaka/sentiment/torch_ddp_finetune_neural_classifier.py", line 1115, in fit
    self.model.load_state_dict(model_state_dict)
  File "/home/ubuntu/nlp-osaka/sentiment/ddp_sentiment_finetune.py", line 1206, in main
    classifier.fit(X_train, X_val, y_train, y_val, rank, world_size, debug, start_epoch, model_state_dict, optimizer_state_dict,
Traceback (most recent call last):
  File "/home/ubuntu/nlp-osaka/sentiment/torch_ddp_finetune_neural_classifier.py", line 1115, in fit
    self.model.load_state_dict(model_state_dict)
Traceback (most recent call last):
  File "/home/ubuntu/nlp-osaka/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 2152, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
Traceback (most recent call last):
  File "/home/ubuntu/nlp-osaka/sentiment/ddp_sentiment_finetune.py", line 1206, in main
    classifier.fit(X_train, X_val, y_train, y_val, rank, world_size, debug, start_epoch, model_state_dict, optimizer_state_dict,
  File "/home/ubuntu/nlp-osaka/sentiment/ddp_sentiment_finetune.py", line 1206, in main
    classifier.fit(X_train, X_val, y_train, y_val, rank, world_size, debug, start_epoch, model_state_dict, optimizer_state_dict,
  File "/home/ubuntu/nlp-osaka/sentiment/torch_ddp_finetune_neural_classifier.py", line 1115, in fit
    self.model.load_state_dict(model_state_dict)
  File "/home/ubuntu/nlp-osaka/sentiment/ddp_sentiment_finetune.py", line 1206, in main
    classifier.fit(X_train, X_val, y_train, y_val, rank, world_size, debug, start_epoch, model_state_dict, optimizer_state_dict,
  File "/home/ubuntu/nlp-osaka/sentiment/torch_ddp_finetune_neural_classifier.py", line 1115, in fit
    self.model.load_state_dict(model_state_dict)
  File "/home/ubuntu/nlp-osaka/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 2152, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
  File "/home/ubuntu/nlp-osaka/sentiment/torch_ddp_finetune_neural_classifier.py", line 1115, in fit
    self.model.load_state_dict(model_state_dict)
  File "/home/ubuntu/nlp-osaka/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 2152, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for BERTClassifier:
	Missing key(s) in state_dict: "bert.embeddings.word_embeddings.weight", "bert.embeddings.position_embeddings.weight", "bert.embeddings.token_type_embeddings.weight", "bert.embeddings.LayerNorm.weight", "bert.embeddings.LayerNorm.bias", "bert.encoder.layer.0.attention.self.query.weight", "bert.encoder.layer.0.attention.self.query.bias", "bert.encoder.layer.0.attention.self.key.weight", "bert.encoder.layer.0.attention.self.key.bias", "bert.encoder.layer.0.attention.self.value.weight", "bert.encoder.layer.0.attention.self.value.bias", "bert.encoder.layer.0.attention.output.dense.weight", "bert.encoder.layer.0.attention.output.dense.bias", "bert.encoder.layer.0.attention.output.LayerNorm.weight", "bert.encoder.layer.0.attention.output.LayerNorm.bias", "bert.encoder.layer.0.intermediate.dense.weight", "bert.encoder.layer.0.intermediate.dense.bias", "bert.encoder.layer.0.output.dense.weight", "bert.encoder.layer.0.output.dense.bias", "bert.encoder.layer.0.output.LayerNorm.weight", "bert.encoder.layer.0.output.LayerNorm.bias", "bert.encoder.layer.1.attention.self.query.weight", "bert.encoder.layer.1.attention.self.query.bias", "bert.encoder.layer.1.attention.self.key.weight", "bert.encoder.layer.1.attention.self.key.bias", "bert.encoder.layer.1.attention.self.value.weight", "bert.encoder.layer.1.attention.self.value.bias", "bert.encoder.layer.1.attention.output.dense.weight", "bert.encoder.layer.1.attention.output.dense.bias", "bert.encoder.layer.1.attention.output.LayerNorm.weight", "bert.encoder.layer.1.attention.output.LayerNorm.bias", "bert.encoder.layer.1.intermediate.dense.weight", "bert.encoder.layer.1.intermediate.dense.bias", "bert.encoder.layer.1.output.dense.weight", "bert.encoder.layer.1.output.dense.bias", "bert.encoder.layer.1.output.LayerNorm.weight", "bert.encoder.layer.1.output.LayerNorm.bias", "bert.encoder.layer.2.attention.self.query.weight", "bert.encoder.layer.2.attention.self.query.bias", "bert.encoder.layer.2.attention.self.key.weight", "bert.encoder.layer.2.attention.self.key.bias", "bert.encoder.layer.2.attention.self.value.weight", "bert.encoder.layer.2.attention.self.value.bias", "bert.encoder.layer.2.attention.output.dense.weight", "bert.encoder.layer.2.attention.output.dense.bias", "bert.encoder.layer.2.attention.output.LayerNorm.weight", "bert.encoder.layer.2.attention.output.LayerNorm.bias", "bert.encoder.layer.2.intermediate.dense.weight", "bert.encoder.layer.2.intermediate.dense.bias", "bert.encoder.layer.2.output.dense.weight", "bert.encoder.layer.2.output.dense.bias", "bert.encoder.layer.2.output.LayerNorm.weight", "bert.encoder.layer.2.output.LayerNorm.bias", "bert.encoder.layer.3.attention.self.query.weight", "bert.encoder.layer.3.attention.self.query.bias", "bert.encoder.layer.3.attention.self.key.weight", "bert.encoder.layer.3.attention.self.key.bias", "bert.encoder.layer.3.attention.self.value.weight", "bert.encoder.layer.3.attention.self.value.bias", "bert.encoder.layer.3.attention.output.dense.weight", "bert.encoder.layer.3.attention.output.dense.bias", "bert.encoder.layer.3.attention.output.LayerNorm.weight", "bert.encoder.layer.3.attention.output.LayerNorm.bias", "bert.encoder.layer.3.intermediate.dense.weight", "bert.encoder.layer.3.intermediate.dense.bias", "bert.encoder.layer.3.output.dense.weight", "bert.encoder.layer.3.output.dense.bias", "bert.encoder.layer.3.output.LayerNorm.weight", "bert.encoder.layer.3.output.LayerNorm.bias", "bert.encoder.layer.4.attention.self.query.weight", "bert.encoder.layer.4.attention.self.query.bias", "bert.encoder.layer.4.attention.self.key.weight", "bert.encoder.layer.4.attention.self.key.bias", "bert.encoder.layer.4.attention.self.value.weight", "bert.encoder.layer.4.attention.self.value.bias", "bert.encoder.layer.4.attention.output.dense.weight", "bert.encoder.layer.4.attention.output.dense.bias", "bert.encoder.layer.4.attention.output.LayerNorm.weight", "bert.encoder.layer.4.attention.output.LayerNorm.bias", "bert.encoder.layer.4.intermediate.dense.weight", "bert.encoder.layer.4.intermediate.dense.bias", "bert.encoder.layer.4.output.dense.weight", "bert.encoder.layer.4.output.dense.bias", "bert.encoder.layer.4.output.LayerNorm.weight", "bert.encoder.layer.4.output.LayerNorm.bias", "bert.encoder.layer.5.attention.self.query.weight", "bert.encoder.layer.5.attention.self.query.bias", "bert.encoder.layer.5.attention.self.key.weight", "bert.encoder.layer.5.attention.self.key.bias", "bert.encoder.layer.5.attention.self.value.weight", "bert.encoder.layer.5.attention.self.value.bias", "bert.encoder.layer.5.attention.output.dense.weight", "bert.encoder.layer.5.attention.output.dense.bias", "bert.encoder.layer.5.attention.output.LayerNorm.weight", "bert.encoder.layer.5.attention.output.LayerNorm.bias", "bert.encoder.layer.5.intermediate.dense.weight", "bert.encoder.layer.5.intermediate.dense.bias", "bert.encoder.layer.5.output.dense.weight", "bert.encoder.layer.5.output.dense.bias", "bert.encoder.layer.5.output.LayerNorm.weight", "bert.encoder.layer.5.output.LayerNorm.bias", "bert.encoder.layer.6.attention.self.query.weight", "bert.encoder.layer.6.attention.self.query.bias", "bert.encoder.layer.6.attention.self.key.weight", "bert.encoder.layer.6.attention.self.key.bias", "bert.encoder.layer.6.attention.self.value.weight", "bert.encoder.layer.6.attention.self.value.bias", "bert.encoder.layer.6.attention.output.dense.weight", "bert.encoder.layer.6.attention.output.dense.bias", "bert.encoder.layer.6.attention.output.LayerNorm.weight", "bert.encoder.layer.6.attention.output.LayerNorm.bias", "bert.encoder.layer.6.intermediate.dense.weight", "bert.encoder.layer.6.intermediate.dense.bias", "bert.encoder.layer.6.output.dense.weight", "bert.encoder.layer.6.output.dense.bias", "bert.encoder.layer.6.output.LayerNorm.weight", "bert.encoder.layer.6.output.LayerNorm.bias", "bert.encoder.layer.7.attention.self.query.weight", "bert.encoder.layer.7.attention.self.query.bias", "bert.encoder.layer.7.attention.self.key.weight", "bert.encoder.layer.7.attention.self.key.bias", "bert.encoder.layer.7.attention.self.value.weight", "bert.encoder.layer.7.attention.self.value.bias", "bert.encoder.layer.7.attention.output.dense.weight", "bert.encoder.layer.7.attention.output.dense.bias", "bert.encoder.layer.7.attention.output.LayerNorm.weight", "bert.encoder.layer.7.attention.output.LayerNorm.bias", "bert.encoder.layer.7.intermediate.dense.weight", "bert.encoder.layer.7.intermediate.dense.bias", "bert.encoder.layer.7.output.dense.weight", "bert.encoder.layer.7.output.dense.bias", "bert.encoder.layer.7.output.LayerNorm.weight", "bert.encoder.layer.7.output.LayerNorm.bias", "bert.encoder.layer.8.attention.self.query.weight", "bert.encoder.layer.8.attention.self.query.bias", "bert.encoder.layer.8.attention.self.key.weight", "bert.encoder.layer.8.attention.self.key.bias", "bert.encoder.layer.8.attention.self.value.weight", "bert.encoder.layer.8.attention.self.value.bias", "bert.encoder.layer.8.attention.output.dense.weight", "bert.encoder.layer.8.attention.output.dense.bias", "bert.encoder.layer.8.attention.output.LayerNorm.weight", "bert.encoder.layer.8.attention.output.LayerNorm.bias", "bert.encoder.layer.8.intermediate.dense.weight", "bert.encoder.layer.8.intermediate.dense.bias", "bert.encoder.layer.8.output.dense.weight", "bert.encoder.layer.8.output.dense.bias", "bert.encoder.layer.8.output.LayerNorm.weight", "bert.encoder.layer.8.output.LayerNorm.bias", "bert.encoder.layer.9.attention.self.query.weight", "bert.encoder.layer.9.attention.self.query.bias", "bert.encoder.layer.9.attention.self.key.weight", "bert.encoder.layer.9.attention.self.key.bias", "bert.encoder.layer.9.attention.self.value.weight", "bert.encoder.layer.9.attention.self.value.bias", "bert.encoder.layer.9.attention.output.dense.weight", "bert.encoder.layer.9.attention.output.dense.bias", "bert.encoder.layer.9.attention.output.LayerNorm.weight", "bert.encoder.layer.9.attention.output.LayerNorm.bias", "bert.encoder.layer.9.intermediate.dense.weight", "bert.encoder.layer.9.intermediate.dense.bias", "bert.encoder.layer.9.output.dense.weight", "bert.encoder.layer.9.output.dense.bias", "bert.encoder.layer.9.output.LayerNorm.weight", "bert.encoder.layer.9.output.LayerNorm.bias", "bert.encoder.layer.10.attention.self.query.weight", "bert.encoder.layer.10.attention.self.query.bias", "bert.encoder.layer.10.attention.self.key.weight", "bert.encoder.layer.10.attention.self.key.bias", "bert.encoder.layer.10.attention.self.value.weight", "bert.encoder.layer.10.attention.self.value.bias", "bert.encoder.layer.10.attention.output.dense.weight", "bert.encoder.layer.10.attention.output.dense.bias", "bert.encoder.layer.10.attention.output.LayerNorm.weight", "bert.encoder.layer.10.attention.output.LayerNorm.bias", "bert.encoder.layer.10.intermediate.dense.weight", "bert.encoder.layer.10.intermediate.dense.bias", "bert.encoder.layer.10.output.dense.weight", "bert.encoder.layer.10.output.dense.bias", "bert.encoder.layer.10.output.LayerNorm.weight", "bert.encoder.layer.10.output.LayerNorm.bias", "bert.encoder.layer.11.attention.self.query.weight", "bert.encoder.layer.11.attention.self.query.bias", "bert.encoder.layer.11.attention.self.key.weight", "bert.encoder.layer.11.attention.self.key.bias", "bert.encoder.layer.11.attention.self.value.weight", "bert.encoder.layer.11.attention.self.value.bias", "bert.encoder.layer.11.attention.output.dense.weight", "bert.encoder.layer.11.attention.output.dense.bias", "bert.encoder.layer.11.attention.output.LayerNorm.weight", "bert.encoder.layer.11.attention.output.LayerNorm.bias", "bert.encoder.layer.11.intermediate.dense.weight", "bert.encoder.layer.11.intermediate.dense.bias", "bert.encoder.layer.11.output.dense.weight", "bert.encoder.layer.11.output.dense.bias", "bert.encoder.layer.11.output.LayerNorm.weight", "bert.encoder.layer.11.output.LayerNorm.bias", "bert.encoder.layer.12.attention.self.query.weight", "bert.encoder.layer.12.attention.self.query.bias", "bert.encoder.layer.12.attention.self.key.weight", "bert.encoder.layer.12.attention.self.key.bias", "bert.encoder.layer.12.attention.self.value.weight", "bert.encoder.layer.12.attention.self.value.bias", "bert.encoder.layer.12.attention.output.dense.weight", "bert.encoder.layer.12.attention.output.dense.bias", "bert.encoder.layer.12.attention.output.LayerNorm.weight", "bert.encoder.layer.12.attention.output.LayerNorm.bias", "bert.encoder.layer.12.intermediate.dense.weight", "bert.encoder.layer.12.intermediate.dense.bias", "bert.encoder.layer.12.output.dense.weight", "bert.encoder.layer.12.output.dense.bias", "bert.encoder.layer.12.output.LayerNorm.weight", "bert.encoder.layer.12.output.LayerNorm.bias", "bert.encoder.layer.13.attention.self.query.weight", "bert.encoder.layer.13.attention.self.query.bias", "bert.encoder.layer.13.attention.self.key.weight", "bert.encoder.layer.13.attention.self.key.bias", "bert.encoder.layer.13.attention.self.value.weight", "bert.encoder.layer.13.attention.self.value.bias", "bert.encoder.layer.13.attention.output.dense.weight", "bert.encoder.layer.13.attention.output.dense.bias", "bert.encoder.layer.13.attention.output.LayerNorm.weight", "bert.encoder.layer.13.attention.output.LayerNorm.bias", "bert.encoder.layer.13.intermediate.dense.weight", "bert.encoder.layer.13.intermediate.dense.bias", "bert.encoder.layer.13.output.dense.weight", "bert.encoder.layer.13.output.dense.bias", "bert.encoder.layer.13.output.LayerNorm.weight", "bert.encoder.layer.13.output.LayerNorm.bias", "bert.encoder.layer.14.attention.self.query.weight", "bert.encoder.layer.14.attention.self.query.bias", "bert.encoder.layer.14.attention.self.key.weight", "bert.encoder.layer.14.attention.self.key.bias", "bert.encoder.layer.14.attention.self.value.weight", "bert.encoder.layer.14.attention.self.value.bias", "bert.encoder.layer.14.attention.output.dense.weight", "bert.encoder.layer.14.attention.output.dense.bias", "bert.encoder.layer.14.attention.output.LayerNorm.weight", "bert.encoder.layer.14.attention.output.LayerNorm.bias", "bert.encoder.layer.14.intermediate.dense.weight", "bert.encoder.layer.14.intermediate.dense.bias", "bert.encoder.layer.14.output.dense.weight", "bert.encoder.layer.14.output.dense.bias", "bert.encoder.layer.14.output.LayerNorm.weight", "bert.encoder.layer.14.output.LayerNorm.bias", "bert.encoder.layer.15.attention.self.query.weight", "bert.encoder.layer.15.attention.self.query.bias", "bert.encoder.layer.15.attention.self.key.weight", "bert.encoder.layer.15.attention.self.key.bias", "bert.encoder.layer.15.attention.self.value.weight", "bert.encoder.layer.15.attention.self.value.bias", "bert.encoder.layer.15.attention.output.dense.weight", "bert.encoder.layer.15.attention.output.dense.bias", "bert.encoder.layer.15.attention.output.LayerNorm.weight", "bert.encoder.layer.15.attention.output.LayerNorm.bias", "bert.encoder.layer.15.intermediate.dense.weight", "bert.encoder.layer.15.intermediate.dense.bias", "bert.encoder.layer.15.output.dense.weight", "bert.encoder.layer.15.output.dense.bias", "bert.encoder.layer.15.output.LayerNorm.weight", "bert.encoder.layer.15.output.LayerNorm.bias", "bert.encoder.layer.16.attention.self.query.weight", "bert.encoder.layer.16.attention.self.query.bias", "bert.encoder.layer.16.attention.self.key.weight", "bert.encoder.layer.16.attention.self.key.bias", "bert.encoder.layer.16.attention.self.value.weight", "bert.encoder.layer.16.attention.self.value.bias", "bert.encoder.layer.16.attention.output.dense.weight", "bert.encoder.layer.16.attention.output.dense.bias", "bert.encoder.layer.16.attention.output.LayerNorm.weight", "bert.encoder.layer.16.attention.output.LayerNorm.bias", "bert.encoder.layer.16.intermediate.dense.weight", "bert.encoder.layer.16.intermediate.dense.bias", "bert.encoder.layer.16.output.dense.weight", "bert.encoder.layer.16.output.dense.bias", "bert.encoder.layer.16.output.LayerNorm.weight", "bert.encoder.layer.16.output.LayerNorm.bias", "bert.encoder.layer.17.attention.self.query.weight", "bert.encoder.layer.17.attention.self.query.bias", "bert.encoder.layer.17.attention.self.key.weight", "bert.encoder.layer.17.attention.self.key.bias", "bert.encoder.layer.17.attention.self.value.weight", "bert.encoder.layer.17.attention.self.value.bias", "bert.encoder.layer.17.attention.output.dense.weight", "bert.encoder.layer.17.attention.output.dense.bias", "bert.encoder.layer.17.attention.output.LayerNorm.weight", "bert.encoder.layer.17.attention.output.LayerNorm.bias", "bert.encoder.layer.17.intermediate.dense.weight", "bert.encoder.layer.17.intermediate.dense.bias", "bert.encoder.layer.17.output.dense.weight", "bert.encoder.layer.17.output.dense.bias", "bert.encoder.layer.17.output.LayerNorm.weight", "bert.encoder.layer.17.output.LayerNorm.bias", "bert.encoder.layer.18.attention.self.query.weight", "bert.encoder.layer.18.attention.self.query.bias", "bert.encoder.layer.18.attention.self.key.weight", "bert.encoder.layer.18.attention.self.key.bias", "bert.encoder.layer.18.attention.self.value.weight", "bert.encoder.layer.18.attention.self.value.bias", "bert.encoder.layer.18.attention.output.dense.weight", "bert.encoder.layer.18.attention.output.dense.bias", "bert.encoder.layer.18.attention.output.LayerNorm.weight", "bert.encoder.layer.18.attention.output.LayerNorm.bias", "bert.encoder.layer.18.intermediate.dense.weight", "bert.encoder.layer.18.intermediate.dense.bias", "bert.encoder.layer.18.output.dense.weight", "bert.encoder.layer.18.output.dense.bias", "bert.encoder.layer.18.output.LayerNorm.weight", "bert.encoder.layer.18.output.LayerNorm.bias", "bert.encoder.layer.19.attention.self.query.weight", "bert.encoder.layer.19.attention.self.query.bias", "bert.encoder.layer.19.attention.self.key.weight", "bert.encoder.layer.19.attention.self.key.bias", "bert.encoder.layer.19.attention.self.value.weight", "bert.encoder.layer.19.attention.self.value.bias", "bert.encoder.layer.19.attention.output.dense.weight", "bert.encoder.layer.19.attention.output.dense.bias", "bert.encoder.layer.19.attention.output.LayerNorm.weight", "bert.encoder.layer.19.attention.output.LayerNorm.bias", "bert.encoder.layer.19.intermediate.dense.weight", "bert.encoder.layer.19.intermediate.dense.bias", "bert.encoder.layer.19.output.dense.weight", "bert.encoder.layer.19.output.dense.bias", "bert.encoder.layer.19.output.LayerNorm.weight", "bert.encoder.layer.19.output.LayerNorm.bias", "bert.encoder.layer.20.attention.self.query.weight", "bert.encoder.layer.20.attention.self.query.bias", "bert.encoder.layer.20.attention.self.key.weight", "bert.encoder.layer.20.attention.self.key.bias", "bert.encoder.layer.20.attention.self.value.weight", "bert.encoder.layer.20.attention.self.value.bias", "bert.encoder.layer.20.attention.output.dense.weight", "bert.encoder.layer.20.attention.output.dense.bias", "bert.encoder.layer.20.attention.output.LayerNorm.weight", "bert.encoder.layer.20.attention.output.LayerNorm.bias", "bert.encoder.layer.20.intermediate.dense.weight", "bert.encoder.layer.20.intermediate.dense.bias", "bert.encoder.layer.20.output.dense.weight", "bert.encoder.layer.20.output.dense.bias", "bert.encoder.layer.20.output.LayerNorm.weight", "bert.encoder.layer.20.output.LayerNorm.bias", "bert.encoder.layer.21.attention.self.query.weight", "bert.encoder.layer.21.attention.self.query.bias", "bert.encoder.layer.21.attention.self.key.weight", "bert.encoder.layer.21.attention.self.key.bias", "bert.encoder.layer.21.attention.self.value.weight", "bert.encoder.layer.21.attention.self.value.bias", "bert.encoder.layer.21.attention.output.dense.weight", "bert.encoder.layer.21.attention.output.dense.bias", "bert.encoder.layer.21.attention.output.LayerNorm.weight", "bert.encoder.layer.21.attention.output.LayerNorm.bias", "bert.encoder.layer.21.intermediate.dense.weight", "bert.encoder.layer.21.intermediate.dense.bias", "bert.encoder.layer.21.output.dense.weight", "bert.encoder.layer.21.output.dense.bias", "bert.encoder.layer.21.output.LayerNorm.weight", "bert.encoder.layer.21.output.LayerNorm.bias", "bert.encoder.layer.22.attention.self.query.weight", "bert.encoder.layer.22.attention.self.query.bias", "bert.encoder.layer.22.attention.self.key.weight", "bert.encoder.layer.22.attention.self.key.bias", "bert.encoder.layer.22.attention.self.value.weight", "bert.encoder.layer.22.attention.self.value.bias", "bert.encoder.layer.22.attention.output.dense.weight", "bert.encoder.layer.22.attention.output.dense.bias", "bert.encoder.layer.22.attention.output.LayerNorm.weight", "bert.encoder.layer.22.attention.output.LayerNorm.bias", "bert.encoder.layer.22.intermediate.dense.weight", "bert.encoder.layer.22.intermediate.dense.bias", "bert.encoder.layer.22.output.dense.weight", "bert.encoder.layer.22.output.dense.bias", "bert.encoder.layer.22.output.LayerNorm.weight", "bert.encoder.layer.22.output.LayerNorm.bias", "bert.encoder.layer.23.attention.self.query.weight", "bert.encoder.layer.23.attention.self.query.bias", "bert.encoder.layer.23.attention.self.key.weight", "bert.encoder.layer.23.attention.self.key.bias", "bert.encoder.layer.23.attention.self.value.weight", "bert.encoder.layer.23.attention.self.value.bias", "bert.encoder.layer.23.attention.output.dense.weight", "bert.encoder.layer.23.attention.output.dense.bias", "bert.encoder.layer.23.attention.output.LayerNorm.weight", "bert.encoder.layer.23.attention.output.LayerNorm.bias", "bert.encoder.layer.23.intermediate.dense.weight", "bert.encoder.layer.23.intermediate.dense.bias", "bert.encoder.layer.23.output.dense.weight", "bert.encoder.layer.23.output.dense.bias", "bert.encoder.layer.23.output.LayerNorm.weight", "bert.encoder.layer.23.output.LayerNorm.bias". 
  File "/home/ubuntu/nlp-osaka/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 2152, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
  File "/home/ubuntu/nlp-osaka/sentiment/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py", line 2152, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for BERTClassifier:
	Missing key(s) in state_dict: "bert.embeddings.word_embeddings.weight", "bert.embeddings.position_embeddings.weight", "bert.embeddings.token_type_embeddings.weight", "bert.embeddings.LayerNorm.weight", "bert.embeddings.LayerNorm.bias", "bert.encoder.layer.0.attention.self.query.weight", "bert.encoder.layer.0.attention.self.query.bias", "bert.encoder.layer.0.attention.self.key.weight", "bert.encoder.layer.0.attention.self.key.bias", "bert.encoder.layer.0.attention.self.value.weight", "bert.encoder.layer.0.attention.self.value.bias", "bert.encoder.layer.0.attention.output.dense.weight", "bert.encoder.layer.0.attention.output.dense.bias", "bert.encoder.layer.0.attention.output.LayerNorm.weight", "bert.encoder.layer.0.attention.output.LayerNorm.bias", "bert.encoder.layer.0.intermediate.dense.weight", "bert.encoder.layer.0.intermediate.dense.bias", "bert.encoder.layer.0.output.dense.weight", "bert.encoder.layer.0.output.dense.bias", "bert.encoder.layer.0.output.LayerNorm.weight", "bert.encoder.layer.0.output.LayerNorm.bias", "bert.encoder.layer.1.attention.self.query.weight", "bert.encoder.layer.1.attention.self.query.bias", "bert.encoder.layer.1.attention.self.key.weight", "bert.encoder.layer.1.attention.self.key.bias", "bert.encoder.layer.1.attention.self.value.weight", "bert.encoder.layer.1.attention.self.value.bias", "bert.encoder.layer.1.attention.output.dense.weight", "bert.encoder.layer.1.attention.output.dense.bias", "bert.encoder.layer.1.attention.output.LayerNorm.weight", "bert.encoder.layer.1.attention.output.LayerNorm.bias", "bert.encoder.layer.1.intermediate.dense.weight", "bert.encoder.layer.1.intermediate.dense.bias", "bert.encoder.layer.1.output.dense.weight", "bert.encoder.layer.1.output.dense.bias", "bert.encoder.layer.1.output.LayerNorm.weight", "bert.encoder.layer.1.output.LayerNorm.bias", "bert.encoder.layer.2.attention.self.query.weight", "bert.encoder.layer.2.attention.self.query.bias", "bert.encoder.layer.2.attention.self.key.weight", "bert.encoder.layer.2.attention.self.key.bias", "bert.encoder.layer.2.attention.self.value.weight", "bert.encoder.layer.2.attention.self.value.bias", "bert.encoder.layer.2.attention.output.dense.weight", "bert.encoder.layer.2.attention.output.dense.bias", "bert.encoder.layer.2.attention.output.LayerNorm.weight", "bert.encoder.layer.2.attention.output.LayerNorm.bias", "bert.encoder.layer.2.intermediate.dense.weight", "bert.encoder.layer.2.intermediate.dense.bias", "bert.encoder.layer.2.output.dense.weight", "bert.encoder.layer.2.output.dense.bias", "bert.encoder.layer.2.output.LayerNorm.weight", "bert.encoder.layer.2.output.LayerNorm.bias", "bert.encoder.layer.3.attention.self.query.weight", "bert.encoder.layer.3.attention.self.query.bias", "bert.encoder.layer.3.attention.self.key.weight", "bert.encoder.layer.3.attention.self.key.bias", "bert.encoder.layer.3.attention.self.value.weight", "bert.encoder.layer.3.attention.self.value.bias", "bert.encoder.layer.3.attention.output.dense.weight", "bert.encoder.layer.3.attention.output.dense.bias", "bert.encoder.layer.3.attention.output.LayerNorm.weight", "bert.encoder.layer.3.attention.output.LayerNorm.bias", "bert.encoder.layer.3.intermediate.dense.weight", "bert.encoder.layer.3.intermediate.dense.bias", "bert.encoder.layer.3.output.dense.weight", "bert.encoder.layer.3.output.dense.bias", "bert.encoder.layer.3.output.LayerNorm.weight", "bert.encoder.layer.3.output.LayerNorm.bias", "bert.encoder.layer.4.attention.self.query.weight", "bert.encoder.layer.4.attention.self.query.bias", "bert.encoder.layer.4.attention.self.key.weight", "bert.encoder.layer.4.attention.self.key.bias", "bert.encoder.layer.4.attention.self.value.weight", "bert.encoder.layer.4.attention.self.value.bias", "bert.encoder.layer.4.attention.output.dense.weight", "bert.encoder.layer.4.attention.output.dense.bias", "bert.encoder.layer.4.attention.output.LayerNorm.weight", "bert.encoder.layer.4.attention.output.LayerNorm.bias", "bert.encoder.layer.4.intermediate.dense.weight", "bert.encoder.layer.4.intermediate.dense.bias", "bert.encoder.layer.4.output.dense.weight", "bert.encoder.layer.4.output.dense.bias", "bert.encoder.layer.4.output.LayerNorm.weight", "bert.encoder.layer.4.output.LayerNorm.bias", "bert.encoder.layer.5.attention.self.query.weight", "bert.encoder.layer.5.attention.self.query.bias", "bert.encoder.layer.5.attention.self.key.weight", "bert.encoder.layer.5.attention.self.key.bias", "bert.encoder.layer.5.attention.self.value.weight", "bert.encoder.layer.5.attention.self.value.bias", "bert.encoder.layer.5.attention.output.dense.weight", "bert.encoder.layer.5.attention.output.dense.bias", "bert.encoder.layer.5.attention.output.LayerNorm.weight", "bert.encoder.layer.5.attention.output.LayerNorm.bias", "bert.encoder.layer.5.intermediate.dense.weight", "bert.encoder.layer.5.intermediate.dense.bias", "bert.encoder.layer.5.output.dense.weight", "bert.encoder.layer.5.output.dense.bias", "bert.encoder.layer.5.output.LayerNorm.weight", "bert.encoder.layer.5.output.LayerNorm.bias", "bert.encoder.layer.6.attention.self.query.weight", "bert.encoder.layer.6.attention.self.query.bias", "bert.encoder.layer.6.attention.self.key.weight", "bert.encoder.layer.6.attention.self.key.bias", "bert.encoder.layer.6.attention.self.value.weight", "bert.encoder.layer.6.attention.self.value.bias", "bert.encoder.layer.6.attention.output.dense.weight", "bert.encoder.layer.6.attention.output.dense.bias", "bert.encoder.layer.6.attention.output.LayerNorm.weight", "bert.encoder.layer.6.attention.output.LayerNorm.bias", "bert.encoder.layer.6.intermediate.dense.weight", "bert.encoder.layer.6.intermediate.dense.bias", "bert.encoder.layer.6.output.dense.weight", "bert.encoder.layer.6.output.dense.bias", "bert.encoder.layer.6.output.LayerNorm.weight", "bert.encoder.layer.6.output.LayerNorm.bias", "bert.encoder.layer.7.attention.self.query.weight", "bert.encoder.layer.7.attention.self.query.bias", "bert.encoder.layer.7.attention.self.key.weight", "bert.encoder.layer.7.attention.self.key.bias", "bert.encoder.layer.7.attention.self.value.weight", "bert.encoder.layer.7.attention.self.value.bias", "bert.encoder.layer.7.attention.output.dense.weight", "bert.encoder.layer.7.attention.output.dense.bias", "bert.encoder.layer.7.attention.output.LayerNorm.weight", "bert.encoder.layer.7.attention.output.LayerNorm.bias", "bert.encoder.layer.7.intermediate.dense.weight", "bert.encoder.layer.7.intermediate.dense.bias", "bert.encoder.layer.7.output.dense.weight", "bert.encoder.layer.7.output.dense.bias", "bert.encoder.layer.7.output.LayerNorm.weight", "bert.encoder.layer.7.output.LayerNorm.bias", "bert.encoder.layer.8.attention.self.query.weight", "bert.encoder.layer.8.attention.self.query.bias", "bert.encoder.layer.8.attention.self.key.weight", "bert.encoder.layer.8.attention.self.key.bias", "bert.encoder.layer.8.attention.self.value.weight", "bert.encoder.layer.8.attention.self.value.bias", "bert.encoder.layer.8.attention.output.dense.weight", "bert.encoder.layer.8.attention.output.dense.bias", "bert.encoder.layer.8.attention.output.LayerNorm.weight", "bert.encoder.layer.8.attention.output.LayerNorm.bias", "bert.encoder.layer.8.intermediate.dense.weight", "bert.encoder.layer.8.intermediate.dense.bias", "bert.encoder.layer.8.output.dense.weight", "bert.encoder.layer.8.output.dense.bias", "bert.encoder.layer.8.output.LayerNorm.weight", "bert.encoder.layer.8.output.LayerNorm.bias", "bert.encoder.layer.9.attention.self.query.weight", "bert.encoder.layer.9.attention.self.query.bias", "bert.encoder.layer.9.attention.self.key.weight", "bert.encoder.layer.9.attention.self.key.bias", "bert.encoder.layer.9.attention.self.value.weight", "bert.encoder.layer.9.attention.self.value.bias", "bert.encoder.layer.9.attention.output.dense.weight", "bert.encoder.layer.9.attention.output.dense.bias", "bert.encoder.layer.9.attention.output.LayerNorm.weight", "bert.encoder.layer.9.attention.output.LayerNorm.bias", "bert.encoder.layer.9.intermediate.dense.weight", "bert.encoder.layer.9.intermediate.dense.bias", "bert.encoder.layer.9.output.dense.weight", "bert.encoder.layer.9.output.dense.bias", "bert.encoder.layer.9.output.LayerNorm.weight", "bert.encoder.layer.9.output.LayerNorm.bias", "bert.encoder.layer.10.attention.self.query.weight", "bert.encoder.layer.10.attention.self.query.bias", "bert.encoder.layer.10.attention.self.key.weight", "bert.encoder.layer.10.attention.self.key.bias", "bert.encoder.layer.10.attention.self.value.weight", "bert.encoder.layer.10.attention.self.value.bias", "bert.encoder.layer.10.attention.output.dense.weight", "bert.encoder.layer.10.attention.output.dense.bias", "bert.encoder.layer.10.attention.output.LayerNorm.weight", "bert.encoder.layer.10.attention.output.LayerNorm.bias", "bert.encoder.layer.10.intermediate.dense.weight", "bert.encoder.layer.10.intermediate.dense.bias", "bert.encoder.layer.10.output.dense.weight", "bert.encoder.layer.10.output.dense.bias", "bert.encoder.layer.10.output.LayerNorm.weight", "bert.encoder.layer.10.output.LayerNorm.bias", "bert.encoder.layer.11.attention.self.query.weight", "bert.encoder.layer.11.attention.self.query.bias", "bert.encoder.layer.11.attention.self.key.weight", "bert.encoder.layer.11.attention.self.key.bias", "bert.encoder.layer.11.attention.self.value.weight", "bert.encoder.layer.11.attention.self.value.bias", "bert.encoder.layer.11.attention.output.dense.weight", "bert.encoder.layer.11.attention.output.dense.bias", "bert.encoder.layer.11.attention.output.LayerNorm.weight", "bert.encoder.layer.11.attention.output.LayerNorm.bias", "bert.encoder.layer.11.intermediate.dense.weight", "bert.encoder.layer.11.intermediate.dense.bias", "bert.encoder.layer.11.output.dense.weight", "bert.encoder.layer.11.output.dense.bias", "bert.encoder.layer.11.output.LayerNorm.weight", "bert.encoder.layer.11.output.LayerNorm.bias", "bert.encoder.layer.12.attention.self.query.weight", "bert.encoder.layer.12.attention.self.query.bias", "bert.encoder.layer.12.attention.self.key.weight", "bert.encoder.layer.12.attention.self.key.bias", "bert.encoder.layer.12.attention.self.value.weight", "bert.encoder.layer.12.attention.self.value.bias", "bert.encoder.layer.12.attention.output.dense.weight", "bert.encoder.layer.12.attention.output.dense.bias", "bert.encoder.layer.12.attention.output.LayerNorm.weight", "bert.encoder.layer.12.attention.output.LayerNorm.bias", "bert.encoder.layer.12.intermediate.dense.weight", "bert.encoder.layer.12.intermediate.dense.bias", "bert.encoder.layer.12.output.dense.weight", "bert.encoder.layer.12.output.dense.bias", "bert.encoder.layer.12.output.LayerNorm.weight", "bert.encoder.layer.12.output.LayerNorm.bias", "bert.encoder.layer.13.attention.self.query.weight", "bert.encoder.layer.13.attention.self.query.bias", "bert.encoder.layer.13.attention.self.key.weight", "bert.encoder.layer.13.attention.self.key.bias", "bert.encoder.layer.13.attention.self.value.weight", "bert.encoder.layer.13.attention.self.value.bias", "bert.encoder.layer.13.attention.output.dense.weight", "bert.encoder.layer.13.attention.output.dense.bias", "bert.encoder.layer.13.attention.output.LayerNorm.weight", "bert.encoder.layer.13.attention.output.LayerNorm.bias", "bert.encoder.layer.13.intermediate.dense.weight", "bert.encoder.layer.13.intermediate.dense.bias", "bert.encoder.layer.13.output.dense.weight", "bert.encoder.layer.13.output.dense.bias", "bert.encoder.layer.13.output.LayerNorm.weight", "bert.encoder.layer.13.output.LayerNorm.bias", "bert.encoder.layer.14.attention.self.query.weight", "bert.encoder.layer.14.attention.self.query.bias", "bert.encoder.layer.14.attention.self.key.weight", "bert.encoder.layer.14.attention.self.key.bias", "bert.encoder.layer.14.attention.self.value.weight", "bert.encoder.layer.14.attention.self.value.bias", "bert.encoder.layer.14.attention.output.dense.weight", "bert.encoder.layer.14.attention.output.dense.bias", "bert.encoder.layer.14.attention.output.LayerNorm.weight", "bert.encoder.layer.14.attention.output.LayerNorm.bias", "bert.encoder.layer.14.intermediate.dense.weight", "bert.encoder.layer.14.intermediate.dense.bias", "bert.encoder.layer.14.output.dense.weight", "bert.encoder.layer.14.output.dense.bias", "bert.encoder.layer.14.output.LayerNorm.weight", "bert.encoder.layer.14.output.LayerNorm.bias", "bert.encoder.layer.15.attention.self.query.weight", "bert.encoder.layer.15.attention.self.query.bias", "bert.encoder.layer.15.attention.self.key.weight", "bert.encoder.layer.15.attention.self.key.bias", "bert.encoder.layer.15.attention.self.value.weight", "bert.encoder.layer.15.attention.self.value.bias", "bert.encoder.layer.15.attention.output.dense.weight", "bert.encoder.layer.15.attention.output.dense.bias", "bert.encoder.layer.15.attention.output.LayerNorm.weight", "bert.encoder.layer.15.attention.output.LayerNorm.bias", "bert.encoder.layer.15.intermediate.dense.weight", "bert.encoder.layer.15.intermediate.dense.bias", "bert.encoder.layer.15.output.dense.weight", "bert.encoder.layer.15.output.dense.bias", "bert.encoder.layer.15.output.LayerNorm.weight", "bert.encoder.layer.15.output.LayerNorm.bias", "bert.encoder.layer.16.attention.self.query.weight", "bert.encoder.layer.16.attention.self.query.bias", "bert.encoder.layer.16.attention.self.key.weight", "bert.encoder.layer.16.attention.self.key.bias", "bert.encoder.layer.16.attention.self.value.weight", "bert.encoder.layer.16.attention.self.value.bias", "bert.encoder.layer.16.attention.output.dense.weight", "bert.encoder.layer.16.attention.output.dense.bias", "bert.encoder.layer.16.attention.output.LayerNorm.weight", "bert.encoder.layer.16.attention.output.LayerNorm.bias", "bert.encoder.layer.16.intermediate.dense.weight", "bert.encoder.layer.16.intermediate.dense.bias", "bert.encoder.layer.16.output.dense.weight", "bert.encoder.layer.16.output.dense.bias", "bert.encoder.layer.16.output.LayerNorm.weight", "bert.encoder.layer.16.output.LayerNorm.bias", "bert.encoder.layer.17.attention.self.query.weight", "bert.encoder.layer.17.attention.self.query.bias", "bert.encoder.layer.17.attention.self.key.weight", "bert.encoder.layer.17.attention.self.key.bias", "bert.encoder.layer.17.attention.self.value.weight", "bert.encoder.layer.17.attention.self.value.bias", "bert.encoder.layer.17.attention.output.dense.weight", "bert.encoder.layer.17.attention.output.dense.bias", "bert.encoder.layer.17.attention.output.LayerNorm.weight", "bert.encoder.layer.17.attention.output.LayerNorm.bias", "bert.encoder.layer.17.intermediate.dense.weight", "bert.encoder.layer.17.intermediate.dense.bias", "bert.encoder.layer.17.output.dense.weight", "bert.encoder.layer.17.output.dense.bias", "bert.encoder.layer.17.output.LayerNorm.weight", "bert.encoder.layer.17.output.LayerNorm.bias", "bert.encoder.layer.18.attention.self.query.weight", "bert.encoder.layer.18.attention.self.query.bias", "bert.encoder.layer.18.attention.self.key.weight", "bert.encoder.layer.18.attention.self.key.bias", "bert.encoder.layer.18.attention.self.value.weight", "bert.encoder.layer.18.attention.self.value.bias", "bert.encoder.layer.18.attention.output.dense.weight", "bert.encoder.layer.18.attention.output.dense.bias", "bert.encoder.layer.18.attention.output.LayerNorm.weight", "bert.encoder.layer.18.attention.output.LayerNorm.bias", "bert.encoder.layer.18.intermediate.dense.weight", "bert.encoder.layer.18.intermediate.dense.bias", "bert.encoder.layer.18.output.dense.weight", "bert.encoder.layer.18.output.dense.bias", "bert.encoder.layer.18.output.LayerNorm.weight", "bert.encoder.layer.18.output.LayerNorm.bias", "bert.encoder.layer.19.attention.self.query.weight", "bert.encoder.layer.19.attention.self.query.bias", "bert.encoder.layer.19.attention.self.key.weight", "bert.encoder.layer.19.attention.self.key.bias", "bert.encoder.layer.19.attention.self.value.weight", "bert.encoder.layer.19.attention.self.value.bias", "bert.encoder.layer.19.attention.output.dense.weight", "bert.encoder.layer.19.attention.output.dense.bias", "bert.encoder.layer.19.attention.output.LayerNorm.weight", "bert.encoder.layer.19.attention.output.LayerNorm.bias", "bert.encoder.layer.19.intermediate.dense.weight", "bert.encoder.layer.19.intermediate.dense.bias", "bert.encoder.layer.19.output.dense.weight", "bert.encoder.layer.19.output.dense.bias", "bert.encoder.layer.19.output.LayerNorm.weight", "bert.encoder.layer.19.output.LayerNorm.bias", "bert.encoder.layer.20.attention.self.query.weight", "bert.encoder.layer.20.attention.self.query.bias", "bert.encoder.layer.20.attention.self.key.weight", "bert.encoder.layer.20.attention.self.key.bias", "bert.encoder.layer.20.attention.self.value.weight", "bert.encoder.layer.20.attention.self.value.bias", "bert.encoder.layer.20.attention.output.dense.weight", "bert.encoder.layer.20.attention.output.dense.bias", "bert.encoder.layer.20.attention.output.LayerNorm.weight", "bert.encoder.layer.20.attention.output.LayerNorm.bias", "bert.encoder.layer.20.intermediate.dense.weight", "bert.encoder.layer.20.intermediate.dense.bias", "bert.encoder.layer.20.output.dense.weight", "bert.encoder.layer.20.output.dense.bias", "bert.encoder.layer.20.output.LayerNorm.weight", "bert.encoder.layer.20.output.LayerNorm.bias", "bert.encoder.layer.21.attention.self.query.weight", "bert.encoder.layer.21.attention.self.query.bias", "bert.encoder.layer.21.attention.self.key.weight", "bert.encoder.layer.21.attention.self.key.bias", "bert.encoder.layer.21.attention.self.value.weight", "bert.encoder.layer.21.attention.self.value.bias", "bert.encoder.layer.21.attention.output.dense.weight", "bert.encoder.layer.21.attention.output.dense.bias", "bert.encoder.layer.21.attention.output.LayerNorm.weight", "bert.encoder.layer.21.attention.output.LayerNorm.bias", "bert.encoder.layer.21.intermediate.dense.weight", "bert.encoder.layer.21.intermediate.dense.bias", "bert.encoder.layer.21.output.dense.weight", "bert.encoder.layer.21.output.dense.bias", "bert.encoder.layer.21.output.LayerNorm.weight", "bert.encoder.layer.21.output.LayerNorm.bias", "bert.encoder.layer.22.attention.self.query.weight", "bert.encoder.layer.22.attention.self.query.bias", "bert.encoder.layer.22.attention.self.key.weight", "bert.encoder.layer.22.attention.self.key.bias", "bert.encoder.layer.22.attention.self.value.weight", "bert.encoder.layer.22.attention.self.value.bias", "bert.encoder.layer.22.attention.output.dense.weight", "bert.encoder.layer.22.attention.output.dense.bias", "bert.encoder.layer.22.attention.output.LayerNorm.weight", "bert.encoder.layer.22.attention.output.LayerNorm.bias", "bert.encoder.layer.22.intermediate.dense.weight", "bert.encoder.layer.22.intermediate.dense.bias", "bert.encoder.layer.22.output.dense.weight", "bert.encoder.layer.22.output.dense.bias", "bert.encoder.layer.22.output.LayerNorm.weight", "bert.encoder.layer.22.output.LayerNorm.bias", "bert.encoder.layer.23.attention.self.query.weight", "bert.encoder.layer.23.attention.self.query.bias", "bert.encoder.layer.23.attention.self.key.weight", "bert.encoder.layer.23.attention.self.key.bias", "bert.encoder.layer.23.attention.self.value.weight", "bert.encoder.layer.23.attention.self.value.bias", "bert.encoder.layer.23.attention.output.dense.weight", "bert.encoder.layer.23.attention.output.dense.bias", "bert.encoder.layer.23.attention.output.LayerNorm.weight", "bert.encoder.layer.23.attention.output.LayerNorm.bias", "bert.encoder.layer.23.intermediate.dense.weight", "bert.encoder.layer.23.intermediate.dense.bias", "bert.encoder.layer.23.output.dense.weight", "bert.encoder.layer.23.output.dense.bias", "bert.encoder.layer.23.output.LayerNorm.weight", "bert.encoder.layer.23.output.LayerNorm.bias". 
RuntimeError: Error(s) in loading state_dict for BERTClassifier:
	Missing key(s) in state_dict: "bert.embeddings.word_embeddings.weight", "bert.embeddings.position_embeddings.weight", "bert.embeddings.token_type_embeddings.weight", "bert.embeddings.LayerNorm.weight", "bert.embeddings.LayerNorm.bias", "bert.encoder.layer.0.attention.self.query.weight", "bert.encoder.layer.0.attention.self.query.bias", "bert.encoder.layer.0.attention.self.key.weight", "bert.encoder.layer.0.attention.self.key.bias", "bert.encoder.layer.0.attention.self.value.weight", "bert.encoder.layer.0.attention.self.value.bias", "bert.encoder.layer.0.attention.output.dense.weight", "bert.encoder.layer.0.attention.output.dense.bias", "bert.encoder.layer.0.attention.output.LayerNorm.weight", "bert.encoder.layer.0.attention.output.LayerNorm.bias", "bert.encoder.layer.0.intermediate.dense.weight", "bert.encoder.layer.0.intermediate.dense.bias", "bert.encoder.layer.0.output.dense.weight", "bert.encoder.layer.0.output.dense.bias", "bert.encoder.layer.0.output.LayerNorm.weight", "bert.encoder.layer.0.output.LayerNorm.bias", "bert.encoder.layer.1.attention.self.query.weight", "bert.encoder.layer.1.attention.self.query.bias", "bert.encoder.layer.1.attention.self.key.weight", "bert.encoder.layer.1.attention.self.key.bias", "bert.encoder.layer.1.attention.self.value.weight", "bert.encoder.layer.1.attention.self.value.bias", "bert.encoder.layer.1.attention.output.dense.weight", "bert.encoder.layer.1.attention.output.dense.bias", "bert.encoder.layer.1.attention.output.LayerNorm.weight", "bert.encoder.layer.1.attention.output.LayerNorm.bias", "bert.encoder.layer.1.intermediate.dense.weight", "bert.encoder.layer.1.intermediate.dense.bias", "bert.encoder.layer.1.output.dense.weight", "bert.encoder.layer.1.output.dense.bias", "bert.encoder.layer.1.output.LayerNorm.weight", "bert.encoder.layer.1.output.LayerNorm.bias", "bert.encoder.layer.2.attention.self.query.weight", "bert.encoder.layer.2.attention.self.query.bias", "bert.encoder.layer.2.attention.self.key.weight", "bert.encoder.layer.2.attention.self.key.bias", "bert.encoder.layer.2.attention.self.value.weight", "bert.encoder.layer.2.attention.self.value.bias", "bert.encoder.layer.2.attention.output.dense.weight", "bert.encoder.layer.2.attention.output.dense.bias", "bert.encoder.layer.2.attention.output.LayerNorm.weight", "bert.encoder.layer.2.attention.output.LayerNorm.bias", "bert.encoder.layer.2.intermediate.dense.weight", "bert.encoder.layer.2.intermediate.dense.bias", "bert.encoder.layer.2.output.dense.weight", "bert.encoder.layer.2.output.dense.bias", "bert.encoder.layer.2.output.LayerNorm.weight", "bert.encoder.layer.2.output.LayerNorm.bias", "bert.encoder.layer.3.attention.self.query.weight", "bert.encoder.layer.3.attention.self.query.bias", "bert.encoder.layer.3.attention.self.key.weight", "bert.encoder.layer.3.attention.self.key.bias", "bert.encoder.layer.3.attention.self.value.weight", "bert.encoder.layer.3.attention.self.value.bias", "bert.encoder.layer.3.attention.output.dense.weight", "bert.encoder.layer.3.attention.output.dense.bias", "bert.encoder.layer.3.attention.output.LayerNorm.weight", "bert.encoder.layer.3.attention.output.LayerNorm.bias", "bert.encoder.layer.3.intermediate.dense.weight", "bert.encoder.layer.3.intermediate.dense.bias", "bert.encoder.layer.3.output.dense.weight", "bert.encoder.layer.3.output.dense.bias", "bert.encoder.layer.3.output.LayerNorm.weight", "bert.encoder.layer.3.output.LayerNorm.bias", "bert.encoder.layer.4.attention.self.query.weight", "bert.encoder.layer.4.attention.self.query.bias", "bert.encoder.layer.4.attention.self.key.weight", "bert.encoder.layer.4.attention.self.key.bias", "bert.encoder.layer.4.attention.self.value.weight", "bert.encoder.layer.4.attention.self.value.bias", "bert.encoder.layer.4.attention.output.dense.weight", "bert.encoder.layer.4.attention.output.dense.bias", "bert.encoder.layer.4.attention.output.LayerNorm.weight", "bert.encoder.layer.4.attention.output.LayerNorm.bias", "bert.encoder.layer.4.intermediate.dense.weight", "bert.encoder.layer.4.intermediate.dense.bias", "bert.encoder.layer.4.output.dense.weight", "bert.encoder.layer.4.output.dense.bias", "bert.encoder.layer.4.output.LayerNorm.weight", "bert.encoder.layer.4.output.LayerNorm.bias", "bert.encoder.layer.5.attention.self.query.weight", "bert.encoder.layer.5.attention.self.query.bias", "bert.encoder.layer.5.attention.self.key.weight", "bert.encoder.layer.5.attention.self.key.bias", "bert.encoder.layer.5.attention.self.value.weight", "bert.encoder.layer.5.attention.self.value.bias", "bert.encoder.layer.5.attention.output.dense.weight", "bert.encoder.layer.5.attention.output.dense.bias", "bert.encoder.layer.5.attention.output.LayerNorm.weight", "bert.encoder.layer.5.attention.output.LayerNorm.bias", "bert.encoder.layer.5.intermediate.dense.weight", "bert.encoder.layer.5.intermediate.dense.bias", "bert.encoder.layer.5.output.dense.weight", "bert.encoder.layer.5.output.dense.bias", "bert.encoder.layer.5.output.LayerNorm.weight", "bert.encoder.layer.5.output.LayerNorm.bias", "bert.encoder.layer.6.attention.self.query.weight", "bert.encoder.layer.6.attention.self.query.bias", "bert.encoder.layer.6.attention.self.key.weight", "bert.encoder.layer.6.attention.self.key.bias", "bert.encoder.layer.6.attention.self.value.weight", "bert.encoder.layer.6.attention.self.value.bias", "bert.encoder.layer.6.attention.output.dense.weight", "bert.encoder.layer.6.attention.output.dense.bias", "bert.encoder.layer.6.attention.output.LayerNorm.weight", "bert.encoder.layer.6.attention.output.LayerNorm.bias", "bert.encoder.layer.6.intermediate.dense.weight", "bert.encoder.layer.6.intermediate.dense.bias", "bert.encoder.layer.6.output.dense.weight", "bert.encoder.layer.6.output.dense.bias", "bert.encoder.layer.6.output.LayerNorm.weight", "bert.encoder.layer.6.output.LayerNorm.bias", "bert.encoder.layer.7.attention.self.query.weight", "bert.encoder.layer.7.attention.self.query.bias", "bert.encoder.layer.7.attention.self.key.weight", "bert.encoder.layer.7.attention.self.key.bias", "bert.encoder.layer.7.attention.self.value.weight", "bert.encoder.layer.7.attention.self.value.bias", "bert.encoder.layer.7.attention.output.dense.weight", "bert.encoder.layer.7.attention.output.dense.bias", "bert.encoder.layer.7.attention.output.LayerNorm.weight", "bert.encoder.layer.7.attention.output.LayerNorm.bias", "bert.encoder.layer.7.intermediate.dense.weight", "bert.encoder.layer.7.intermediate.dense.bias", "bert.encoder.layer.7.output.dense.weight", "bert.encoder.layer.7.output.dense.bias", "bert.encoder.layer.7.output.LayerNorm.weight", "bert.encoder.layer.7.output.LayerNorm.bias", "bert.encoder.layer.8.attention.self.query.weight", "bert.encoder.layer.8.attention.self.query.bias", "bert.encoder.layer.8.attention.self.key.weight", "bert.encoder.layer.8.attention.self.key.bias", "bert.encoder.layer.8.attention.self.value.weight", "bert.encoder.layer.8.attention.self.value.bias", "bert.encoder.layer.8.attention.output.dense.weight", "bert.encoder.layer.8.attention.output.dense.bias", "bert.encoder.layer.8.attention.output.LayerNorm.weight", "bert.encoder.layer.8.attention.output.LayerNorm.bias", "bert.encoder.layer.8.intermediate.dense.weight", "bert.encoder.layer.8.intermediate.dense.bias", "bert.encoder.layer.8.output.dense.weight", "bert.encoder.layer.8.output.dense.bias", "bert.encoder.layer.8.output.LayerNorm.weight", "bert.encoder.layer.8.output.LayerNorm.bias", "bert.encoder.layer.9.attention.self.query.weight", "bert.encoder.layer.9.attention.self.query.bias", "bert.encoder.layer.9.attention.self.key.weight", "bert.encoder.layer.9.attention.self.key.bias", "bert.encoder.layer.9.attention.self.value.weight", "bert.encoder.layer.9.attention.self.value.bias", "bert.encoder.layer.9.attention.output.dense.weight", "bert.encoder.layer.9.attention.output.dense.bias", "bert.encoder.layer.9.attention.output.LayerNorm.weight", "bert.encoder.layer.9.attention.output.LayerNorm.bias", "bert.encoder.layer.9.intermediate.dense.weight", "bert.encoder.layer.9.intermediate.dense.bias", "bert.encoder.layer.9.output.dense.weight", "bert.encoder.layer.9.output.dense.bias", "bert.encoder.layer.9.output.LayerNorm.weight", "bert.encoder.layer.9.output.LayerNorm.bias", "bert.encoder.layer.10.attention.self.query.weight", "bert.encoder.layer.10.attention.self.query.bias", "bert.encoder.layer.10.attention.self.key.weight", "bert.encoder.layer.10.attention.self.key.bias", "bert.encoder.layer.10.attention.self.value.weight", "bert.encoder.layer.10.attention.self.value.bias", "bert.encoder.layer.10.attention.output.dense.weight", "bert.encoder.layer.10.attention.output.dense.bias", "bert.encoder.layer.10.attention.output.LayerNorm.weight", "bert.encoder.layer.10.attention.output.LayerNorm.bias", "bert.encoder.layer.10.intermediate.dense.weight", "bert.encoder.layer.10.intermediate.dense.bias", "bert.encoder.layer.10.output.dense.weight", "bert.encoder.layer.10.output.dense.bias", "bert.encoder.layer.10.output.LayerNorm.weight", "bert.encoder.layer.10.output.LayerNorm.bias", "bert.encoder.layer.11.attention.self.query.weight", "bert.encoder.layer.11.attention.self.query.bias", "bert.encoder.layer.11.attention.self.key.weight", "bert.encoder.layer.11.attention.self.key.bias", "bert.encoder.layer.11.attention.self.value.weight", "bert.encoder.layer.11.attention.self.value.bias", "bert.encoder.layer.11.attention.output.dense.weight", "bert.encoder.layer.11.attention.output.dense.bias", "bert.encoder.layer.11.attention.output.LayerNorm.weight", "bert.encoder.layer.11.attention.output.LayerNorm.bias", "bert.encoder.layer.11.intermediate.dense.weight", "bert.encoder.layer.11.intermediate.dense.bias", "bert.encoder.layer.11.output.dense.weight", "bert.encoder.layer.11.output.dense.bias", "bert.encoder.layer.11.output.LayerNorm.weight", "bert.encoder.layer.11.output.LayerNorm.bias", "bert.encoder.layer.12.attention.self.query.weight", "bert.encoder.layer.12.attention.self.query.bias", "bert.encoder.layer.12.attention.self.key.weight", "bert.encoder.layer.12.attention.self.key.bias", "bert.encoder.layer.12.attention.self.value.weight", "bert.encoder.layer.12.attention.self.value.bias", "bert.encoder.layer.12.attention.output.dense.weight", "bert.encoder.layer.12.attention.output.dense.bias", "bert.encoder.layer.12.attention.output.LayerNorm.weight", "bert.encoder.layer.12.attention.output.LayerNorm.bias", "bert.encoder.layer.12.intermediate.dense.weight", "bert.encoder.layer.12.intermediate.dense.bias", "bert.encoder.layer.12.output.dense.weight", "bert.encoder.layer.12.output.dense.bias", "bert.encoder.layer.12.output.LayerNorm.weight", "bert.encoder.layer.12.output.LayerNorm.bias", "bert.encoder.layer.13.attention.self.query.weight", "bert.encoder.layer.13.attention.self.query.bias", "bert.encoder.layer.13.attention.self.key.weight", "bert.encoder.layer.13.attention.self.key.bias", "bert.encoder.layer.13.attention.self.value.weight", "bert.encoder.layer.13.attention.self.value.bias", "bert.encoder.layer.13.attention.output.dense.weight", "bert.encoder.layer.13.attention.output.dense.bias", "bert.encoder.layer.13.attention.output.LayerNorm.weight", "bert.encoder.layer.13.attention.output.LayerNorm.bias", "bert.encoder.layer.13.intermediate.dense.weight", "bert.encoder.layer.13.intermediate.dense.bias", "bert.encoder.layer.13.output.dense.weight", "bert.encoder.layer.13.output.dense.bias", "bert.encoder.layer.13.output.LayerNorm.weight", "bert.encoder.layer.13.output.LayerNorm.bias", "bert.encoder.layer.14.attention.self.query.weight", "bert.encoder.layer.14.attention.self.query.bias", "bert.encoder.layer.14.attention.self.key.weight", "bert.encoder.layer.14.attention.self.key.bias", "bert.encoder.layer.14.attention.self.value.weight", "bert.encoder.layer.14.attention.self.value.bias", "bert.encoder.layer.14.attention.output.dense.weight", "bert.encoder.layer.14.attention.output.dense.bias", "bert.encoder.layer.14.attention.output.LayerNorm.weight", "bert.encoder.layer.14.attention.output.LayerNorm.bias", "bert.encoder.layer.14.intermediate.dense.weight", "bert.encoder.layer.14.intermediate.dense.bias", "bert.encoder.layer.14.output.dense.weight", "bert.encoder.layer.14.output.dense.bias", "bert.encoder.layer.14.output.LayerNorm.weight", "bert.encoder.layer.14.output.LayerNorm.bias", "bert.encoder.layer.15.attention.self.query.weight", "bert.encoder.layer.15.attention.self.query.bias", "bert.encoder.layer.15.attention.self.key.weight", "bert.encoder.layer.15.attention.self.key.bias", "bert.encoder.layer.15.attention.self.value.weight", "bert.encoder.layer.15.attention.self.value.bias", "bert.encoder.layer.15.attention.output.dense.weight", "bert.encoder.layer.15.attention.output.dense.bias", "bert.encoder.layer.15.attention.output.LayerNorm.weight", "bert.encoder.layer.15.attention.output.LayerNorm.bias", "bert.encoder.layer.15.intermediate.dense.weight", "bert.encoder.layer.15.intermediate.dense.bias", "bert.encoder.layer.15.output.dense.weight", "bert.encoder.layer.15.output.dense.bias", "bert.encoder.layer.15.output.LayerNorm.weight", "bert.encoder.layer.15.output.LayerNorm.bias", "bert.encoder.layer.16.attention.self.query.weight", "bert.encoder.layer.16.attention.self.query.bias", "bert.encoder.layer.16.attention.self.key.weight", "bert.encoder.layer.16.attention.self.key.bias", "bert.encoder.layer.16.attention.self.value.weight", "bert.encoder.layer.16.attention.self.value.bias", "bert.encoder.layer.16.attention.output.dense.weight", "bert.encoder.layer.16.attention.output.dense.bias", "bert.encoder.layer.16.attention.output.LayerNorm.weight", "bert.encoder.layer.16.attention.output.LayerNorm.bias", "bert.encoder.layer.16.intermediate.dense.weight", "bert.encoder.layer.16.intermediate.dense.bias", "bert.encoder.layer.16.output.dense.weight", "bert.encoder.layer.16.output.dense.bias", "bert.encoder.layer.16.output.LayerNorm.weight", "bert.encoder.layer.16.output.LayerNorm.bias", "bert.encoder.layer.17.attention.self.query.weight", "bert.encoder.layer.17.attention.self.query.bias", "bert.encoder.layer.17.attention.self.key.weight", "bert.encoder.layer.17.attention.self.key.bias", "bert.encoder.layer.17.attention.self.value.weight", "bert.encoder.layer.17.attention.self.value.bias", "bert.encoder.layer.17.attention.output.dense.weight", "bert.encoder.layer.17.attention.output.dense.bias", "bert.encoder.layer.17.attention.output.LayerNorm.weight", "bert.encoder.layer.17.attention.output.LayerNorm.bias", "bert.encoder.layer.17.intermediate.dense.weight", "bert.encoder.layer.17.intermediate.dense.bias", "bert.encoder.layer.17.output.dense.weight", "bert.encoder.layer.17.output.dense.bias", "bert.encoder.layer.17.output.LayerNorm.weight", "bert.encoder.layer.17.output.LayerNorm.bias", "bert.encoder.layer.18.attention.self.query.weight", "bert.encoder.layer.18.attention.self.query.bias", "bert.encoder.layer.18.attention.self.key.weight", "bert.encoder.layer.18.attention.self.key.bias", "bert.encoder.layer.18.attention.self.value.weight", "bert.encoder.layer.18.attention.self.value.bias", "bert.encoder.layer.18.attention.output.dense.weight", "bert.encoder.layer.18.attention.output.dense.bias", "bert.encoder.layer.18.attention.output.LayerNorm.weight", "bert.encoder.layer.18.attention.output.LayerNorm.bias", "bert.encoder.layer.18.intermediate.dense.weight", "bert.encoder.layer.18.intermediate.dense.bias", "bert.encoder.layer.18.output.dense.weight", "bert.encoder.layer.18.output.dense.bias", "bert.encoder.layer.18.output.LayerNorm.weight", "bert.encoder.layer.18.output.LayerNorm.bias", "bert.encoder.layer.19.attention.self.query.weight", "bert.encoder.layer.19.attention.self.query.bias", "bert.encoder.layer.19.attention.self.key.weight", "bert.encoder.layer.19.attention.self.key.bias", "bert.encoder.layer.19.attention.self.value.weight", "bert.encoder.layer.19.attention.self.value.bias", "bert.encoder.layer.19.attention.output.dense.weight", "bert.encoder.layer.19.attention.output.dense.bias", "bert.encoder.layer.19.attention.output.LayerNorm.weight", "bert.encoder.layer.19.attention.output.LayerNorm.bias", "bert.encoder.layer.19.intermediate.dense.weight", "bert.encoder.layer.19.intermediate.dense.bias", "bert.encoder.layer.19.output.dense.weight", "bert.encoder.layer.19.output.dense.bias", "bert.encoder.layer.19.output.LayerNorm.weight", "bert.encoder.layer.19.output.LayerNorm.bias", "bert.encoder.layer.20.attention.self.query.weight", "bert.encoder.layer.20.attention.self.query.bias", "bert.encoder.layer.20.attention.self.key.weight", "bert.encoder.layer.20.attention.self.key.bias", "bert.encoder.layer.20.attention.self.value.weight", "bert.encoder.layer.20.attention.self.value.bias", "bert.encoder.layer.20.attention.output.dense.weight", "bert.encoder.layer.20.attention.output.dense.bias", "bert.encoder.layer.20.attention.output.LayerNorm.weight", "bert.encoder.layer.20.attention.output.LayerNorm.bias", "bert.encoder.layer.20.intermediate.dense.weight", "bert.encoder.layer.20.intermediate.dense.bias", "bert.encoder.layer.20.output.dense.weight", "bert.encoder.layer.20.output.dense.bias", "bert.encoder.layer.20.output.LayerNorm.weight", "bert.encoder.layer.20.output.LayerNorm.bias", "bert.encoder.layer.21.attention.self.query.weight", "bert.encoder.layer.21.attention.self.query.bias", "bert.encoder.layer.21.attention.self.key.weight", "bert.encoder.layer.21.attention.self.key.bias", "bert.encoder.layer.21.attention.self.value.weight", "bert.encoder.layer.21.attention.self.value.bias", "bert.encoder.layer.21.attention.output.dense.weight", "bert.encoder.layer.21.attention.output.dense.bias", "bert.encoder.layer.21.attention.output.LayerNorm.weight", "bert.encoder.layer.21.attention.output.LayerNorm.bias", "bert.encoder.layer.21.intermediate.dense.weight", "bert.encoder.layer.21.intermediate.dense.bias", "bert.encoder.layer.21.output.dense.weight", "bert.encoder.layer.21.output.dense.bias", "bert.encoder.layer.21.output.LayerNorm.weight", "bert.encoder.layer.21.output.LayerNorm.bias", "bert.encoder.layer.22.attention.self.query.weight", "bert.encoder.layer.22.attention.self.query.bias", "bert.encoder.layer.22.attention.self.key.weight", "bert.encoder.layer.22.attention.self.key.bias", "bert.encoder.layer.22.attention.self.value.weight", "bert.encoder.layer.22.attention.self.value.bias", "bert.encoder.layer.22.attention.output.dense.weight", "bert.encoder.layer.22.attention.output.dense.bias", "bert.encoder.layer.22.attention.output.LayerNorm.weight", "bert.encoder.layer.22.attention.output.LayerNorm.bias", "bert.encoder.layer.22.intermediate.dense.weight", "bert.encoder.layer.22.intermediate.dense.bias", "bert.encoder.layer.22.output.dense.weight", "bert.encoder.layer.22.output.dense.bias", "bert.encoder.layer.22.output.LayerNorm.weight", "bert.encoder.layer.22.output.LayerNorm.bias", "bert.encoder.layer.23.attention.self.query.weight", "bert.encoder.layer.23.attention.self.query.bias", "bert.encoder.layer.23.attention.self.key.weight", "bert.encoder.layer.23.attention.self.key.bias", "bert.encoder.layer.23.attention.self.value.weight", "bert.encoder.layer.23.attention.self.value.bias", "bert.encoder.layer.23.attention.output.dense.weight", "bert.encoder.layer.23.attention.output.dense.bias", "bert.encoder.layer.23.attention.output.LayerNorm.weight", "bert.encoder.layer.23.attention.output.LayerNorm.bias", "bert.encoder.layer.23.intermediate.dense.weight", "bert.encoder.layer.23.intermediate.dense.bias", "bert.encoder.layer.23.output.dense.weight", "bert.encoder.layer.23.output.dense.bias", "bert.encoder.layer.23.output.LayerNorm.weight", "bert.encoder.layer.23.output.LayerNorm.bias". 
RuntimeError: Error(s) in loading state_dict for BERTClassifier:
	Missing key(s) in state_dict: "bert.embeddings.word_embeddings.weight", "bert.embeddings.position_embeddings.weight", "bert.embeddings.token_type_embeddings.weight", "bert.embeddings.LayerNorm.weight", "bert.embeddings.LayerNorm.bias", "bert.encoder.layer.0.attention.self.query.weight", "bert.encoder.layer.0.attention.self.query.bias", "bert.encoder.layer.0.attention.self.key.weight", "bert.encoder.layer.0.attention.self.key.bias", "bert.encoder.layer.0.attention.self.value.weight", "bert.encoder.layer.0.attention.self.value.bias", "bert.encoder.layer.0.attention.output.dense.weight", "bert.encoder.layer.0.attention.output.dense.bias", "bert.encoder.layer.0.attention.output.LayerNorm.weight", "bert.encoder.layer.0.attention.output.LayerNorm.bias", "bert.encoder.layer.0.intermediate.dense.weight", "bert.encoder.layer.0.intermediate.dense.bias", "bert.encoder.layer.0.output.dense.weight", "bert.encoder.layer.0.output.dense.bias", "bert.encoder.layer.0.output.LayerNorm.weight", "bert.encoder.layer.0.output.LayerNorm.bias", "bert.encoder.layer.1.attention.self.query.weight", "bert.encoder.layer.1.attention.self.query.bias", "bert.encoder.layer.1.attention.self.key.weight", "bert.encoder.layer.1.attention.self.key.bias", "bert.encoder.layer.1.attention.self.value.weight", "bert.encoder.layer.1.attention.self.value.bias", "bert.encoder.layer.1.attention.output.dense.weight", "bert.encoder.layer.1.attention.output.dense.bias", "bert.encoder.layer.1.attention.output.LayerNorm.weight", "bert.encoder.layer.1.attention.output.LayerNorm.bias", "bert.encoder.layer.1.intermediate.dense.weight", "bert.encoder.layer.1.intermediate.dense.bias", "bert.encoder.layer.1.output.dense.weight", "bert.encoder.layer.1.output.dense.bias", "bert.encoder.layer.1.output.LayerNorm.weight", "bert.encoder.layer.1.output.LayerNorm.bias", "bert.encoder.layer.2.attention.self.query.weight", "bert.encoder.layer.2.attention.self.query.bias", "bert.encoder.layer.2.attention.self.key.weight", "bert.encoder.layer.2.attention.self.key.bias", "bert.encoder.layer.2.attention.self.value.weight", "bert.encoder.layer.2.attention.self.value.bias", "bert.encoder.layer.2.attention.output.dense.weight", "bert.encoder.layer.2.attention.output.dense.bias", "bert.encoder.layer.2.attention.output.LayerNorm.weight", "bert.encoder.layer.2.attention.output.LayerNorm.bias", "bert.encoder.layer.2.intermediate.dense.weight", "bert.encoder.layer.2.intermediate.dense.bias", "bert.encoder.layer.2.output.dense.weight", "bert.encoder.layer.2.output.dense.bias", "bert.encoder.layer.2.output.LayerNorm.weight", "bert.encoder.layer.2.output.LayerNorm.bias", "bert.encoder.layer.3.attention.self.query.weight", "bert.encoder.layer.3.attention.self.query.bias", "bert.encoder.layer.3.attention.self.key.weight", "bert.encoder.layer.3.attention.self.key.bias", "bert.encoder.layer.3.attention.self.value.weight", "bert.encoder.layer.3.attention.self.value.bias", "bert.encoder.layer.3.attention.output.dense.weight", "bert.encoder.layer.3.attention.output.dense.bias", "bert.encoder.layer.3.attention.output.LayerNorm.weight", "bert.encoder.layer.3.attention.output.LayerNorm.bias", "bert.encoder.layer.3.intermediate.dense.weight", "bert.encoder.layer.3.intermediate.dense.bias", "bert.encoder.layer.3.output.dense.weight", "bert.encoder.layer.3.output.dense.bias", "bert.encoder.layer.3.output.LayerNorm.weight", "bert.encoder.layer.3.output.LayerNorm.bias", "bert.encoder.layer.4.attention.self.query.weight", "bert.encoder.layer.4.attention.self.query.bias", "bert.encoder.layer.4.attention.self.key.weight", "bert.encoder.layer.4.attention.self.key.bias", "bert.encoder.layer.4.attention.self.value.weight", "bert.encoder.layer.4.attention.self.value.bias", "bert.encoder.layer.4.attention.output.dense.weight", "bert.encoder.layer.4.attention.output.dense.bias", "bert.encoder.layer.4.attention.output.LayerNorm.weight", "bert.encoder.layer.4.attention.output.LayerNorm.bias", "bert.encoder.layer.4.intermediate.dense.weight", "bert.encoder.layer.4.intermediate.dense.bias", "bert.encoder.layer.4.output.dense.weight", "bert.encoder.layer.4.output.dense.bias", "bert.encoder.layer.4.output.LayerNorm.weight", "bert.encoder.layer.4.output.LayerNorm.bias", "bert.encoder.layer.5.attention.self.query.weight", "bert.encoder.layer.5.attention.self.query.bias", "bert.encoder.layer.5.attention.self.key.weight", "bert.encoder.layer.5.attention.self.key.bias", "bert.encoder.layer.5.attention.self.value.weight", "bert.encoder.layer.5.attention.self.value.bias", "bert.encoder.layer.5.attention.output.dense.weight", "bert.encoder.layer.5.attention.output.dense.bias", "bert.encoder.layer.5.attention.output.LayerNorm.weight", "bert.encoder.layer.5.attention.output.LayerNorm.bias", "bert.encoder.layer.5.intermediate.dense.weight", "bert.encoder.layer.5.intermediate.dense.bias", "bert.encoder.layer.5.output.dense.weight", "bert.encoder.layer.5.output.dense.bias", "bert.encoder.layer.5.output.LayerNorm.weight", "bert.encoder.layer.5.output.LayerNorm.bias", "bert.encoder.layer.6.attention.self.query.weight", "bert.encoder.layer.6.attention.self.query.bias", "bert.encoder.layer.6.attention.self.key.weight", "bert.encoder.layer.6.attention.self.key.bias", "bert.encoder.layer.6.attention.self.value.weight", "bert.encoder.layer.6.attention.self.value.bias", "bert.encoder.layer.6.attention.output.dense.weight", "bert.encoder.layer.6.attention.output.dense.bias", "bert.encoder.layer.6.attention.output.LayerNorm.weight", "bert.encoder.layer.6.attention.output.LayerNorm.bias", "bert.encoder.layer.6.intermediate.dense.weight", "bert.encoder.layer.6.intermediate.dense.bias", "bert.encoder.layer.6.output.dense.weight", "bert.encoder.layer.6.output.dense.bias", "bert.encoder.layer.6.output.LayerNorm.weight", "bert.encoder.layer.6.output.LayerNorm.bias", "bert.encoder.layer.7.attention.self.query.weight", "bert.encoder.layer.7.attention.self.query.bias", "bert.encoder.layer.7.attention.self.key.weight", "bert.encoder.layer.7.attention.self.key.bias", "bert.encoder.layer.7.attention.self.value.weight", "bert.encoder.layer.7.attention.self.value.bias", "bert.encoder.layer.7.attention.output.dense.weight", "bert.encoder.layer.7.attention.output.dense.bias", "bert.encoder.layer.7.attention.output.LayerNorm.weight", "bert.encoder.layer.7.attention.output.LayerNorm.bias", "bert.encoder.layer.7.intermediate.dense.weight", "bert.encoder.layer.7.intermediate.dense.bias", "bert.encoder.layer.7.output.dense.weight", "bert.encoder.layer.7.output.dense.bias", "bert.encoder.layer.7.output.LayerNorm.weight", "bert.encoder.layer.7.output.LayerNorm.bias", "bert.encoder.layer.8.attention.self.query.weight", "bert.encoder.layer.8.attention.self.query.bias", "bert.encoder.layer.8.attention.self.key.weight", "bert.encoder.layer.8.attention.self.key.bias", "bert.encoder.layer.8.attention.self.value.weight", "bert.encoder.layer.8.attention.self.value.bias", "bert.encoder.layer.8.attention.output.dense.weight", "bert.encoder.layer.8.attention.output.dense.bias", "bert.encoder.layer.8.attention.output.LayerNorm.weight", "bert.encoder.layer.8.attention.output.LayerNorm.bias", "bert.encoder.layer.8.intermediate.dense.weight", "bert.encoder.layer.8.intermediate.dense.bias", "bert.encoder.layer.8.output.dense.weight", "bert.encoder.layer.8.output.dense.bias", "bert.encoder.layer.8.output.LayerNorm.weight", "bert.encoder.layer.8.output.LayerNorm.bias", "bert.encoder.layer.9.attention.self.query.weight", "bert.encoder.layer.9.attention.self.query.bias", "bert.encoder.layer.9.attention.self.key.weight", "bert.encoder.layer.9.attention.self.key.bias", "bert.encoder.layer.9.attention.self.value.weight", "bert.encoder.layer.9.attention.self.value.bias", "bert.encoder.layer.9.attention.output.dense.weight", "bert.encoder.layer.9.attention.output.dense.bias", "bert.encoder.layer.9.attention.output.LayerNorm.weight", "bert.encoder.layer.9.attention.output.LayerNorm.bias", "bert.encoder.layer.9.intermediate.dense.weight", "bert.encoder.layer.9.intermediate.dense.bias", "bert.encoder.layer.9.output.dense.weight", "bert.encoder.layer.9.output.dense.bias", "bert.encoder.layer.9.output.LayerNorm.weight", "bert.encoder.layer.9.output.LayerNorm.bias", "bert.encoder.layer.10.attention.self.query.weight", "bert.encoder.layer.10.attention.self.query.bias", "bert.encoder.layer.10.attention.self.key.weight", "bert.encoder.layer.10.attention.self.key.bias", "bert.encoder.layer.10.attention.self.value.weight", "bert.encoder.layer.10.attention.self.value.bias", "bert.encoder.layer.10.attention.output.dense.weight", "bert.encoder.layer.10.attention.output.dense.bias", "bert.encoder.layer.10.attention.output.LayerNorm.weight", "bert.encoder.layer.10.attention.output.LayerNorm.bias", "bert.encoder.layer.10.intermediate.dense.weight", "bert.encoder.layer.10.intermediate.dense.bias", "bert.encoder.layer.10.output.dense.weight", "bert.encoder.layer.10.output.dense.bias", "bert.encoder.layer.10.output.LayerNorm.weight", "bert.encoder.layer.10.output.LayerNorm.bias", "bert.encoder.layer.11.attention.self.query.weight", "bert.encoder.layer.11.attention.self.query.bias", "bert.encoder.layer.11.attention.self.key.weight", "bert.encoder.layer.11.attention.self.key.bias", "bert.encoder.layer.11.attention.self.value.weight", "bert.encoder.layer.11.attention.self.value.bias", "bert.encoder.layer.11.attention.output.dense.weight", "bert.encoder.layer.11.attention.output.dense.bias", "bert.encoder.layer.11.attention.output.LayerNorm.weight", "bert.encoder.layer.11.attention.output.LayerNorm.bias", "bert.encoder.layer.11.intermediate.dense.weight", "bert.encoder.layer.11.intermediate.dense.bias", "bert.encoder.layer.11.output.dense.weight", "bert.encoder.layer.11.output.dense.bias", "bert.encoder.layer.11.output.LayerNorm.weight", "bert.encoder.layer.11.output.LayerNorm.bias", "bert.encoder.layer.12.attention.self.query.weight", "bert.encoder.layer.12.attention.self.query.bias", "bert.encoder.layer.12.attention.self.key.weight", "bert.encoder.layer.12.attention.self.key.bias", "bert.encoder.layer.12.attention.self.value.weight", "bert.encoder.layer.12.attention.self.value.bias", "bert.encoder.layer.12.attention.output.dense.weight", "bert.encoder.layer.12.attention.output.dense.bias", "bert.encoder.layer.12.attention.output.LayerNorm.weight", "bert.encoder.layer.12.attention.output.LayerNorm.bias", "bert.encoder.layer.12.intermediate.dense.weight", "bert.encoder.layer.12.intermediate.dense.bias", "bert.encoder.layer.12.output.dense.weight", "bert.encoder.layer.12.output.dense.bias", "bert.encoder.layer.12.output.LayerNorm.weight", "bert.encoder.layer.12.output.LayerNorm.bias", "bert.encoder.layer.13.attention.self.query.weight", "bert.encoder.layer.13.attention.self.query.bias", "bert.encoder.layer.13.attention.self.key.weight", "bert.encoder.layer.13.attention.self.key.bias", "bert.encoder.layer.13.attention.self.value.weight", "bert.encoder.layer.13.attention.self.value.bias", "bert.encoder.layer.13.attention.output.dense.weight", "bert.encoder.layer.13.attention.output.dense.bias", "bert.encoder.layer.13.attention.output.LayerNorm.weight", "bert.encoder.layer.13.attention.output.LayerNorm.bias", "bert.encoder.layer.13.intermediate.dense.weight", "bert.encoder.layer.13.intermediate.dense.bias", "bert.encoder.layer.13.output.dense.weight", "bert.encoder.layer.13.output.dense.bias", "bert.encoder.layer.13.output.LayerNorm.weight", "bert.encoder.layer.13.output.LayerNorm.bias", "bert.encoder.layer.14.attention.self.query.weight", "bert.encoder.layer.14.attention.self.query.bias", "bert.encoder.layer.14.attention.self.key.weight", "bert.encoder.layer.14.attention.self.key.bias", "bert.encoder.layer.14.attention.self.value.weight", "bert.encoder.layer.14.attention.self.value.bias", "bert.encoder.layer.14.attention.output.dense.weight", "bert.encoder.layer.14.attention.output.dense.bias", "bert.encoder.layer.14.attention.output.LayerNorm.weight", "bert.encoder.layer.14.attention.output.LayerNorm.bias", "bert.encoder.layer.14.intermediate.dense.weight", "bert.encoder.layer.14.intermediate.dense.bias", "bert.encoder.layer.14.output.dense.weight", "bert.encoder.layer.14.output.dense.bias", "bert.encoder.layer.14.output.LayerNorm.weight", "bert.encoder.layer.14.output.LayerNorm.bias", "bert.encoder.layer.15.attention.self.query.weight", "bert.encoder.layer.15.attention.self.query.bias", "bert.encoder.layer.15.attention.self.key.weight", "bert.encoder.layer.15.attention.self.key.bias", "bert.encoder.layer.15.attention.self.value.weight", "bert.encoder.layer.15.attention.self.value.bias", "bert.encoder.layer.15.attention.output.dense.weight", "bert.encoder.layer.15.attention.output.dense.bias", "bert.encoder.layer.15.attention.output.LayerNorm.weight", "bert.encoder.layer.15.attention.output.LayerNorm.bias", "bert.encoder.layer.15.intermediate.dense.weight", "bert.encoder.layer.15.intermediate.dense.bias", "bert.encoder.layer.15.output.dense.weight", "bert.encoder.layer.15.output.dense.bias", "bert.encoder.layer.15.output.LayerNorm.weight", "bert.encoder.layer.15.output.LayerNorm.bias", "bert.encoder.layer.16.attention.self.query.weight", "bert.encoder.layer.16.attention.self.query.bias", "bert.encoder.layer.16.attention.self.key.weight", "bert.encoder.layer.16.attention.self.key.bias", "bert.encoder.layer.16.attention.self.value.weight", "bert.encoder.layer.16.attention.self.value.bias", "bert.encoder.layer.16.attention.output.dense.weight", "bert.encoder.layer.16.attention.output.dense.bias", "bert.encoder.layer.16.attention.output.LayerNorm.weight", "bert.encoder.layer.16.attention.output.LayerNorm.bias", "bert.encoder.layer.16.intermediate.dense.weight", "bert.encoder.layer.16.intermediate.dense.bias", "bert.encoder.layer.16.output.dense.weight", "bert.encoder.layer.16.output.dense.bias", "bert.encoder.layer.16.output.LayerNorm.weight", "bert.encoder.layer.16.output.LayerNorm.bias", "bert.encoder.layer.17.attention.self.query.weight", "bert.encoder.layer.17.attention.self.query.bias", "bert.encoder.layer.17.attention.self.key.weight", "bert.encoder.layer.17.attention.self.key.bias", "bert.encoder.layer.17.attention.self.value.weight", "bert.encoder.layer.17.attention.self.value.bias", "bert.encoder.layer.17.attention.output.dense.weight", "bert.encoder.layer.17.attention.output.dense.bias", "bert.encoder.layer.17.attention.output.LayerNorm.weight", "bert.encoder.layer.17.attention.output.LayerNorm.bias", "bert.encoder.layer.17.intermediate.dense.weight", "bert.encoder.layer.17.intermediate.dense.bias", "bert.encoder.layer.17.output.dense.weight", "bert.encoder.layer.17.output.dense.bias", "bert.encoder.layer.17.output.LayerNorm.weight", "bert.encoder.layer.17.output.LayerNorm.bias", "bert.encoder.layer.18.attention.self.query.weight", "bert.encoder.layer.18.attention.self.query.bias", "bert.encoder.layer.18.attention.self.key.weight", "bert.encoder.layer.18.attention.self.key.bias", "bert.encoder.layer.18.attention.self.value.weight", "bert.encoder.layer.18.attention.self.value.bias", "bert.encoder.layer.18.attention.output.dense.weight", "bert.encoder.layer.18.attention.output.dense.bias", "bert.encoder.layer.18.attention.output.LayerNorm.weight", "bert.encoder.layer.18.attention.output.LayerNorm.bias", "bert.encoder.layer.18.intermediate.dense.weight", "bert.encoder.layer.18.intermediate.dense.bias", "bert.encoder.layer.18.output.dense.weight", "bert.encoder.layer.18.output.dense.bias", "bert.encoder.layer.18.output.LayerNorm.weight", "bert.encoder.layer.18.output.LayerNorm.bias", "bert.encoder.layer.19.attention.self.query.weight", "bert.encoder.layer.19.attention.self.query.bias", "bert.encoder.layer.19.attention.self.key.weight", "bert.encoder.layer.19.attention.self.key.bias", "bert.encoder.layer.19.attention.self.value.weight", "bert.encoder.layer.19.attention.self.value.bias", "bert.encoder.layer.19.attention.output.dense.weight", "bert.encoder.layer.19.attention.output.dense.bias", "bert.encoder.layer.19.attention.output.LayerNorm.weight", "bert.encoder.layer.19.attention.output.LayerNorm.bias", "bert.encoder.layer.19.intermediate.dense.weight", "bert.encoder.layer.19.intermediate.dense.bias", "bert.encoder.layer.19.output.dense.weight", "bert.encoder.layer.19.output.dense.bias", "bert.encoder.layer.19.output.LayerNorm.weight", "bert.encoder.layer.19.output.LayerNorm.bias", "bert.encoder.layer.20.attention.self.query.weight", "bert.encoder.layer.20.attention.self.query.bias", "bert.encoder.layer.20.attention.self.key.weight", "bert.encoder.layer.20.attention.self.key.bias", "bert.encoder.layer.20.attention.self.value.weight", "bert.encoder.layer.20.attention.self.value.bias", "bert.encoder.layer.20.attention.output.dense.weight", "bert.encoder.layer.20.attention.output.dense.bias", "bert.encoder.layer.20.attention.output.LayerNorm.weight", "bert.encoder.layer.20.attention.output.LayerNorm.bias", "bert.encoder.layer.20.intermediate.dense.weight", "bert.encoder.layer.20.intermediate.dense.bias", "bert.encoder.layer.20.output.dense.weight", "bert.encoder.layer.20.output.dense.bias", "bert.encoder.layer.20.output.LayerNorm.weight", "bert.encoder.layer.20.output.LayerNorm.bias", "bert.encoder.layer.21.attention.self.query.weight", "bert.encoder.layer.21.attention.self.query.bias", "bert.encoder.layer.21.attention.self.key.weight", "bert.encoder.layer.21.attention.self.key.bias", "bert.encoder.layer.21.attention.self.value.weight", "bert.encoder.layer.21.attention.self.value.bias", "bert.encoder.layer.21.attention.output.dense.weight", "bert.encoder.layer.21.attention.output.dense.bias", "bert.encoder.layer.21.attention.output.LayerNorm.weight", "bert.encoder.layer.21.attention.output.LayerNorm.bias", "bert.encoder.layer.21.intermediate.dense.weight", "bert.encoder.layer.21.intermediate.dense.bias", "bert.encoder.layer.21.output.dense.weight", "bert.encoder.layer.21.output.dense.bias", "bert.encoder.layer.21.output.LayerNorm.weight", "bert.encoder.layer.21.output.LayerNorm.bias", "bert.encoder.layer.22.attention.self.query.weight", "bert.encoder.layer.22.attention.self.query.bias", "bert.encoder.layer.22.attention.self.key.weight", "bert.encoder.layer.22.attention.self.key.bias", "bert.encoder.layer.22.attention.self.value.weight", "bert.encoder.layer.22.attention.self.value.bias", "bert.encoder.layer.22.attention.output.dense.weight", "bert.encoder.layer.22.attention.output.dense.bias", "bert.encoder.layer.22.attention.output.LayerNorm.weight", "bert.encoder.layer.22.attention.output.LayerNorm.bias", "bert.encoder.layer.22.intermediate.dense.weight", "bert.encoder.layer.22.intermediate.dense.bias", "bert.encoder.layer.22.output.dense.weight", "bert.encoder.layer.22.output.dense.bias", "bert.encoder.layer.22.output.LayerNorm.weight", "bert.encoder.layer.22.output.LayerNorm.bias", "bert.encoder.layer.23.attention.self.query.weight", "bert.encoder.layer.23.attention.self.query.bias", "bert.encoder.layer.23.attention.self.key.weight", "bert.encoder.layer.23.attention.self.key.bias", "bert.encoder.layer.23.attention.self.value.weight", "bert.encoder.layer.23.attention.self.value.bias", "bert.encoder.layer.23.attention.output.dense.weight", "bert.encoder.layer.23.attention.output.dense.bias", "bert.encoder.layer.23.attention.output.LayerNorm.weight", "bert.encoder.layer.23.attention.output.LayerNorm.bias", "bert.encoder.layer.23.intermediate.dense.weight", "bert.encoder.layer.23.intermediate.dense.bias", "bert.encoder.layer.23.output.dense.weight", "bert.encoder.layer.23.output.dense.bias", "bert.encoder.layer.23.output.LayerNorm.weight", "bert.encoder.layer.23.output.LayerNorm.bias". 
RuntimeError: Error(s) in loading state_dict for BERTClassifier:
	Missing key(s) in state_dict: "bert.embeddings.word_embeddings.weight", "bert.embeddings.position_embeddings.weight", "bert.embeddings.token_type_embeddings.weight", "bert.embeddings.LayerNorm.weight", "bert.embeddings.LayerNorm.bias", "bert.encoder.layer.0.attention.self.query.weight", "bert.encoder.layer.0.attention.self.query.bias", "bert.encoder.layer.0.attention.self.key.weight", "bert.encoder.layer.0.attention.self.key.bias", "bert.encoder.layer.0.attention.self.value.weight", "bert.encoder.layer.0.attention.self.value.bias", "bert.encoder.layer.0.attention.output.dense.weight", "bert.encoder.layer.0.attention.output.dense.bias", "bert.encoder.layer.0.attention.output.LayerNorm.weight", "bert.encoder.layer.0.attention.output.LayerNorm.bias", "bert.encoder.layer.0.intermediate.dense.weight", "bert.encoder.layer.0.intermediate.dense.bias", "bert.encoder.layer.0.output.dense.weight", "bert.encoder.layer.0.output.dense.bias", "bert.encoder.layer.0.output.LayerNorm.weight", "bert.encoder.layer.0.output.LayerNorm.bias", "bert.encoder.layer.1.attention.self.query.weight", "bert.encoder.layer.1.attention.self.query.bias", "bert.encoder.layer.1.attention.self.key.weight", "bert.encoder.layer.1.attention.self.key.bias", "bert.encoder.layer.1.attention.self.value.weight", "bert.encoder.layer.1.attention.self.value.bias", "bert.encoder.layer.1.attention.output.dense.weight", "bert.encoder.layer.1.attention.output.dense.bias", "bert.encoder.layer.1.attention.output.LayerNorm.weight", "bert.encoder.layer.1.attention.output.LayerNorm.bias", "bert.encoder.layer.1.intermediate.dense.weight", "bert.encoder.layer.1.intermediate.dense.bias", "bert.encoder.layer.1.output.dense.weight", "bert.encoder.layer.1.output.dense.bias", "bert.encoder.layer.1.output.LayerNorm.weight", "bert.encoder.layer.1.output.LayerNorm.bias", "bert.encoder.layer.2.attention.self.query.weight", "bert.encoder.layer.2.attention.self.query.bias", "bert.encoder.layer.2.attention.self.key.weight", "bert.encoder.layer.2.attention.self.key.bias", "bert.encoder.layer.2.attention.self.value.weight", "bert.encoder.layer.2.attention.self.value.bias", "bert.encoder.layer.2.attention.output.dense.weight", "bert.encoder.layer.2.attention.output.dense.bias", "bert.encoder.layer.2.attention.output.LayerNorm.weight", "bert.encoder.layer.2.attention.output.LayerNorm.bias", "bert.encoder.layer.2.intermediate.dense.weight", "bert.encoder.layer.2.intermediate.dense.bias", "bert.encoder.layer.2.output.dense.weight", "bert.encoder.layer.2.output.dense.bias", "bert.encoder.layer.2.output.LayerNorm.weight", "bert.encoder.layer.2.output.LayerNorm.bias", "bert.encoder.layer.3.attention.self.query.weight", "bert.encoder.layer.3.attention.self.query.bias", "bert.encoder.layer.3.attention.self.key.weight", "bert.encoder.layer.3.attention.self.key.bias", "bert.encoder.layer.3.attention.self.value.weight", "bert.encoder.layer.3.attention.self.value.bias", "bert.encoder.layer.3.attention.output.dense.weight", "bert.encoder.layer.3.attention.output.dense.bias", "bert.encoder.layer.3.attention.output.LayerNorm.weight", "bert.encoder.layer.3.attention.output.LayerNorm.bias", "bert.encoder.layer.3.intermediate.dense.weight", "bert.encoder.layer.3.intermediate.dense.bias", "bert.encoder.layer.3.output.dense.weight", "bert.encoder.layer.3.output.dense.bias", "bert.encoder.layer.3.output.LayerNorm.weight", "bert.encoder.layer.3.output.LayerNorm.bias", "bert.encoder.layer.4.attention.self.query.weight", "bert.encoder.layer.4.attention.self.query.bias", "bert.encoder.layer.4.attention.self.key.weight", "bert.encoder.layer.4.attention.self.key.bias", "bert.encoder.layer.4.attention.self.value.weight", "bert.encoder.layer.4.attention.self.value.bias", "bert.encoder.layer.4.attention.output.dense.weight", "bert.encoder.layer.4.attention.output.dense.bias", "bert.encoder.layer.4.attention.output.LayerNorm.weight", "bert.encoder.layer.4.attention.output.LayerNorm.bias", "bert.encoder.layer.4.intermediate.dense.weight", "bert.encoder.layer.4.intermediate.dense.bias", "bert.encoder.layer.4.output.dense.weight", "bert.encoder.layer.4.output.dense.bias", "bert.encoder.layer.4.output.LayerNorm.weight", "bert.encoder.layer.4.output.LayerNorm.bias", "bert.encoder.layer.5.attention.self.query.weight", "bert.encoder.layer.5.attention.self.query.bias", "bert.encoder.layer.5.attention.self.key.weight", "bert.encoder.layer.5.attention.self.key.bias", "bert.encoder.layer.5.attention.self.value.weight", "bert.encoder.layer.5.attention.self.value.bias", "bert.encoder.layer.5.attention.output.dense.weight", "bert.encoder.layer.5.attention.output.dense.bias", "bert.encoder.layer.5.attention.output.LayerNorm.weight", "bert.encoder.layer.5.attention.output.LayerNorm.bias", "bert.encoder.layer.5.intermediate.dense.weight", "bert.encoder.layer.5.intermediate.dense.bias", "bert.encoder.layer.5.output.dense.weight", "bert.encoder.layer.5.output.dense.bias", "bert.encoder.layer.5.output.LayerNorm.weight", "bert.encoder.layer.5.output.LayerNorm.bias", "bert.encoder.layer.6.attention.self.query.weight", "bert.encoder.layer.6.attention.self.query.bias", "bert.encoder.layer.6.attention.self.key.weight", "bert.encoder.layer.6.attention.self.key.bias", "bert.encoder.layer.6.attention.self.value.weight", "bert.encoder.layer.6.attention.self.value.bias", "bert.encoder.layer.6.attention.output.dense.weight", "bert.encoder.layer.6.attention.output.dense.bias", "bert.encoder.layer.6.attention.output.LayerNorm.weight", "bert.encoder.layer.6.attention.output.LayerNorm.bias", "bert.encoder.layer.6.intermediate.dense.weight", "bert.encoder.layer.6.intermediate.dense.bias", "bert.encoder.layer.6.output.dense.weight", "bert.encoder.layer.6.output.dense.bias", "bert.encoder.layer.6.output.LayerNorm.weight", "bert.encoder.layer.6.output.LayerNorm.bias", "bert.encoder.layer.7.attention.self.query.weight", "bert.encoder.layer.7.attention.self.query.bias", "bert.encoder.layer.7.attention.self.key.weight", "bert.encoder.layer.7.attention.self.key.bias", "bert.encoder.layer.7.attention.self.value.weight", "bert.encoder.layer.7.attention.self.value.bias", "bert.encoder.layer.7.attention.output.dense.weight", "bert.encoder.layer.7.attention.output.dense.bias", "bert.encoder.layer.7.attention.output.LayerNorm.weight", "bert.encoder.layer.7.attention.output.LayerNorm.bias", "bert.encoder.layer.7.intermediate.dense.weight", "bert.encoder.layer.7.intermediate.dense.bias", "bert.encoder.layer.7.output.dense.weight", "bert.encoder.layer.7.output.dense.bias", "bert.encoder.layer.7.output.LayerNorm.weight", "bert.encoder.layer.7.output.LayerNorm.bias", "bert.encoder.layer.8.attention.self.query.weight", "bert.encoder.layer.8.attention.self.query.bias", "bert.encoder.layer.8.attention.self.key.weight", "bert.encoder.layer.8.attention.self.key.bias", "bert.encoder.layer.8.attention.self.value.weight", "bert.encoder.layer.8.attention.self.value.bias", "bert.encoder.layer.8.attention.output.dense.weight", "bert.encoder.layer.8.attention.output.dense.bias", "bert.encoder.layer.8.attention.output.LayerNorm.weight", "bert.encoder.layer.8.attention.output.LayerNorm.bias", "bert.encoder.layer.8.intermediate.dense.weight", "bert.encoder.layer.8.intermediate.dense.bias", "bert.encoder.layer.8.output.dense.weight", "bert.encoder.layer.8.output.dense.bias", "bert.encoder.layer.8.output.LayerNorm.weight", "bert.encoder.layer.8.output.LayerNorm.bias", "bert.encoder.layer.9.attention.self.query.weight", "bert.encoder.layer.9.attention.self.query.bias", "bert.encoder.layer.9.attention.self.key.weight", "bert.encoder.layer.9.attention.self.key.bias", "bert.encoder.layer.9.attention.self.value.weight", "bert.encoder.layer.9.attention.self.value.bias", "bert.encoder.layer.9.attention.output.dense.weight", "bert.encoder.layer.9.attention.output.dense.bias", "bert.encoder.layer.9.attention.output.LayerNorm.weight", "bert.encoder.layer.9.attention.output.LayerNorm.bias", "bert.encoder.layer.9.intermediate.dense.weight", "bert.encoder.layer.9.intermediate.dense.bias", "bert.encoder.layer.9.output.dense.weight", "bert.encoder.layer.9.output.dense.bias", "bert.encoder.layer.9.output.LayerNorm.weight", "bert.encoder.layer.9.output.LayerNorm.bias", "bert.encoder.layer.10.attention.self.query.weight", "bert.encoder.layer.10.attention.self.query.bias", "bert.encoder.layer.10.attention.self.key.weight", "bert.encoder.layer.10.attention.self.key.bias", "bert.encoder.layer.10.attention.self.value.weight", "bert.encoder.layer.10.attention.self.value.bias", "bert.encoder.layer.10.attention.output.dense.weight", "bert.encoder.layer.10.attention.output.dense.bias", "bert.encoder.layer.10.attention.output.LayerNorm.weight", "bert.encoder.layer.10.attention.output.LayerNorm.bias", "bert.encoder.layer.10.intermediate.dense.weight", "bert.encoder.layer.10.intermediate.dense.bias", "bert.encoder.layer.10.output.dense.weight", "bert.encoder.layer.10.output.dense.bias", "bert.encoder.layer.10.output.LayerNorm.weight", "bert.encoder.layer.10.output.LayerNorm.bias", "bert.encoder.layer.11.attention.self.query.weight", "bert.encoder.layer.11.attention.self.query.bias", "bert.encoder.layer.11.attention.self.key.weight", "bert.encoder.layer.11.attention.self.key.bias", "bert.encoder.layer.11.attention.self.value.weight", "bert.encoder.layer.11.attention.self.value.bias", "bert.encoder.layer.11.attention.output.dense.weight", "bert.encoder.layer.11.attention.output.dense.bias", "bert.encoder.layer.11.attention.output.LayerNorm.weight", "bert.encoder.layer.11.attention.output.LayerNorm.bias", "bert.encoder.layer.11.intermediate.dense.weight", "bert.encoder.layer.11.intermediate.dense.bias", "bert.encoder.layer.11.output.dense.weight", "bert.encoder.layer.11.output.dense.bias", "bert.encoder.layer.11.output.LayerNorm.weight", "bert.encoder.layer.11.output.LayerNorm.bias", "bert.encoder.layer.12.attention.self.query.weight", "bert.encoder.layer.12.attention.self.query.bias", "bert.encoder.layer.12.attention.self.key.weight", "bert.encoder.layer.12.attention.self.key.bias", "bert.encoder.layer.12.attention.self.value.weight", "bert.encoder.layer.12.attention.self.value.bias", "bert.encoder.layer.12.attention.output.dense.weight", "bert.encoder.layer.12.attention.output.dense.bias", "bert.encoder.layer.12.attention.output.LayerNorm.weight", "bert.encoder.layer.12.attention.output.LayerNorm.bias", "bert.encoder.layer.12.intermediate.dense.weight", "bert.encoder.layer.12.intermediate.dense.bias", "bert.encoder.layer.12.output.dense.weight", "bert.encoder.layer.12.output.dense.bias", "bert.encoder.layer.12.output.LayerNorm.weight", "bert.encoder.layer.12.output.LayerNorm.bias", "bert.encoder.layer.13.attention.self.query.weight", "bert.encoder.layer.13.attention.self.query.bias", "bert.encoder.layer.13.attention.self.key.weight", "bert.encoder.layer.13.attention.self.key.bias", "bert.encoder.layer.13.attention.self.value.weight", "bert.encoder.layer.13.attention.self.value.bias", "bert.encoder.layer.13.attention.output.dense.weight", "bert.encoder.layer.13.attention.output.dense.bias", "bert.encoder.layer.13.attention.output.LayerNorm.weight", "bert.encoder.layer.13.attention.output.LayerNorm.bias", "bert.encoder.layer.13.intermediate.dense.weight", "bert.encoder.layer.13.intermediate.dense.bias", "bert.encoder.layer.13.output.dense.weight", "bert.encoder.layer.13.output.dense.bias", "bert.encoder.layer.13.output.LayerNorm.weight", "bert.encoder.layer.13.output.LayerNorm.bias", "bert.encoder.layer.14.attention.self.query.weight", "bert.encoder.layer.14.attention.self.query.bias", "bert.encoder.layer.14.attention.self.key.weight", "bert.encoder.layer.14.attention.self.key.bias", "bert.encoder.layer.14.attention.self.value.weight", "bert.encoder.layer.14.attention.self.value.bias", "bert.encoder.layer.14.attention.output.dense.weight", "bert.encoder.layer.14.attention.output.dense.bias", "bert.encoder.layer.14.attention.output.LayerNorm.weight", "bert.encoder.layer.14.attention.output.LayerNorm.bias", "bert.encoder.layer.14.intermediate.dense.weight", "bert.encoder.layer.14.intermediate.dense.bias", "bert.encoder.layer.14.output.dense.weight", "bert.encoder.layer.14.output.dense.bias", "bert.encoder.layer.14.output.LayerNorm.weight", "bert.encoder.layer.14.output.LayerNorm.bias", "bert.encoder.layer.15.attention.self.query.weight", "bert.encoder.layer.15.attention.self.query.bias", "bert.encoder.layer.15.attention.self.key.weight", "bert.encoder.layer.15.attention.self.key.bias", "bert.encoder.layer.15.attention.self.value.weight", "bert.encoder.layer.15.attention.self.value.bias", "bert.encoder.layer.15.attention.output.dense.weight", "bert.encoder.layer.15.attention.output.dense.bias", "bert.encoder.layer.15.attention.output.LayerNorm.weight", "bert.encoder.layer.15.attention.output.LayerNorm.bias", "bert.encoder.layer.15.intermediate.dense.weight", "bert.encoder.layer.15.intermediate.dense.bias", "bert.encoder.layer.15.output.dense.weight", "bert.encoder.layer.15.output.dense.bias", "bert.encoder.layer.15.output.LayerNorm.weight", "bert.encoder.layer.15.output.LayerNorm.bias", "bert.encoder.layer.16.attention.self.query.weight", "bert.encoder.layer.16.attention.self.query.bias", "bert.encoder.layer.16.attention.self.key.weight", "bert.encoder.layer.16.attention.self.key.bias", "bert.encoder.layer.16.attention.self.value.weight", "bert.encoder.layer.16.attention.self.value.bias", "bert.encoder.layer.16.attention.output.dense.weight", "bert.encoder.layer.16.attention.output.dense.bias", "bert.encoder.layer.16.attention.output.LayerNorm.weight", "bert.encoder.layer.16.attention.output.LayerNorm.bias", "bert.encoder.layer.16.intermediate.dense.weight", "bert.encoder.layer.16.intermediate.dense.bias", "bert.encoder.layer.16.output.dense.weight", "bert.encoder.layer.16.output.dense.bias", "bert.encoder.layer.16.output.LayerNorm.weight", "bert.encoder.layer.16.output.LayerNorm.bias", "bert.encoder.layer.17.attention.self.query.weight", "bert.encoder.layer.17.attention.self.query.bias", "bert.encoder.layer.17.attention.self.key.weight", "bert.encoder.layer.17.attention.self.key.bias", "bert.encoder.layer.17.attention.self.value.weight", "bert.encoder.layer.17.attention.self.value.bias", "bert.encoder.layer.17.attention.output.dense.weight", "bert.encoder.layer.17.attention.output.dense.bias", "bert.encoder.layer.17.attention.output.LayerNorm.weight", "bert.encoder.layer.17.attention.output.LayerNorm.bias", "bert.encoder.layer.17.intermediate.dense.weight", "bert.encoder.layer.17.intermediate.dense.bias", "bert.encoder.layer.17.output.dense.weight", "bert.encoder.layer.17.output.dense.bias", "bert.encoder.layer.17.output.LayerNorm.weight", "bert.encoder.layer.17.output.LayerNorm.bias", "bert.encoder.layer.18.attention.self.query.weight", "bert.encoder.layer.18.attention.self.query.bias", "bert.encoder.layer.18.attention.self.key.weight", "bert.encoder.layer.18.attention.self.key.bias", "bert.encoder.layer.18.attention.self.value.weight", "bert.encoder.layer.18.attention.self.value.bias", "bert.encoder.layer.18.attention.output.dense.weight", "bert.encoder.layer.18.attention.output.dense.bias", "bert.encoder.layer.18.attention.output.LayerNorm.weight", "bert.encoder.layer.18.attention.output.LayerNorm.bias", "bert.encoder.layer.18.intermediate.dense.weight", "bert.encoder.layer.18.intermediate.dense.bias", "bert.encoder.layer.18.output.dense.weight", "bert.encoder.layer.18.output.dense.bias", "bert.encoder.layer.18.output.LayerNorm.weight", "bert.encoder.layer.18.output.LayerNorm.bias", "bert.encoder.layer.19.attention.self.query.weight", "bert.encoder.layer.19.attention.self.query.bias", "bert.encoder.layer.19.attention.self.key.weight", "bert.encoder.layer.19.attention.self.key.bias", "bert.encoder.layer.19.attention.self.value.weight", "bert.encoder.layer.19.attention.self.value.bias", "bert.encoder.layer.19.attention.output.dense.weight", "bert.encoder.layer.19.attention.output.dense.bias", "bert.encoder.layer.19.attention.output.LayerNorm.weight", "bert.encoder.layer.19.attention.output.LayerNorm.bias", "bert.encoder.layer.19.intermediate.dense.weight", "bert.encoder.layer.19.intermediate.dense.bias", "bert.encoder.layer.19.output.dense.weight", "bert.encoder.layer.19.output.dense.bias", "bert.encoder.layer.19.output.LayerNorm.weight", "bert.encoder.layer.19.output.LayerNorm.bias", "bert.encoder.layer.20.attention.self.query.weight", "bert.encoder.layer.20.attention.self.query.bias", "bert.encoder.layer.20.attention.self.key.weight", "bert.encoder.layer.20.attention.self.key.bias", "bert.encoder.layer.20.attention.self.value.weight", "bert.encoder.layer.20.attention.self.value.bias", "bert.encoder.layer.20.attention.output.dense.weight", "bert.encoder.layer.20.attention.output.dense.bias", "bert.encoder.layer.20.attention.output.LayerNorm.weight", "bert.encoder.layer.20.attention.output.LayerNorm.bias", "bert.encoder.layer.20.intermediate.dense.weight", "bert.encoder.layer.20.intermediate.dense.bias", "bert.encoder.layer.20.output.dense.weight", "bert.encoder.layer.20.output.dense.bias", "bert.encoder.layer.20.output.LayerNorm.weight", "bert.encoder.layer.20.output.LayerNorm.bias", "bert.encoder.layer.21.attention.self.query.weight", "bert.encoder.layer.21.attention.self.query.bias", "bert.encoder.layer.21.attention.self.key.weight", "bert.encoder.layer.21.attention.self.key.bias", "bert.encoder.layer.21.attention.self.value.weight", "bert.encoder.layer.21.attention.self.value.bias", "bert.encoder.layer.21.attention.output.dense.weight", "bert.encoder.layer.21.attention.output.dense.bias", "bert.encoder.layer.21.attention.output.LayerNorm.weight", "bert.encoder.layer.21.attention.output.LayerNorm.bias", "bert.encoder.layer.21.intermediate.dense.weight", "bert.encoder.layer.21.intermediate.dense.bias", "bert.encoder.layer.21.output.dense.weight", "bert.encoder.layer.21.output.dense.bias", "bert.encoder.layer.21.output.LayerNorm.weight", "bert.encoder.layer.21.output.LayerNorm.bias", "bert.encoder.layer.22.attention.self.query.weight", "bert.encoder.layer.22.attention.self.query.bias", "bert.encoder.layer.22.attention.self.key.weight", "bert.encoder.layer.22.attention.self.key.bias", "bert.encoder.layer.22.attention.self.value.weight", "bert.encoder.layer.22.attention.self.value.bias", "bert.encoder.layer.22.attention.output.dense.weight", "bert.encoder.layer.22.attention.output.dense.bias", "bert.encoder.layer.22.attention.output.LayerNorm.weight", "bert.encoder.layer.22.attention.output.LayerNorm.bias", "bert.encoder.layer.22.intermediate.dense.weight", "bert.encoder.layer.22.intermediate.dense.bias", "bert.encoder.layer.22.output.dense.weight", "bert.encoder.layer.22.output.dense.bias", "bert.encoder.layer.22.output.LayerNorm.weight", "bert.encoder.layer.22.output.LayerNorm.bias", "bert.encoder.layer.23.attention.self.query.weight", "bert.encoder.layer.23.attention.self.query.bias", "bert.encoder.layer.23.attention.self.key.weight", "bert.encoder.layer.23.attention.self.key.bias", "bert.encoder.layer.23.attention.self.value.weight", "bert.encoder.layer.23.attention.self.value.bias", "bert.encoder.layer.23.attention.output.dense.weight", "bert.encoder.layer.23.attention.output.dense.bias", "bert.encoder.layer.23.attention.output.LayerNorm.weight", "bert.encoder.layer.23.attention.output.LayerNorm.bias", "bert.encoder.layer.23.intermediate.dense.weight", "bert.encoder.layer.23.intermediate.dense.bias", "bert.encoder.layer.23.output.dense.weight", "bert.encoder.layer.23.output.dense.bias", "bert.encoder.layer.23.output.LayerNorm.weight", "bert.encoder.layer.23.output.LayerNorm.bias". 
wandb: ðŸš€ View run run_2_merged_ft6 at: https://wandb.ai/jimbeno/Electra Large/runs/gcobol3t
wandb: Find logs at: wandb/run-20241024_022758-gcobol3t/logs
(nlp) ubuntu@138-2-58-218:~/nlp-osaka/sentiment$ git pull
Username for 'https://github.com': jim@jimbeno.net 
Password for 'https://jim@jimbeno.net@github.com': 
remote: Enumerating objects: 5, done.
remote: Counting objects: 100% (5/5), done.
remote: Compressing objects: 100% (1/1), done.
remote: Total 3 (delta 2), reused 3 (delta 2), pack-reused 0 (from 0)
Unpacking objects: 100% (3/3), 886 bytes | 20.00 KiB/s, done.
From https://github.com/jbeno/sentiment
   d4ce292..9ee5534  main       -> origin/main
Updating d4ce292..9ee5534
Fast-forward
 torch_ddp_finetune_neural_classifier.py | 51 +++++++++++++++++++++++++++++++--------------------
 1 file changed, 31 insertions(+), 20 deletions(-)
(nlp) ubuntu@138-2-58-218:~/nlp-osaka/sentiment$ python ./ddp_sentiment_finetune.py --dataset 'merged_local' --weights_name 'google/electra-large-discriminator' --save_data --save_model --save_pickle --save_preds --lr 0.0001 --lr_decay 0.95 --epochs 25 --pooling 'mean' --dropout_rate 0.3 --num_layers 2 --hidden_dim 1024 --hidden_activation 'swishglu' --batch_size 64 --finetune_bert --finetune_layers 6 --l2_strength 0.0001 --checkpoint_interval 5 --use_zero --optimizer 'adamw' --scheduler 'cosine_warmup' --scheduler_kwargs '{"T_0":5, "T_mult":1, "eta_min":1e-7}' --decimal 6 --use_val_split --eval_split 'test' --early_stop 'score' --n_iter_no_change 25 --show_progress --wandb --wandb_project 'Electra Large' --wandb_run 'run_2_merged_ft6' --model_file 'checkpoint_epoch_100_20241024-002635.pth' --load_classifier_only

Starting DDP PyTorch Training...
Device: cuda, Number of GPUs: 8
Spawning 8 processes...
Rank 2 - Device: cuda:2
Rank 7 - Device: cuda:7
Rank 3 - Device: cuda:3
Rank 5 - Device: cuda:5
Rank 4 - Device: cuda:4
Rank 6 - Device: cuda:6
Rank 1 - Device: cuda:1
Rank 0 - Device: cuda:0
8 process groups initialized with 'nccl' backend on localhost:12355
NCCL Timeout: 1 hr 0 min. NCCL Blocking Wait: Enabled
wandb: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: jbeno (jimbeno). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.5
wandb: Run data is saved locally in /home/ubuntu/nlp-osaka/sentiment/wandb/run-20241024_023810-pm00xz45
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run run_2_merged_ft6
wandb: â­ï¸ View project at https://wandb.ai/jimbeno/Electra%20Large
wandb: ðŸš€ View run at https://wandb.ai/jimbeno/Electra%20Large/runs/pm00xz45
Wand run initialized.

Initializing 'google/electra-large-discriminator' tokenizer and model...
Checking for local files...
Found all files in cache, skipping download
All ranks loading tokenizer from local files...
All ranks loading model from local files...
Tokenizer and model initialized (6s)

Loading data...
Using the same dataset for training and evaluation
Splits:
- Train: Using merged_local 'train' split
- Validation: Using merged_local 'validation' split
- Evaluation: Using merged_local 'test' split
Train Data: Merged DynaSent Round 1, Round 2 and SST from Local: 'data/merged'
Validation Data: Merged DynaSent Round 1, Round 2 and SST from Local: 'data/merged'
Evaluation Data: Merged DynaSent Round 1, Round 2 and SST from Local: 'data/merged'
Train size: 102097
Validation size: 5421
Evaluation size: 5421
Train label distribution:
	      Negative: 21910
	       Neutral: 49148
	      Positive: 31039
Validation label distribution:
	      Negative: 1868
	       Neutral: 1669
	      Positive: 1884
Evaluation label distribution:
	      Negative: 1868
	       Neutral: 1669
	      Positive: 1884
Data loaded (2s)

Processing data...
(Batch size: 64, Pooling: Mean, Fine Tune BERT: True, Chunk size: None)...
Extracting sentences and labels...

Data saved to: saves/data_8_gpu_20241024-023820.npz
X Train shape: [102097], X Validation shape: [5421], X Test shape: [5421]
y Train shape: [102097], y Validation shape: [5421], y Test shape: [5421]
Data processed (861ms)

Initializing DDP Neural Classifier...
Layers: 2, Hidden Dim: 1024, Hidden Act: SwishGLU, Dropout: 0.3, Optimizer: AdamW, L2 Strength: 0.0001, Pooling: MEAN, Accumulation Steps: 1, Max Grad Norm: None
Batch Size: 64, Max Epochs: 25, LR: 0.0001, Early Stop: score, Fine-tune BERT: True, Fine-tune Layers: 6, Freeze BERT: False, Target Score: None, Interactive: False
Loading model from: checkpoints/checkpoint_epoch_100_20241024-002635.pth...
Loaded checkpoint: checkpoints/checkpoint_epoch_100_20241024-002635.pth
An error occurred during training: 'TorchDDPNeuralClassifier' object has no attribute 'model'
Traceback (most recent call last):
  File "/home/ubuntu/nlp-osaka/sentiment/ddp_sentiment_finetune.py", line 1197, in main
    classifier, start_epoch, model_state_dict, optimizer_state_dict = initialize_classifier(
  File "/home/ubuntu/nlp-osaka/sentiment/ddp_sentiment_finetune.py", line 918, in initialize_classifier
    start_epoch, model_state_dict, optimizer_state_dict = classifier.load_model(directory=checkpoint_dir, filename=filename, pattern=None, use_saved_params=use_saved_params, rank=rank, debug=debug, load_classifier_only=load_classifer_only)
  File "/home/ubuntu/nlp-osaka/sentiment/torch_ddp_finetune_neural_classifier.py", line 734, in load_model
    missing_keys, unexpected_keys = self.model.load_state_dict(classifier_state_dict, strict=False)
AttributeError: 'TorchDDPNeuralClassifier' object has no attribute 'model'
An error occurred during training: 'TorchDDPNeuralClassifier' object has no attribute 'model'
Traceback (most recent call last):
  File "/home/ubuntu/nlp-osaka/sentiment/ddp_sentiment_finetune.py", line 1197, in main
    classifier, start_epoch, model_state_dict, optimizer_state_dict = initialize_classifier(
  File "/home/ubuntu/nlp-osaka/sentiment/ddp_sentiment_finetune.py", line 918, in initialize_classifier
    start_epoch, model_state_dict, optimizer_state_dict = classifier.load_model(directory=checkpoint_dir, filename=filename, pattern=None, use_saved_params=use_saved_params, rank=rank, debug=debug, load_classifier_only=load_classifer_only)
  File "/home/ubuntu/nlp-osaka/sentiment/torch_ddp_finetune_neural_classifier.py", line 734, in load_model
    missing_keys, unexpected_keys = self.model.load_state_dict(classifier_state_dict, strict=False)
AttributeError: 'TorchDDPNeuralClassifier' object has no attribute 'model'
An error occurred during training: 'TorchDDPNeuralClassifier' object has no attribute 'model'
An error occurred during training: 'TorchDDPNeuralClassifier' object has no attribute 'model'
An error occurred during training: 'TorchDDPNeuralClassifier' object has no attribute 'model'
An error occurred during training: 'TorchDDPNeuralClassifier' object has no attribute 'model'
An error occurred during training: 'TorchDDPNeuralClassifier' object has no attribute 'model'
Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
  File "/home/ubuntu/nlp-osaka/sentiment/ddp_sentiment_finetune.py", line 1197, in main
    classifier, start_epoch, model_state_dict, optimizer_state_dict = initialize_classifier(
  File "/home/ubuntu/nlp-osaka/sentiment/ddp_sentiment_finetune.py", line 1197, in main
    classifier, start_epoch, model_state_dict, optimizer_state_dict = initialize_classifier(
  File "/home/ubuntu/nlp-osaka/sentiment/ddp_sentiment_finetune.py", line 1197, in main
    classifier, start_epoch, model_state_dict, optimizer_state_dict = initialize_classifier(
  File "/home/ubuntu/nlp-osaka/sentiment/ddp_sentiment_finetune.py", line 918, in initialize_classifier
    start_epoch, model_state_dict, optimizer_state_dict = classifier.load_model(directory=checkpoint_dir, filename=filename, pattern=None, use_saved_params=use_saved_params, rank=rank, debug=debug, load_classifier_only=load_classifer_only)
  File "/home/ubuntu/nlp-osaka/sentiment/ddp_sentiment_finetune.py", line 918, in initialize_classifier
    start_epoch, model_state_dict, optimizer_state_dict = classifier.load_model(directory=checkpoint_dir, filename=filename, pattern=None, use_saved_params=use_saved_params, rank=rank, debug=debug, load_classifier_only=load_classifer_only)
  File "/home/ubuntu/nlp-osaka/sentiment/ddp_sentiment_finetune.py", line 918, in initialize_classifier
    start_epoch, model_state_dict, optimizer_state_dict = classifier.load_model(directory=checkpoint_dir, filename=filename, pattern=None, use_saved_params=use_saved_params, rank=rank, debug=debug, load_classifier_only=load_classifer_only)
  File "/home/ubuntu/nlp-osaka/sentiment/torch_ddp_finetune_neural_classifier.py", line 734, in load_model
    missing_keys, unexpected_keys = self.model.load_state_dict(classifier_state_dict, strict=False)
  File "/home/ubuntu/nlp-osaka/sentiment/torch_ddp_finetune_neural_classifier.py", line 734, in load_model
    missing_keys, unexpected_keys = self.model.load_state_dict(classifier_state_dict, strict=False)
  File "/home/ubuntu/nlp-osaka/sentiment/torch_ddp_finetune_neural_classifier.py", line 734, in load_model
    missing_keys, unexpected_keys = self.model.load_state_dict(classifier_state_dict, strict=False)
AttributeError: 'TorchDDPNeuralClassifier' object has no attribute 'model'
AttributeError: 'TorchDDPNeuralClassifier' object has no attribute 'model'
AttributeError: 'TorchDDPNeuralClassifier' object has no attribute 'model'
Traceback (most recent call last):
  File "/home/ubuntu/nlp-osaka/sentiment/ddp_sentiment_finetune.py", line 1197, in main
    classifier, start_epoch, model_state_dict, optimizer_state_dict = initialize_classifier(
  File "/home/ubuntu/nlp-osaka/sentiment/ddp_sentiment_finetune.py", line 918, in initialize_classifier
    start_epoch, model_state_dict, optimizer_state_dict = classifier.load_model(directory=checkpoint_dir, filename=filename, pattern=None, use_saved_params=use_saved_params, rank=rank, debug=debug, load_classifier_only=load_classifer_only)
  File "/home/ubuntu/nlp-osaka/sentiment/torch_ddp_finetune_neural_classifier.py", line 734, in load_model
    missing_keys, unexpected_keys = self.model.load_state_dict(classifier_state_dict, strict=False)
AttributeError: 'TorchDDPNeuralClassifier' object has no attribute 'model'
Traceback (most recent call last):
  File "/home/ubuntu/nlp-osaka/sentiment/ddp_sentiment_finetune.py", line 1197, in main
    classifier, start_epoch, model_state_dict, optimizer_state_dict = initialize_classifier(
  File "/home/ubuntu/nlp-osaka/sentiment/ddp_sentiment_finetune.py", line 918, in initialize_classifier
    start_epoch, model_state_dict, optimizer_state_dict = classifier.load_model(directory=checkpoint_dir, filename=filename, pattern=None, use_saved_params=use_saved_params, rank=rank, debug=debug, load_classifier_only=load_classifer_only)
  File "/home/ubuntu/nlp-osaka/sentiment/torch_ddp_finetune_neural_classifier.py", line 734, in load_model
    missing_keys, unexpected_keys = self.model.load_state_dict(classifier_state_dict, strict=False)
AttributeError: 'TorchDDPNeuralClassifier' object has no attribute 'model'
An error occurred during training: 'TorchDDPNeuralClassifier' object has no attribute 'model'
Traceback (most recent call last):
  File "/home/ubuntu/nlp-osaka/sentiment/ddp_sentiment_finetune.py", line 1197, in main
    classifier, start_epoch, model_state_dict, optimizer_state_dict = initialize_classifier(
  File "/home/ubuntu/nlp-osaka/sentiment/ddp_sentiment_finetune.py", line 918, in initialize_classifier
    start_epoch, model_state_dict, optimizer_state_dict = classifier.load_model(directory=checkpoint_dir, filename=filename, pattern=None, use_saved_params=use_saved_params, rank=rank, debug=debug, load_classifier_only=load_classifer_only)
  File "/home/ubuntu/nlp-osaka/sentiment/torch_ddp_finetune_neural_classifier.py", line 734, in load_model
    missing_keys, unexpected_keys = self.model.load_state_dict(classifier_state_dict, strict=False)
AttributeError: 'TorchDDPNeuralClassifier' object has no attribute 'model'
wandb: ðŸš€ View run run_2_merged_ft6 at: https://wandb.ai/jimbeno/Electra Large/runs/pm00xz45
wandb: Find logs at: wandb/run-20241024_023810-pm00xz45/logs
(nlp) ubuntu@138-2-58-218:~/nlp-osaka/sentiment$ git pull
Username for 'https://github.com': jim@jimbeno.net
Password for 'https://jim@jimbeno.net@github.com': 
remote: Enumerating objects: 7, done.
remote: Counting objects: 100% (7/7), done.
remote: Compressing objects: 100% (1/1), done.
remote: Total 4 (delta 3), reused 4 (delta 3), pack-reused 0 (from 0)
Unpacking objects: 100% (4/4), 608 bytes | 0 bytes/s, done.
From https://github.com/jbeno/sentiment
   9ee5534..28c7c70  main       -> origin/main
Updating 9ee5534..28c7c70
Fast-forward
 ddp_sentiment_finetune.py               | 14 ++++++--------
 torch_ddp_finetune_neural_classifier.py | 74 +++++++++-----------------------------------------------------------------
 2 files changed, 15 insertions(+), 73 deletions(-)
(nlp) ubuntu@138-2-58-218:~/nlp-osaka/sentiment$ python ./ddp_sentiment_finetune.py --dataset 'merged_local' --weights_name 'google/electra-large-discriminator' --save_data --save_model --save_pickle --save_preds --lr 0.0002 --lr_decay 0.95 --epochs 50 --pooling 'mean' --dropout_rate 0.3 --num_layers 2 --hidden_dim 1024 --hidden_activation 'swishglu' --batch_size 16 --accumulation_steps 2 --finetune_bert --finetune_layers 24 --l2_strength 0.0001  --checkpoint_interval 5 --use_zero --optimizer 'adamw' --scheduler 'cosine_warmup' --scheduler_kwargs '{"T_0":5, "T_mult":1, "eta_min":1e-7}' --decimal 6 --use_val_split --eval_split 'test' --early_stop 'score' --n_iter_no_change 50 --show_progress --wandb --wandb_project 'Electra Large' --wandb_run 'stage_1_merged' --model_file 'TBD' --data_file 'TBD'
^CTraceback (most recent call last):
  File "/home/ubuntu/nlp-osaka/sentiment/./ddp_sentiment_finetune.py", line 36, in <module>
    from datasets import load_dataset
  File "/home/ubuntu/nlp-osaka/sentiment/nlp/lib/python3.10/site-packages/datasets/__init__.py", line 22, in <module>
    from .arrow_dataset import Dataset
  File "/home/ubuntu/nlp-osaka/sentiment/nlp/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 66, in <module>
    from .arrow_reader import ArrowReader
  File "/home/ubuntu/nlp-osaka/sentiment/nlp/lib/python3.10/site-packages/datasets/arrow_reader.py", line 30, in <module>
    from .download.download_config import DownloadConfig
  File "/home/ubuntu/nlp-osaka/sentiment/nlp/lib/python3.10/site-packages/datasets/download/__init__.py", line 10, in <module>
    from .streaming_download_manager import StreamingDownloadManager
  File "/home/ubuntu/nlp-osaka/sentiment/nlp/lib/python3.10/site-packages/datasets/download/streaming_download_manager.py", line 21, in <module>
    from ..filesystems import COMPRESSION_FILESYSTEMS
  File "/home/ubuntu/nlp-osaka/sentiment/nlp/lib/python3.10/site-packages/datasets/filesystems/__init__.py", line 8, in <module>
    import fsspec.asyn
  File "/home/ubuntu/nlp-osaka/sentiment/nlp/lib/python3.10/site-packages/fsspec/asyn.py", line 16, in <module>
    from .implementations.local import LocalFileSystem, make_path_posix, trailing_sep
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 879, in exec_module
  File "<frozen importlib._bootstrap_external>", line 964, in get_code
  File "<frozen importlib._bootstrap_external>", line 448, in cache_from_source
  File "<frozen importlib._bootstrap_external>", line 128, in _path_join
  File "<frozen importlib._bootstrap_external>", line 128, in <listcomp>
KeyboardInterrupt

(nlp) ubuntu@138-2-58-218:~/nlp-osaka/sentiment$ python ./ddp_sentiment_finetune.py --dataset 'merged_local' --weights_name 'google/electra-large-discriminator' --save_data --save_model --save_pickle --save_preds --lr 0.0002 --lr_decay 0.95 --epochs 50 --pooling 'mean' --dropout_rate 0.3 --num_layers 2 --hidden_dim 1024 --hidden_activation 'swishglu' --batch_size 16 --accumulation_steps 2 --finetune_bert --finetune_layers 24 --l2_strength 0.0001  --checkpoint_interval 5 --use_zero --optimizer 'adamw' --scheduler 'cosine_warmup' --scheduler_kwargs '{"T_0":5, "T_mult":1, "eta_min":1e-7}' --decimal 6 --use_val_split --eval_split 'test' --early_stop 'score' --n_iter_no_change 50 --show_progress --wandb --wandb_project 'Electra Large' --wandb_run 'stage_1_merged'

Starting DDP PyTorch Training...
^C^C^C^C^C^C
Ctrl+C received. Terminating all processes...
Rank 0 - Current process: MainProcess cleaning up...
No active child processes to terminate
Rank 0 - Exiting program...
(nlp) ubuntu@138-2-58-218:~/nlp-osaka/sentiment$ python ./ddp_sentiment_finetune.py --dataset 'merged_local' --weights_name 'google/electra-large-discriminator' --save_data --save_model --save_pickle --save_preds --lr 0.00002 --lr_decay 0.95 --epochs 50 --pooling 'mean' --dropout_rate 0.3 --num_layers 2 --hidden_dim 1024 --hidden_activation 'swishglu' --batch_size 16 --accumulation_steps 2 --finetune_bert --finetune_layers 24 --l2_strength 0.0001  --checkpoint_interval 5 --use_zero --optimizer 'adamw' --scheduler 'cosine_warmup' --scheduler_kwargs '{"T_0":5, "T_mult":1, "eta_min":1e-7}' --decimal 6 --use_val_split --eval_split 'test' --early_stop 'score' --n_iter_no_change 50 --show_progress --wandb --wandb_project 'Electra Large' --wandb_run 'stage_1_merged'

Starting DDP PyTorch Training...
Device: cuda, Number of GPUs: 8
Spawning 8 processes...
Rank 3 - Device: cuda:3
Rank 1 - Device: cuda:1
Rank 4 - Device: cuda:4
Rank 7 - Device: cuda:7
Rank 6 - Device: cuda:6
Rank 2 - Device: cuda:2
Rank 5 - Device: cuda:5
Rank 0 - Device: cuda:0
8 process groups initialized with 'nccl' backend on localhost:12355
NCCL Timeout: 1 hr 0 min. NCCL Blocking Wait: Enabled
wandb: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: jbeno (jimbeno). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.5
wandb: Run data is saved locally in /home/ubuntu/nlp-osaka/sentiment/wandb/run-20241024_025325-k5ydgtod
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stage_1_merged
wandb: â­ï¸ View project at https://wandb.ai/jimbeno/Electra%20Large
wandb: ðŸš€ View run at https://wandb.ai/jimbeno/Electra%20Large/runs/k5ydgtod
Wand run initialized.

Initializing 'google/electra-large-discriminator' tokenizer and model...
Checking for local files...
Found all files in cache, skipping download
All ranks loading tokenizer from local files...
All ranks loading model from local files...
Tokenizer and model initialized (6s)

Loading data...
Using the same dataset for training and evaluation
Splits:
- Train: Using merged_local 'train' split
- Validation: Using merged_local 'validation' split
- Evaluation: Using merged_local 'test' split
Train Data: Merged DynaSent Round 1, Round 2 and SST from Local: 'data/merged'
Validation Data: Merged DynaSent Round 1, Round 2 and SST from Local: 'data/merged'
Evaluation Data: Merged DynaSent Round 1, Round 2 and SST from Local: 'data/merged'
Train size: 102097
Validation size: 5421
Evaluation size: 5421
Train label distribution:
	      Negative: 21910
	       Neutral: 49148
	      Positive: 31039
Validation label distribution:
	      Negative: 1868
	       Neutral: 1669
	      Positive: 1884
Evaluation label distribution:
	      Negative: 1868
	       Neutral: 1669
	      Positive: 1884
Data loaded (2s)

Processing data...
(Batch size: 16, Pooling: Mean, Fine Tune BERT: True, Chunk size: None)...
Extracting sentences and labels...

Data saved to: saves/data_8_gpu_20241024-025336.npz
X Train shape: [102097], X Validation shape: [5421], X Test shape: [5421]
y Train shape: [102097], y Validation shape: [5421], y Test shape: [5421]
Data processed (852ms)

Initializing DDP Neural Classifier...
Layers: 2, Hidden Dim: 1024, Hidden Act: SwishGLU, Dropout: 0.3, Optimizer: AdamW, L2 Strength: 0.0001, Pooling: MEAN, Accumulation Steps: 2, Max Grad Norm: None
Batch Size: 16, Max Epochs: 50, LR: 2e-05, Early Stop: score, Fine-tune BERT: True, Fine-tune Layers: 24, Freeze BERT: False, Target Score: None, Interactive: False
Classifier initialized (16ms)

Fitting DDP Neural Classifier on training data...
Num Workers: 0, Prefetch: None
Score-based early stopping enabled (macro average F1 score against validation set). Validation fraction: 0.1
Training will stop early if the score does not improve by at least 0.00001 for 50 iterations.
Using provided validation set for early stopping.
Building dataset and dataloader...
Initializing model, graph, optimizer...
BERT's original pooler removed. Using custom pooling type: mean
BERT has 334,092,288 trainable parameters and 0 non-trainable parameters
Number of BERT layers requiring gradients: 24 out of 24
Fine-tuning the last 24 out of 24 BERT layers

Model Architecture Summary:
BERTClassifier(
  (bert): ElectraModel(
    (embeddings): ElectraEmbeddings(
      (word_embeddings): Embedding(30522, 1024, padding_idx=0)
      (position_embeddings): Embedding(512, 1024)
      (token_type_embeddings): Embedding(2, 1024)
      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): ElectraEncoder(
      (layer): ModuleList(
        (0-23): 24 x ElectraLayer(
          (attention): ElectraAttention(
            (self): ElectraSelfAttention(
              (query): Linear(in_features=1024, out_features=1024, bias=True)
              (key): Linear(in_features=1024, out_features=1024, bias=True)
              (value): Linear(in_features=1024, out_features=1024, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): ElectraSelfOutput(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): ElectraIntermediate(
            (dense): Linear(in_features=1024, out_features=4096, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): ElectraOutput(
            (dense): Linear(in_features=4096, out_features=1024, bias=True)
            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
  (custom_pooling): PoolingLayer()
  (classifier): Classifier(
    (layers): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): SwishGLU(
        (projection): Linear(in_features=1024, out_features=2048, bias=True)
        (activation): SiLU()
      )
      (2): Dropout(p=0.3, inplace=False)
      (3): Linear(in_features=1024, out_features=1024, bias=True)
      (4): SwishGLU(
        (projection): Linear(in_features=1024, out_features=2048, bias=True)
        (activation): SiLU()
      )
      (5): Dropout(p=0.3, inplace=False)
      (6): Linear(in_features=1024, out_features=3, bias=True)
    )
  )
)

Model Parameters:
  bert.embeddings.word_embeddings: 31,254,528 (trainable)
  bert.embeddings.position_embeddings: 524,288 (trainable)
  bert.embeddings.token_type_embeddings: 2,048 (trainable)
  bert.embeddings.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.0.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.0.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.0.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.0.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.0.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.0.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.0.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.0.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.1.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.1.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.1.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.1.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.1.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.1.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.1.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.1.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.2.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.2.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.2.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.2.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.2.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.2.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.2.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.2.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.3.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.3.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.3.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.3.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.3.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.3.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.3.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.3.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.4.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.4.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.4.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.4.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.4.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.4.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.4.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.4.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.5.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.5.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.5.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.5.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.5.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.5.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.5.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.5.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.6.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.6.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.6.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.6.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.6.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.6.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.6.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.6.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.7.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.7.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.7.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.7.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.7.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.7.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.7.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.7.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.8.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.8.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.8.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.8.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.8.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.8.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.8.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.8.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.9.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.9.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.9.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.9.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.9.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.9.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.9.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.9.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.10.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.10.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.10.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.10.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.10.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.10.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.10.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.10.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.11.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.11.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.11.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.11.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.11.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.11.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.11.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.11.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.12.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.12.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.12.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.12.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.12.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.12.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.12.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.12.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.13.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.13.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.13.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.13.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.13.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.13.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.13.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.13.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.14.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.14.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.14.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.14.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.14.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.14.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.14.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.14.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.15.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.15.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.15.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.15.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.15.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.15.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.15.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.15.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.16.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.16.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.16.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.16.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.16.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.16.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.16.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.16.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.17.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.17.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.17.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.17.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.17.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.17.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.17.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.17.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.18.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.18.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.18.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.18.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.18.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.18.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.18.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.18.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.19.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.19.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.19.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.19.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.19.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.19.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.19.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.19.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.20.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.20.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.20.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.20.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.20.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.20.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.20.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.20.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.21.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.21.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.21.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.21.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.21.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.21.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.21.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.21.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.22.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.22.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.22.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.22.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.22.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.22.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.22.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.22.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.23.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.23.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.23.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.23.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.23.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.23.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.23.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.23.output.LayerNorm: 2,048 (trainable)
  classifier.layers.0: 1,049,600 (trainable)
  classifier.layers.1.projection: 2,099,200 (trainable)
  classifier.layers.3: 1,049,600 (trainable)
  classifier.layers.6: 3,075 (trainable)

Total layers: 200
Trainable layers: 200
Total parameters: 338,293,763
Trainable parameters: 338,293,763
Percentage of trainable parameters: 100.00%
Using optimizer: AdamW, Use Zero: True, Base Learning Rate: 2e-05, L2 strength: 0.0001
Layer-wise decay factor: 0.95
Using scheduler: CosineAnnealingWarmRestarts
Scheduler arguments:
- T_0: 5
- T_mult: 1
- eta_min: 1e-07

Starting training loop...
Start epoch: 1, Max Iterations: 50, Early Stop: score, Tolerance: 0.00001, Number Iterations No Change: 50
Epoch 1/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [23:53<00:00,  1.80s/it, loss=1.7091, lr=1.81e-05, grad=M:0.1541, status=Epoch complete]â–ˆ Epoch  1: Loss T 1.709082 V 0.941350 | F1 T 0.430926 V 0.384811 B 0.384811 SC 0/50 | Acc T 0.607263 V 0.470501 | LR 1.81e-05 | Grad â†“ 0.000000 â†‘ 1.111575 M 0.154069 | 23m 53s
Epoch 2/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [23:47<00:00,  1.79s/it, loss=1.0281, lr=1.31e-05, grad=M:0.2655, status=Epoch complete]
â–ˆ Epoch  2: Loss T 1.028122 V 0.503963 | F1 T 0.862364 V 0.816236 B 0.816236 SC 0/50 | Acc T 0.866646 V 0.817109 | LR 1.31e-05 | Grad â†“ 0.000000 â†‘ 1.902102 M 0.265542 | 23m 47s
Epoch 3/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [23:45<00:00,  1.79s/it, loss=0.7796, lr=6.99e-06, grad=M:0.1288, status=Epoch complete]
â–ˆ Epoch  3: Loss T 0.779640 V 0.466841 | F1 T 0.879966 V 0.821761 B 0.821761 SC 0/50 | Acc T 0.883060 V 0.823009 | LR 6.99e-06 | Grad â†“ 0.000000 â†‘ 1.064733 M 0.128769 | 23m 45s
Epoch 4/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [23:44<00:00,  1.78s/it, loss=0.6836, lr=2.01e-06, grad=M:0.2223, status=Epoch complete]
â–ˆ Epoch  4: Loss T 0.683558 V 0.472396 | F1 T 0.889505 V 0.830107 B 0.830107 SC 0/50 | Acc T 0.891434 V 0.831858 | LR 2.01e-06 | Grad â†“ 0.000000 â†‘ 1.802672 M 0.222314 | 23m 44s
Epoch 5/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [23:44<00:00,  1.78s/it, loss=0.6428, lr=1.00e-07, grad=M:0.1535, status=Epoch complete]
â–ˆ Epoch  5: Loss T 0.642816 V 0.487312 | F1 T 0.892272 V 0.828903 B 0.830107 SC 1/50 | Acc T 0.894049 V 0.830568 | LR 1.00e-07 | Grad â†“ 0.000000 â†‘ 1.316910 M 0.153527 | 23m 44s
Saved model state: checkpoints/checkpoint_epoch_5_20241024-045233.pth
Epoch 6/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [23:44<00:00,  1.78s/it, loss=0.7379, lr=1.81e-05, grad=M:0.2465, status=Epoch complete]
â–ˆ Epoch  6: Loss T 0.737864 V 0.541290 | F1 T 0.892231 V 0.819913 B 0.830107 SC 2/50 | Acc T 0.894686 V 0.820981 | LR 1.81e-05 | Grad â†“ 0.000000 â†‘ 1.929573 M 0.246548 | 23m 44s
Epoch 7/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [23:45<00:00,  1.79s/it, loss=0.6789, lr=1.31e-05, grad=M:0.2251, status=Epoch complete]
â–ˆ Epoch  7: Loss T 0.678919 V 0.524164 | F1 T 0.903286 V 0.818249 B 0.830107 SC 3/50 | Acc T 0.905430 V 0.819322 | LR 1.31e-05 | Grad â†“ 0.000000 â†‘ 1.329330 M 0.225125 | 23m 45s
Epoch 8/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [23:44<00:00,  1.79s/it, loss=0.6187, lr=6.99e-06, grad=M:0.1270, status=Epoch complete]
â–ˆ Epoch  8: Loss T 0.618737 V 0.511483 | F1 T 0.906339 V 0.813984 B 0.830107 SC 4/50 | Acc T 0.907868 V 0.815450 | LR 6.99e-06 | Grad â†“ 0.000000 â†‘ 0.863283 M 0.127040 | 23m 44s
Epoch 9/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [23:45<00:00,  1.79s/it, loss=0.5561, lr=2.01e-06, grad=M:0.1571, status=Epoch complete]
â–ˆ Epoch  9: Loss T 0.556115 V 0.537396 | F1 T 0.916713 V 0.822166 B 0.830107 SC 5/50 | Acc T 0.918152 V 0.823746 | LR 2.01e-06 | Grad â†“ 0.000000 â†‘ 1.079785 M 0.157080 | 23m 45s
Epoch 10/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [23:44<00:00,  1.79s/it, loss=0.5203, lr=1.00e-07, grad=M:0.2526, status=Epoch complete]
â–ˆ Epoch 10: Loss T 0.520321 V 0.544240 | F1 T 0.917497 V 0.822914 B 0.830107 SC 6/50 | Acc T 0.918877 V 0.824484 | LR 1.00e-07 | Grad â†“ 0.000000 â†‘ 1.852688 M 0.252639 | 23m 44s
Memory: Rank 0: 34.84 GB | Rank 1: 35.43 GB | Rank 2: 35.70 GB | Rank 3: 35.46 GB | Rank 4: 35.43 GB | Rank 5: 35.46 GB | Rank 6: 35.43 GB | Rank 7: 35.31 GB (Max: 42.29 GB, Total: 338.28 GB)
Saved model state: checkpoints/checkpoint_epoch_10_20241024-065147.pth
Epoch 11/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [23:43<00:00,  1.78s/it, loss=0.6197, lr=1.81e-05, grad=M:0.2144, status=Epoch complete]
â–ˆ Epoch 11: Loss T 0.619678 V 0.526696 | F1 T 0.902811 V 0.830318 B 0.830318 SC 0/50 | Acc T 0.905204 V 0.832412 | LR 1.81e-05 | Grad â†“ 0.000000 â†‘ 1.490163 M 0.214379 | 23m 43s
Epoch 12/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [23:44<00:00,  1.78s/it, loss=0.5689, lr=1.31e-05, grad=M:0.1456, status=Epoch complete]
â–ˆ Epoch 12: Loss T 0.568921 V 0.527506 | F1 T 0.916747 V 0.825068 B 0.830318 SC 1/50 | Acc T 0.918221 V 0.827249 | LR 1.31e-05 | Grad â†“ 0.000000 â†‘ 0.948652 M 0.145589 | 23m 44s
Epoch 13/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [23:44<00:00,  1.79s/it, loss=0.5064, lr=6.99e-06, grad=M:0.2901, status=Epoch complete]
â–ˆ Epoch 13: Loss T 0.506448 V 0.562735 | F1 T 0.934842 V 0.825049 B 0.830318 SC 2/50 | Acc T 0.936682 V 0.826143 | LR 6.99e-06 | Grad â†“ 0.000000 â†‘ 1.941967 M 0.290146 | 23m 44s
Epoch 14/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [23:44<00:00,  1.79s/it, loss=0.4438, lr=2.01e-06, grad=M:0.1898, status=Epoch complete]
â–ˆ Epoch 14: Loss T 0.443808 V 0.583496 | F1 T 0.936419 V 0.827856 B 0.830318 SC 3/50 | Acc T 0.938406 V 0.829093 | LR 2.01e-06 | Grad â†“ 0.000000 â†‘ 1.224209 M 0.189835 | 23m 44s
Epoch 15/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [23:43<00:00,  1.78s/it, loss=0.4179, lr=1.00e-07, grad=M:0.2092, status=Epoch complete]
â–ˆ Epoch 15: Loss T 0.417924 V 0.607380 | F1 T 0.938952 V 0.826470 B 0.830318 SC 4/50 | Acc T 0.940561 V 0.827802 | LR 1.00e-07 | Grad â†“ 0.000000 â†‘ 1.591728 M 0.209179 | 23m 43s
Saved model state: checkpoints/checkpoint_epoch_15_20241024-085039.pth
Epoch 16/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [23:44<00:00,  1.78s/it, loss=0.5357, lr=1.81e-05, grad=M:0.2861, status=Epoch complete]
â–ˆ Epoch 16: Loss T 0.535662 V 0.620911 | F1 T 0.927596 V 0.828608 B 0.830318 SC 5/50 | Acc T 0.929670 V 0.831490 | LR 1.81e-05 | Grad â†“ 0.000000 â†‘ 2.219006 M 0.286149 | 23m 44s
Epoch 17/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [23:44<00:00,  1.79s/it, loss=0.5204, lr=1.31e-05, grad=M:1.2523, status=Epoch complete]
â–ˆ Epoch 17: Loss T 0.520439 V 0.636813 | F1 T 0.917193 V 0.813278 B 0.830318 SC 6/50 | Acc T 0.920336 V 0.813975 | LR 1.31e-05 | Grad â†“ 0.000000 â†‘ 9.205060 M 1.252286 | 23m 44s
Epoch 18/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [23:44<00:00,  1.78s/it, loss=0.5037, lr=6.99e-06, grad=M:0.2504, status=Epoch complete]
â–ˆ Epoch 18: Loss T 0.503705 V 0.655000 | F1 T 0.939928 V 0.815720 B 0.830318 SC 7/50 | Acc T 0.941550 V 0.815819 | LR 6.99e-06 | Grad â†“ 0.000000 â†‘ 1.656595 M 0.250385 | 23m 44s
Epoch 19/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [23:45<00:00,  1.79s/it, loss=0.4314, lr=2.01e-06, grad=M:0.3525, status=Epoch complete]
â–ˆ Epoch 19: Loss T 0.431432 V 0.677574 | F1 T 0.946110 V 0.822547 B 0.830318 SC 8/50 | Acc T 0.947505 V 0.823562 | LR 2.01e-06 | Grad â†“ 0.000000 â†‘ 2.698990 M 0.352530 | 23m 45s
Epoch 20/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [23:46<00:00,  1.79s/it, loss=0.3920, lr=1.00e-07, grad=M:0.1816, status=Epoch complete]
â–ˆ Epoch 20: Loss T 0.392034 V 0.691314 | F1 T 0.946330 V 0.823688 B 0.830318 SC 9/50 | Acc T 0.947602 V 0.824853 | LR 1.00e-07 | Grad â†“ 0.000000 â†‘ 1.250880 M 0.181634 | 23m 46s
Memory: Rank 0: 34.84 GB | Rank 1: 35.43 GB | Rank 2: 35.70 GB | Rank 3: 35.46 GB | Rank 4: 35.43 GB | Rank 5: 35.46 GB | Rank 6: 35.43 GB | Rank 7: 35.31 GB (Max: 42.29 GB, Total: 338.28 GB)
Saved model state: checkpoints/checkpoint_epoch_20_20241024-104936.pth
Epoch 21/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [23:43<00:00,  1.78s/it, loss=0.4918, lr=1.81e-05, grad=M:0.0922, status=Epoch complete]
â–ˆ Epoch 21: Loss T 0.491765 V 0.589298 | F1 T 0.893233 V 0.799613 B 0.830318 SC 10/50 | Acc T 0.888663 V 0.802176 | LR 1.81e-05 | Grad â†“ 0.000000 â†‘ 0.565359 M 0.092223 | 23m 43s
Epoch 22/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [23:45<00:00,  1.79s/it, loss=0.5785, lr=1.31e-05, grad=M:0.1287, status=Epoch complete]
â–ˆ Epoch 22: Loss T 0.578494 V 0.659761 | F1 T 0.914715 V 0.806353 B 0.830318 SC 11/50 | Acc T 0.912246 V 0.807891 | LR 1.31e-05 | Grad â†“ 0.000000 â†‘ 0.893668 M 0.128677 | 23m 45s
Epoch 23/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [23:44<00:00,  1.79s/it, loss=0.4790, lr=6.99e-06, grad=M:0.3045, status=Epoch complete]
â–ˆ Epoch 23: Loss T 0.479006 V 0.691093 | F1 T 0.941237 V 0.812530 B 0.830318 SC 12/50 | Acc T 0.940022 V 0.814159 | LR 6.99e-06 | Grad â†“ 0.000000 â†‘ 2.611857 M 0.304489 | 23m 44s
Epoch 24/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [23:45<00:00,  1.79s/it, loss=0.4116, lr=2.01e-06, grad=M:2.3815, status=Epoch complete]
â–ˆ Epoch 24: Loss T 0.411642 V 0.707501 | F1 T 0.947397 V 0.826806 B 0.830318 SC 13/50 | Acc T 0.946799 V 0.827987 | LR 2.01e-06 | Grad â†“ 0.000000 â†‘ 14.953546 M 2.381474 | 23m 45s
Epoch 25/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [23:45<00:00,  1.79s/it, loss=0.3939, lr=1.00e-07, grad=M:0.3561, status=Epoch complete]
â–ˆ Epoch 25: Loss T 0.393872 V 0.690750 | F1 T 0.949737 V 0.823098 B 0.830318 SC 14/50 | Acc T 0.949385 V 0.824115 | LR 1.00e-07 | Grad â†“ 0.000000 â†‘ 6.309641 M 0.356090 | 23m 45s
Saved model state: checkpoints/checkpoint_epoch_25_20241024-124831.pth
Epoch 26/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [23:46<00:00,  1.79s/it, loss=0.4696, lr=1.81e-05, grad=M:0.6163, status=Epoch complete]
â–ˆ Epoch 26: Loss T 0.469558 V 0.642648 | F1 T 0.903474 V 0.794935 B 0.830318 SC 15/50 | Acc T 0.901835 V 0.796645 | LR 1.81e-05 | Grad â†“ 0.000000 â†‘ 13.055661 M 0.616288 | 23m 46s
Epoch 27/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [23:44<00:00,  1.79s/it, loss=0.5136, lr=1.31e-05, grad=M:0.2534, status=Epoch complete]
â–ˆ Epoch 27: Loss T 0.513632 V 0.697620 | F1 T 0.922618 V 0.799213 B 0.830318 SC 16/50 | Acc T 0.925194 V 0.799594 | LR 1.31e-05 | Grad â†“ 0.000000 â†‘ 1.750356 M 0.253378 | 23m 44s
Epoch 28/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [23:45<00:00,  1.79s/it, loss=0.5346, lr=6.99e-06, grad=M:0.4919, status=Epoch complete]
â–ˆ Epoch 28: Loss T 0.534593 V 0.633723 | F1 T 0.934605 V 0.814102 B 0.830318 SC 17/50 | Acc T 0.935478 V 0.816003 | LR 6.99e-06 | Grad â†“ 0.000000 â†‘ 4.332369 M 0.491855 | 23m 45s
Epoch 29/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [23:45<00:00,  1.79s/it, loss=0.4461, lr=2.01e-06, grad=M:0.2510, status=Epoch complete]
â–ˆ Epoch 29: Loss T 0.446078 V 0.688938 | F1 T 0.938553 V 0.812192 B 0.830318 SC 18/50 | Acc T 0.938896 V 0.813975 | LR 2.01e-06 | Grad â†“ 0.000000 â†‘ 1.922468 M 0.250988 | 23m 45s
Epoch 30/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [23:44<00:00,  1.78s/it, loss=0.4204, lr=1.00e-07, grad=M:0.2110, status=Epoch complete]
â–ˆ Epoch 30: Loss T 0.420421 V 0.681516 | F1 T 0.941883 V 0.812795 B 0.830318 SC 19/50 | Acc T 0.942402 V 0.814344 | LR 1.00e-07 | Grad â†“ 0.000000 â†‘ 1.435026 M 0.210959 | 23m 44s
Memory: Rank 0: 34.84 GB | Rank 1: 35.43 GB | Rank 2: 35.70 GB | Rank 3: 35.46 GB | Rank 4: 35.43 GB | Rank 5: 35.46 GB | Rank 6: 35.43 GB | Rank 7: 35.31 GB (Max: 42.29 GB, Total: 338.28 GB)
Saved model state: checkpoints/checkpoint_epoch_30_20241024-144728.pth
Epoch 31/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [23:46<00:00,  1.79s/it, loss=0.4956, lr=1.81e-05, grad=M:0.2443, status=Epoch complete]
â–ˆ Epoch 31: Loss T 0.495585 V 0.759797 | F1 T 0.939545 V 0.800994 B 0.830318 SC 20/50 | Acc T 0.940404 V 0.802176 | LR 1.81e-05 | Grad â†“ 0.000000 â†‘ 1.883388 M 0.244282 | 23m 46s
Epoch 32/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [23:44<00:00,  1.79s/it, loss=0.3920, lr=1.31e-05, grad=M:0.1950, status=Epoch complete]
â–ˆ Epoch 32: Loss T 0.391981 V 0.669718 | F1 T 0.953774 V 0.819989 B 0.830318 SC 21/50 | Acc T 0.954204 V 0.821903 | LR 1.31e-05 | Grad â†“ 0.000000 â†‘ 1.405856 M 0.194971 | 23m 44s
Epoch 33/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [23:43<00:00,  1.78s/it, loss=0.3324, lr=6.99e-06, grad=M:0.2158, status=Epoch complete]
â–ˆ Epoch 33: Loss T 0.332382 V 0.734744 | F1 T 0.962870 V 0.819044 B 0.830318 SC 22/50 | Acc T 0.963106 V 0.820059 | LR 6.99e-06 | Grad â†“ 0.000000 â†‘ 1.604935 M 0.215787 | 23m 43s
Epoch 34/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [23:45<00:00,  1.79s/it, loss=0.3054, lr=2.01e-06, grad=M:0.2183, status=Epoch complete]
â–ˆ Epoch 34: Loss T 0.305400 V 0.759872 | F1 T 0.965451 V 0.819850 B 0.830318 SC 23/50 | Acc T 0.965672 V 0.820796 | LR 2.01e-06 | Grad â†“ 0.000000 â†‘ 1.258677 M 0.218292 | 23m 45s
Epoch 35/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [15:16<00:00,  1.05s/it, loss=0.2921, lr=1.00e-07, grad=M:0.1751, status=Consolidating optimizer state...]^C
Ctrl+C received. Terminating all processes...
Rank 0 - Current process: MainProcess cleaning up...
Terminating all child processes of MainProcess...
Terminated child process: SpawnProcess-5
Terminated child process: SpawnProcess-4
Terminated child process: SpawnProcess-2
Terminated child process: SpawnProcess-8
Terminated child process: SpawnProcess-1
Terminated child process: SpawnProcess-3
Terminated child process: SpawnProcess-7
Terminated child process: SpawnProcess-6
Rank 0 - Exiting program...
/usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
(nlp) ubuntu@138-2-58-218:~/nlp-osaka/sentiment$ python ./ddp_sentiment_finetune.py --dataset 'merged_local' --weights_name 'google/electra-large-discriminator' --save_data --save_model --save_pickle --save_preds --lr 0.00001 --lr_decay 0.95 --epochs 50 --pooling 'mean' --dropout_rate 0.3 --num_layers 2 --hidden_dim 1024 --hidden_activation 'swishglu' --batch_size 16 --accumulation_steps 2 --finetune_bert --finetune_layers 24 --l2_strength 0.01  --checkpoint_interval 1 --use_zero --optimizer 'adamw' --scheduler 'cosine_warmup' --scheduler_kwargs '{"T_0":5, "T_mult":1, "eta_min":1e-7}' --decimal 6 --use_val_split --eval_split 'test' --early_stop 'score' --n_iter_no_change 10 --show_progress --wandb --wandb_project 'Electra Large' --wandb_run 'stage_1_merged'

Starting DDP PyTorch Training...
Device: cuda, Number of GPUs: 8
Spawning 8 processes...
Rank 1 - Device: cuda:1
Rank 4 - Device: cuda:4
Rank 6 - Device: cuda:6
Rank 2 - Device: cuda:2
Rank 5 - Device: cuda:5
Rank 7 - Device: cuda:7
Rank 3 - Device: cuda:3
Rank 0 - Device: cuda:0
8 process groups initialized with 'nccl' backend on localhost:12355
NCCL Timeout: 1 hr 0 min. NCCL Blocking Wait: Enabled
wandb: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: jbeno (jimbeno). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.5
wandb: Run data is saved locally in /home/ubuntu/nlp-osaka/sentiment/wandb/run-20241024_164255-nsy5h33f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stage_1_merged
wandb: â­ï¸ View project at https://wandb.ai/jimbeno/Electra%20Large
wandb: ðŸš€ View run at https://wandb.ai/jimbeno/Electra%20Large/runs/nsy5h33f
Wand run initialized.

Initializing 'google/electra-large-discriminator' tokenizer and model...
Checking for local files...
Found all files in cache, skipping download
All ranks loading tokenizer from local files...
All ranks loading model from local files...
Tokenizer and model initialized (5s)

Loading data...
Using the same dataset for training and evaluation
Splits:
- Train: Using merged_local 'train' split
- Validation: Using merged_local 'validation' split
- Evaluation: Using merged_local 'test' split
Train Data: Merged DynaSent Round 1, Round 2 and SST from Local: 'data/merged'
Validation Data: Merged DynaSent Round 1, Round 2 and SST from Local: 'data/merged'
Evaluation Data: Merged DynaSent Round 1, Round 2 and SST from Local: 'data/merged'
Train size: 102097
Validation size: 5421
Evaluation size: 5421
Train label distribution:
	      Negative: 21910
	       Neutral: 49148
	      Positive: 31039
Validation label distribution:
	      Negative: 1868
	       Neutral: 1669
	      Positive: 1884
Evaluation label distribution:
	      Negative: 1868
	       Neutral: 1669
	      Positive: 1884
Data loaded (703ms)

Processing data...
(Batch size: 16, Pooling: Mean, Fine Tune BERT: True, Chunk size: None)...
Extracting sentences and labels...

Data saved to: saves/data_8_gpu_20241024-164303.npz
X Train shape: [102097], X Validation shape: [5421], X Test shape: [5421]
y Train shape: [102097], y Validation shape: [5421], y Test shape: [5421]
Data processed (847ms)

Initializing DDP Neural Classifier...
Layers: 2, Hidden Dim: 1024, Hidden Act: SwishGLU, Dropout: 0.3, Optimizer: AdamW, L2 Strength: 0.01, Pooling: MEAN, Accumulation Steps: 2, Max Grad Norm: None
Batch Size: 16, Max Epochs: 50, LR: 1e-05, Early Stop: score, Fine-tune BERT: True, Fine-tune Layers: 24, Freeze BERT: False, Target Score: None, Interactive: False
Classifier initialized (28ms)

Fitting DDP Neural Classifier on training data...
Num Workers: 0, Prefetch: None
Score-based early stopping enabled (macro average F1 score against validation set). Validation fraction: 0.1
Training will stop early if the score does not improve by at least 0.00001 for 10 iterations.
Using provided validation set for early stopping.
Building dataset and dataloader...
Initializing model, graph, optimizer...
BERT's original pooler removed. Using custom pooling type: mean
BERT has 334,092,288 trainable parameters and 0 non-trainable parameters
Number of BERT layers requiring gradients: 24 out of 24
Fine-tuning the last 24 out of 24 BERT layers

Model Architecture Summary:
BERTClassifier(
  (bert): ElectraModel(
    (embeddings): ElectraEmbeddings(
      (word_embeddings): Embedding(30522, 1024, padding_idx=0)
      (position_embeddings): Embedding(512, 1024)
      (token_type_embeddings): Embedding(2, 1024)
      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): ElectraEncoder(
      (layer): ModuleList(
        (0-23): 24 x ElectraLayer(
          (attention): ElectraAttention(
            (self): ElectraSelfAttention(
              (query): Linear(in_features=1024, out_features=1024, bias=True)
              (key): Linear(in_features=1024, out_features=1024, bias=True)
              (value): Linear(in_features=1024, out_features=1024, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): ElectraSelfOutput(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): ElectraIntermediate(
            (dense): Linear(in_features=1024, out_features=4096, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): ElectraOutput(
            (dense): Linear(in_features=4096, out_features=1024, bias=True)
            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
  (custom_pooling): PoolingLayer()
  (classifier): Classifier(
    (layers): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): SwishGLU(
        (projection): Linear(in_features=1024, out_features=2048, bias=True)
        (activation): SiLU()
      )
      (2): Dropout(p=0.3, inplace=False)
      (3): Linear(in_features=1024, out_features=1024, bias=True)
      (4): SwishGLU(
        (projection): Linear(in_features=1024, out_features=2048, bias=True)
        (activation): SiLU()
      )
      (5): Dropout(p=0.3, inplace=False)
      (6): Linear(in_features=1024, out_features=3, bias=True)
    )
  )
)

Model Parameters:
  bert.embeddings.word_embeddings: 31,254,528 (trainable)
  bert.embeddings.position_embeddings: 524,288 (trainable)
  bert.embeddings.token_type_embeddings: 2,048 (trainable)
  bert.embeddings.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.0.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.0.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.0.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.0.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.0.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.0.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.0.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.0.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.1.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.1.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.1.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.1.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.1.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.1.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.1.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.1.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.2.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.2.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.2.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.2.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.2.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.2.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.2.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.2.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.3.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.3.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.3.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.3.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.3.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.3.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.3.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.3.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.4.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.4.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.4.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.4.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.4.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.4.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.4.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.4.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.5.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.5.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.5.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.5.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.5.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.5.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.5.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.5.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.6.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.6.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.6.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.6.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.6.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.6.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.6.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.6.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.7.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.7.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.7.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.7.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.7.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.7.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.7.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.7.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.8.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.8.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.8.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.8.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.8.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.8.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.8.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.8.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.9.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.9.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.9.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.9.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.9.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.9.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.9.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.9.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.10.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.10.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.10.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.10.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.10.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.10.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.10.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.10.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.11.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.11.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.11.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.11.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.11.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.11.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.11.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.11.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.12.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.12.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.12.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.12.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.12.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.12.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.12.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.12.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.13.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.13.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.13.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.13.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.13.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.13.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.13.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.13.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.14.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.14.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.14.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.14.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.14.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.14.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.14.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.14.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.15.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.15.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.15.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.15.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.15.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.15.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.15.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.15.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.16.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.16.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.16.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.16.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.16.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.16.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.16.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.16.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.17.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.17.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.17.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.17.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.17.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.17.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.17.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.17.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.18.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.18.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.18.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.18.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.18.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.18.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.18.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.18.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.19.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.19.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.19.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.19.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.19.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.19.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.19.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.19.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.20.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.20.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.20.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.20.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.20.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.20.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.20.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.20.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.21.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.21.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.21.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.21.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.21.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.21.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.21.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.21.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.22.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.22.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.22.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.22.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.22.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.22.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.22.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.22.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.23.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.23.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.23.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.23.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.23.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.23.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.23.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.23.output.LayerNorm: 2,048 (trainable)
  classifier.layers.0: 1,049,600 (trainable)
  classifier.layers.1.projection: 2,099,200 (trainable)
  classifier.layers.3: 1,049,600 (trainable)
  classifier.layers.6: 3,075 (trainable)

Total layers: 200
Trainable layers: 200
Total parameters: 338,293,763
Trainable parameters: 338,293,763
Percentage of trainable parameters: 100.00%
Using optimizer: AdamW, Use Zero: True, Base Learning Rate: 1e-05, L2 strength: 0.01
Layer-wise decay factor: 0.95
Using scheduler: CosineAnnealingWarmRestarts
Scheduler arguments:
- T_0: 5
- T_mult: 1
- eta_min: 1e-07

Starting training loop...
Start epoch: 1, Max Iterations: 50, Early Stop: score, Tolerance: 0.00001, Number Iterations No Change: 10
Epoch 1/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [23:56<00:00,  1.80s/it, loss=1.8021, lr=9.06e-06, grad=M:0.1559, status=Epoch complete]
â–ˆ Epoch  1: Loss T 1.802063 V 0.977394 | F1 T 0.438215 V 0.387110 B 0.387110 SC 0/10 | Acc T 0.617831 V 0.477323 | LR 9.06e-06 | Grad â†“ 0.000000 â†‘ 1.019622 M 0.155868 | 23m 56s
Saved model state: checkpoints/checkpoint_epoch_1_20241024-170701.pth
Epoch 2/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [23:49<00:00,  1.79s/it, loss=1.6227, lr=6.59e-06, grad=M:0.3681, status=Epoch complete]
â–ˆ Epoch  2: Loss T 1.622710 V 1.001343 | F1 T 0.280226 V 0.230577 B 0.387110 SC 1/10 | Acc T 0.479403 V 0.317294 | LR 6.59e-06 | Grad â†“ 0.000000 â†‘ 6.276710 M 0.368088 | 23m 49s
Saved model state: checkpoints/checkpoint_epoch_2_20241024-173101.pth
Epoch 3/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [23:46<00:00,  1.79s/it, loss=1.3071, lr=3.53e-06, grad=M:0.2323, status=Epoch complete]
â–ˆ Epoch  3: Loss T 1.307086 V 0.747763 | F1 T 0.814584 V 0.785051 B 0.785051 SC 0/10 | Acc T 0.823905 V 0.785951 | LR 3.53e-06 | Grad â†“ 0.000000 â†‘ 1.717918 M 0.232323 | 23m 46s
Saved model state: checkpoints/checkpoint_epoch_3_20241024-175458.pth
Epoch 4/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [23:46<00:00,  1.79s/it, loss=1.0096, lr=1.05e-06, grad=M:0.3289, status=Epoch complete]
â–ˆ Epoch  4: Loss T 1.009605 V 0.511187 | F1 T 0.837251 V 0.818891 B 0.818891 SC 0/10 | Acc T 0.841123 V 0.821165 | LR 1.05e-06 | Grad â†“ 0.000000 â†‘ 1.896666 M 0.328932 | 23m 46s
Saved model state: checkpoints/checkpoint_epoch_4_20241024-181854.pth
Epoch 5/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [23:48<00:00,  1.79s/it, loss=0.9193, lr=1.00e-07, grad=M:0.1702, status=Epoch complete]
â–ˆ Epoch  5: Loss T 0.919257 V 0.506435 | F1 T 0.840524 V 0.818892 B 0.818891 SC 1/10 | Acc T 0.844531 V 0.820796 | LR 1.00e-07 | Grad â†“ 0.000000 â†‘ 1.223533 M 0.170223 | 23m 48s
Saved model state: checkpoints/checkpoint_epoch_5_20241024-184253.pth
Epoch 6/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [23:48<00:00,  1.79s/it, loss=0.9793, lr=9.06e-06, grad=M:0.2460, status=Epoch complete]
â–ˆ Epoch  6: Loss T 0.979336 V 0.531252 | F1 T 0.848298 V 0.808993 B 0.818891 SC 2/10 | Acc T 0.854139 V 0.809366 | LR 9.06e-06 | Grad â†“ 0.000000 â†‘ 1.462248 M 0.245967 | 23m 48s
Saved model state: checkpoints/checkpoint_epoch_6_20241024-190651.pth
Epoch 7/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [23:50<00:00,  1.79s/it, loss=1.0215, lr=6.59e-06, grad=M:0.8825, status=Epoch complete]
â–ˆ Epoch  7: Loss T 1.021522 V 0.522849 | F1 T 0.845441 V 0.805660 B 0.818891 SC 3/10 | Acc T 0.849359 V 0.806785 | LR 6.59e-06 | Grad â†“ 0.000000 â†‘ 7.864930 M 0.882471 | 23m 50s
Saved model state: checkpoints/checkpoint_epoch_7_20241024-193052.pth
Epoch 8/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [23:47<00:00,  1.79s/it, loss=0.8553, lr=3.53e-06, grad=M:0.6014, status=Epoch complete]
â–ˆ Epoch  8: Loss T 0.855313 V 0.486726 | F1 T 0.860747 V 0.820141 B 0.820141 SC 0/10 | Acc T 0.862953 V 0.822271 | LR 3.53e-06 | Grad â†“ 0.000000 â†‘ 4.323188 M 0.601362 | 23m 47s
Saved model state: checkpoints/checkpoint_epoch_8_20241024-195450.pth
Epoch 9/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [23:47<00:00,  1.79s/it, loss=0.7728, lr=1.05e-06, grad=M:0.1716, status=Epoch complete]
â–ˆ Epoch  9: Loss T 0.772813 V 0.489708 | F1 T 0.869819 V 0.822752 B 0.822752 SC 0/10 | Acc T 0.872042 V 0.824484 | LR 1.05e-06 | Grad â†“ 0.000000 â†‘ 1.088907 M 0.171570 | 23m 47s
Saved model state: checkpoints/checkpoint_epoch_9_20241024-201847.pth
Epoch 10/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [23:46<00:00,  1.79s/it, loss=0.7459, lr=1.00e-07, grad=M:0.9090, status=Epoch complete]
â–ˆ Epoch 10: Loss T 0.745933 V 0.488204 | F1 T 0.870207 V 0.825287 B 0.825287 SC 0/10 | Acc T 0.872307 V 0.827065 | LR 1.00e-07 | Grad â†“ 0.000000 â†‘ 8.420140 M 0.909050 | 23m 46s
Memory: Rank 0: 34.87 GB | Rank 1: 35.46 GB | Rank 2: 35.66 GB | Rank 3: 35.46 GB | Rank 4: 35.46 GB | Rank 5: 35.46 GB | Rank 6: 35.46 GB | Rank 7: 35.31 GB (Max: 42.29 GB, Total: 338.28 GB)
Saved model state: checkpoints/checkpoint_epoch_10_20241024-204300.pth
Epoch 11/50:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–       | 732/798 [13:58<01:15,  1.14s/it, loss=0.3793, lr=9.20e-06, grad=M:0.2059Epoch 11/50:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ       | 733/798 [13:59<01:14,  1.15s/it, loss=0.3793, lr=9.20e-06, grad=M:0.2059Epoch 11/50:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ       | 733/798 [13:59<01:14,  1.15s/it, loss=0.3773, lr=9.20e-06, grad=M:0.3965Epoch 11/50:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹       | 734/798 [14:01<01:13,  1.14s/it, loss=0.3773, lr=9.20e-06, grad=M:0.3965Epoch 11/50:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹       | 734/798 [14:01<01:13,  1.14s/it, loss=0.4248, lr=9.20e-06, grad=M:0.2065Epoch 11/50:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š       | 735/798 [14:02<01:12,  1.15s/it, loss=0.4248, lr=9.20e-06, grad=M:0.2065Epoch 11/50:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š       | 735/798 [14:02<01:12,  1.15s/it, loss=0.3784, lr=9.20e-06, grad=M:0.2829Epoch 11/50:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰       | 736/798 [14:03<01:10,  1.14s/it, loss=0.3784, lr=9.20e-06, grad=M:0.2829Epoch 11/50:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰       | 736/798 [14:03<01:10,  1.14s/it, loss=0.3744, lr=9.20e-06, grad=M:1.1504Epoch 11/50:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ       | 737/798 [14:04<01:09,  1.15s/it, loss=0.3744, lr=9.20e-06, grad=M:1.1504Epoch 11/50:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ       | 737/798 [14:04<01:09,  1.15s/it, loss=0.3979, lr=9.19e-06, grad=M:1.2198Epoch 11/50:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–      | 738/798 [14:05<01:08,  1.14s/it, loss=0.3979, lr=9.19e-06, grad=M:1.2198Epoch 11/50:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–      | 738/798 [14:05<01:08,  1.14s/it, loss=0.4567, lr=9.19e-06, grad=M:0.2245Epoch 11/50:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž      | 739/798 [14:06<01:07,  1.15s/it, loss=0.4567, lr=9.19e-06, grad=M:0.2245Epoch 11/50:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž      | 739/798 [14:06<01:07,  1.15s/it, loss=0.3285, lr=9.19e-06, grad=M:0.3264Epoch 11/50:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–      | 740/798 [14:07<01:06,  1.14s/it, loss=0.3285, lr=9.19e-06, grad=M:0.3264Epoch 11/50:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–      | 740/798 [14:07<01:06,  1.14s/it, loss=0.4852, lr=9.19e-06, grad=M:0.2809Epoch 11/50:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ      | 741/798 [14:09<01:09,  1.23s/it, loss=0.4852, lr=9.19e-06, grad=M:0.2809Epoch 11/50:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ      | 741/798 [14:09<01:09,  1.23s/it, loss=0.3809, lr=9.18e-06, grad=M:0.5035Epoch 11/50:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ      | 742/798 [14:10<01:07,  1.20s/it, loss=0.3809, lr=9.18e-06, grad=M:0.5035Epoch 11/50:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ      | 742/798 [14:10<01:07,  1.20s/it, loss=0.3926, lr=9.18e-06, grad=M:0.1796Epoch 11/50:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹      | 743/798 [14:11<01:05,  1.18s/it, loss=0.3926, lr=9.18e-06, grad=M:0.1796Epoch 11/50:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹      | 743/798 [14:11<01:05,  1.18s/it, loss=0.4537, lr=9.18e-06, grad=M:0.2552Epoch 11/50:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š      | 744/798 [14:12<01:03,  1.17s/it, loss=0.4537, lr=9.18e-06, grad=M:0.2552Epoch 11/50:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š      | 744/798 [14:12<01:03,  1.17s/it, loss=0.3637, lr=9.18e-06, grad=M:0.1770Epoch 11/50:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰      | 745/798 [14:13<01:01,  1.16s/it, loss=0.3637, lr=9.18e-06, grad=M:0.1770Epoch 11/50:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰      | 745/798 [14:13<01:01,  1.16s/it, loss=0.4148, lr=9.17e-06, grad=M:0.2633Epoch 11/50:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ      | 746/798 [14:15<01:00,  1.15s/it, loss=0.4148, lr=9.17e-06, grad=M:0.2633Epoch 11/50:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ      | 746/798 [14:15<01:00,  1.15s/it, loss=0.4460, lr=9.17e-06, grad=M:0.3555Epoch 11/50:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–     | 747/798 [14:16<00:58,  1.15s/it, loss=0.4460, lr=9.17e-06, grad=M:0.3555Epoch 11/50:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–     | 747/798 [14:16<00:58,  1.15s/it, loss=0.4866, lr=9.17e-06, grad=M:0.4459Epoch 11/50:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 748/798 [14:17<00:57,  1.15s/it, loss=0.4866, lr=9.17e-06, grad=M:0.4459Epoch 11/50:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 748/798 [14:17<00:57,  1.15s/it, loss=0.4093, lr=9.17e-06, grad=M:0.2429Epoch 11/50:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–     | 749/798 [14:18<00:56,  1.15s/it, loss=0.4093, lr=9.17e-06, grad=M:0.2429Epoch 11/50:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–     | 749/798 [14:18<00:56,  1.15s/it, loss=0.3397, lr=9.17e-06, grad=M:0.5822Epoch 11/50:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 750/798 [14:19<00:54,  1.14s/it, loss=0.3397, lr=9.17e-06, grad=M:0.5822Epoch 11/50:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 750/798 [14:19<00:54,  1.14s/it, loss=0.3844, lr=9.17e-06, grad=M:0.2929Epoch 11/50:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 751/798 [14:20<00:54,  1.15s/it, loss=0.3844, lr=9.17e-06, grad=M:0.2929Epoch 11/50:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 751/798 [14:20<00:54,  1.15s/it, loss=0.3976, lr=9.16e-06, grad=M:0.3840Epoch 11/50:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 752/798 [14:21<00:52,  1.14s/it, loss=0.3976, lr=9.16e-06, grad=M:0.3840Epoch 11/50:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 752/798 [14:21<00:52,  1.14s/it, loss=0.4062, lr=9.16e-06, grad=M:0.1838Epoch 11/50:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 753/798 [14:23<00:51,  1.15s/it, loss=0.4062, lr=9.16e-06, grad=M:0.1838Epoch 11/50:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 753/798 [14:23<00:51,  1.15s/it, loss=0.3730, lr=9.16e-06, grad=M:0.2333Epoch 11/50:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 754/798 [14:24<00:50,  1.14s/it, loss=0.3730, lr=9.16e-06, grad=M:0.2333Epoch 11/50:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 754/798 [14:24<00:50,  1.14s/it, loss=0.3633, lr=9.16e-06, grad=M:0.1895Epoch 11/50:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 755/798 [14:25<00:51,  1.19s/it, loss=0.3633, lr=9.16e-06, grad=M:0.1895Epoch 11/50:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 755/798 [14:25<00:51,  1.19s/it, loss=0.3179, lr=9.15e-06, grad=M:0.2492Epoch 11/50:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 756/798 [14:26<00:49,  1.17s/it, loss=0.3179, lr=9.15e-06, grad=M:0.2492Epoch 11/50:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 756/798 [14:26<00:49,  1.17s/it, loss=0.3049, lr=9.15e-06, grad=M:0.1459Epoch 11/50:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 757/798 [14:27<00:47,  1.17s/it, loss=0.3049, lr=9.15e-06, grad=M:0.1459Epoch 11/50:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 757/798 [14:27<00:47,  1.17s/it, loss=0.4746, lr=9.15e-06, grad=M:0.2666Epoch 11/50:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 758/798 [14:28<00:46,  1.16s/it, loss=0.4746, lr=9.15e-06, grad=M:0.2666Epoch 11/50:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 758/798 [14:28<00:46,  1.16s/it, loss=0.3740, lr=9.15e-06, grad=M:0.1589Epoch 11/50:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 759/798 [14:30<00:45,  1.16s/it, loss=0.3740, lr=9.15e-06, grad=M:0.1589Epoch 11/50:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 759/798 [14:30<00:45,  1.16s/it, loss=0.4801, lr=9.14e-06, grad=M:0.2544Epoch 11/50:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 760/798 [14:31<00:43,  1.15s/it, loss=0.4801, lr=9.14e-06, grad=M:0.2544Epoch 11/50:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 760/798 [14:31<00:43,  1.15s/it, loss=0.2846, lr=9.14e-06, grad=M:0.1461Epoch 11/50:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 761/798 [14:32<00:42,  1.15s/it, loss=0.2846, lr=9.14e-06, grad=M:0.1461Epoch 11/50:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 761/798 [14:32<00:42,  1.15s/it, loss=0.4554, lr=9.14e-06, grad=M:0.2283Epoch 11/50:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 762/798 [14:33<00:41,  1.15s/it, loss=0.4554, lr=9.14e-06, grad=M:0.2283Epoch 11/50:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 762/798 [14:33<00:41,  1.15s/it, loss=0.3678, lr=9.14e-06, grad=M:0.1368Epoch 11/50:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 763/798 [14:34<00:40,  1.15s/it, loss=0.3678, lr=9.14e-06, grad=M:0.1368Epoch 11/50:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 763/798 [14:34<00:40,  1.15s/it, loss=0.3360, lr=9.14e-06, grad=M:0.2371Epoch 11/50:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 764/798 [14:35<00:38,  1.14s/it, loss=0.3360, lr=9.14e-06, grad=M:0.2371Epoch 11/50:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 764/798 [14:35<00:38,  1.14s/it, loss=0.4315, lr=9.14e-06, grad=M:0.2933Epoch 11/50:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 765/798 [14:37<00:40,  1.22s/it, loss=0.4315, lr=9.14e-06, grad=M:0.2933Epoch 11/50:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 765/798 [14:37<00:40,  1.22s/it, loss=0.4590, lr=9.13e-06, grad=M:0.3239Epoch 11/50:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 766/798 [14:38<00:38,  1.19s/it, loss=0.4590, lr=9.13e-06, grad=M:0.3239Epoch 11/50:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 766/798 [14:38<00:38,  1.19s/it, loss=0.4293, lr=9.13e-06, grad=M:0.1368Epoch 11/50:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 767/798 [14:39<00:36,  1.18s/it, loss=0.4293, lr=9.13e-06, grad=M:0.1368Epoch 11/50:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 767/798 [14:39<00:36,  1.18s/it, loss=0.4256, lr=9.13e-06, grad=M:0.2853Epoch 11/50:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 768/798 [14:40<00:34,  1.17s/it, loss=0.4256, lr=9.13e-06, grad=M:0.2853Epoch 11/50:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 768/798 [14:40<00:34,  1.17s/it, loss=0.3884, lr=9.13e-06, grad=M:0.3051Epoch 11/50:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 769/798 [14:41<00:33,  1.16s/it, loss=0.3884, lr=9.13e-06, grad=M:0.3051Epoch 11/50:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 769/798 [14:41<00:33,  1.16s/it, loss=0.5050, lr=9.12e-06, grad=M:0.5037Epoch 11/50:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 770/798 [14:42<00:32,  1.15s/it, loss=0.5050, lr=9.12e-06, grad=M:0.5037Epoch 11/50:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 770/798 [14:42<00:32,  1.15s/it, loss=0.4075, lr=9.12e-06, grad=M:0.2127Epoch 11/50:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 771/798 [14:44<00:31,  1.15s/it, loss=0.4075, lr=9.12e-06, grad=M:0.2127Epoch 11/50:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 771/798 [14:44<00:31,  1.15s/it, loss=0.3794, lr=9.12e-06, grad=M:0.2962Epoch 11/50:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 772/798 [14:45<00:29,  1.15s/it, loss=0.3794, lr=9.12e-06, grad=M:0.2962Epoch 11/50:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 772/798 [14:45<00:29,  1.15s/it, loss=0.4446, lr=9.12e-06, grad=M:0.1792Epoch 11/50:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 773/798 [14:46<00:28,  1.15s/it, loss=0.4446, lr=9.12e-06, grad=M:0.1792Epoch 11/50:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 773/798 [14:46<00:28,  1.15s/it, loss=0.3121, lr=9.11e-06, grad=M:0.2990Epoch 11/50:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 774/798 [14:47<00:27,  1.14s/it, loss=0.3121, lr=9.11e-06, grad=M:0.2990Epoch 11/50:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 774/798 [14:47<00:27,  1.14s/it, loss=0.4950, lr=9.11e-06, grad=M:0.5790Epoch 11/50:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 775/798 [14:48<00:26,  1.15s/it, loss=0.4950, lr=9.11e-06, grad=M:0.5790Epoch 11/50:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 775/798 [14:48<00:26,  1.15s/it, loss=0.3939, lr=9.11e-06, grad=M:0.5949Epoch 11/50:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 776/798 [14:49<00:25,  1.14s/it, loss=0.3939, lr=9.11e-06, grad=M:0.5949Epoch 11/50:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 776/798 [14:49<00:25,  1.14s/it, loss=0.2893, lr=9.11e-06, grad=M:0.2045Epoch 11/50:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 777/798 [14:50<00:24,  1.15s/it, loss=0.2893, lr=9.11e-06, grad=M:0.2045Epoch 11/50:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 777/798 [14:50<00:24,  1.15s/it, loss=0.3763, lr=9.10e-06, grad=M:0.4108Epoch 11/50:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 778/798 [14:52<00:22,  1.14s/it, loss=0.3763, lr=9.10e-06, grad=M:0.4108Epoch 11/50:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 778/798 [14:52<00:22,  1.14s/it, loss=0.4281, lr=9.10e-06, grad=M:0.2785Epoch 11/50:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 779/798 [14:53<00:21,  1.15s/it, loss=0.4281, lr=9.10e-06, grad=M:0.2785Epoch 11/50:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 779/798 [14:53<00:21,  1.15s/it, loss=0.5045, lr=9.10e-06, grad=M:0.4050Epoch 11/50:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 780/798 [14:54<00:20,  1.14s/it, loss=0.5045, lr=9.10e-06, grad=M:0.4050Epoch 11/50:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 780/798 [14:54<00:20,  1.14s/it, loss=0.3850, lr=9.10e-06, grad=M:0.2145Epoch 11/50:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 781/798 [14:55<00:19,  1.15s/it, loss=0.3850, lr=9.10e-06, grad=M:0.2145Epoch 11/50:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 781/798 [14:55<00:19,  1.15s/it, loss=0.3300, lr=9.10e-06, grad=M:0.3972Epoch 11/50:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 782/798 [14:56<00:18,  1.14s/it, loss=0.3300, lr=9.10e-06, grad=M:0.3972Epoch 11/50:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 782/798 [14:56<00:18,  1.14s/it, loss=0.2868, lr=9.10e-06, grad=M:0.1272Epoch 11/50:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 783/798 [14:57<00:17,  1.15s/it, loss=0.2868, lr=9.10e-06, grad=M:0.1272Epoch 11/50:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 783/798 [14:57<00:17,  1.15s/it, loss=0.3267, lr=9.09e-06, grad=M:0.2655Epoch 11/50:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 784/798 [14:58<00:15,  1.14s/it, loss=0.3267, lr=9.09e-06, grad=M:0.2655Epoch 11/50:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 784/798 [14:58<00:15,  1.14s/it, loss=0.4954, lr=9.09e-06, grad=M:0.2296Epoch 11/50:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 785/798 [15:00<00:14,  1.15s/it, loss=0.4954, lr=9.09e-06, grad=M:0.2296Epoch 11/50:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆEpoch 11/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [23:46<00:00,  1.79s/it, loss=0.7654, lr=9.06e-06, grad=M:0.4943, status=Epoch complete]
â–ˆ Epoch 11: Loss T 0.765393 V 0.491115 | F1 T 0.874726 V 0.820362 B 0.825287 SC 1/10 | Acc T 0.876861 V 0.821718 | LR 9.06e-06 | Grad â†“ 0.000000 â†‘ 3.753560 M 0.494250 | 23m 46s
Saved model state: checkpoints/checkpoint_epoch_11_20241024-210656.pth
Epoch 12/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [23:46<00:00,  1.79s/it, loss=0.7184, lr=6.59e-06, grad=M:0.2340, status=Epoch complete]
â–ˆ Epoch 12: Loss T 0.718415 V 0.482274 | F1 T 0.877408 V 0.821888 B 0.825287 SC 2/10 | Acc T 0.878232 V 0.824115 | LR 6.59e-06 | Grad â†“ 0.000000 â†‘ 1.631634 M 0.233999 | 23m 46s
Saved model state: checkpoints/checkpoint_epoch_12_20241024-213053.pth
Epoch 13/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [23:48<00:00,  1.79s/it, loss=0.6810, lr=3.53e-06, grad=M:0.2726, status=Epoch complete]
â–ˆ Epoch 13: Loss T 0.680988 V 0.493630 | F1 T 0.889732 V 0.825522 B 0.825522 SC 0/10 | Acc T 0.891229 V 0.827249 | LR 3.53e-06 | Grad â†“ 0.000000 â†‘ 1.849575 M 0.272574 | 23m 48s
Saved model state: checkpoints/checkpoint_epoch_13_20241024-215451.pth
Epoch 14/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [23:46<00:00,  1.79s/it, loss=0.6413, lr=1.05e-06, grad=M:0.2569, status=Epoch complete]
â–ˆ Epoch 14: Loss T 0.641319 V 0.507582 | F1 T 0.893861 V 0.824809 B 0.825522 SC 1/10 | Acc T 0.895313 V 0.826512 | LR 1.05e-06 | Grad â†“ 0.000000 â†‘ 1.808147 M 0.256895 | 23m 46s
Saved model state: checkpoints/checkpoint_epoch_14_20241024-221848.pth
Epoch 15/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [23:48<00:00,  1.79s/it, loss=0.6187, lr=1.00e-07, grad=M:0.2937, status=Epoch complete]
â–ˆ Epoch 15: Loss T 0.618691 V 0.521020 | F1 T 0.894342 V 0.825079 B 0.825522 SC 2/10 | Acc T 0.895557 V 0.826881 | LR 1.00e-07 | Grad â†“ 0.000000 â†‘ 2.199311 M 0.293728 | 23m 48s
Saved model state: checkpoints/checkpoint_epoch_15_20241024-224246.pth
Epoch 16/50:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹      | 743/798 [14:11<01:06,  1.21s/it, loss=0.3448, lr=9.18e-06, grad=M:0.3736Epoch 16/50:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š      | 744/798 [14:12<01:03,  1.18s/it, loss=0.3448, lr=9.18e-06, grad=M:0.3736Epoch 16/50:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š      | 744/798 [14:12<01:03,  1.18s/it, loss=0.3032, lr=9.18e-06, grad=M:0.2460Epoch 16/50:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰      | 745/798 [14:13<01:02,  1.18s/it, loss=0.3032, lr=9.18e-06, grad=M:0.2460Epoch 16/50:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰      | 745/798 [14:13<01:02,  1.18s/it, loss=0.2856, lr=9.17e-06, grad=M:0.3052Epoch 16/50:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ      | 746/798 [14:14<01:00,  1.16s/it, loss=0.2856, lr=9.17e-06, grad=M:0.3052Epoch 16/50:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ      | 746/798 [14:14<01:00,  1.16s/it, loss=0.2783, lr=9.17e-06, grad=M:0.4921Epoch 16/50:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–     | 747/798 [14:15<00:59,  1.16s/it, loss=0.2783, lr=9.17e-06, grad=M:0.4921Epoch 16/50:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–     | 747/798 [14:15<00:59,  1.16s/it, loss=0.3012, lr=9.17e-06, grad=M:0.5372Epoch 16/50:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 748/798 [14:16<00:57,  1.15s/it, loss=0.3012, lr=9.17e-06, grad=M:0.5372Epoch 16/50:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 748/798 [14:16<00:57,  1.15s/it, loss=0.4039, lr=9.17e-06, grad=M:0.3765Epoch 16/50:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–     | 749/798 [14:18<00:56,  1.15s/it, loss=0.4039, lr=9.17e-06, grad=M:0.3765Epoch 16/50:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–     | 749/798 [14:18<00:56,  1.15s/it, loss=0.3017, lr=9.17e-06, grad=M:0.4179Epoch 16/50:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 750/798 [14:19<00:55,  1.15s/it, loss=0.3017, lr=9.17e-06, grad=M:0.4179Epoch 16/50:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 750/798 [14:19<00:55,  1.15s/it, loss=0.5105, lr=9.17e-06, grad=M:0.2541Epoch 16/50:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 751/798 [14:20<00:54,  1.15s/it, loss=0.5105, lr=9.17e-06, grad=M:0.2541Epoch 16/50:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 751/798 [14:20<00:54,  1.15s/it, loss=0.3918, lr=9.16e-06, grad=M:0.5992Epoch 16/50:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 752/798 [14:21<00:52,  1.14s/it, loss=0.3918, lr=9.16e-06, grad=M:0.5992Epoch 16/50:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 752/798 [14:21<00:52,  1.14s/it, loss=0.3280, lr=9.16e-06, grad=M:0.2470Epoch 16/50:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 753/798 [14:22<00:51,  1.15s/it, loss=0.3280, lr=9.16e-06, grad=M:0.2470Epoch 16/50:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 753/798 [14:22<00:51,  1.15s/it, loss=0.4193, lr=9.16e-06, grad=M:0.3289Epoch 16/50:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 754/798 [14:23<00:50,  1.14s/it, loss=0.4193, lr=9.16e-06, grad=M:0.3289Epoch 16/50:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 754/798 [14:23<00:50,  1.14s/it, loss=0.3320, lr=9.16e-06, grad=M:0.2671Epoch 16/50:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 755/798 [14:24<00:49,  1.15s/it, loss=0.3320, lr=9.16e-06, grad=M:0.2671Epoch 16/50:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 755/798 [14:24<00:49,  1.15s/it, loss=0.3882, lr=9.15e-06, grad=M:0.3961Epoch 16/50:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 756/798 [14:26<00:48,  1.14s/it, loss=0.3882, lr=9.15e-06, grad=M:0.3961Epoch 16/50:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 756/798 [14:26<00:48,  1.14s/it, loss=0.3158, lr=9.15e-06, grad=M:0.1733Epoch 16/50:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 757/798 [14:27<00:47,  1.15s/it, loss=0.3158, lr=9.15e-06, grad=M:0.1733Epoch 16/50:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 757/798 [14:27<00:47,  1.15s/it, loss=0.3561, lr=9.15e-06, grad=M:0.2575Epoch 16/50:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 758/798 [14:28<00:45,  1.14s/it, loss=0.3561, lr=9.15e-06, grad=M:0.2575Epoch 16/50:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 758/798 [14:28<00:45,  1.14s/it, loss=0.3446, lr=9.15e-06, grad=M:0.2411Epoch 16/50:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 759/798 [14:29<00:44,  1.15s/it, loss=0.3446, lr=9.15e-06, grad=M:0.2411Epoch 16/50:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 759/798 [14:29<00:44,  1.15s/it, loss=0.3909, lr=9.14e-06, grad=M:0.3767Epoch 16/50:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 760/798 [14:30<00:43,  1.14s/it, loss=0.3909, lr=9.14e-06, grad=M:0.3767Epoch 16/50:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 760/798 [14:30<00:43,  1.14s/it, loss=0.2457, lr=9.14e-06, grad=M:0.1439Epoch 16/50:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 761/798 [14:31<00:42,  1.15s/it, loss=0.2457, lr=9.14e-06, grad=M:0.1439Epoch 16/50:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 761/798 [14:31<00:42,  1.15s/it, loss=0.2678, lr=9.14e-06, grad=M:0.2335Epoch 16/50:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 762/798 [14:32<00:41,  1.14s/it, loss=0.2678, lr=9.14e-06, grad=M:0.2335Epoch 16/50:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 762/798 [14:32<00:41,  1.14s/it, loss=0.3323, lr=9.14e-06, grad=M:0.1921Epoch 16/50:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 763/798 [14:34<00:40,  1.15s/it, loss=0.3323, lr=9.14e-06, grad=M:0.1921Epoch 16/50:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 763/798 [14:34<00:40,  1.15s/it, loss=0.3104, lr=9.14e-06, grad=M:0.2677Epoch 16/50:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 764/798 [14:35<00:38,  1.14s/it, loss=0.3104, lr=9.14e-06, grad=M:0.2677Epoch 16/50:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 764/798 [14:35<00:38,  1.14s/it, loss=0.3801, lr=9.14e-06, grad=M:0.7553Epoch 16/50:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 765/798 [14:36<00:37,  1.15s/it, loss=0.3801, lr=9.14e-06, grad=M:0.7553Epoch 16/50:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 765/798 [14:36<00:37,  1.15s/it, loss=0.4271, lr=9.13e-06, grad=M:2.4087Epoch 16/50:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 766/798 [14:37<00:36,  1.14s/it, loss=0.4271, lr=9.13e-06, grad=M:2.4087Epoch 16/50:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 766/798 [14:37<00:36,  1.14s/it, loss=0.3472, lr=9.13e-06, grad=M:1.2581Epoch 16/50:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 767/798 [14:38<00:35,  1.15s/it, loss=0.3472, lr=9.13e-06, grad=M:1.2581Epoch 16/50:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 767/798 [14:38<00:35,  1.15s/it, loss=0.3580, lr=9.13e-06, grad=M:1.2906Epoch 16/50:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 768/798 [14:39<00:34,  1.14s/it, loss=0.3580, lr=9.13e-06, grad=M:1.2906Epoch 16/50:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 768/798 [14:39<00:34,  1.14s/it, loss=0.3804, lr=9.13e-06, grad=M:0.2389Epoch 16/50:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 769/798 [14:41<00:33,  1.15s/it, loss=0.3804, lr=9.13e-06, grad=M:0.2389Epoch 16/50:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 769/798 [14:41<00:33,  1.15s/it, loss=0.3257, lr=9.12e-06, grad=M:0.3182Epoch 16/50:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 770/798 [14:42<00:31,  1.14s/it, loss=0.3257, lr=9.12e-06, grad=M:0.3182Epoch 16/50:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 770/798 [14:42<00:31,  1.14s/it, loss=0.3453, lr=9.12e-06, grad=M:0.5254Epoch 16/50:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 771/798 [14:43<00:30,  1.15s/it, loss=0.3453, lr=9.12e-06, grad=M:0.5254Epoch 16/50:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 771/798 [14:43<00:30,  1.15s/it, loss=0.3488, lr=9.12e-06, grad=M:0.5994Epoch 16/50:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 772/798 [14:44<00:29,  1.14s/it, loss=0.3488, lr=9.12e-06, grad=M:0.5994Epoch 16/50:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 772/798 [14:44<00:29,  1.14s/it, loss=0.3384, lr=9.12e-06, grad=M:0.5632Epoch 16/50:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 773/798 [14:45<00:28,  1.15s/it, loss=0.3384, lr=9.12e-06, grad=M:0.5632Epoch 16/50:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 773/798 [14:45<00:28,  1.15s/it, loss=0.2667, lr=9.11e-06, grad=M:0.8645Epoch 16/50:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 774/798 [14:46<00:27,  1.14s/it, loss=0.2667, lr=9.11e-06, grad=M:0.8645Epoch 16/50:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 774/798 [14:46<00:27,  1.14s/it, loss=0.3235, lr=9.11e-06, grad=M:0.6569Epoch 16/50:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 775/798 [14:47<00:26,  1.15s/it, loss=0.3235, lr=9.11e-06, grad=M:0.6569Epoch 16/50:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 775/798 [14:47<00:26,  1.15s/it, loss=0.3188, lr=9.11e-06, grad=M:0.7588Epoch 16/50:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 776/798 [14:49<00:25,  1.14s/it, loss=0.3188, lr=9.11e-06, grad=M:0.7588Epoch 16/50:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 776/798 [14:49<00:25,  1.14s/it, loss=0.3151, lr=9.11e-06, grad=M:0.3164Epoch 16/50:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 777/798 [14:50<00:24,  1.15s/it, loss=0.3151, lr=9.11e-06, grad=M:0.3164Epoch 16/50:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 777/798 [14:50<00:24,  1.15s/it, loss=0.4231, lr=9.10e-06, grad=M:0.7090Epoch 16/50:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 778/798 [14:51<00:22,  1.14s/it, loss=0.4231, lr=9.10e-06, grad=M:0.7090Epoch 16/50:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 778/798 [14:51<00:22,  1.14s/it, loss=0.2499, lr=9.10e-06, grad=M:0.1645Epoch 16/50:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 779/798 [14:52<00:21,  1.15s/it, loss=0.2499, lr=9.10e-06, grad=M:0.1645Epoch 16/50:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 779/798 [14:52<00:21,  1.15s/it, loss=0.3100, lr=9.10e-06, grad=M:0.3232Epoch 16/50:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 780/798 [14:53<00:20,  1.14s/it, loss=0.3100, lr=9.10e-06, grad=M:0.3232Epoch 16/50:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 780/798 [14:53<00:20,  1.14s/it, loss=0.3585, lr=9.10e-06, grad=M:0.2186Epoch 16/50:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 781/798 [14:54<00:19,  1.15s/it, loss=0.3585, lr=9.10e-06, grad=M:0.2186Epoch 16/50:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 781/798 [14:54<00:19,  1.15s/it, loss=0.3706, lr=9.10e-06, grad=M:0.3734Epoch 16/50:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 782/798 [14:55<00:18,  1.14s/it, loss=0.3706, lr=9.10e-06, grad=M:0.3734Epoch 16/50:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 782/798 [14:55<00:18,  1.14s/it, loss=0.4105, lr=9.10e-06, grad=M:0.2398Epoch 16/50:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 783/798 [14:57<00:17,  1.15s/it, loss=0.4105, lr=9.10e-06, grad=M:0.2398Epoch 16/50:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 783/798 [14:57<00:17,  1.15s/it, loss=0.3314, lr=9.09e-06, grad=M:0.3641Epoch 16/50:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 784/798 [14:58<00:15,  1.14s/it, loss=0.3314, lr=9.09e-06, grad=M:0.3641Epoch 16/50:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 784/798 [14:58<00:15,  1.14s/it, loss=0.3753, lr=9.09e-06, grad=M:0.2632Epoch 16/50:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 785/798 [14:59<00:14,  1.15s/it, loss=0.3753, lr=9.09e-06, grad=M:0.2632Epoch 16/50:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 785/798 [14:59<00:14,  1.15s/it, loss=0.2302, lr=9.09e-06, grad=M:0.3764Epoch 16/50:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 786/798 [15:00<00:13,  1.14s/it, loss=0.2302, lr=9.09e-06, grad=M:0.3764Epoch 16/50:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 786/798 [15:00<00:13,  1.14s/it, loss=0.3692, lr=9.09e-06, grad=M:0.7712Epoch 16/50:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 787/798 [15:01<00:12,  1.15s/it, loss=0.3692, lr=9.09e-06, grad=M:0.7712Epoch 16/50:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 787/798 [15:01<00:12,  1.15s/it, loss=0.3567, lr=9.08e-06, grad=M:0.8320Epoch 16/50:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 788/798 [15:02<00:11,  1.14s/it, loss=0.3567, lr=9.08e-06, grad=M:0.8320Epoch 16/50:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 788/798 [15:02<00:11,  1.14s/it, loss=0.3395, lr=9.08e-06, grad=M:0.2120Epoch 16/50:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 789/798 [15:03<00:10,  1.15s/it, loss=0.3395, lr=9.08e-06, grad=M:0.2120Epoch 16/50:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 789/798 [15:03<00:10,  1.15s/it, loss=0.4064, lr=9.08e-06, grad=M:0.4906Epoch 16/50:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 790/798 [15:05<00:09,  1.14s/it, loss=0.4064, lr=9.08e-06, grad=M:0.4906Epoch 16/50:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 790/798 [15:05<00:09,  1.14s/it, loss=0.2983, lr=9.08e-06, grad=M:0.2094Epoch 16/50:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 791/798 [15:06<00:08,  1.15s/it, loss=0.2983, lr=9.08e-06, grad=M:0.2094Epoch 16/50:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 791/798 [15:06<00:08,  1.15s/it, loss=0.4161, lr=9.07e-06, grad=M:0.3205Epoch 16/50:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 792/798 [15:07<00:06,  1.14s/it, loss=0.4161, lr=9.07e-06, grad=M:0.3205Epoch 16/50:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 792/798 [15:07<00:06,  1.14s/it, loss=0.2908, lr=9.07e-06, grad=M:0.3533Epoch 16/50:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 793/798 [15:08<00:05,  1.15s/it, loss=0.2908, lr=9.07e-06, grad=M:0.3533Epoch 16/50:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 793/798 [15:08<00:05,  1.15s/it, loss=0.2907, lr=9.07e-06, grad=M:0.3816Epoch 16/50:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 794/798 [15:09<00:04,  1.14s/it, loss=0.2907, lr=9.07e-06, grad=M:0.3816Epoch 16/50:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 794/798 [15:09<00:04,  1.14s/it, loss=0.4187, lr=9.07e-06, grad=M:0.6578Epoch 16/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 795/798 [15:10<00:03,  1.15s/it, loss=0.4187, lr=9.07e-06, grad=M:0.6578Epoch 16/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 795/798 [15:10<00:03,  1.15s/it, loss=0.3028, lr=9.06e-06, grad=M:1.3807Epoch 16/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 796/798 [15:11<00:02,  1.14s/it, loss=0.3028, lr=9.06e-06, grad=M:1.3807Epoch 16/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 796/798 [15:11<00:02,  1.14s/it, loss=0.3395, lr=9.06e-06, grad=M:0.2227Epoch 16/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 797/798 [15:13<00:01,  1.15s/it, loss=0.3395, lr=9.06e-06, grad=M:0.2227Epoch 16/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 797/798 [15:13<00:01,  1.15s/it, loss=0.2177, lr=9.06e-06, grad=M:0.2709Epoch 16/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [15:13<00:00,  1.05s/it, loss=0.2177, lr=9.06e-06, grad=M:0.2709Epoch 16/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [15:13<00:00,  1.05s/it, loss=0.4517, lr=9.06e-06, grad=M:0.2807Epoch 16/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [15:13<00:00,  1.05s/it, loss=0.6677, lr=9.06e-06, grad=M:0.2807, status=Post-epoch processing...Epoch 16/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [15:13<00:00,  1.05s/it, loss=0.6677, lr=9.06e-06, grad=M:0.2807, status=Consolidating optimizer state...Epoch 16/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [18:45<00:00,  1.05s/it, loss=0.6677, lr=9.06e-06, grad=M:0.2807, status=Computing train metrics...Epoch 16/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [23:31<00:00,  1.05s/it, loss=0.6677, lr=9.06e-06, grad=M:0.2807, status=Computing validation metrics...Epoch 16/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [23:47<00:00,  1.05s/it, loss=0.6677, lr=9.06e-06, grad=M:0.2807, status=Epoch completeEpoch 16/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [23:47<00:00,  1.79s/it, loss=0.6677, lr=9.06e-06, grad=M:0.2807, status=Epoch complete]
â–ˆ Epoch 16: Loss T 0.667721 V 0.499441 | F1 T 0.893125 V 0.822157 B 0.825522 SC 3/10 | Acc T 0.894989 V 0.823378 | LR 9.06e-06 | Grad â†“ 0.000000 â†‘ 1.930216 M 0.280720 | 23m 47s
Saved model state: checkpoints/checkpoint_epoch_16_20241024-230644.pth
Epoch 17/50:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 789/798 [15:05<00:10,  1.15s/it, loss=0.3915, lr=6.62e-06, grad=M:0.3328]Epoch 17/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [23:48<00:00,  1.79s/it, loss=0.6476, lr=6.59e-06, grad=M:0.9207, status=Epoch complete]
â–ˆ Epoch 17: Loss T 0.647598 V 0.532852 | F1 T 0.894336 V 0.819470 B 0.825522 SC 4/10 | Acc T 0.897271 V 0.820428 | LR 6.59e-06 | Grad â†“ 0.000000 â†‘ 8.989134 M 0.920716 | 23m 48s
Saved model state: checkpoints/checkpoint_epoch_17_20241024-233042.pth
Epoch 18/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [23:47<00:00,  1.79s/it, loss=0.6523, lr=3.53e-06, grad=M:0.3800, status=Epoch complete]
â–ˆ Epoch 18: Loss T 0.652302 V 0.559312 | F1 T 0.896993 V 0.817042 B 0.825522 SC 5/10 | Acc T 0.899495 V 0.818215 | LR 3.53e-06 | Grad â†“ 0.000000 â†‘ 2.847815 M 0.380043 | 23m 47s
Saved model state: checkpoints/checkpoint_epoch_18_20241024-235440.pth
Epoch 19/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [23:47<00:00,  1.79s/it, loss=0.6443, lr=1.05e-06, grad=M:0.3552, status=Epoch complete]
â–ˆ Epoch 19: Loss T 0.644347 V 0.571050 | F1 T 0.906185 V 0.822284 B 0.825522 SC 6/10 | Acc T 0.908299 V 0.823193 | LR 1.05e-06 | Grad â†“ 0.000000 â†‘ 2.844336 M 0.355170 | 23m 47s
Saved model state: checkpoints/checkpoint_epoch_19_20241025-001838.pth
Epoch 20/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [23:47<00:00,  1.79s/it, loss=0.6038, lr=1.00e-07, grad=M:0.2729, status=Epoch complete]
â–ˆ Epoch 20: Loss T 0.603752 V 0.573312 | F1 T 0.905990 V 0.821727 B 0.825522 SC 7/10 | Acc T 0.907780 V 0.823009 | LR 1.00e-07 | Grad â†“ 0.000000 â†‘ 2.055032 M 0.272916 | 23m 47s
Memory: Rank 0: 34.87 GB | Rank 1: 35.46 GB | Rank 2: 35.66 GB | Rank 3: 35.46 GB | Rank 4: 35.46 GB | Rank 5: 35.46 GB | Rank 6: 35.46 GB | Rank 7: 35.31 GB (Max: 42.29 GB, Total: 338.28 GB)
Saved model state: checkpoints/checkpoint_epoch_20_20241025-004237.pth
Epoch 21/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [23:46<00:00,  1.79s/it, loss=0.6599, lr=9.06e-06, grad=M:0.1962, status=Epoch complete]
â–ˆ Epoch 21: Loss T 0.659929 V 0.558746 | F1 T 0.901943 V 0.813221 B 0.825522 SC 8/10 | Acc T 0.903344 V 0.813975 | LR 9.06e-06 | Grad â†“ 0.000000 â†‘ 1.257383 M 0.196187 | 23m 46s
Saved model state: checkpoints/checkpoint_epoch_21_20241025-010634.pth
Epoch 22/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [23:47<00:00,  1.79s/it, loss=0.6831, lr=6.59e-06, grad=M:0.2957, status=Epoch complete]
â–ˆ Epoch 22: Loss T 0.683077 V 0.644542 | F1 T 0.894880 V 0.811446 B 0.825522 SC 9/10 | Acc T 0.895734 V 0.812684 | LR 6.59e-06 | Grad â†“ 0.000000 â†‘ 2.253749 M 0.295662 | 23m 47s
Saved model state: checkpoints/checkpoint_epoch_22_20241025-013031.pth
Epoch 23/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [23:49<00:00,  1.79s/it, loss=0.6454, lr=3.53e-06, grad=M:0.2559, status=Epoch complete]
â–ˆ Epoch 23: Loss T 0.645443 V 0.565451 | F1 T 0.900551 V 0.819405 B 0.825522 SC 10/10 | Acc T 0.901698 V 0.820428 | LR 3.53e-06 | Grad â†“ 0.000000 â†‘ 1.984049 M 0.255918 | 23m 49s
Stopping early after 23 epochs due to no improvement in validation score in last 10 iterations.
Saved model state: checkpoints/checkpoint_epoch_23_20241025-015430.pth
Saving model in ONNX format...
Model saved in ONNX format to saves/model_20241025-015811.onnx and uploaded to Weights & Biases.
Saved model state: checkpoints/final_model_20241025-015825.pth
Saved model pickle: checkpoints/final_model_20241025-015825.pkl
Training completed (9h 15m 37s)

Evaluating model...

stage_1_merged Multi-Class Classification Report

              precision    recall  f1-score   support

    negative   0.861386  0.838330  0.849702      1868
     neutral   0.750420  0.803475  0.776042      1669
    positive   0.862885  0.831741  0.847027      1884

    accuracy                       0.825309      5421
   macro avg   0.824897  0.824515  0.824257      5421
weighted avg   0.827743  0.825309  0.826094      5421

ROC AUC: 0.942585

Predicted  negative  neutral  positive
Actual                                
negative       1566      220        82
neutral         161     1341       167
positive         91      226      1567

Saved predictions: saves/predictions_20241025-020244.csv

Macro F1 Score: 0.82

Evaluation completed (6m 4s)
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:            eval/macro_f1_score â–
wandb:             gradients/max_norm â–â–†â–‚â–‚â–â–â–‡â–„â–â–ˆâ–ƒâ–‚â–‚â–‚â–‚â–‚â–ˆâ–ƒâ–ƒâ–‚â–â–‚â–‚
wandb:            gradients/mean_norm â–â–ƒâ–‚â–ƒâ–â–‚â–ˆâ–…â–â–ˆâ–„â–‚â–‚â–‚â–‚â–‚â–ˆâ–ƒâ–ƒâ–‚â–â–‚â–‚
wandb:             gradients/min_norm â–‚â–â–„â–†â–…â–…â–…â–„â–ƒâ–†â–…â–ƒâ–ƒâ–ƒâ–ƒâ–„â–ƒâ–„â–ˆâ–„â–ƒâ–…â–„
wandb:                    other/epoch â–â–â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–‡â–‡â–‡â–ˆâ–ˆ
wandb:            other/learning_rate â–ˆâ–†â–„â–‚â–â–ˆâ–†â–„â–‚â–â–ˆâ–†â–„â–‚â–â–ˆâ–†â–„â–‚â–â–ˆâ–†â–„
wandb:               other/stop_limit â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 train/accuracy â–ƒâ–â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                     train/loss â–ˆâ–‡â–…â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–
wandb:           train/macro_f1_score â–ƒâ–â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:               train/stop_count â–â–‚â–â–â–‚â–‚â–ƒâ–â–â–â–‚â–‚â–â–‚â–‚â–ƒâ–„â–…â–…â–†â–‡â–‡â–ˆ
wandb:            validation/accuracy â–ƒâ–â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb: validation/best_macro_f1_score â–â–â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                validation/loss â–ˆâ–ˆâ–…â–â–â–‚â–‚â–â–â–â–â–â–â–â–‚â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚
wandb:      validation/macro_f1_score â–ƒâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb: 
wandb: Run summary:
wandb:            eval/macro_f1_score 0.82426
wandb:             gradients/max_norm 1.98405
wandb:            gradients/mean_norm 0.25592
wandb:             gradients/min_norm 0.0
wandb:                    other/epoch 23
wandb:            other/learning_rate 0.0
wandb:               other/stop_limit 10
wandb:                 train/accuracy 0.9017
wandb:                     train/loss 0.64544
wandb:           train/macro_f1_score 0.90055
wandb:               train/stop_count 10
wandb:            validation/accuracy 0.82043
wandb: validation/best_macro_f1_score 0.82552
wandb:                validation/loss 0.56545
wandb:      validation/macro_f1_score 0.81941
wandb: 
wandb: ðŸš€ View run stage_1_merged at: https://wandb.ai/jimbeno/Electra%20Large/runs/nsy5h33f
wandb: â­ï¸ View project at: https://wandb.ai/jimbeno/Electra%20Large
wandb: Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 2 other file(s)
wandb: Find logs at: ./wandb/run-20241024_164255-nsy5h33f/logs
TOTAL Time: 9h 23m 29s
(nlp) ubuntu@138-2-58-218:~/nlp-osaka/sentiment$ python ./ddp_sentiment_finetune.py --dataset 'merged_local' --weights_name 'google/electra-large-discriminator' --save_data --save_model --save_pickle --save_preds --lr 0.00001 --lr_decay 0.95 --epochs 50 --pooling 'mean' --dropout_rate 0.3 --num_layers 2 --hidden_dim 1024 --hidden_activation 'swishglu' --batch_size 16 --accumulation_steps 2 --finetune_bert --finetune_layers 24 --l2_strength 0.01  --checkpoint_interval 1 --use_zero --optimizer 'adamw' --scheduler 'cosine_warmup' --scheduler_kwargs '{"T_0":5, "T_mult":1, "eta_min":1e-7}' --decimal 6 --use_val_split --eval_split 'test' --early_stop 'score' --n_iter_no_change 10 --show_progress --wandb --wandb_project 'Electra Large' --wandb_run 'stage_1_merged_epoch13' --model_file 'checkpoint_epoch_13_20241024-215451.pth' --interactive

Starting DDP PyTorch Training...
Device: cuda, Number of GPUs: 8
Spawning 8 processes...
Rank 3 - Device: cuda:3
Rank 4 - Device: cuda:4
Rank 1 - Device: cuda:1
Rank 5 - Device: cuda:5
Rank 6 - Device: cuda:6
Rank 7 - Device: cuda:7
Rank 2 - Device: cuda:2
Rank 0 - Device: cuda:0
8 process groups initialized with 'nccl' backend on localhost:12355
NCCL Timeout: 1 hr 0 min. NCCL Blocking Wait: Enabled
wandb: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: jbeno (jimbeno). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.5
wandb: Run data is saved locally in /home/ubuntu/nlp-osaka/sentiment/wandb/run-20241025_023753-sl31fb9c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stage_1_merged_epoch13
wandb: â­ï¸ View project at https://wandb.ai/jimbeno/Electra%20Large
wandb: ðŸš€ View run at https://wandb.ai/jimbeno/Electra%20Large/runs/sl31fb9c
Wand run initialized.

Initializing 'google/electra-large-discriminator' tokenizer and model...
Checking for local files...
Found all files in cache, skipping download
All ranks loading tokenizer from local files...
All ranks loading model from local files...
Tokenizer and model initialized (3s)

Loading data...
Using the same dataset for training and evaluation
Splits:
- Train: Using merged_local 'train' split
- Validation: Using merged_local 'validation' split
- Evaluation: Using merged_local 'test' split
Train Data: Merged DynaSent Round 1, Round 2 and SST from Local: 'data/merged'
Validation Data: Merged DynaSent Round 1, Round 2 and SST from Local: 'data/merged'
Evaluation Data: Merged DynaSent Round 1, Round 2 and SST from Local: 'data/merged'
Train size: 102097
Validation size: 5421
Evaluation size: 5421
Train label distribution:
	      Negative: 21910
	       Neutral: 49148
	      Positive: 31039
Validation label distribution:
	      Negative: 1868
	       Neutral: 1669
	      Positive: 1884
Evaluation label distribution:
	      Negative: 1868
	       Neutral: 1669
	      Positive: 1884
Data loaded (385ms)

Processing data...
(Batch size: 16, Pooling: Mean, Fine Tune BERT: True, Chunk size: None)...
Extracting sentences and labels...

Data saved to: saves/data_8_gpu_20241025-023758.npz
X Train shape: [102097], X Validation shape: [5421], X Test shape: [5421]
y Train shape: [102097], y Validation shape: [5421], y Test shape: [5421]
Data processed (846ms)

Initializing DDP Neural Classifier...
Layers: 2, Hidden Dim: 1024, Hidden Act: SwishGLU, Dropout: 0.3, Optimizer: AdamW, L2 Strength: 0.01, Pooling: MEAN, Accumulation Steps: 2, Max Grad Norm: None
Batch Size: 16, Max Epochs: 50, LR: 1e-05, Early Stop: score, Fine-tune BERT: True, Fine-tune Layers: 24, Freeze BERT: False, Target Score: None, Interactive: True
Loading model from: checkpoints/checkpoint_epoch_13_20241024-215451.pth...
Loaded checkpoint: checkpoints/checkpoint_epoch_13_20241024-215451.pth
Retrieved model state dictionary.
Retrieved optimizer state dictionary.
Classifier initialized (36s)

Fitting DDP Neural Classifier on training data...
Num Workers: 0, Prefetch: None
Score-based early stopping enabled (macro average F1 score against validation set). Validation fraction: 0.1
Training will stop early if the score does not improve by at least 0.00001 for 10 iterations.
Using provided validation set for early stopping.
Building dataset and dataloader...
Initializing model, graph, optimizer...
BERT's original pooler removed. Using custom pooling type: mean
BERT has 334,092,288 trainable parameters and 0 non-trainable parameters
Number of BERT layers requiring gradients: 24 out of 24
Fine-tuning the last 24 out of 24 BERT layers

Model Architecture Summary:
BERTClassifier(
  (bert): ElectraModel(
    (embeddings): ElectraEmbeddings(
      (word_embeddings): Embedding(30522, 1024, padding_idx=0)
      (position_embeddings): Embedding(512, 1024)
      (token_type_embeddings): Embedding(2, 1024)
      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): ElectraEncoder(
      (layer): ModuleList(
        (0-23): 24 x ElectraLayer(
          (attention): ElectraAttention(
            (self): ElectraSelfAttention(
              (query): Linear(in_features=1024, out_features=1024, bias=True)
              (key): Linear(in_features=1024, out_features=1024, bias=True)
              (value): Linear(in_features=1024, out_features=1024, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): ElectraSelfOutput(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): ElectraIntermediate(
            (dense): Linear(in_features=1024, out_features=4096, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): ElectraOutput(
            (dense): Linear(in_features=4096, out_features=1024, bias=True)
            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
  (custom_pooling): PoolingLayer()
  (classifier): Classifier(
    (layers): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): SwishGLU(
        (projection): Linear(in_features=1024, out_features=2048, bias=True)
        (activation): SiLU()
      )
      (2): Dropout(p=0.3, inplace=False)
      (3): Linear(in_features=1024, out_features=1024, bias=True)
      (4): SwishGLU(
        (projection): Linear(in_features=1024, out_features=2048, bias=True)
        (activation): SiLU()
      )
      (5): Dropout(p=0.3, inplace=False)
      (6): Linear(in_features=1024, out_features=3, bias=True)
    )
  )
)

Model Parameters:
  bert.embeddings.word_embeddings: 31,254,528 (trainable)
  bert.embeddings.position_embeddings: 524,288 (trainable)
  bert.embeddings.token_type_embeddings: 2,048 (trainable)
  bert.embeddings.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.0.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.0.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.0.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.0.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.0.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.0.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.0.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.0.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.1.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.1.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.1.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.1.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.1.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.1.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.1.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.1.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.2.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.2.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.2.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.2.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.2.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.2.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.2.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.2.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.3.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.3.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.3.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.3.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.3.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.3.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.3.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.3.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.4.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.4.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.4.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.4.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.4.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.4.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.4.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.4.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.5.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.5.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.5.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.5.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.5.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.5.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.5.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.5.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.6.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.6.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.6.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.6.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.6.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.6.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.6.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.6.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.7.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.7.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.7.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.7.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.7.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.7.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.7.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.7.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.8.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.8.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.8.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.8.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.8.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.8.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.8.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.8.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.9.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.9.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.9.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.9.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.9.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.9.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.9.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.9.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.10.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.10.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.10.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.10.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.10.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.10.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.10.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.10.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.11.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.11.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.11.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.11.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.11.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.11.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.11.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.11.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.12.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.12.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.12.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.12.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.12.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.12.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.12.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.12.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.13.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.13.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.13.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.13.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.13.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.13.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.13.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.13.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.14.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.14.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.14.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.14.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.14.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.14.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.14.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.14.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.15.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.15.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.15.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.15.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.15.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.15.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.15.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.15.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.16.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.16.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.16.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.16.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.16.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.16.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.16.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.16.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.17.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.17.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.17.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.17.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.17.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.17.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.17.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.17.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.18.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.18.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.18.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.18.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.18.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.18.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.18.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.18.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.19.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.19.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.19.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.19.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.19.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.19.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.19.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.19.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.20.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.20.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.20.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.20.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.20.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.20.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.20.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.20.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.21.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.21.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.21.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.21.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.21.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.21.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.21.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.21.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.22.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.22.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.22.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.22.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.22.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.22.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.22.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.22.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.23.attention.self.query: 1,049,600 (trainable)
  bert.encoder.layer.23.attention.self.key: 1,049,600 (trainable)
  bert.encoder.layer.23.attention.self.value: 1,049,600 (trainable)
  bert.encoder.layer.23.attention.output.dense: 1,049,600 (trainable)
  bert.encoder.layer.23.attention.output.LayerNorm: 2,048 (trainable)
  bert.encoder.layer.23.intermediate.dense: 4,198,400 (trainable)
  bert.encoder.layer.23.output.dense: 4,195,328 (trainable)
  bert.encoder.layer.23.output.LayerNorm: 2,048 (trainable)
  classifier.layers.0: 1,049,600 (trainable)
  classifier.layers.1.projection: 2,099,200 (trainable)
  classifier.layers.3: 1,049,600 (trainable)
  classifier.layers.6: 3,075 (trainable)

Total layers: 200
Trainable layers: 200
Total parameters: 338,293,763
Trainable parameters: 338,293,763
Percentage of trainable parameters: 100.00%
Using optimizer: AdamW, Use Zero: True, Base Learning Rate: 1e-05, L2 strength: 0.01
Layer-wise decay factor: 0.95
Using scheduler: CosineAnnealingWarmRestarts
Scheduler arguments:
- T_0: 5
- T_mult: 1
- eta_min: 1e-07

Starting training loop...
Start epoch: 14, Max Iterations: 50, Early Stop: score, Tolerance: 0.00001, Number Iterations No Change: 10

[Enter] to continue for 1 epoch, [Q]uit, [S]ave, [H]elp: q
Quitting training...
Saving model in ONNX format...
Model saved in ONNX format to saves/model_20241025-024209.onnx and uploaded to Weights & Biases.
Saved model state: checkpoints/final_model_20241025-024222.pth
Saved model pickle: checkpoints/final_model_20241025-024222.pkl
Training completed (4m 2s)

Evaluating model...

stage_1_merged_epoch13 Multi-Class Classification Report

              precision    recall  f1-score   support

    negative   0.863687  0.837794  0.850543      1868
     neutral   0.762959  0.784901  0.773774      1669
    positive   0.850423  0.854034  0.852225      1884

    accuracy                       0.827154      5421
   macro avg   0.825689  0.825577  0.825514      5421
weighted avg   0.828065  0.827154  0.827492      5421

ROC AUC: 0.947537

Predicted  negative  neutral  positive
Actual                                
negative       1565      208        95
neutral         171     1310       188
positive         76      199      1609

Saved predictions: saves/predictions_20241025-024640.csv

Macro F1 Score: 0.83

Evaluation completed (6m 26s)
wandb:                                                                                
wandb: 
wandb: Run history:
wandb: eval/macro_f1_score â–
wandb: 
wandb: Run summary:
wandb: eval/macro_f1_score 0.82551
wandb: 
wandb: ðŸš€ View run stage_1_merged_epoch13 at: https://wandb.ai/jimbeno/Electra%20Large/runs/sl31fb9c
wandb: â­ï¸ View project at: https://wandb.ai/jimbeno/Electra%20Large
wandb: Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 2 other file(s)
wandb: Find logs at: ./wandb/run-20241025_023753-sl31fb9c/logs
TOTAL Time: 12m 6s
(nlp) ubuntu@138-2-58-218:~/nlp-osaka/sentiment$ logout
Connection to 138.2.58.218 closed.
(base) Jims-MBP:multiclass jim$ cd ..
(base) Jims-MBP:final_project jim$ ls
electra_large	multiclass	negative	neutral		positive
(base) Jims-MBP:final_project jim$ cd electra_large/
(base) Jims-MBP:electra_large jim$ scp ubuntu@138.2.58.218:~/nlp-osaka/sentiment/saves/predictions_20241025-024640.csv .
Enter passphrase for key '/Users/jim/.ssh/id_rsa': 
predictions_20241025-024640.csv                                                                                                                      100%  517KB 718.2KB/s   00:00    
(base) Jims-MBP:electra_large jim$ scp ubuntu@138.2.58.218:~/nlp-osaka/sentiment/checkpoints/final_model_20241025-024222.pkl .
Enter passphrase for key '/Users/jim/.ssh/id_rsa': 
final_model_20241025-024222.pkl                                                                                                                      100% 1579MB   5.8MB/s   04:30    
(base) Jims-MBP:electra_large jim$ 
(base) Jims-MBP:electra_large jim$ 
(base) Jims-MBP:electra_large jim$ ssh ubuntu@104.171.202.167
The authenticity of host '104.171.202.167 (104.171.202.167)' can't be established.
ED25519 key fingerprint is SHA256:/XQxUxKFNzHVVBpFUYtSqszurv31/7Ilt+lCt5BOlgg.
This key is not known by any other names
Are you sure you want to continue connecting (yes/no/[fingerprint])? yes
Warning: Permanently added '104.171.202.167' (ED25519) to the list of known hosts.
Enter passphrase for key '/Users/jim/.ssh/id_rsa': 
Welcome to Ubuntu 22.04.5 LTS (GNU/Linux 6.8.0-47-generic x86_64)
 .============.
 ||   __      ||    _                    _         _
 ||   \_\     ||   | |    __ _ _ __ ___ | |__   __| | __ _
 ||    \_\    ||   | |   / _` | '_ ` _ \| '_ \ / _` |/ _` |
 ||   /_Î»_\   ||   | |__| (_| | | | | | | |_) | (_| | (_| |
 ||  /_/ \_\  ||   |_____\__,_|_| |_| |_|_.__/ \__,_|\__,_|
  .============.                                  GPU CLOUD

ubuntu@104-171-202-167:~$ cd nlp-test/
ubuntu@104-171-202-167:~/nlp-test$ cd sentiment/
ubuntu@104-171-202-167:~/nlp-test/sentiment$ source nlp/bin/activate
(nlp) ubuntu@104-171-202-167:~/nlp-test/sentiment$ ls
'=1.20.0'      compare.py              ddp_sentiment_finetune.py    nlp                test_input.py                              torch_shallow_neural_classifier.py
 README.md     data                    dspy_sentiment.ipynb         requirements.txt   torch_ddp_finetune_neural_classifier.bak   utils.bak
 __pycache__   data_processing.ipynb   dspy_sentiment_final.ipynb   saves              torch_ddp_finetune_neural_classifier.py    utils.py
 checkpoints   datawaza_funcs.py       list                         sst.py             torch_ddp_neural_classifier.py             wandb
 colors.py     ddp_sentiment.py        model.onnx                   test.ipynb         torch_model_base.py
(nlp) ubuntu@104-171-202-167:~/nlp-test/sentiment$ more requirements.txt 
numpy>=1.20.0
scipy>=1.7.0
matplotlib>=3.7.0
scikit-learn>=1.0.2
nltk>=3.7
pytest>=7.1
jupyter>=1.0.0
pandas>=1.5
# uncomment the following line to install pytorch and torchvision
torch>=2.2.0; sys_platform != "linux" and sys_platform != "win32"
torch>=2.2.0+${DEVICE}; sys_platform == "linux" or sys_platform == "win32"
torchvision==0.16.2
torchaudio==2.1.2
transformers>=4.38.0
datasets==2.14.6
spacy==3.7.2
dspy-ai==2.3.1
# dependencies for dspy-ai
openai<=0.28.1
python-dotenv
wget
(nlp) ubuntu@104-171-202-167:~/nlp-test/sentiment$ ls
'=1.20.0'      compare.py              ddp_sentiment_finetune.py    nlp                test_input.py                              torch_shallow_neural_classifier.py
 README.md     data                    dspy_sentiment.ipynb         requirements.txt   torch_ddp_finetune_neural_classifier.bak   utils.bak
 __pycache__   data_processing.ipynb   dspy_sentiment_final.ipynb   saves              torch_ddp_finetune_neural_classifier.py    utils.py
 checkpoints   datawaza_funcs.py       list                         sst.py             torch_ddp_neural_classifier.py             wandb
 colors.py     ddp_sentiment.py        model.onnx                   test.ipynb         torch_model_base.py
(nlp) ubuntu@104-171-202-167:~/nlp-test/sentiment$ git pull
Username for 'https://github.com': jim@jimbeno.net
Password for 'https://jim@jimbeno.net@github.com': 
remote: Enumerating objects: 29, done.
remote: Counting objects: 100% (29/29), done.
remote: Compressing objects: 100% (17/17), done.
remote: Total 26 (delta 18), reused 17 (delta 9), pack-reused 0 (from 0)
Unpacking objects: 100% (26/26), 7.09 KiB | 12.00 KiB/s, done.
From https://github.com/jbeno/sentiment
   a1be65f..28c7c70  main       -> origin/main
Updating a1be65f..28c7c70
Fast-forward
 ddp_sentiment_finetune.py               | 18 +++++++++++++-----
 torch_ddp_finetune_neural_classifier.py | 78 ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++--------
 2 files changed, 83 insertions(+), 13 deletions(-)
(nlp) ubuntu@104-171-202-167:~/nlp-test/sentiment$ python ./ddp_sentiment_finetune.py --dataset 'merged_local' --weights_name 'google/electra-base-discriminator' --save_data --save_model --save_pickle --save_preds --lr 0.00001 --lr_decay 0.95 --epochs 50 --pooling 'mean' --dropout_rate 0.3 --num_layers 2 --hidden_dim 1024 --hidden_activation 'swishglu' --batch_size 16 --accumulation_steps 2 --finetune_bert --finetune_layers 12 --l2_strength 0.01  --checkpoint_interval 1 --use_zero --optimizer 'adamw' --scheduler 'cosine_warmup' --scheduler_kwargs '{"T_0":5, "T_mult":1, "eta_min":1e-7}' --decimal 6 --use_val_split --eval_split 'test' --early_stop 'score' --n_iter_no_change 10 --show_progress --wandb --wandb_project 'Electra Base' --wandb_run 'stage_1_merged'

Starting DDP PyTorch Training...
Device: cuda, Number of GPUs: 8
Spawning 8 processes...
Rank 6 - Device: cuda:6
Rank 7 - Device: cuda:7
Rank 3 - Device: cuda:3
Rank 5 - Device: cuda:5
Rank 4 - Device: cuda:4
Rank 1 - Device: cuda:1
Rank 2 - Device: cuda:2
Rank 0 - Device: cuda:0
8 process groups initialized with 'nccl' backend on localhost:12355
NCCL Timeout: 1 hr 0 min. NCCL Blocking Wait: Enabled
wandb: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.
An error occurred during training: api_key not configured (no-tty). call wandb.login(key=[your_api_key])
Traceback (most recent call last):
  File "/home/ubuntu/nlp-test/sentiment/ddp_sentiment_finetune.py", line 1124, in main
    wandb_run = wandb.init(project=wandb_project, name=wandb_run_name, config={
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/wandb/sdk/wandb_init.py", line 1266, in init
    wandb._sentry.reraise(e)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/wandb/analytics/sentry.py", line 155, in reraise
    raise exc.with_traceback(sys.exc_info()[2])
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/wandb/sdk/wandb_init.py", line 1251, in init
    wi.setup(kwargs)
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/wandb/sdk/wandb_init.py", line 303, in setup
    wandb_login._login(
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/wandb/sdk/wandb_login.py", line 347, in _login
    wlogin.prompt_api_key()
  File "/home/ubuntu/nlp-test/sentiment/nlp/lib/python3.10/site-packages/wandb/sdk/wandb_login.py", line 281, in prompt_api_key
    raise UsageError("api_key not configured (no-tty). call " + directive)
wandb.errors.errors.UsageError: api_key not configured (no-tty). call wandb.login(key=[your_api_key])
^C
Ctrl+C received. Terminating all processes...
Rank 0 - Current process: MainProcess cleaning up...
Terminating all child processes of MainProcess...
Terminated child process: SpawnProcess-8
Terminated child process: SpawnProcess-2
Terminated child process: SpawnProcess-7
Terminated child process: SpawnProcess-3
Terminated child process: SpawnProcess-6
Terminated child process: SpawnProcess-5
Terminated child process: SpawnProcess-1
Terminated child process: SpawnProcess-4
Rank 0 - Exiting program...
(nlp) ubuntu@104-171-202-167:~/nlp-test/sentiment$ wandb login
wandb: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)
wandb: You can find your API key in your browser here: https://wandb.ai/authorize
wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit: 
wandb: Appending key for api.wandb.ai to your netrc file: /home/ubuntu/.netrc
(nlp) ubuntu@104-171-202-167:~/nlp-test/sentiment$ python ./ddp_sentiment_finetune.py --dataset 'merged_local' --weights_name 'google/electra-base-discriminator' --save_data --save_model --save_pickle --save_preds --lr 0.00001 --lr_decay 0.95 --epochs 50 --pooling 'mean' --dropout_rate 0.3 --num_layers 2 --hidden_dim 1024 --hidden_activation 'swishglu' --batch_size 16 --accumulation_steps 2 --finetune_bert --finetune_layers 12 --l2_strength 0.01  --checkpoint_interval 1 --use_zero --optimizer 'adamw' --scheduler 'cosine_warmup' --scheduler_kwargs '{"T_0":5, "T_mult":1, "eta_min":1e-7}' --decimal 6 --use_val_split --eval_split 'test' --early_stop 'score' --n_iter_no_change 10 --show_progress --wandb --wandb_project 'Electra Base' --wandb_run 'stage_1_merged'

Starting DDP PyTorch Training...
Device: cuda, Number of GPUs: 8
Spawning 8 processes...
Rank 4 - Device: cuda:4
Rank 6 - Device: cuda:6
Rank 1 - Device: cuda:1
Rank 7 - Device: cuda:7
Rank 5 - Device: cuda:5
Rank 2 - Device: cuda:2
Rank 3 - Device: cuda:3
Rank 0 - Device: cuda:0
8 process groups initialized with 'nccl' backend on localhost:12355
NCCL Timeout: 1 hr 0 min. NCCL Blocking Wait: Enabled
wandb: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: jbeno (jimbeno). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.3
wandb: Run data is saved locally in /home/ubuntu/nlp-test/sentiment/wandb/run-20241026_021437-j2y7e6pc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stage_1_merged
wandb: â­ï¸ View project at https://wandb.ai/jimbeno/Electra%20Base
wandb: ðŸš€ View run at https://wandb.ai/jimbeno/Electra%20Base/runs/j2y7e6pc
Wand run initialized.

Initializing 'google/electra-base-discriminator' tokenizer and model...
Checking for local files...
Some files not found locally, downloading...
tokenizer_config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48.0/48.0 [00:00<00:00, 142kB/s]
config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 666/666 [00:00<00:00, 1.62MB/s]
vocab.txt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 232k/232k [00:00<00:00, 7.78MB/s]
tokenizer.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 466k/466k [00:00<00:00, 13.7MB/s]
pytorch_model.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 440M/440M [00:02<00:00, 159MB/s]
Download complete
All ranks loading tokenizer from local files...
All ranks loading model from local files...
Tokenizer and model initialized (8s)

Loading data...
Using the same dataset for training and evaluation
Splits:
- Train: Using merged_local 'train' split
- Validation: Using merged_local 'validation' split
- Evaluation: Using merged_local 'test' split
Train Data: Merged DynaSent Round 1, Round 2 and SST from Local: 'data/merged'
Validation Data: Merged DynaSent Round 1, Round 2 and SST from Local: 'data/merged'
Evaluation Data: Merged DynaSent Round 1, Round 2 and SST from Local: 'data/merged'
Train size: 102097
Validation size: 5421
Evaluation size: 5421
Train label distribution:
	      Negative: 21910
	       Neutral: 49148
	      Positive: 31039
Validation label distribution:
	      Negative: 1868
	       Neutral: 1669
	      Positive: 1884
Evaluation label distribution:
	      Negative: 1868
	       Neutral: 1669
	      Positive: 1884
Data loaded (561ms)

Processing data...
(Batch size: 16, Pooling: Mean, Fine Tune BERT: True, Chunk size: None)...
Extracting sentences and labels...

Data saved to: saves/data_8_gpu_20241026-021447.npz
X Train shape: [102097], X Validation shape: [5421], X Test shape: [5421]
y Train shape: [102097], y Validation shape: [5421], y Test shape: [5421]
Data processed (741ms)

Initializing DDP Neural Classifier...
Layers: 2, Hidden Dim: 1024, Hidden Act: SwishGLU, Dropout: 0.3, Optimizer: AdamW, L2 Strength: 0.01, Pooling: MEAN, Accumulation Steps: 2, Max Grad Norm: None
Batch Size: 16, Max Epochs: 50, LR: 1e-05, Early Stop: score, Fine-tune BERT: True, Fine-tune Layers: 12, Freeze BERT: False, Target Score: None, Interactive: False
Classifier initialized (24ms)

Fitting DDP Neural Classifier on training data...
Num Workers: 0, Prefetch: None
Score-based early stopping enabled (macro average F1 score against validation set). Validation fraction: 0.1
Training will stop early if the score does not improve by at least 0.00001 for 10 iterations.
Using provided validation set for early stopping.
Building dataset and dataloader...
Initializing model, graph, optimizer...
BERT's original pooler removed. Using custom pooling type: mean
BERT has 108,891,648 trainable parameters and 0 non-trainable parameters
Number of BERT layers requiring gradients: 12 out of 12
Fine-tuning the last 12 out of 12 BERT layers

Model Architecture Summary:
BERTClassifier(
  (bert): ElectraModel(
    (embeddings): ElectraEmbeddings(
      (word_embeddings): Embedding(30522, 768, padding_idx=0)
      (position_embeddings): Embedding(512, 768)
      (token_type_embeddings): Embedding(2, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): ElectraEncoder(
      (layer): ModuleList(
        (0-11): 12 x ElectraLayer(
          (attention): ElectraAttention(
            (self): ElectraSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): ElectraSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): ElectraIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): ElectraOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
  (custom_pooling): PoolingLayer()
  (classifier): Classifier(
    (layers): Sequential(
      (0): Linear(in_features=768, out_features=1024, bias=True)
      (1): SwishGLU(
        (projection): Linear(in_features=1024, out_features=2048, bias=True)
        (activation): SiLU()
      )
      (2): Dropout(p=0.3, inplace=False)
      (3): Linear(in_features=1024, out_features=1024, bias=True)
      (4): SwishGLU(
        (projection): Linear(in_features=1024, out_features=2048, bias=True)
        (activation): SiLU()
      )
      (5): Dropout(p=0.3, inplace=False)
      (6): Linear(in_features=1024, out_features=3, bias=True)
    )
  )
)

Model Parameters:
  bert.embeddings.word_embeddings: 23,440,896 (trainable)
  bert.embeddings.position_embeddings: 393,216 (trainable)
  bert.embeddings.token_type_embeddings: 1,536 (trainable)
  bert.embeddings.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.0.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.0.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.0.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.0.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.0.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.0.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.0.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.0.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.1.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.1.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.1.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.1.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.1.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.1.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.1.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.1.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.2.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.2.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.2.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.2.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.2.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.2.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.2.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.2.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.3.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.3.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.3.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.3.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.3.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.3.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.3.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.3.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.4.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.4.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.4.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.4.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.4.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.4.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.4.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.4.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.5.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.5.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.5.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.5.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.5.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.5.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.5.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.5.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.6.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.6.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.6.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.6.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.6.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.6.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.6.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.6.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.7.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.7.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.7.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.7.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.7.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.7.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.7.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.7.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.8.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.8.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.8.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.8.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.8.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.8.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.8.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.8.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.9.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.9.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.9.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.9.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.9.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.9.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.9.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.9.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.10.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.10.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.10.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.10.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.10.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.10.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.10.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.10.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.11.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.11.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.11.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.11.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.11.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.11.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.11.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.11.output.LayerNorm: 1,536 (trainable)
  classifier.layers.0: 787,456 (trainable)
  classifier.layers.1.projection: 2,099,200 (trainable)
  classifier.layers.3: 1,049,600 (trainable)
  classifier.layers.6: 3,075 (trainable)

Total layers: 104
Trainable layers: 104
Total parameters: 112,830,979
Trainable parameters: 112,830,979
Percentage of trainable parameters: 100.00%
Using optimizer: AdamW, Use Zero: True, Base Learning Rate: 1e-05, L2 strength: 0.01
Layer-wise decay factor: 0.95
Using scheduler: CosineAnnealingWarmRestarts
Scheduler arguments:
- T_0: 5
- T_mult: 1
- eta_min: 1e-07

Starting training loop...
Start epoch: 1, Max Iterations: 50, Early Stop: score, Tolerance: 0.00001, Number Iterations No Change: 10
Epoch 1/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:31<00:00,  1.40it/s, loss=1.7946, lr=9.06e-06, grad=M:0.1632, status=Epoch complete]
â–ˆ Epoch  1: Loss T 1.794583 V 1.009601 | F1 T 0.471111 V 0.430371 B 0.430371 SC 0/10 | Acc T 0.605931 V 0.500737 | LR 9.06e-06 | Grad â†“ 0.000000 â†‘ 0.969738 M 0.163202 | 9m 31s
Saved model state: checkpoints/checkpoint_epoch_1_20241026-022419.pth
Epoch 2/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:29<00:00,  1.40it/s, loss=1.5213, lr=6.59e-06, grad=M:0.2611, status=Epoch complete]
â–ˆ Epoch  2: Loss T 1.521316 V 0.882993 | F1 T 0.771691 V 0.710032 B 0.710032 SC 0/10 | Acc T 0.789274 V 0.710914 | LR 6.59e-06 | Grad â†“ 0.000000 â†‘ 1.498628 M 0.261054 | 9m 29s
Saved model state: checkpoints/checkpoint_epoch_2_20241026-023354.pth
Epoch 3/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:30<00:00,  1.40it/s, loss=1.2575, lr=3.53e-06, grad=M:0.2165, status=Epoch complete]
â–ˆ Epoch  3: Loss T 1.257462 V 0.825619 | F1 T 0.783481 V 0.720878 B 0.720878 SC 0/10 | Acc T 0.800419 V 0.723451 | LR 3.53e-06 | Grad â†“ 0.000000 â†‘ 1.627718 M 0.216542 | 9m 30s
Saved model state: checkpoints/checkpoint_epoch_3_20241026-024328.pth
Epoch 4/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:29<00:00,  1.40it/s, loss=1.1922, lr=1.05e-06, grad=M:0.2378, status=Epoch complete]
â–ˆ Epoch  4: Loss T 1.192246 V 0.792281 | F1 T 0.793337 V 0.728710 B 0.728710 SC 0/10 | Acc T 0.807961 V 0.730826 | LR 1.05e-06 | Grad â†“ 0.000000 â†‘ 1.427621 M 0.237804 | 9m 29s
Saved model state: checkpoints/checkpoint_epoch_4_20241026-025303.pth
Epoch 5/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:29<00:00,  1.40it/s, loss=1.1310, lr=1.00e-07, grad=M:0.1822, status=Epoch complete]
â–ˆ Epoch  5: Loss T 1.130965 V 0.757569 | F1 T 0.797320 V 0.734028 B 0.734028 SC 0/10 | Acc T 0.810007 V 0.735804 | LR 1.00e-07 | Grad â†“ 0.000000 â†‘ 1.218381 M 0.182232 | 9m 29s
Saved model state: checkpoints/checkpoint_epoch_5_20241026-030238.pth
Epoch 6/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:29<00:00,  1.40it/s, loss=1.0040, lr=9.06e-06, grad=M:0.3505, status=Epoch complete]
â–ˆ Epoch  6: Loss T 1.003978 V 0.669513 | F1 T 0.822947 V 0.756253 B 0.756253 SC 0/10 | Acc T 0.832259 V 0.757559 | LR 9.06e-06 | Grad â†“ 0.000000 â†‘ 2.213244 M 0.350488 | 9m 29s
Saved model state: checkpoints/checkpoint_epoch_6_20241026-031213.pth
Epoch 7/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:28<00:00,  1.40it/s, loss=0.9073, lr=6.59e-06, grad=M:0.2201, status=Epoch complete]
â–ˆ Epoch  7: Loss T 0.907271 V 0.642360 | F1 T 0.838853 V 0.759858 B 0.759858 SC 0/10 | Acc T 0.846304 V 0.761246 | LR 6.59e-06 | Grad â†“ 0.000000 â†‘ 1.490472 M 0.220102 | 9m 28s
Saved model state: checkpoints/checkpoint_epoch_7_20241026-032146.pth
Epoch 8/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:27<00:00,  1.41it/s, loss=0.8450, lr=3.53e-06, grad=M:0.2283, status=Epoch complete]
â–ˆ Epoch  8: Loss T 0.844994 V 0.618621 | F1 T 0.852578 V 0.769740 B 0.769740 SC 0/10 | Acc T 0.857694 V 0.771018 | LR 3.53e-06 | Grad â†“ 0.000000 â†‘ 1.507362 M 0.228283 | 9m 27s
Saved model state: checkpoints/checkpoint_epoch_8_20241026-033118.pth
Epoch 9/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:29<00:00,  1.40it/s, loss=0.7999, lr=1.05e-06, grad=M:0.2506, status=Epoch complete]
â–ˆ Epoch  9: Loss T 0.799946 V 0.631986 | F1 T 0.857832 V 0.767268 B 0.769740 SC 1/10 | Acc T 0.862973 V 0.768437 | LR 1.05e-06 | Grad â†“ 0.000000 â†‘ 1.598961 M 0.250597 | 9m 29s
Saved model state: checkpoints/checkpoint_epoch_9_20241026-034051.pth
Epoch 10/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:28<00:00,  1.40it/s, loss=0.7775, lr=1.00e-07, grad=M:0.3415, status=Epoch complete]
â–ˆ Epoch 10: Loss T 0.777534 V 0.633862 | F1 T 0.858720 V 0.769290 B 0.769740 SC 2/10 | Acc T 0.863639 V 0.770465 | LR 1.00e-07 | Grad â†“ 0.000000 â†‘ 2.467170 M 0.341490 | 9m 28s
Memory: Rank 0: 13.74 GB | Rank 1: 14.10 GB | Rank 2: 14.00 GB | Rank 3: 14.00 GB | Rank 4: 14.08 GB | Rank 5: 14.09 GB | Rank 6: 14.04 GB | Rank 7: 14.14 GB (Max: 16.93 GB, Total: 135.43 GB)
Saved model state: checkpoints/checkpoint_epoch_10_20241026-035028.pth
Epoch 11/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:28<00:00,  1.40it/s, loss=0.7975, lr=9.06e-06, grad=M:0.2546, status=Epoch complete]
â–ˆ Epoch 11: Loss T 0.797468 V 0.620167 | F1 T 0.870936 V 0.772042 B 0.772042 SC 0/10 | Acc T 0.875215 V 0.772861 | LR 9.06e-06 | Grad â†“ 0.000000 â†‘ 1.486251 M 0.254558 | 9m 28s
Saved model state: checkpoints/checkpoint_epoch_11_20241026-040001.pth
Epoch 12/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:29<00:00,  1.40it/s, loss=0.7434, lr=6.59e-06, grad=M:0.3096, status=Epoch complete]
â–ˆ Epoch 12: Loss T 0.743377 V 0.602725 | F1 T 0.882994 V 0.774726 B 0.774726 SC 0/10 | Acc T 0.885861 V 0.775996 | LR 6.59e-06 | Grad â†“ 0.000000 â†‘ 1.916358 M 0.309559 | 9m 29s
Saved model state: checkpoints/checkpoint_epoch_12_20241026-040935.pth
Epoch 13/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:29<00:00,  1.40it/s, loss=0.6876, lr=3.53e-06, grad=M:0.1862, status=Epoch complete]
â–ˆ Epoch 13: Loss T 0.687640 V 0.657894 | F1 T 0.894655 V 0.776763 B 0.776763 SC 0/10 | Acc T 0.897546 V 0.777655 | LR 3.53e-06 | Grad â†“ 0.000000 â†‘ 1.191260 M 0.186195 | 9m 29s
Saved model state: checkpoints/checkpoint_epoch_13_20241026-041909.pth
Epoch 14/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:29<00:00,  1.40it/s, loss=0.6446, lr=1.05e-06, grad=M:0.3020, status=Epoch complete]
â–ˆ Epoch 14: Loss T 0.644642 V 0.676298 | F1 T 0.900398 V 0.778240 B 0.778240 SC 0/10 | Acc T 0.903040 V 0.779130 | LR 1.05e-06 | Grad â†“ 0.000000 â†‘ 1.873516 M 0.302026 | 9m 29s
Saved model state: checkpoints/checkpoint_epoch_14_20241026-042844.pth
Epoch 15/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:29<00:00,  1.40it/s, loss=0.6206, lr=1.00e-07, grad=M:0.3526, status=Epoch complete]
â–ˆ Epoch 15: Loss T 0.620597 V 0.689662 | F1 T 0.900967 V 0.775785 B 0.778240 SC 1/10 | Acc T 0.903383 V 0.776733 | LR 1.00e-07 | Grad â†“ 0.000000 â†‘ 2.136268 M 0.352564 | 9m 29s
Saved model state: checkpoints/checkpoint_epoch_15_20241026-043821.pth
Epoch 16/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:27<00:00,  1.40it/s, loss=0.6517, lr=9.06e-06, grad=M:0.2867, status=Epoch complete]
â–ˆ Epoch 16: Loss T 0.651661 V 0.656315 | F1 T 0.911593 V 0.777583 B 0.778240 SC 2/10 | Acc T 0.913980 V 0.777839 | LR 9.06e-06 | Grad â†“ 0.000000 â†‘ 1.838318 M 0.286701 | 9m 28s
Saved model state: checkpoints/checkpoint_epoch_16_20241026-044753.pth
Epoch 17/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:28<00:00,  1.40it/s, loss=0.5983, lr=6.59e-06, grad=M:0.3719, status=Epoch complete]
â–ˆ Epoch 17: Loss T 0.598255 V 0.691040 | F1 T 0.922605 V 0.775409 B 0.778240 SC 3/10 | Acc T 0.924450 V 0.775811 | LR 6.59e-06 | Grad â†“ 0.000000 â†‘ 2.250370 M 0.371903 | 9m 28s
Saved model state: checkpoints/checkpoint_epoch_17_20241026-045726.pth
Epoch 18/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:27<00:00,  1.41it/s, loss=0.5457, lr=3.53e-06, grad=M:0.2925, status=Epoch complete]
â–ˆ Epoch 18: Loss T 0.545707 V 0.728037 | F1 T 0.931354 V 0.777869 B 0.778240 SC 4/10 | Acc T 0.933029 V 0.778392 | LR 3.53e-06 | Grad â†“ 0.000000 â†‘ 1.889881 M 0.292456 | 9m 27s
Saved model state: checkpoints/checkpoint_epoch_18_20241026-050700.pth
Epoch 19/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:30<00:00,  1.40it/s, loss=0.5040, lr=1.05e-06, grad=M:0.4648, status=Epoch complete]
â–ˆ Epoch 19: Loss T 0.504030 V 0.785090 | F1 T 0.936181 V 0.776964 B 0.778240 SC 5/10 | Acc T 0.937456 V 0.777471 | LR 1.05e-06 | Grad â†“ 0.000000 â†‘ 3.150250 M 0.464841 | 9m 30s
Saved model state: checkpoints/checkpoint_epoch_19_20241026-051635.pth
Epoch 20/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [09:28<00:00,  1.40it/s, loss=0.4826, lr=1.00e-07, grad=M:0.2589, status=Epoch complete]
â–ˆ Epoch 20: Loss T 0.482586 V 0.802308 | F1 T 0.936912 V 0.777495 B 0.778240 SC 6/10 | Acc T 0.937965 V 0.778208 | LR 1.00e-07 | Grad â†“ 0.000000 â†‘ 1.820220 M 0.258929 | 9m 28s
Memory: Rank 0: 13.75 GB | Rank 1: 14.10 GB | Rank 2: 14.00 GB | Rank 3: 14.00 GB | Rank 4: 14.08 GB | Rank 5: 14.09 GB | Rank 6: 14.04 GB | Rank 7: 14.14 GB (Max: 16.93 GB, Total: 135.43 GB)
Saved model state: checkpoints/checkpoint_epoch_20_20241026-052608.pth
Epoch 21/50:   2%|â–ˆâ–‰                                                                                         | 17/798 [00:08<06:27,  2.01it/s, loss=0.2299, lr=1.00e-05, grad=M:0.5010]^C
Ctrl+C received. Terminating all processes...
Rank 0 - Current process: MainProcess cleaning up...
Terminating all child processes of MainProcess...
Terminated child process: SpawnProcess-5
Terminated child process: SpawnProcess-4
Terminated child process: SpawnProcess-1
Terminated child process: SpawnProcess-3
Terminated child process: SpawnProcess-8
Terminated child process: SpawnProcess-2
Terminated child process: SpawnProcess-7
Terminated child process: SpawnProcess-6
Rank 0 - Exiting program...
/usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
(nlp) ubuntu@104-171-202-167:~/nlp-test/sentiment$ python ./ddp_sentiment_finetune.py --dataset 'merged_local' --weights_name 'google/electra-base-discriminator' --save_data --save_model --save_pickle --save_preds --lr 0.00001 --lr_decay 0.95 --epochs 50 --pooling 'mean' --dropout_rate 0.3 --num_layers 2 --hidden_dim 1024 --hidden_activation 'swishglu' --batch_size 16 --accumulation_steps 2 --finetune_bert --finetune_layers 12 --l2_strength 0.01  --checkpoint_interval 1 --use_zero --optimizer 'adamw' --scheduler 'cosine_warmup' --scheduler_kwargs '{"T_0":5, "T_mult":1, "eta_min":1e-7}' --decimal 6 --use_val_split --eval_split 'test' --early_stop 'score' --n_iter_no_change 10 --show_progress --wandb --wandb_project 'Electra Base' --wandb_run 'stage_1_merged' --model_file 'checkpoint_epoch_20_20241026-052608.pth' --interactive

Starting DDP PyTorch Training...
Device: cuda, Number of GPUs: 8
Spawning 8 processes...
Rank 1 - Device: cuda:1
Rank 7 - Device: cuda:7
Rank 6 - Device: cuda:6
Rank 3 - Device: cuda:3
Rank 2 - Device: cuda:2
Rank 5 - Device: cuda:5
Rank 4 - Device: cuda:4
Rank 0 - Device: cuda:0
8 process groups initialized with 'nccl' backend on localhost:12355
NCCL Timeout: 1 hr 0 min. NCCL Blocking Wait: Enabled
wandb: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: jbeno (jimbeno). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.3
wandb: Run data is saved locally in /home/ubuntu/nlp-test/sentiment/wandb/run-20241026_052732-rly8s8zt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stage_1_merged
wandb: â­ï¸ View project at https://wandb.ai/jimbeno/Electra%20Base
wandb: ðŸš€ View run at https://wandb.ai/jimbeno/Electra%20Base/runs/rly8s8zt
Wand run initialized.

Initializing 'google/electra-base-discriminator' tokenizer and model...
Checking for local files...
Found all files in cache, skipping download
All ranks loading tokenizer from local files...
All ranks loading model from local files...
Tokenizer and model initialized (4s)

Loading data...
Using the same dataset for training and evaluation
Splits:
- Train: Using merged_local 'train' split
- Validation: Using merged_local 'validation' split
- Evaluation: Using merged_local 'test' split
Train Data: Merged DynaSent Round 1, Round 2 and SST from Local: 'data/merged'
Validation Data: Merged DynaSent Round 1, Round 2 and SST from Local: 'data/merged'
Evaluation Data: Merged DynaSent Round 1, Round 2 and SST from Local: 'data/merged'
Train size: 102097
Validation size: 5421
Evaluation size: 5421
Train label distribution:
	      Negative: 21910
	       Neutral: 49148
	      Positive: 31039
Validation label distribution:
	      Negative: 1868
	       Neutral: 1669
	      Positive: 1884
Evaluation label distribution:
	      Negative: 1868
	       Neutral: 1669
	      Positive: 1884
Data loaded (629ms)

Processing data...
(Batch size: 16, Pooling: Mean, Fine Tune BERT: True, Chunk size: None)...
Extracting sentences and labels...

Data saved to: saves/data_8_gpu_20241026-052739.npz
X Train shape: [102097], X Validation shape: [5421], X Test shape: [5421]
y Train shape: [102097], y Validation shape: [5421], y Test shape: [5421]
Data processed (760ms)

Initializing DDP Neural Classifier...
Layers: 2, Hidden Dim: 1024, Hidden Act: SwishGLU, Dropout: 0.3, Optimizer: AdamW, L2 Strength: 0.01, Pooling: MEAN, Accumulation Steps: 2, Max Grad Norm: None
Batch Size: 16, Max Epochs: 50, LR: 1e-05, Early Stop: score, Fine-tune BERT: True, Fine-tune Layers: 12, Freeze BERT: False, Target Score: None, Interactive: True
Loading model from: checkpoints/checkpoint_epoch_20_20241026-052608.pth...
Loaded checkpoint: checkpoints/checkpoint_epoch_20_20241026-052608.pth
Retrieved model state dictionary.
Retrieved optimizer state dictionary.
Classifier initialized (8s)

Fitting DDP Neural Classifier on training data...
Num Workers: 0, Prefetch: None
Score-based early stopping enabled (macro average F1 score against validation set). Validation fraction: 0.1
Training will stop early if the score does not improve by at least 0.00001 for 10 iterations.
Using provided validation set for early stopping.
Building dataset and dataloader...
Initializing model, graph, optimizer...
BERT's original pooler removed. Using custom pooling type: mean
BERT has 108,891,648 trainable parameters and 0 non-trainable parameters
Number of BERT layers requiring gradients: 12 out of 12
Fine-tuning the last 12 out of 12 BERT layers

Model Architecture Summary:
BERTClassifier(
  (bert): ElectraModel(
    (embeddings): ElectraEmbeddings(
      (word_embeddings): Embedding(30522, 768, padding_idx=0)
      (position_embeddings): Embedding(512, 768)
      (token_type_embeddings): Embedding(2, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): ElectraEncoder(
      (layer): ModuleList(
        (0-11): 12 x ElectraLayer(
          (attention): ElectraAttention(
            (self): ElectraSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): ElectraSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): ElectraIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): ElectraOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
  (custom_pooling): PoolingLayer()
  (classifier): Classifier(
    (layers): Sequential(
      (0): Linear(in_features=768, out_features=1024, bias=True)
      (1): SwishGLU(
        (projection): Linear(in_features=1024, out_features=2048, bias=True)
        (activation): SiLU()
      )
      (2): Dropout(p=0.3, inplace=False)
      (3): Linear(in_features=1024, out_features=1024, bias=True)
      (4): SwishGLU(
        (projection): Linear(in_features=1024, out_features=2048, bias=True)
        (activation): SiLU()
      )
      (5): Dropout(p=0.3, inplace=False)
      (6): Linear(in_features=1024, out_features=3, bias=True)
    )
  )
)

Model Parameters:
  bert.embeddings.word_embeddings: 23,440,896 (trainable)
  bert.embeddings.position_embeddings: 393,216 (trainable)
  bert.embeddings.token_type_embeddings: 1,536 (trainable)
  bert.embeddings.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.0.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.0.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.0.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.0.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.0.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.0.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.0.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.0.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.1.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.1.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.1.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.1.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.1.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.1.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.1.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.1.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.2.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.2.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.2.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.2.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.2.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.2.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.2.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.2.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.3.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.3.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.3.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.3.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.3.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.3.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.3.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.3.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.4.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.4.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.4.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.4.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.4.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.4.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.4.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.4.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.5.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.5.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.5.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.5.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.5.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.5.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.5.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.5.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.6.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.6.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.6.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.6.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.6.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.6.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.6.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.6.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.7.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.7.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.7.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.7.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.7.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.7.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.7.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.7.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.8.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.8.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.8.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.8.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.8.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.8.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.8.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.8.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.9.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.9.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.9.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.9.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.9.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.9.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.9.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.9.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.10.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.10.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.10.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.10.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.10.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.10.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.10.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.10.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.11.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.11.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.11.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.11.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.11.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.11.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.11.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.11.output.LayerNorm: 1,536 (trainable)
  classifier.layers.0: 787,456 (trainable)
  classifier.layers.1.projection: 2,099,200 (trainable)
  classifier.layers.3: 1,049,600 (trainable)
  classifier.layers.6: 3,075 (trainable)

Total layers: 104
Trainable layers: 104
Total parameters: 112,830,979
Trainable parameters: 112,830,979
Percentage of trainable parameters: 100.00%
Using optimizer: AdamW, Use Zero: True, Base Learning Rate: 1e-05, L2 strength: 0.01
Layer-wise decay factor: 0.95
Using scheduler: CosineAnnealingWarmRestarts
Scheduler arguments:
- T_0: 5
- T_mult: 1
- eta_min: 1e-07

Starting training loop...
Start epoch: 21, Max Iterations: 50, Early Stop: score, Tolerance: 0.00001, Number Iterations No Change: 10

[Enter] to continue for 1 epoch, [Q]uit, [S]ave, [H]elp: q
Quitting training...
Saving model in ONNX format...
Model saved in ONNX format to saves/model_20241026-052850.onnx and uploaded to Weights & Biases.
Saved model state: checkpoints/final_model_20241026-052857.pth
Saved model pickle: checkpoints/final_model_20241026-052857.pkl
Training completed (1m 16s)

Evaluating model...

stage_1_merged Multi-Class Classification Report

              precision    recall  f1-score   support

    negative   0.847879  0.748929  0.795338      1868
     neutral   0.711445  0.793289  0.750142      1669
    positive   0.815183  0.826433  0.820770      1884

    accuracy                       0.789522      5421
   macro avg   0.791502  0.789551  0.788750      5421
weighted avg   0.794511  0.789522  0.790262      5421

ROC AUC: 0.923116

Predicted  negative  neutral  positive
Actual                                
negative       1399      311       158
neutral         150     1324       195
positive        101      226      1557

Saved predictions: saves/predictions_20241026-053046.csv

Macro F1 Score: 0.79

Evaluation completed (2m 33s)
wandb:                                                                                
wandb: 
wandb: Run history:
wandb: eval/macro_f1_score â–
wandb: 
wandb: Run summary:
wandb: eval/macro_f1_score 0.78875
wandb: 
wandb: ðŸš€ View run stage_1_merged at: https://wandb.ai/jimbeno/Electra%20Base/runs/rly8s8zt
wandb: â­ï¸ View project at: https://wandb.ai/jimbeno/Electra%20Base
wandb: Synced 4 W&B file(s), 0 media file(s), 5 artifact file(s) and 2 other file(s)
wandb: Find logs at: ./wandb/run-20241026_052732-rly8s8zt/logs
TOTAL Time: 4m 26s
(nlp) ubuntu@104-171-202-167:~/nlp-test/sentiment$ python ./ddp_sentiment_finetune.py --dataset 'merged_local' --weights_name 'google/electra-base-discriminator' --save_data --save_model --save_pickle --save_preds --lr 0.00001 --lr_decay 0.95 --epochs 50 --pooling 'mean' --dropout_rate 0.3 --num_layers 2 --hidden_dim 1024 --hidden_activation 'swishglu' --batch_size 16 --accumulation_steps 2 --finetune_bert --finetune_layers 12 --l2_strength 0.01  --checkpoint_interval 1 --use_zero --optimizer 'adamw' --scheduler 'cosine_warmup' --scheduler_kwargs '{"T_0":5, "T_mult":1, "eta_min":1e-7}' --decimal 6 --use_val_split --eval_split 'test' --early_stop 'score' --n_iter_no_change 10 --show_progress --wandb --wandb_project 'Electra Base' --wandb_run 'stage_1_merged_epoch14' --model_file 'checkpoint_epoch_14_20241026-042844.pth' --interactive

Starting DDP PyTorch Training...
Device: cuda, Number of GPUs: 8
Spawning 8 processes...
Rank 3 - Device: cuda:3
Rank 7 - Device: cuda:7
Rank 5 - Device: cuda:5
Rank 1 - Device: cuda:1
Rank 4 - Device: cuda:4
Rank 2 - Device: cuda:2
Rank 6 - Device: cuda:6
Rank 0 - Device: cuda:0
8 process groups initialized with 'nccl' backend on localhost:12355
NCCL Timeout: 1 hr 0 min. NCCL Blocking Wait: Enabled
wandb: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: jbeno (jimbeno). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.3
wandb: Run data is saved locally in /home/ubuntu/nlp-test/sentiment/wandb/run-20241026_053343-jsr2tzc9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stage_1_merged_epoch14
wandb: â­ï¸ View project at https://wandb.ai/jimbeno/Electra%20Base
wandb: ðŸš€ View run at https://wandb.ai/jimbeno/Electra%20Base/runs/jsr2tzc9
Wand run initialized.

Initializing 'google/electra-base-discriminator' tokenizer and model...
Checking for local files...
Found all files in cache, skipping download
All ranks loading tokenizer from local files...
All ranks loading model from local files...
Tokenizer and model initialized (3s)

Loading data...
Using the same dataset for training and evaluation
Splits:
- Train: Using merged_local 'train' split
- Validation: Using merged_local 'validation' split
- Evaluation: Using merged_local 'test' split
Train Data: Merged DynaSent Round 1, Round 2 and SST from Local: 'data/merged'
Validation Data: Merged DynaSent Round 1, Round 2 and SST from Local: 'data/merged'
Evaluation Data: Merged DynaSent Round 1, Round 2 and SST from Local: 'data/merged'
Train size: 102097
Validation size: 5421
Evaluation size: 5421
Train label distribution:
	      Negative: 21910
	       Neutral: 49148
	      Positive: 31039
Validation label distribution:
	      Negative: 1868
	       Neutral: 1669
	      Positive: 1884
Evaluation label distribution:
	      Negative: 1868
	       Neutral: 1669
	      Positive: 1884
Data loaded (310ms)

Processing data...
(Batch size: 16, Pooling: Mean, Fine Tune BERT: True, Chunk size: None)...
Extracting sentences and labels...

Data saved to: saves/data_8_gpu_20241026-053348.npz
X Train shape: [102097], X Validation shape: [5421], X Test shape: [5421]
y Train shape: [102097], y Validation shape: [5421], y Test shape: [5421]
Data processed (764ms)

Initializing DDP Neural Classifier...
Layers: 2, Hidden Dim: 1024, Hidden Act: SwishGLU, Dropout: 0.3, Optimizer: AdamW, L2 Strength: 0.01, Pooling: MEAN, Accumulation Steps: 2, Max Grad Norm: None
Batch Size: 16, Max Epochs: 50, LR: 1e-05, Early Stop: score, Fine-tune BERT: True, Fine-tune Layers: 12, Freeze BERT: False, Target Score: None, Interactive: True
Loading model from: checkpoints/checkpoint_epoch_14_20241026-042844.pth...
Loaded checkpoint: checkpoints/checkpoint_epoch_14_20241026-042844.pth
Retrieved model state dictionary.
Retrieved optimizer state dictionary.
Classifier initialized (11s)

Fitting DDP Neural Classifier on training data...
Num Workers: 0, Prefetch: None
Score-based early stopping enabled (macro average F1 score against validation set). Validation fraction: 0.1
Training will stop early if the score does not improve by at least 0.00001 for 10 iterations.
Using provided validation set for early stopping.
Building dataset and dataloader...
Initializing model, graph, optimizer...
BERT's original pooler removed. Using custom pooling type: mean
BERT has 108,891,648 trainable parameters and 0 non-trainable parameters
Number of BERT layers requiring gradients: 12 out of 12
Fine-tuning the last 12 out of 12 BERT layers

Model Architecture Summary:
BERTClassifier(
  (bert): ElectraModel(
    (embeddings): ElectraEmbeddings(
      (word_embeddings): Embedding(30522, 768, padding_idx=0)
      (position_embeddings): Embedding(512, 768)
      (token_type_embeddings): Embedding(2, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): ElectraEncoder(
      (layer): ModuleList(
        (0-11): 12 x ElectraLayer(
          (attention): ElectraAttention(
            (self): ElectraSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): ElectraSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): ElectraIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): ElectraOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
  (custom_pooling): PoolingLayer()
  (classifier): Classifier(
    (layers): Sequential(
      (0): Linear(in_features=768, out_features=1024, bias=True)
      (1): SwishGLU(
        (projection): Linear(in_features=1024, out_features=2048, bias=True)
        (activation): SiLU()
      )
      (2): Dropout(p=0.3, inplace=False)
      (3): Linear(in_features=1024, out_features=1024, bias=True)
      (4): SwishGLU(
        (projection): Linear(in_features=1024, out_features=2048, bias=True)
        (activation): SiLU()
      )
      (5): Dropout(p=0.3, inplace=False)
      (6): Linear(in_features=1024, out_features=3, bias=True)
    )
  )
)

Model Parameters:
  bert.embeddings.word_embeddings: 23,440,896 (trainable)
  bert.embeddings.position_embeddings: 393,216 (trainable)
  bert.embeddings.token_type_embeddings: 1,536 (trainable)
  bert.embeddings.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.0.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.0.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.0.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.0.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.0.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.0.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.0.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.0.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.1.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.1.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.1.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.1.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.1.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.1.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.1.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.1.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.2.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.2.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.2.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.2.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.2.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.2.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.2.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.2.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.3.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.3.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.3.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.3.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.3.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.3.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.3.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.3.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.4.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.4.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.4.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.4.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.4.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.4.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.4.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.4.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.5.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.5.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.5.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.5.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.5.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.5.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.5.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.5.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.6.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.6.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.6.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.6.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.6.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.6.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.6.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.6.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.7.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.7.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.7.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.7.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.7.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.7.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.7.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.7.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.8.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.8.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.8.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.8.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.8.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.8.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.8.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.8.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.9.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.9.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.9.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.9.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.9.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.9.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.9.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.9.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.10.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.10.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.10.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.10.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.10.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.10.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.10.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.10.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.11.attention.self.query: 590,592 (trainable)
  bert.encoder.layer.11.attention.self.key: 590,592 (trainable)
  bert.encoder.layer.11.attention.self.value: 590,592 (trainable)
  bert.encoder.layer.11.attention.output.dense: 590,592 (trainable)
  bert.encoder.layer.11.attention.output.LayerNorm: 1,536 (trainable)
  bert.encoder.layer.11.intermediate.dense: 2,362,368 (trainable)
  bert.encoder.layer.11.output.dense: 2,360,064 (trainable)
  bert.encoder.layer.11.output.LayerNorm: 1,536 (trainable)
  classifier.layers.0: 787,456 (trainable)
  classifier.layers.1.projection: 2,099,200 (trainable)
  classifier.layers.3: 1,049,600 (trainable)
  classifier.layers.6: 3,075 (trainable)

Total layers: 104
Trainable layers: 104
Total parameters: 112,830,979
Trainable parameters: 112,830,979
Percentage of trainable parameters: 100.00%
Using optimizer: AdamW, Use Zero: True, Base Learning Rate: 1e-05, L2 strength: 0.01
Layer-wise decay factor: 0.95
Using scheduler: CosineAnnealingWarmRestarts
Scheduler arguments:
- T_0: 5
- T_mult: 1
- eta_min: 1e-07

Starting training loop...
Start epoch: 15, Max Iterations: 50, Early Stop: score, Tolerance: 0.00001, Number Iterations No Change: 10

[Enter] to continue for 1 epoch, [Q]uit, [S]ave, [H]elp: q
Quitting training...
Saving model in ONNX format...
Model saved in ONNX format to saves/model_20241026-053500.onnx and uploaded to Weights & Biases.
Saved model state: checkpoints/final_model_20241026-053505.pth
Saved model pickle: checkpoints/final_model_20241026-053505.pkl
Training completed (1m 12s)

Evaluating model...

stage_1_merged_epoch14 Multi-Class Classification Report

              precision    recall  f1-score   support

    negative   0.841456  0.767131  0.802576      1868
     neutral   0.726275  0.793289  0.758305      1669
    positive   0.816359  0.821125  0.818735      1884

    accuracy                       0.793949      5421
   macro avg   0.794697  0.793848  0.793205      5421
weighted avg   0.797272  0.793949  0.794562      5421

ROC AUC: 0.926417

Predicted  negative  neutral  positive
Actual                                
negative       1433      270       165
neutral         162     1324       183
positive        108      229      1547

Saved predictions: saves/predictions_20241026-053655.csv

Macro F1 Score: 0.79

Evaluation completed (2m 33s)
wandb:                                                                                
wandb: 
wandb: Run history:
wandb: eval/macro_f1_score â–
wandb: 
wandb: Run summary:
wandb: eval/macro_f1_score 0.79321
wandb: 
wandb: ðŸš€ View run stage_1_merged_epoch14 at: https://wandb.ai/jimbeno/Electra%20Base/runs/jsr2tzc9
wandb: â­ï¸ View project at: https://wandb.ai/jimbeno/Electra%20Base
wandb: Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 2 other file(s)
wandb: Find logs at: ./wandb/run-20241026_053343-jsr2tzc9/logs
TOTAL Time: 4m 22s
(nlp) ubuntu@104-171-202-167:~/nlp-test/sentiment$ 
