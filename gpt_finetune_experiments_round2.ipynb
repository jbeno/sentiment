{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3208bebc",
   "metadata": {},
   "source": [
    "# GPT-4o/4o-mini Fine-Tuning and DSPy Experiments\n",
    "\n",
    "Round 2: Seed 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f6aadee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set different seed and temperature for variability\n",
    "random_seed = 123\n",
    "temperature = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae22d221",
   "metadata": {},
   "source": [
    "## Initial Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab698db",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b7d665d-000e-4bae-83a8-1f7c78879df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OS and utilities\n",
    "import os\n",
    "import io\n",
    "import time\n",
    "import pickle\n",
    "from time import sleep\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import warnings\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Data processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine learning\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import ElectraTokenizer\n",
    "import tiktoken\n",
    "\n",
    "# OpenAI\n",
    "from openai import OpenAI\n",
    "\n",
    "# DSPy and ReCOGS\n",
    "import dsp\n",
    "import dspy\n",
    "from dspy.evaluate.evaluate import Evaluate\n",
    "from dspy import Retrieve\n",
    "\n",
    "# Instrumentation and tracing\n",
    "from phoenix.otel import register\n",
    "from openinference.instrumentation.dspy import DSPyInstrumentor\n",
    "\n",
    "# Typing\n",
    "from typing import List, Union\n",
    "\n",
    "# Local imports\n",
    "from datawaza_funcs import eval_model\n",
    "from utils import fix_random_seeds, prepare_device, setup_environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80380fc",
   "metadata": {},
   "source": [
    "### Environment and Preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5609266f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DSPy notebook cache\n",
    "root_path = '.'\n",
    "os.environ[\"DSP_NOTEBOOK_CACHEDIR\"] = os.path.join(root_path, 'cache')\n",
    "\n",
    "# Pandas display options\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "378007d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress specific warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"resume_download is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use force_download=True.\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\"`resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff190c03",
   "metadata": {},
   "source": [
    "### API Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6068202a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load API keys from .env file\n",
    "load_dotenv()\n",
    "openai_key = os.getenv('OPENAI_API_KEY')\n",
    "arize_key = os.getenv('ARIZE_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a04d21c",
   "metadata": {},
   "source": [
    "### Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67c8b8a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ID                                Creation Date                           \n",
      "--------------------------------------------------------------------------------\n",
      "gpt-4o-mini-tts                         2025-03-19 17:05:59                     \n",
      "o1-pro                                  2025-03-17 22:49:51                     \n",
      "o1-pro-2025-03-19                       2025-03-17 22:45:04                     \n",
      "gpt-4o-mini-transcribe                  2025-03-15 19:56:36                     \n",
      "gpt-4o-transcribe                       2025-03-15 19:54:23                     \n",
      "gpt-4o-mini-search-preview              2025-03-07 23:46:01                     \n",
      "gpt-4o-mini-search-preview-2025-03-11   2025-03-07 23:40:58                     \n",
      "gpt-4o-search-preview                   2025-03-07 23:05:20                     \n",
      "gpt-4o-search-preview-2025-03-11        2025-03-07 22:56:10                     \n",
      "computer-use-preview-2025-03-11         2025-03-07 19:50:21                     \n",
      "gpt-4.5-preview-2025-02-27              2025-02-27 02:28:24                     \n",
      "gpt-4.5-preview                         2025-02-27 02:24:19                     \n",
      "gpt-4o-2024-11-20                       2025-02-12 03:39:03                     \n",
      "o3-mini-2025-01-31                      2025-01-27 20:36:40                     \n",
      "o3-mini                                 2025-01-17 20:39:43                     \n",
      "computer-use-preview                    2024-12-20 00:47:57                     \n",
      "gpt-4o-mini-audio-preview               2024-12-16 22:17:04                     \n",
      "gpt-4o-mini-realtime-preview            2024-12-16 22:16:20                     \n",
      "o1                                      2024-12-16 19:03:36                     \n",
      "o1-2024-12-17                           2024-12-16 05:29:36                     \n",
      "gpt-4o-mini-audio-preview-2024-12-17    2024-12-13 18:52:00                     \n",
      "gpt-4o-mini-realtime-preview-2024-12-17 2024-12-13 17:56:41                     \n",
      "gpt-4o-audio-preview-2024-12-17         2024-12-12 20:10:39                     \n",
      "gpt-4o-realtime-preview-2024-12-17      2024-12-11 19:30:30                     \n",
      "omni-moderation-2024-09-26              2024-11-27 19:07:46                     \n",
      "omni-moderation-latest                  2024-11-15 16:47:45                     \n",
      "gpt-4o-realtime-preview                 2024-09-30 01:33:18                     \n",
      "gpt-4o-audio-preview                    2024-09-27 18:07:23                     \n",
      "gpt-4o-audio-preview-2024-10-01         2024-09-26 22:17:22                     \n",
      "gpt-4o-realtime-preview-2024-10-01      2024-09-23 22:49:26                     \n",
      "o1-mini                                 2024-09-06 18:56:48                     \n",
      "o1-mini-2024-09-12                      2024-09-06 18:56:19                     \n",
      "o1-preview                              2024-09-06 18:54:57                     \n",
      "o1-preview-2024-09-12                   2024-09-06 18:54:25                     \n",
      "chatgpt-4o-latest                       2024-08-13 02:12:11                     \n",
      "gpt-4o-2024-08-06                       2024-08-04 23:38:39                     \n",
      "gpt-4o-mini                             2024-07-16 23:32:21                     \n",
      "gpt-4o-mini-2024-07-18                  2024-07-16 23:31:57                     \n",
      "gpt-4o-2024-05-13                       2024-05-10 19:08:52                     \n",
      "gpt-4o                                  2024-05-10 18:50:49                     \n",
      "gpt-4-turbo-2024-04-09                  2024-04-08 18:41:17                     \n",
      "gpt-4-turbo                             2024-04-05 23:57:21                     \n",
      "gpt-3.5-turbo-0125                      2024-01-23 22:19:18                     \n",
      "gpt-4-turbo-preview                     2024-01-23 19:22:57                     \n",
      "gpt-4-0125-preview                      2024-01-23 19:20:12                     \n",
      "text-embedding-3-large                  2024-01-22 19:53:00                     \n",
      "text-embedding-3-small                  2024-01-22 18:43:17                     \n",
      "tts-1-hd-1106                           2023-11-03 23:18:53                     \n",
      "tts-1-1106                              2023-11-03 23:14:01                     \n",
      "tts-1-hd                                2023-11-03 21:13:35                     \n",
      "gpt-3.5-turbo-1106                      2023-11-02 21:15:48                     \n",
      "gpt-4-1106-preview                      2023-11-02 20:33:26                     \n",
      "dall-e-2                                2023-11-01 00:22:57                     \n",
      "dall-e-3                                2023-10-31 20:46:29                     \n",
      "gpt-3.5-turbo-instruct-0914             2023-09-07 21:34:32                     \n",
      "gpt-3.5-turbo-instruct                  2023-08-24 18:23:47                     \n",
      "babbage-002                             2023-08-21 16:16:55                     \n",
      "davinci-002                             2023-08-21 16:11:41                     \n",
      "gpt-4                                   2023-06-27 16:13:31                     \n",
      "gpt-4-0613                              2023-06-12 16:54:56                     \n",
      "gpt-3.5-turbo-16k                       2023-05-10 22:35:02                     \n",
      "tts-1                                   2023-04-19 21:49:11                     \n",
      "gpt-3.5-turbo                           2023-02-28 18:56:42                     \n",
      "whisper-1                               2023-02-27 21:13:04                     \n",
      "text-embedding-ada-002                  2022-12-16 19:01:39                     \n"
     ]
    }
   ],
   "source": [
    "# Create OpenAI client\n",
    "client = OpenAI()\n",
    "models = client.models.list()\n",
    "\n",
    "# Print OpenAI models by creation date\n",
    "sorted_models = sorted(models.dict()['data'], key=lambda x: x['created'], reverse=True)\n",
    "print(f\"{'Model ID':<40}{'Creation Date':<40}\")\n",
    "print('-'*80)\n",
    "for model in sorted_models:\n",
    "    if not model['id'].startswith('ft:'):\n",
    "        print(f\"{model['id']:<40}{datetime.fromtimestamp(int(model['created'])).strftime('%Y-%m-%d %H:%M:%S'):<40}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70692f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ID                                Creation Date                           \n",
      "--------------------------------------------------------------------------------\n",
      "ft:gpt-4o-mini-2024-07-18:personal:5-epochs:BCEIpoGP:ckpt-step-30042025-03-17 23:36:55                     \n",
      "ft:gpt-4o-mini-2024-07-18:personal:5-epochs:BCEIpYAW:ckpt-step-45062025-03-17 23:36:55                     \n",
      "ft:gpt-4o-mini-2024-07-18:personal:5-epochs:BCEIp15y2025-03-17 23:36:55                     \n",
      "ft:gpt-4o-mini-2024-07-18:personal:5-epochs:BBxo5jXI:ckpt-step-45062025-03-17 06:00:06                     \n",
      "ft:gpt-4o-mini-2024-07-18:personal:5-epochs:BBxo6eOL2025-03-17 06:00:06                     \n",
      "ft:gpt-4o-mini-2024-07-18:personal:5-epochs:BBxo5hHh:ckpt-step-30042025-03-17 06:00:05                     \n",
      "ft:gpt-4o-mini-2024-07-18:personal::BBq9HSob2025-03-16 21:49:27                     \n",
      "ft:gpt-4o-mini-2024-07-18:personal::BBcWZcsN:ckpt-step-45062025-03-16 07:16:35                     \n",
      "ft:gpt-4o-mini-2024-07-18:personal::BBcWZoJK:ckpt-step-60082025-03-16 07:16:35                     \n",
      "ft:gpt-4o-mini-2024-07-18:personal::BBcWZNa32025-03-16 07:16:35                     \n",
      "ft:gpt-4o-2024-08-06:personal::ANcREuvn 2024-10-29 09:04:25                     \n",
      "ft:gpt-4o-2024-08-06:personal::ANcRE82D:ckpt-step-15012024-10-29 09:04:24                     \n",
      "ft:gpt-4o-mini-2024-07-18:personal::ANVDva8W2024-10-29 01:22:12                     \n",
      "ft:gpt-4o-mini-2024-07-18:personal::ANVDv9OK:ckpt-step-15012024-10-29 01:22:11                     \n",
      "ft:gpt-4o-2024-08-06:personal::AN55MS6K 2024-10-27 21:27:37                     \n",
      "ft:gpt-4o-2024-08-06:personal::AN55MR8o:ckpt-step-15012024-10-27 21:27:36                     \n",
      "ft:gpt-4o-mini-2024-07-18:personal::AN2RNUvd2024-10-27 18:38:10                     \n",
      "ft:gpt-4o-mini-2024-07-18:personal::AN2RNzz6:ckpt-step-15012024-10-27 18:38:09                     \n",
      "ft:gpt-4o-2024-08-06:personal::AM5cgCGf:ckpt-step-15012024-10-25 03:49:54                     \n",
      "ft:gpt-4o-2024-08-06:personal::AM5cg622 2024-10-25 03:49:54                     \n",
      "ft:gpt-4o-mini-2024-07-18:personal::ALnBCEST:ckpt-step-15012024-10-24 08:08:18                     \n",
      "ft:gpt-4o-mini-2024-07-18:personal::ALnBCKLv2024-10-24 08:08:18                     \n",
      "ft:gpt-4o-mini-2024-07-18:personal::AAC6TH6s:ckpt-step-15062024-09-22 08:19:30                     \n",
      "ft:gpt-4o-mini-2024-07-18:personal::AAC6UAgP2024-09-22 08:19:30                     \n"
     ]
    }
   ],
   "source": [
    "# Print the fine-tuned models\n",
    "print(f\"{'Model ID':<40}{'Creation Date':<40}\")\n",
    "print('-'*80)\n",
    "for model in sorted_models:\n",
    "    if model['id'].startswith('ft:'):\n",
    "        print(f\"{model['id']:<40}{datetime.fromtimestamp(int(model['created'])).strftime('%Y-%m-%d %H:%M:%S'):<40}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "da9933f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the language model\n",
    "lm = dspy.OpenAI(model='gpt-4o-mini-2024-07-18', api_key=openai_key, max_tokens=8192, temperature=temperature)\n",
    "dspy.settings.configure(lm=lm, experimental=False, seed=random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbcc2f1",
   "metadata": {},
   "source": [
    "### Arize Phoenix for Traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa95b347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arize environment variables\n",
    "os.environ[\"OTEL_EXPORTER_OTLP_HEADERS\"] = f\"api_key={arize_key}\"\n",
    "os.environ[\"PHOENIX_CLIENT_HEADERS\"] = f\"api_key={arize_key}\"\n",
    "os.environ[\"PHOENIX_COLLECTOR_ENDPOINT\"] = \"https://app.phoenix.arize.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bad5245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the tracer provider\n",
    "tracer_provider = register(\n",
    "  project_name=\"final_project_round_2\",\n",
    "  endpoint=\"https://app.phoenix.arize.com/v1/traces\",\n",
    "  headers={\"api_key\": f\"{arize_key}\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78316edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the DSPy instrumentor\n",
    "DSPyInstrumentor().instrument(tracer_provider=tracer_provider)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da14956-1813-4372-b747-d7a2dbd10bc1",
   "metadata": {},
   "source": [
    "## Sentiment Data\n",
    "\n",
    "The dataset is a merge of DynaSent R1, DynaSent R2, and SST-3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22f20b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the merged datasets\n",
    "train_df = pd.read_csv('data/merged/train_all.csv')\n",
    "val_df = pd.read_csv('data/merged/val_all.csv')\n",
    "test_df = pd.read_csv('data/merged/test_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4550880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 102097\n",
      "Validation: 5421\n",
      "Test: 6530\n"
     ]
    }
   ],
   "source": [
    "# Print the lengths of each dataset\n",
    "print(f\"Train: {len(train_df)}\")\n",
    "print(f\"Validation: {len(val_df)}\")\n",
    "print(f\"Test: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83b8ca91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>source</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Those 2 drinks are part of the HK culture and has years of history. It is so bad.</td>\n",
       "      <td>negative</td>\n",
       "      <td>dynasent_r2</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I was told by the repair company that was doing the car repair that fixing the rim was \"impossible\" and to replace it.</td>\n",
       "      <td>negative</td>\n",
       "      <td>dynasent_r1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It is there to give them a good time .</td>\n",
       "      <td>neutral</td>\n",
       "      <td>sst_local</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Like leafing through an album of photos accompanied by the sketchiest of captions .</td>\n",
       "      <td>negative</td>\n",
       "      <td>sst_local</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Johnny was a talker and liked to have fun.</td>\n",
       "      <td>positive</td>\n",
       "      <td>dynasent_r1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                 sentence  \\\n",
       "0                                       Those 2 drinks are part of the HK culture and has years of history. It is so bad.   \n",
       "1  I was told by the repair company that was doing the car repair that fixing the rim was \"impossible\" and to replace it.   \n",
       "2                                                                                  It is there to give them a good time .   \n",
       "3                                     Like leafing through an album of photos accompanied by the sketchiest of captions .   \n",
       "4                                                                              Johnny was a talker and liked to have fun.   \n",
       "\n",
       "      label       source  split  \n",
       "0  negative  dynasent_r2  train  \n",
       "1  negative  dynasent_r1  train  \n",
       "2   neutral    sst_local  train  \n",
       "3  negative    sst_local  train  \n",
       "4  positive  dynasent_r1  train  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Review the train dataset\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a145a809-6cc7-4711-aa94-850fd1383ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creat a list of dspy.Example objects from train_df\n",
    "train_ex = [dspy.Example(review=row['sentence'], classification=row['label']).with_inputs('review') for _, row in train_df.iterrows()]\n",
    "val_ex = [dspy.Example(review=row['sentence'], classification=row['label']).with_inputs('review') for _, row in val_df.iterrows()]\n",
    "test_ex = [dspy.Example(review=row['sentence'], classification=row['label']).with_inputs('review') for _, row in test_df.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f25e7c11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Example({'review': 'Those 2 drinks are part of the HK culture and has years of history. It is so bad.', 'classification': 'negative'}) (input_keys={'review'}),\n",
       " Example({'review': 'I was told by the repair company that was doing the car repair that fixing the rim was \"impossible\" and to replace it.', 'classification': 'negative'}) (input_keys={'review'}),\n",
       " Example({'review': 'It is there to give them a good time .', 'classification': 'neutral'}) (input_keys={'review'}),\n",
       " Example({'review': 'Like leafing through an album of photos accompanied by the sketchiest of captions .', 'classification': 'negative'}) (input_keys={'review'}),\n",
       " Example({'review': 'Johnny was a talker and liked to have fun.', 'classification': 'positive'}) (input_keys={'review'})]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Review the first few examples\n",
    "train_ex[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372ce2db",
   "metadata": {},
   "source": [
    "## ELECTRA Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967e021c",
   "metadata": {},
   "source": [
    "### Setup DDP Environment\n",
    "\n",
    "I fine-tuned my models in a DDP multi-GPU environment using `finetune.py`. Because I'm loading a checkpoint from that pipeline, which has a DDP wrapper, I'm runninig some minimal functions here to setup a basic single-GPU DDP environemnt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "05a2b165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set some variables for the DDP environment\n",
    "rank = 0\n",
    "device_type = 'cuda'\n",
    "world_size = 1\n",
    "backend = 'nccl'\n",
    "debug = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "77792345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the device\n",
    "device = prepare_device(rank, device_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df440d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 0 - Device: cuda:0\n",
      "1 process groups initialized with 'nccl' backend on localhost:12355\n",
      "NCCL Timeout: 1 hr 0 min. NCCL Blocking Wait: Enabled\n"
     ]
    }
   ],
   "source": [
    "# Initiate the process group\n",
    "setup_environment(rank, world_size, backend, device, debug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "a4d34860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set random seeds\n",
    "fix_random_seeds(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6862aec",
   "metadata": {},
   "source": [
    "### Load ELECTRA Tokenizer and Fine-Tuned Model\n",
    "\n",
    "We'll load an ELECTRA model that was fine-tuned on sentiment using `finetune.py`. This will be part of our DSPy module's forward pass. We'll get the ELECTRA classification for the review, and that will be input/context in the prompt for the GPT4o-mini language model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637efaca",
   "metadata": {},
   "source": [
    "#### Use This to Reproduce\n",
    "\n",
    "Uncomment the following code to load the fine-tuned models from Hugging Face.\n",
    "\n",
    "### NOTE: Need to use these models for round 1 vs round 2:\n",
    "\n",
    "**ROUND 1**\n",
    "- Base: from HF 'jbeno/electra-base-classifier-sentiment' (why? did not update because round 1 was best)\n",
    "- Large: from local 'models/final_model_20241025-024222.pkl' (why? HF large was updated to round 2)\n",
    "\n",
    "**ROUND 2**\n",
    "- Base: from local 'final_model_20250323-020916.pkl' (why? did not upload this to HF because less good)\n",
    "- Large: from HF 'jbeno/electra-large-classifier-sentiment' (why? HF large was updated because performed best)\n",
    "\n",
    "NOTE: I am temporarily doing the opposite of this in this file because round1 file is busy running experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b833c67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElectraClassifier(\n",
       "  (electra): ElectraModel(\n",
       "    (embeddings): ElectraEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): ElectraEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooling): PoolingLayer()\n",
       "  (classifier): Classifier(\n",
       "    (layers): Sequential(\n",
       "      (0): Linear(in_features=768, out_features=1024, bias=True)\n",
       "      (1): SwishGLU(\n",
       "        (projection): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "        (activation): SiLU()\n",
       "      )\n",
       "      (2): Dropout(p=0.3, inplace=False)\n",
       "      (3): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (4): SwishGLU(\n",
       "        (projection): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "        (activation): SiLU()\n",
       "      )\n",
       "      (5): Dropout(p=0.3, inplace=False)\n",
       "      (6): Linear(in_features=1024, out_features=3, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import sys\n",
    "#!{sys.executable} -m pip install electra_classifier\n",
    "from transformers import AutoTokenizer\n",
    "from electra_classifier import ElectraClassifier\n",
    "\n",
    "large_model_name = \"jbeno/electra-large-classifier-sentiment\"\n",
    "base_model_name = \"jbeno/electra-base-classifier-sentiment\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(large_model_name)\n",
    "\n",
    "electra_large_model = ElectraClassifier.from_pretrained(large_model_name)\n",
    "electra_large_model.to(device)\n",
    "\n",
    "electra_base_model = ElectraClassifier.from_pretrained(base_model_name)\n",
    "electra_base_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8e4dc3",
   "metadata": {},
   "source": [
    "#### Original Code\n",
    "\n",
    "What follows is the code used for the original research. You can skip this section if you've loaded it from Hugging Face above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "51d94693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the ELECTRA tokenizer from Hugging Face\n",
    "#tokenizer = ElectraTokenizer.from_pretrained('google/electra-large-discriminator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3177d6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to unpickle the checkpoint saved with DDP and GPUs\n",
    "# class CPU_Unpickler(pickle.Unpickler):\n",
    "#     def find_class(self, module, name):\n",
    "#         if module == 'torch.storage' and name == '_load_from_bytes':\n",
    "#             return lambda b: torch.load(io.BytesIO(b), map_location='cpu')\n",
    "#         else: return super().find_class(module, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fae1cec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the ELECTRA Large model from a checkpoint pickle file\n",
    "# NOTE: This file path does not exist in the repository, use the Hugging Face approach above instead\n",
    "# with open('models/final_model_20241025-024222.pkl', 'rb') as f:\n",
    "#     electra_large_model = CPU_Unpickler(f).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0283f827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the model to the device (GPU ideally) to speed up inference time\n",
    "# electra_large_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89678a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review the ELECTRA Large model with custom pooling and classifier head\n",
    "#electra_large_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7e3637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the ELECTRA Base model from a checkpoint pickle file\n",
    "# NOTE: This file path does not exist in the repository, use the Hugging Face approach above instead\n",
    "# with open('final_model_20250323-020916.pkl', 'rb') as f:\n",
    "#     electra_base_model = CPU_Unpickler(f).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af0f039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the model to the device (GPU ideally) to speed up inference time\n",
    "# electra_base_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993ff1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review the ELECTRA Base model with custom pooling and classifier head\n",
    "#electra_base_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3845252a",
   "metadata": {},
   "source": [
    "### ELECTRA Prediction Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9550d51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the class label mapping dictionary\n",
    "numeric_dict = {0: 'negative', 1: 'neutral', 2: 'positive'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b1d831d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize function\n",
    "def tokenize(texts, tokenizer, device):\n",
    "    encoded = tokenizer.batch_encode_plus(\n",
    "        texts,\n",
    "        add_special_tokens=True,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    input_ids = encoded['input_ids'].to(device)\n",
    "    attention_mask = encoded['attention_mask'].to(device)\n",
    "    \n",
    "    return input_ids, attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3f3816fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict the class of a sentence\n",
    "def predict_sentence(model, sentence, tokenizer, numeric_dict):\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    #model = model.model  # Needed for DDP wrapped models\n",
    "    \n",
    "    # Tokenize the input sentence\n",
    "    input_ids, attention_mask = tokenize([sentence], tokenizer, device)\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Perform inference\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "    # Get the predictions\n",
    "    if isinstance(outputs, torch.Tensor):\n",
    "        logits = outputs\n",
    "    elif hasattr(outputs, 'logits'):\n",
    "        logits = outputs.logits\n",
    "    else:\n",
    "        logits = outputs[0]\n",
    "\n",
    "    probabilities = torch.softmax(logits, dim=1)\n",
    "    predicted_class = torch.argmax(probabilities, dim=1).item()\n",
    "    predicted_label = numeric_dict[predicted_class]\n",
    "\n",
    "    # Move probabilities back to CPU and convert to list\n",
    "    probabilities = probabilities.cpu().squeeze().tolist()\n",
    "\n",
    "    # Free up GPU memory\n",
    "    del input_ids, attention_mask, logits, outputs\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    return predicted_class, predicted_label, probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8f0e022e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_review = \"Those 2 drinks are part of the HK culture and has years of history. It is so bad.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8db51557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,\n",
       " 'negative',\n",
       " [0.9988487958908081, 0.0008097602985799313, 0.0003413360973354429])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test prediction with ELECTRA base model\n",
    "predict_sentence(electra_base_model, test_review, tokenizer, numeric_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2a394eaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,\n",
       " 'negative',\n",
       " [0.9990077614784241, 0.0005539217963814735, 0.000438391842180863])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test prediction with ELECTRA large model\n",
    "predict_sentence(electra_large_model, test_review, tokenizer, numeric_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eeb8535",
   "metadata": {},
   "source": [
    "## DSPy Signatures, Modules, Instances\n",
    "\n",
    "All the experiments involving GPT models use DSPy signatures and modules. These are defined here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17f96e0",
   "metadata": {},
   "source": [
    "### Classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d23b92cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DSPy signature that defines the prompt: review -> classification\n",
    "class Classify(dspy.Signature):\n",
    "    __doc__ = \"\"\"Classify the sentiment of a review as either 'negative', 'neutral', or 'positive'.\"\"\"\n",
    "\n",
    "    review = dspy.InputField(desc=\"The review text to classify.\")\n",
    "    classification = dspy.OutputField(desc=\"One word representing the sentiment classification: 'negative', 'neutral', or 'positive' (do not repeat the field name, do not use 'mixed')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6df11d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DSPy module to classify the sentiment of a review\n",
    "class GPTSentiment(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.generate_answer = dspy.Predict(Classify)\n",
    "\n",
    "    def forward(self, review):\n",
    "\n",
    "        prediction = self.generate_answer(review=review)\n",
    "        # Sleep to avoid rate limiting\n",
    "        sleep(0.25)\n",
    "        \n",
    "        return dspy.Prediction(classification=prediction.classification.lower().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b9a60150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the GPT sentiment module\n",
    "gpt_sentiment = GPTSentiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ec1f5c",
   "metadata": {},
   "source": [
    "### Classify with Pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "5a8a99bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DSPy signature that defines the prompt: review, classifier_decision -> classification\n",
    "class ClassifyWithPred(dspy.Signature):\n",
    "    __doc__ = \"\"\"Classify the sentiment of a review as either 'negative', 'neutral', or 'positive'.\"\"\"\n",
    "\n",
    "    review = dspy.InputField(desc=\"The review text to classify.\")\n",
    "    classifier_decision = dspy.InputField(desc=\"The sentiment classification proposed by a model fine-tuned on sentiment.\")\n",
    "    classification = dspy.OutputField(desc=\"One word representing the sentiment classification: 'negative', 'neutral', or 'positive' (do not repeat the field name, do not use 'mixed')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "e61c275f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DSPy module that uses the ELECTRA model to help classify the sentiment of a review\n",
    "class CollabSentiment(dspy.Module):\n",
    "    def __init__(self, model_type='base'):\n",
    "        super().__init__()\n",
    "        self.generate_answer = dspy.Predict(ClassifyWithPred)\n",
    "        self.numeric_dict = {0: 'negative', 1: 'neutral', 2: 'positive'}\n",
    "        \n",
    "        # Determine which model and tokenizer to use\n",
    "        if model_type == 'base':\n",
    "            self.model = electra_base_model\n",
    "            self.model_name = 'google/electra-base-discriminator'\n",
    "        elif model_type == 'large':\n",
    "            self.model = electra_large_model\n",
    "            self.model_name = 'google/electra-large-discriminator'\n",
    "        else:\n",
    "            raise ValueError(\"Invalid model_type. Choose 'base' or 'large'.\")\n",
    "\n",
    "        # Load the ELECTRA tokenizer from Hugging Face\n",
    "        self.tokenizer = ElectraTokenizer.from_pretrained(self.model_name)\n",
    "    \n",
    "    def classify_with_electra(self, review):\n",
    "        _, predicted_label, probabilities = predict_sentence(self.model, review, self.tokenizer, self.numeric_dict)\n",
    "        return predicted_label, probabilities\n",
    "    \n",
    "    def model_summary(self):\n",
    "        # Display the model summary to confirm\n",
    "        print(f\"Model Summary for {self.model_name}:\\n\")\n",
    "        \n",
    "        # Print the model architecture\n",
    "        print(self.model)\n",
    "        #print(self.model.model)  # Needed for DDP wrapped models\n",
    "\n",
    "    def forward(self, review):\n",
    "        classifier_decision, probabilities = self.classify_with_electra(review)\n",
    "    \n",
    "        prediction = self.generate_answer(review=review, classifier_decision=classifier_decision)\n",
    "        # Sleep to avoid rate limiting\n",
    "        time.sleep(0.25)\n",
    "        \n",
    "        return dspy.Prediction(classification=prediction.classification.lower().strip(),\n",
    "                               classifier_decision=classifier_decision, probabilities=probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "dd35a851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the Electra Base + GPT sentiment module\n",
    "electra_base_gpt_sentiment = CollabSentiment(model_type='base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "68a363de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary for google/electra-base-discriminator:\n",
      "\n",
      "ElectraClassifier(\n",
      "  (electra): ElectraModel(\n",
      "    (embeddings): ElectraEmbeddings(\n",
      "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): ElectraEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-11): 12 x ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pooling): PoolingLayer()\n",
      "  (classifier): Classifier(\n",
      "    (layers): Sequential(\n",
      "      (0): Linear(in_features=768, out_features=1024, bias=True)\n",
      "      (1): SwishGLU(\n",
      "        (projection): Linear(in_features=1024, out_features=2048, bias=True)\n",
      "        (activation): SiLU()\n",
      "      )\n",
      "      (2): Dropout(p=0.3, inplace=False)\n",
      "      (3): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (4): SwishGLU(\n",
      "        (projection): Linear(in_features=1024, out_features=2048, bias=True)\n",
      "        (activation): SiLU()\n",
      "      )\n",
      "      (5): Dropout(p=0.3, inplace=False)\n",
      "      (6): Linear(in_features=1024, out_features=3, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Verify the base model is loaded correctly\n",
    "electra_base_gpt_sentiment.model_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f30c0996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the ELECTRA Large + GPT sentiment module\n",
    "electra_large_gpt_sentiment = CollabSentiment(model_type='large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4862d727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary for google/electra-large-discriminator:\n",
      "\n",
      "ElectraClassifier(\n",
      "  (electra): ElectraModel(\n",
      "    (embeddings): ElectraEmbeddings(\n",
      "      (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 1024)\n",
      "      (token_type_embeddings): Embedding(2, 1024)\n",
      "      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): ElectraEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-23): 24 x ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pooling): PoolingLayer()\n",
      "  (classifier): Classifier(\n",
      "    (layers): Sequential(\n",
      "      (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (1): SwishGLU(\n",
      "        (projection): Linear(in_features=1024, out_features=2048, bias=True)\n",
      "        (activation): SiLU()\n",
      "      )\n",
      "      (2): Dropout(p=0.3, inplace=False)\n",
      "      (3): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (4): SwishGLU(\n",
      "        (projection): Linear(in_features=1024, out_features=2048, bias=True)\n",
      "        (activation): SiLU()\n",
      "      )\n",
      "      (5): Dropout(p=0.3, inplace=False)\n",
      "      (6): Linear(in_features=1024, out_features=3, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Verify the large model is loaded correctly\n",
    "electra_large_gpt_sentiment.model_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a354bc73",
   "metadata": {},
   "source": [
    "### Classify with Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "6434c908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DSPy signature that defines the prompt: review, classifier_decision -> classification\n",
    "class ClassifyWithProbs(dspy.Signature):\n",
    "    __doc__ = \"\"\"Classify the sentiment of a review as either 'negative', 'neutral', or 'positive'.\"\"\"\n",
    "\n",
    "    review = dspy.InputField(desc=\"The review text to classify.\")\n",
    "    negative_probability = dspy.InputField(desc=\"Probability the review is negative from a model fine-tuned on sentiment\")\n",
    "    neutral_probability = dspy.InputField(desc=\"Probability the review is neutral from a model fine-tuned on sentiment\")\n",
    "    positive_probability = dspy.InputField(desc=\"Probability the review is positive from a model fine-tuned on sentiment\")\n",
    "    classification = dspy.OutputField(desc=\"One word representing the sentiment classification: 'negative', 'neutral', or 'positive' (do not repeat the field name, do not use 'mixed')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "36780008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DSPy module that uses the ELECTRA model to help classify the sentiment of a review\n",
    "class CollabSentimentProbs(dspy.Module):\n",
    "    def __init__(self, model_type='base'):\n",
    "        super().__init__()\n",
    "        self.generate_answer = dspy.Predict(ClassifyWithProbs)\n",
    "        self.numeric_dict = {0: 'negative', 1: 'neutral', 2: 'positive'}\n",
    "        \n",
    "        # Determine which model and tokenizer to use\n",
    "        if model_type == 'base':\n",
    "            self.model = electra_base_model\n",
    "            self.model_name = 'google/electra-base-discriminator'\n",
    "        elif model_type == 'large':\n",
    "            self.model = electra_large_model\n",
    "            self.model_name = 'google/electra-large-discriminator'\n",
    "        else:\n",
    "            raise ValueError(\"Invalid model_type. Choose 'base' or 'large'.\")\n",
    "\n",
    "        # Load the ELECTRA tokenizer from Hugging Face\n",
    "        self.tokenizer = ElectraTokenizer.from_pretrained(self.model_name)\n",
    "    \n",
    "    def classify_with_electra(self, review):\n",
    "        _, predicted_label, probabilities = predict_sentence(self.model, review, self.tokenizer, self.numeric_dict)\n",
    "        # Convert each probability to a percent\n",
    "        neg_prob = f\"{probabilities[0] * 100:.2f}%\"\n",
    "        neu_prob = f\"{probabilities[1] * 100:.2f}%\"\n",
    "        pos_prob = f\"{probabilities[2] * 100:.2f}%\"\n",
    "        return predicted_label, neg_prob, neu_prob, pos_prob\n",
    "    \n",
    "    def model_summary(self):\n",
    "        # Display the model summary to confirm\n",
    "        print(f\"Model Summary for {self.model_name}:\\n\")\n",
    "        \n",
    "        # Print the model architecture\n",
    "        print(self.model)\n",
    "        #print(self.model.model)  # Needed for DDP wrapped models\n",
    "\n",
    "    def forward(self, review):\n",
    "        classifier_decision, neg_prob, neu_prob, pos_prob = self.classify_with_electra(review)\n",
    "\n",
    "        prediction = self.generate_answer(\n",
    "            review=review, \n",
    "            negative_probability = neg_prob,\n",
    "            neutral_probability = neu_prob,\n",
    "            positive_probability = pos_prob\n",
    "        )\n",
    "\n",
    "         # Sleep to avoid rate limiting\n",
    "        time.sleep(0.25)\n",
    "\n",
    "        return dspy.Prediction(\n",
    "            classification=prediction.classification.lower().strip(),\n",
    "            negative_probability=neg_prob,\n",
    "            neutral_probability=neu_prob,\n",
    "            positive_probability=pos_prob\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e4af3f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "electra_large_gpt_sentiment_probs = CollabSentimentProbs(model_type='large')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5349f042",
   "metadata": {},
   "source": [
    "### Classify with Prediction and Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "148bc31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DSPy signature that defines the prompt: review, classifier_decision -> classification\n",
    "class ClassifyWithPredProbs(dspy.Signature):\n",
    "    __doc__ = \"\"\"Classify the sentiment of a review as either 'negative', 'neutral', or 'positive'.\"\"\"\n",
    "\n",
    "    review = dspy.InputField(desc=\"The review text to classify.\")\n",
    "    classifier_decision = dspy.InputField(desc=\"The sentiment classification proposed by a model fine-tuned on sentiment.\")\n",
    "    negative_probability = dspy.InputField(desc=\"Probability the review is negative\")\n",
    "    neutral_probability = dspy.InputField(desc=\"Probability the review is neutral\")\n",
    "    positive_probability = dspy.InputField(desc=\"Probability the review is positive\")\n",
    "    classification = dspy.OutputField(desc=\"One word representing the sentiment classification: 'negative', 'neutral', or 'positive' (do not repeat the field name, do not use 'mixed')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "2d18c5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DSPy module that uses the ELECTRA model to help classify the sentiment of a review\n",
    "class CollabSentimentPredProbs(dspy.Module):\n",
    "    def __init__(self, model_type='base'):\n",
    "        super().__init__()\n",
    "        self.generate_answer = dspy.Predict(ClassifyWithPredProbs)\n",
    "        self.numeric_dict = {0: 'negative', 1: 'neutral', 2: 'positive'}\n",
    "        \n",
    "        # Determine which model and tokenizer to use\n",
    "        if model_type == 'base':\n",
    "            self.model = electra_base_model\n",
    "            self.model_name = 'google/electra-base-discriminator'\n",
    "        elif model_type == 'large':\n",
    "            self.model = electra_large_model\n",
    "            self.model_name = 'google/electra-large-discriminator'\n",
    "        else:\n",
    "            raise ValueError(\"Invalid model_type. Choose 'base' or 'large'.\")\n",
    "\n",
    "        # Load the ELECTRA tokenizer from Hugging Face\n",
    "        self.tokenizer = ElectraTokenizer.from_pretrained(self.model_name)\n",
    "    \n",
    "    def classify_with_electra(self, review):\n",
    "        _, predicted_label, probabilities = predict_sentence(self.model, review, self.tokenizer, self.numeric_dict)\n",
    "        # Convert each probability to a percent\n",
    "        neg_prob = f\"{probabilities[0] * 100:.2f}%\"\n",
    "        neu_prob = f\"{probabilities[1] * 100:.2f}%\"\n",
    "        pos_prob = f\"{probabilities[2] * 100:.2f}%\"\n",
    "        return predicted_label, neg_prob, neu_prob, pos_prob\n",
    "    \n",
    "    def model_summary(self):\n",
    "        # Display the model summary to confirm\n",
    "        print(f\"Model Summary for {self.model_name}:\\n\")\n",
    "        \n",
    "        # Print the model architecture\n",
    "        print(self.model)\n",
    "        #print(self.model.model)  # Needed for DDP wrapped models\n",
    "\n",
    "    def forward(self, review):\n",
    "        classifier_decision, neg_prob, neu_prob, pos_prob = self.classify_with_electra(review)\n",
    "\n",
    "        prediction = self.generate_answer(\n",
    "            review=review, \n",
    "            negative_probability = neg_prob,\n",
    "            neutral_probability = neu_prob,\n",
    "            positive_probability = pos_prob,\n",
    "            classifier_decision=classifier_decision\n",
    "        )\n",
    "\n",
    "         # Sleep to avoid rate limiting\n",
    "        time.sleep(0.25)\n",
    "\n",
    "        return dspy.Prediction(\n",
    "            classification=prediction.classification.lower().strip(), \n",
    "            classifier_decision=classifier_decision, \n",
    "            negative_probability=neg_prob,\n",
    "            neutral_probability=neu_prob,\n",
    "            positive_probability=pos_prob\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "252146f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "electra_large_gpt_sentiment_pred_probs = CollabSentimentPredProbs(model_type='large')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14a61a1",
   "metadata": {},
   "source": [
    "### Classify with Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "27e09fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retriever class to get the top similar reviews\n",
    "class ElectraSentimentRetriever(Retrieve):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        tokenizer,\n",
    "        examples: List[dict],\n",
    "        k: int = 3,\n",
    "        max_length: int = 512,\n",
    "        batch_size: int = 32,\n",
    "    ):\n",
    "        super().__init__(k=k)\n",
    "        \n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.model = model\n",
    "        #self.model = model.model  # Needed for DDP wrapped models\n",
    "        self.tokenizer = tokenizer\n",
    "        self.model.eval()\n",
    "        \n",
    "        self.max_length = max_length\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        # Precompute embeddings for examples\n",
    "        self.examples = examples\n",
    "        self.example_texts = []\n",
    "        self.example_classes = []\n",
    "        for ex in self.examples:\n",
    "            text = ex.get('review', ex.get('sentence', ''))\n",
    "            classification = ex.get('classification', ex.get('label', ''))\n",
    "            self.example_texts.append(text)\n",
    "            self.example_classes.append(classification)\n",
    "        \n",
    "        # Precompute and store example embeddings\n",
    "        self.example_embeddings = self._get_embeddings(self.example_texts)\n",
    "\n",
    "    def _get_embeddings_batch(self, texts: List[str]) -> torch.Tensor:\n",
    "        encoded = self.tokenizer(\n",
    "            texts,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        \n",
    "        input_ids = encoded['input_ids'].to(self.device)\n",
    "        attention_mask = encoded['attention_mask'].to(self.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            base_model = self.model.module if hasattr(self.model, 'module') else self.model\n",
    "            #electra_outputs = base_model.bert(  # Used in initial research\n",
    "            electra_outputs = base_model.electra(  # Used with Hugging Face models\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask\n",
    "            )\n",
    "            #pooled_output = base_model.custom_pooling(  # Used in initial research\n",
    "            pooled_output = base_model.pooling(  # Used with Hugging Face models\n",
    "                electra_outputs.last_hidden_state,\n",
    "                attention_mask\n",
    "            )\n",
    "            normalized_embeddings = F.normalize(pooled_output, p=2, dim=1)\n",
    "        \n",
    "        del input_ids, attention_mask, electra_outputs, pooled_output\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        return normalized_embeddings\n",
    "\n",
    "    def _get_embeddings(self, texts: List[str]) -> torch.Tensor:\n",
    "        embeddings_list = []\n",
    "        for i in range(0, len(texts), self.batch_size):\n",
    "            batch_texts = texts[i:i + self.batch_size]\n",
    "            batch_embeddings = self._get_embeddings_batch(batch_texts)\n",
    "            embeddings_list.append(batch_embeddings)\n",
    "        return torch.cat(embeddings_list, dim=0)\n",
    "\n",
    "    def forward(self, query_or_queries: Union[str, List[str]]) -> List[dict]:\n",
    "        # Handle both single query and multiple queries\n",
    "        queries = [query_or_queries] if isinstance(query_or_queries, str) else query_or_queries\n",
    "        queries = [q for q in queries if q]\n",
    "\n",
    "        # Generate embeddings for queries\n",
    "        query_embeddings = self._get_embeddings(queries)\n",
    "        \n",
    "        # Calculate similarities with precomputed example embeddings\n",
    "        similarities = F.cosine_similarity(\n",
    "            query_embeddings.unsqueeze(1),\n",
    "            self.example_embeddings.unsqueeze(0),\n",
    "            dim=2\n",
    "        )\n",
    "        \n",
    "        # Get top indices for each query\n",
    "        top_indices = similarities.argsort(dim=1, descending=True)[:, :self.k * 2]\n",
    "\n",
    "        results = []\n",
    "        if len(queries) == 1:\n",
    "            selected_reviews = {}\n",
    "            \n",
    "            # Try to get balanced examples first\n",
    "            for idx in top_indices[0]:\n",
    "                idx = int(idx)\n",
    "                sentiment = self.example_classes[idx]\n",
    "                if sentiment not in selected_reviews and len(selected_reviews) < self.k:\n",
    "                    selected_reviews[sentiment] = {\n",
    "                        'index': idx,\n",
    "                        'similarity_score': float(similarities[0][idx]),\n",
    "                        'review': self.example_texts[idx],\n",
    "                        'classification': sentiment\n",
    "                    }\n",
    "            \n",
    "            # Fill remaining slots with highest similarity scores\n",
    "            if len(selected_reviews) < self.k:\n",
    "                for idx in top_indices[0]:\n",
    "                    idx = int(idx)\n",
    "                    if len(results) >= self.k:\n",
    "                        break\n",
    "                    if not any(r.get('index') == idx for r in results):\n",
    "                        results.append({\n",
    "                            'index': idx,\n",
    "                            'similarity_score': float(similarities[0][idx]),\n",
    "                            'review': self.example_texts[idx],\n",
    "                            'classification': self.example_classes[idx]\n",
    "                        })\n",
    "            \n",
    "            # Add balanced selections to results\n",
    "            results.extend(selected_reviews.values())\n",
    "            results = results[:self.k]\n",
    "        else:\n",
    "            # Handle multiple queries (if needed)\n",
    "            pass\n",
    "\n",
    "        # Clean up GPU memory\n",
    "        del query_embeddings, similarities\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5e32ce21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DSPy signature that defines the prompt: examples, review, classifier_decision -> classification\n",
    "class ClassifyWithPredExamples(dspy.Signature):\n",
    "    __doc__ = \"\"\"Classify the sentiment of a review as either 'negative', 'neutral', or 'positive'.\"\"\"\n",
    "\n",
    "    examples = dspy.InputField(\n",
    "        desc=\"A list of examples that demonstrate different sentiment classes.\",\n",
    "        format=lambda examples: \"\\n\".join([\n",
    "            f\"- {ex['classification']}: {ex['review']}\"\n",
    "            for i, ex in enumerate(examples)\n",
    "        ]) if isinstance(examples, list) else examples\n",
    "    )\n",
    "    review = dspy.InputField(desc=\"The review text to classify.\")\n",
    "    classifier_decision = dspy.InputField(desc=\"The sentiment classification proposed by a model fine-tuned on sentiment.\")\n",
    "    classification = dspy.OutputField(desc=\"One word representing the sentiment classification: 'negative', 'neutral', or 'positive' (do not repeat the field name, do not use 'mixed')\")\n",
    "\n",
    "class CollabSentimentExamples(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.tokenizer = ElectraTokenizer.from_pretrained('google/electra-large-discriminator')\n",
    "\n",
    "        self.example_data = [\n",
    "            {\n",
    "                'review': row['sentence'],\n",
    "                'classification': self.numeric_dict[row['label']] if isinstance(row['label'], (int, np.integer)) else row['label']\n",
    "            }\n",
    "            for _, row in val_df.iterrows()\n",
    "        ]\n",
    "        self.retrieve = ElectraSentimentRetriever(\n",
    "            model=electra_large_model,\n",
    "            tokenizer=self.tokenizer,\n",
    "            examples=self.example_data,\n",
    "            k=5\n",
    "        )\n",
    "\n",
    "        self.generate_answer = dspy.Predict(ClassifyWithPredExamples)\n",
    "        \n",
    "        self.numeric_dict = {0: 'negative', 1: 'neutral', 2: 'positive'}\n",
    "\n",
    "    def classify_with_electra(self, review):\n",
    "        _, predicted_label, probabilities = predict_sentence(electra_large_model, review, self.tokenizer, self.numeric_dict)\n",
    "        return predicted_label, probabilities\n",
    "\n",
    "    def forward(self, review):\n",
    "        examples = self.retrieve(review)\n",
    "        \n",
    "        classifier_decision, probabilities = self.classify_with_electra(review)\n",
    "\n",
    "        prediction = self.generate_answer(\n",
    "            review=review, \n",
    "            examples=examples, \n",
    "            classifier_decision=classifier_decision\n",
    "        )\n",
    "        \n",
    "        return dspy.Prediction(\n",
    "            examples=examples,\n",
    "            classification=prediction.classification,\n",
    "            classifier_decision=classifier_decision,\n",
    "            probabilities=probabilities\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "323f3a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "electra_large_gpt_sentiment_examples = CollabSentimentExamples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1243db9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch to the correct language model and disable experimental mode\n",
    "lm = dspy.OpenAI(model='gpt-4o-mini-2024-07-18', api_key=openai_key, max_tokens=8192, temperature=temperature)\n",
    "dspy.settings.configure(lm=lm, experimental=False, seed=random_seed)\n",
    "dsp.settings.show_guidelines = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6626f5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_example_result = electra_large_gpt_sentiment_examples(test_df['sentence'][11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dcbf4644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    examples=[{'index': 2853, 'similarity_score': 0.9981756210327148, 'review': 'The wasps ankles.', 'classification': 'neutral'}, {'index': 5103, 'similarity_score': 0.9981460571289062, 'review': 'Miss the truck?', 'classification': 'neutral'}, {'index': 1551, 'similarity_score': 0.9970441460609436, 'review': 'Oh come on .', 'classification': 'negative'}, {'index': 2584, 'similarity_score': 0.9968715906143188, 'review': 'I was wrong.', 'classification': 'neutral'}, {'index': 5006, 'similarity_score': 0.9966566562652588, 'review': 'It happens again.', 'classification': 'neutral'}],\n",
       "    classification='neutral',\n",
       "    classifier_decision='neutral',\n",
       "    probabilities=[0.019992714747786522, 0.9609718918800354, 0.019035447388887405]\n",
       ")"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_example_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e49c59c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Classify the sentiment of a review as either 'negative', 'neutral', or 'positive'.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Examples: A list of examples that demonstrate different sentiment classes.\n",
      "\n",
      "Review: The review text to classify.\n",
      "\n",
      "Classifier Decision: The sentiment classification proposed by a model fine-tuned on sentiment.\n",
      "\n",
      "Classification: One word representing the sentiment classification: 'negative', 'neutral', or 'positive' (do not repeat the field name, do not use 'mixed')\n",
      "\n",
      "---\n",
      "\n",
      "Examples:\n",
      "- neutral: The wasps ankles.\n",
      "- neutral: Miss the truck?\n",
      "- negative: Oh come on .\n",
      "- neutral: I was wrong.\n",
      "- neutral: It happens again.\n",
      "\n",
      "Review: How is possible?\n",
      "\n",
      "Classifier Decision: neutral\n",
      "\n",
      "Classification:\u001b[32m neutral\u001b[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\n\\nClassify the sentiment of a review as either 'negative', 'neutral', or 'positive'.\\n\\n---\\n\\nFollow the following format.\\n\\nExamples: A list of examples that demonstrate different sentiment classes.\\n\\nReview: The review text to classify.\\n\\nClassifier Decision: The sentiment classification proposed by a model fine-tuned on sentiment.\\n\\nClassification: One word representing the sentiment classification: 'negative', 'neutral', or 'positive' (do not repeat the field name, do not use 'mixed')\\n\\n---\\n\\nExamples:\\n- neutral: The wasps ankles.\\n- neutral: Miss the truck?\\n- negative: Oh come on .\\n- neutral: I was wrong.\\n- neutral: It happens again.\\n\\nReview: How is possible?\\n\\nClassifier Decision: neutral\\n\\nClassification:\\x1b[32m neutral\\x1b[0m\\n\\n\\n\""
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016f3fab",
   "metadata": {},
   "source": [
    "### Classify with Balanced Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "24a8301c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retreiver class to get the top similar reviews balanced across classes\n",
    "class BalancedElectraSentimentRetriever(Retrieve):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        tokenizer,\n",
    "        examples: List[dict],\n",
    "        k: int = 3,\n",
    "        max_length: int = 512,\n",
    "        batch_size: int = 32,\n",
    "    ):\n",
    "        super().__init__(k=k)\n",
    "        \n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        #self.model = model.model  # Needed for DDP wrapped models\n",
    "        self.model = model  # Needed for Hugging Face models\n",
    "        self.tokenizer = tokenizer\n",
    "        self.model.eval()\n",
    "        \n",
    "        self.max_length = max_length\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        # Precompute embeddings for examples\n",
    "        self.examples = examples\n",
    "        self.example_texts = []\n",
    "        self.example_classes = []\n",
    "        \n",
    "        # Create class indices for balanced retrieval\n",
    "        self.class_indices = defaultdict(list)\n",
    "        \n",
    "        # Process examples and create indices\n",
    "        for i, ex in enumerate(self.examples):\n",
    "            text = ex.get('review', ex.get('sentence', ''))\n",
    "            classification = ex.get('classification', ex.get('label', ''))\n",
    "            self.example_texts.append(text)\n",
    "            self.example_classes.append(classification)\n",
    "            self.class_indices[classification].append(i)\n",
    "        \n",
    "        # Precompute and store example embeddings\n",
    "        self.example_embeddings = self._get_embeddings(self.example_texts)\n",
    "\n",
    "    def _get_embeddings_batch(self, texts: List[str]) -> torch.Tensor:\n",
    "        encoded = self.tokenizer(\n",
    "            texts,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        \n",
    "        input_ids = encoded['input_ids'].to(self.device)\n",
    "        attention_mask = encoded['attention_mask'].to(self.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            base_model = self.model.module if hasattr(self.model, 'module') else self.model\n",
    "            #electra_outputs = base_model.bert(  # Used in initial research\n",
    "            electra_outputs = base_model.electra(  # Used with Hugging Face models\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask\n",
    "            )\n",
    "            #pooled_output = base_model.custom_pooling(  # Used in initial research\n",
    "            pooled_output = base_model.pooling(  # Used with Hugging Face models\n",
    "                electra_outputs.last_hidden_state,\n",
    "                attention_mask\n",
    "            )\n",
    "            normalized_embeddings = F.normalize(pooled_output, p=2, dim=1)\n",
    "        \n",
    "        del input_ids, attention_mask, electra_outputs, pooled_output\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        return normalized_embeddings\n",
    "\n",
    "    def _get_embeddings(self, texts: List[str]) -> torch.Tensor:\n",
    "        embeddings_list = []\n",
    "        for i in range(0, len(texts), self.batch_size):\n",
    "            batch_texts = texts[i:i + self.batch_size]\n",
    "            batch_embeddings = self._get_embeddings_batch(batch_texts)\n",
    "            embeddings_list.append(batch_embeddings)\n",
    "        return torch.cat(embeddings_list, dim=0)\n",
    "\n",
    "    def forward(self, query_or_queries: Union[str, List[str]]) -> List[dict]:\n",
    "        # Handle both single query and multiple queries\n",
    "        queries = [query_or_queries] if isinstance(query_or_queries, str) else query_or_queries\n",
    "        queries = [q for q in queries if q]\n",
    "\n",
    "        # Generate embeddings for queries\n",
    "        query_embeddings = self._get_embeddings(queries)\n",
    "        \n",
    "        # Calculate similarities with precomputed example embeddings\n",
    "        similarities = F.cosine_similarity(\n",
    "            query_embeddings.unsqueeze(1),\n",
    "            self.example_embeddings.unsqueeze(0),\n",
    "            dim=2\n",
    "        )\n",
    "\n",
    "        results = []\n",
    "        if len(queries) == 1:\n",
    "            sorted_results = []\n",
    "            \n",
    "            # Process classes in order: negative, neutral, positive\n",
    "            for class_label in ['negative', 'neutral', 'positive']:\n",
    "                if class_label not in self.class_indices:\n",
    "                    continue\n",
    "                \n",
    "                # Get indices and similarities for this class\n",
    "                class_idx = self.class_indices[class_label]\n",
    "                class_similarities = similarities[0][class_idx]\n",
    "                \n",
    "                # Get top k most similar examples from this class\n",
    "                top_k = min(self.k, len(class_idx))\n",
    "                class_rankings = class_similarities.argsort(descending=True)[:top_k]\n",
    "                \n",
    "                # Store this class's examples, sorted by similarity\n",
    "                class_results = []\n",
    "                for idx in class_rankings:\n",
    "                    original_idx = class_idx[idx]\n",
    "                    class_results.append({\n",
    "                        'index': int(original_idx),\n",
    "                        'similarity_score': float(similarities[0][original_idx]),\n",
    "                        'review': self.example_texts[original_idx],\n",
    "                        'classification': class_label\n",
    "                    })\n",
    "                    \n",
    "                # Sort by similarity within this class block and add to results\n",
    "                class_results.sort(key=lambda x: x['similarity_score'], reverse=True)\n",
    "                sorted_results.extend(class_results)\n",
    "            \n",
    "            return sorted_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b06d04d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DSPy signature that defines the prompt: examples, review, classifier_decision -> classification\n",
    "class ClassifyWithPredExamplesBalanced(dspy.Signature):\n",
    "    __doc__ = \"\"\"Classify the sentiment of a review as either 'negative', 'neutral', or 'positive'.\"\"\"\n",
    "\n",
    "    examples = dspy.InputField(\n",
    "        desc=\"A list of examples that demonstrate different sentiment classes.\",\n",
    "        format=lambda examples: \"\\n\".join([\n",
    "            f\"- {ex['classification']}: {ex['review']}\"\n",
    "            for i, ex in enumerate(examples)\n",
    "        ]) if isinstance(examples, list) else examples\n",
    "    )\n",
    "    review = dspy.InputField(desc=\"The review text to classify.\")\n",
    "    classifier_decision = dspy.InputField(desc=\"The sentiment classification proposed by a model fine-tuned on sentiment.\")\n",
    "    classification = dspy.OutputField(desc=\"One word representing the sentiment classification: 'negative', 'neutral', or 'positive' (do not repeat the field name, do not use 'mixed')\")\n",
    "\n",
    "class CollabSentimentExamplesBalanced(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.tokenizer = ElectraTokenizer.from_pretrained('google/electra-large-discriminator')\n",
    "        # Create example data with both text and classification\n",
    "        self.example_data = [\n",
    "            {\n",
    "                'review': row['sentence'],\n",
    "                'classification': self.numeric_dict[row['label']] if isinstance(row['label'], (int, np.integer)) else row['label']\n",
    "            }\n",
    "            for _, row in val_df.iterrows()\n",
    "        ]\n",
    "        self.retrieve = BalancedElectraSentimentRetriever(\n",
    "            model=electra_large_model,\n",
    "            tokenizer=self.tokenizer,\n",
    "            examples=self.example_data,\n",
    "            k=2\n",
    "        )\n",
    "\n",
    "        self.generate_answer = dspy.Predict(ClassifyWithPredExamplesBalanced)\n",
    "        \n",
    "        self.numeric_dict = {0: 'negative', 1: 'neutral', 2: 'positive'}\n",
    "\n",
    "    def classify_with_electra(self, review):\n",
    "        _, predicted_label, probabilities = predict_sentence(electra_large_model, review, self.tokenizer, self.numeric_dict)\n",
    "        return predicted_label, probabilities\n",
    "\n",
    "    def forward(self, review):\n",
    "        # Now examples will include both text and classification\n",
    "        examples = self.retrieve(review)\n",
    "        \n",
    "        classifier_decision, probabilities = self.classify_with_electra(review)\n",
    "\n",
    "        prediction = self.generate_answer(\n",
    "            review=review, \n",
    "            examples=examples, \n",
    "            classifier_decision=classifier_decision\n",
    "        )\n",
    "        \n",
    "        return dspy.Prediction(\n",
    "            examples=examples,\n",
    "            classification=prediction.classification,\n",
    "            classifier_decision=classifier_decision,\n",
    "            probabilities=probabilities\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "484b7fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "electra_large_gpt_sentiment_examples_balanced = CollabSentimentExamplesBalanced()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d41e41dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch to the correct language model and disable experimental mode\n",
    "lm = dspy.OpenAI(model='gpt-4o-mini-2024-07-18', api_key=openai_key, max_tokens=8192, temperature=temperature)\n",
    "dspy.settings.configure(lm=lm, experimental=False, seed=random_seed)\n",
    "dsp.settings.show_guidelines = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f5a54b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_test_example_result = electra_large_gpt_sentiment_examples_balanced(test_df['sentence'][12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5870de4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    examples=[{'index': 2246, 'similarity_score': 0.9973654747009277, 'review': 'My wife takes a bite while we are eating chips and gets a chunk of ice.', 'classification': 'negative'}, {'index': 2402, 'similarity_score': 0.9973243474960327, 'review': 'On one of the busiest days of the year they had a young girl training in there.', 'classification': 'negative'}, {'index': 4487, 'similarity_score': 0.9984093904495239, 'review': 'I reminded him of lab work & so he looked for it.', 'classification': 'neutral'}, {'index': 3616, 'similarity_score': 0.9984041452407837, 'review': 'The elements that contained fish have been replaced by beef.', 'classification': 'neutral'}, {'index': 4580, 'similarity_score': 0.9970502853393555, 'review': 'The woman who started to work with me had to step away for eyebrow threading, and the same gentleman who had gotten my wine took over for the service.', 'classification': 'positive'}, {'index': 515, 'similarity_score': 0.9968818426132202, 'review': 'I dropped in yesterday for a surprise visit to try and figure out what the delay is.', 'classification': 'positive'}],\n",
       "    classification='neutral',\n",
       "    classifier_decision='neutral',\n",
       "    probabilities=[0.009140947833657265, 0.975822925567627, 0.015036184340715408]\n",
       ")"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_test_example_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e4f32c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Classify the sentiment of a review as either 'negative', 'neutral', or 'positive'.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Examples: A list of examples that demonstrate different sentiment classes.\n",
      "\n",
      "Review: The review text to classify.\n",
      "\n",
      "Classifier Decision: The sentiment classification proposed by a model fine-tuned on sentiment.\n",
      "\n",
      "Classification: One word representing the sentiment classification: 'negative', 'neutral', or 'positive' (do not repeat the field name, do not use 'mixed')\n",
      "\n",
      "---\n",
      "\n",
      "Examples:\n",
      "- negative: My wife takes a bite while we are eating chips and gets a chunk of ice.\n",
      "- negative: On one of the busiest days of the year they had a young girl training in there.\n",
      "- neutral: I reminded him of lab work & so he looked for it.\n",
      "- neutral: The elements that contained fish have been replaced by beef.\n",
      "- positive: The woman who started to work with me had to step away for eyebrow threading, and the same gentleman who had gotten my wine took over for the service.\n",
      "- positive: I dropped in yesterday for a surprise visit to try and figure out what the delay is.\n",
      "\n",
      "Review: She answered the phone by saying \"yeah?\".\n",
      "\n",
      "Classifier Decision: neutral\n",
      "\n",
      "Classification:\u001b[32m neutral\u001b[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\nClassify the sentiment of a review as either \\'negative\\', \\'neutral\\', or \\'positive\\'.\\n\\n---\\n\\nFollow the following format.\\n\\nExamples: A list of examples that demonstrate different sentiment classes.\\n\\nReview: The review text to classify.\\n\\nClassifier Decision: The sentiment classification proposed by a model fine-tuned on sentiment.\\n\\nClassification: One word representing the sentiment classification: \\'negative\\', \\'neutral\\', or \\'positive\\' (do not repeat the field name, do not use \\'mixed\\')\\n\\n---\\n\\nExamples:\\n- negative: My wife takes a bite while we are eating chips and gets a chunk of ice.\\n- negative: On one of the busiest days of the year they had a young girl training in there.\\n- neutral: I reminded him of lab work & so he looked for it.\\n- neutral: The elements that contained fish have been replaced by beef.\\n- positive: The woman who started to work with me had to step away for eyebrow threading, and the same gentleman who had gotten my wine took over for the service.\\n- positive: I dropped in yesterday for a surprise visit to try and figure out what the delay is.\\n\\nReview: She answered the phone by saying \"yeah?\".\\n\\nClassifier Decision: neutral\\n\\nClassification:\\x1b[32m neutral\\x1b[0m\\n\\n\\n'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7790140",
   "metadata": {},
   "source": [
    "### Classify with Predictions, Probabilities, and Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "474d18e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DSPy signature that defines the prompt: examples, review, classifier_decision, negative_probability, neutral_probability, positive_probability -> classification\n",
    "class ClassifyWithPredProbsExamples(dspy.Signature):\n",
    "    __doc__ = \"\"\"Classify the sentiment of a review as either 'negative', 'neutral', or 'positive'.\"\"\"\n",
    "\n",
    "    examples = dspy.InputField(\n",
    "        desc=\"A list of examples that demonstrate different sentiment classes.\",\n",
    "        format=lambda examples: \"\\n\".join([\n",
    "            f\"- {ex['classification']}: {ex['review']}\"\n",
    "            for i, ex in enumerate(examples)\n",
    "        ]) if isinstance(examples, list) else examples\n",
    "    )\n",
    "    review = dspy.InputField(desc=\"The review text to classify.\")\n",
    "    classifier_decision = dspy.InputField(desc=\"The sentiment classification proposed by a model fine-tuned on sentiment.\")\n",
    "    negative_probability = dspy.InputField(desc=\"Probability the review is negative\")\n",
    "    neutral_probability = dspy.InputField(desc=\"Probability the review is neutral\")\n",
    "    positive_probability = dspy.InputField(desc=\"Probability the review is positive\")\n",
    "    classification = dspy.OutputField(desc=\"One word representing the sentiment classification: 'negative', 'neutral', or 'positive' (do not repeat the field name, do not use 'mixed')\")\n",
    "\n",
    "class CollabSentimentPredProbsExamples(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.tokenizer = ElectraTokenizer.from_pretrained('google/electra-large-discriminator')\n",
    "        # Create example data with both text and classification\n",
    "        self.example_data = [\n",
    "            {\n",
    "                'review': row['sentence'],\n",
    "                'classification': self.numeric_dict[row['label']] if isinstance(row['label'], (int, np.integer)) else row['label']\n",
    "            }\n",
    "            for _, row in val_df.iterrows()\n",
    "        ]\n",
    "        self.retrieve = ElectraSentimentRetriever(\n",
    "            model=electra_large_model,\n",
    "            tokenizer=self.tokenizer,\n",
    "            examples=self.example_data,\n",
    "            k=5\n",
    "        )\n",
    "\n",
    "        self.generate_answer = dspy.Predict(ClassifyWithPredProbsExamples)\n",
    "        \n",
    "        self.numeric_dict = {0: 'negative', 1: 'neutral', 2: 'positive'}\n",
    "    \n",
    "    def classify_with_electra(self, review):\n",
    "        _, predicted_label, probabilities = predict_sentence(electra_large_model, review, self.tokenizer, self.numeric_dict)\n",
    "        # Convert each probability to a percent\n",
    "        neg_prob = f\"{probabilities[0] * 100:.2f}%\"\n",
    "        neu_prob = f\"{probabilities[1] * 100:.2f}%\"\n",
    "        pos_prob = f\"{probabilities[2] * 100:.2f}%\"\n",
    "        return predicted_label, neg_prob, neu_prob, pos_prob\n",
    "\n",
    "    def forward(self, review):\n",
    "        examples = self.retrieve(review)\n",
    "        \n",
    "        classifier_decision, neg_prob, neu_prob, pos_prob = self.classify_with_electra(review)\n",
    "\n",
    "        prediction = self.generate_answer(\n",
    "            examples=examples,\n",
    "            review=review, \n",
    "            negative_probability = neg_prob,\n",
    "            neutral_probability = neu_prob,\n",
    "            positive_probability = pos_prob,\n",
    "            classifier_decision=classifier_decision\n",
    "        )\n",
    "\n",
    "        return dspy.Prediction(\n",
    "            examples=examples,\n",
    "            classification=prediction.classification.lower().strip(), \n",
    "            classifier_decision=classifier_decision, \n",
    "            negative_probability=neg_prob,\n",
    "            neutral_probability=neu_prob,\n",
    "            positive_probability=pos_prob,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5ea5a894",
   "metadata": {},
   "outputs": [],
   "source": [
    "electra_large_gpt_sentiment_pred_probs_examples = CollabSentimentPredProbsExamples()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77fefef",
   "metadata": {},
   "source": [
    "## Metric\n",
    "\n",
    "This is the metric function that determines if the DSPy output is a match to the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "222c46f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a classification match metric that is flexible for the DSPy optimizer prompt variations\n",
    "def classification_match(review, pred, trace=None, frac=1.0):\n",
    "    # Define the possible field names, based on the prompts we saw in the COPRO optimizer\n",
    "    field_names = ['classification', 'sentiment_classification']\n",
    "    \n",
    "    # Get the actual classification from the review\n",
    "    actual_classification = None\n",
    "    for field in field_names:\n",
    "        if hasattr(review, field):\n",
    "            actual_classification = getattr(review, field)\n",
    "            break\n",
    "    if actual_classification is None:\n",
    "        raise ValueError(\"No classification field found in the review object\")\n",
    "    \n",
    "    # Get the predicted classification\n",
    "    predicted_classification = None\n",
    "    for field in field_names:\n",
    "        if hasattr(pred, field):\n",
    "            predicted_classification = getattr(pred, field)\n",
    "            break\n",
    "    if predicted_classification is None:\n",
    "        raise ValueError(\"No classification field found in the prediction object\")\n",
    "    \n",
    "    # Clean up the predicted classification\n",
    "    predicted_classification = predicted_classification.lower().strip()\n",
    "    if ':' in predicted_classification:\n",
    "        predicted_classification = predicted_classification.split(':')[-1].strip()\n",
    "    \n",
    "    # Extract just the sentiment if there's additional information\n",
    "    sentiment_words = ['positive', 'neutral', 'negative']\n",
    "    for word in sentiment_words:\n",
    "        if word in predicted_classification:\n",
    "            predicted_classification = word\n",
    "            break\n",
    "    \n",
    "    # Perform the matching\n",
    "    if isinstance(actual_classification, str):\n",
    "        return dsp.answer_match(predicted_classification, [actual_classification], frac=frac)\n",
    "    elif isinstance(actual_classification, list):\n",
    "        return dsp.answer_match(predicted_classification, actual_classification, frac=frac)\n",
    "    else:\n",
    "        raise TypeError(\"Unexpected type for classification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d88743b",
   "metadata": {},
   "source": [
    "## Evaluation Functions\n",
    "\n",
    "Functions to evaluate the performance of an experimental run with a DSPy template and model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "7f9badae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_results_to_df(results):\n",
    "    # Extract the list of tuples from the results tuple\n",
    "    examples = results[1]\n",
    "    \n",
    "    # Initialize an empty list to store the extracted data\n",
    "    data = []\n",
    "    \n",
    "    # Iterate over the list of tuples\n",
    "    for example, prediction, match in examples:\n",
    "        # Base data that's always present\n",
    "        row_data = {\n",
    "            'review': example['review'],\n",
    "            'classification': example['classification'],\n",
    "            'prediction': prediction.classification,\n",
    "            'match': match\n",
    "        }\n",
    "        \n",
    "        # Safely add classifier_decision if it exists\n",
    "        if hasattr(prediction, 'classifier_decision'):\n",
    "            row_data['classifier_decision'] = prediction.classifier_decision\n",
    "        \n",
    "        # Safely add probabilities as a list if they exist\n",
    "        if hasattr(prediction, 'probabilities'):\n",
    "            row_data['probabilities'] = prediction.probabilities\n",
    "\n",
    "        # Safely add explanation values if they exist\n",
    "        if hasattr(prediction, 'explanation'):\n",
    "            row_data['explanation'] = prediction.explanation.strip()\n",
    "        if hasattr(prediction, 'considered_classifier_decision'):\n",
    "            row_data['considered_classifier_decision'] = prediction.considered_classifier_decision.lower().strip()\n",
    "        if hasattr(prediction, 'followed_classifier_decision'):\n",
    "            row_data['followed_classifier_decision'] = prediction.followed_classifier_decision.lower().strip()\n",
    "        if hasattr(prediction, 'followed_classifier_explanation'):\n",
    "            row_data['followed_classifier_explanation'] = prediction.followed_classifier_explanation.strip()\n",
    "    \n",
    "        data.append(row_data)\n",
    "    \n",
    "    # Convert the list to a DataFrame\n",
    "    results_df = pd.DataFrame(data)\n",
    "    \n",
    "    # Print column names and their presence\n",
    "    print(\"\\nColumns in results DataFrame:\")\n",
    "    for col in results_df.columns:\n",
    "        print(f\"{col:<20} {results_df[col].count():>6} values\")\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "91b302ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(data_df, model_name=None):\n",
    "    # Set the dictionaries to convert label formats\n",
    "    label_dict = {'negative': 0, 'neutral': 1, 'positive': 2}\n",
    "    numeric_dict = {0: 'negative', 1: 'neutral', 2: 'positive'}\n",
    "\n",
    "    # Set the y_test and y_pred variables\n",
    "    y_test = data_df['classification']\n",
    "    y_pred = data_df['prediction']\n",
    "\n",
    "    # Convert text labels to numeric labels\n",
    "    y_test_numeric = np.array([label_dict[label] for label in y_test])\n",
    "    y_pred_numeric = np.array([label_dict[label] for label in y_pred])\n",
    "\n",
    "    # Use the DataWaza eval_model function\n",
    "    metrics = eval_model(\n",
    "        y_test=y_test_numeric,\n",
    "        y_pred=y_pred_numeric,\n",
    "        class_map=numeric_dict,\n",
    "        estimator=None,\n",
    "        x_test=None,\n",
    "        class_type='multi' if len(numeric_dict) > 2 else 'binary',\n",
    "        model_name=model_name,\n",
    "        plot=False,\n",
    "        save_plots=True,\n",
    "        save_dir='saves',\n",
    "        debug=False,\n",
    "        pos_label=None,\n",
    "        decimal=4,\n",
    "        return_metrics=True,\n",
    "        threshold=0.5,\n",
    "        wandb_run=None\n",
    "    )\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fd03bce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_invalid_predictions(results_df, dataset):\n",
    "    \"\"\"\n",
    "    Check for and report invalid predictions without modifying data\n",
    "    \n",
    "    Parameters:\n",
    "    results_df: DataFrame with predictions\n",
    "    dataset: Original test dataset\n",
    "    \n",
    "    Returns:\n",
    "    bool: Whether invalid predictions were found\n",
    "    \"\"\"\n",
    "    valid_predictions = {'negative', 'neutral', 'positive'}\n",
    "    \n",
    "    # Show all unique predictions and their counts\n",
    "    print(\"\\nPrediction value counts:\")\n",
    "    value_counts = results_df['prediction'].value_counts()\n",
    "    for value, count in value_counts.items():\n",
    "        print(f\"{value:<20} {count:>6}\")\n",
    "    \n",
    "    # Find invalid predictions\n",
    "    invalid_mask = ~results_df['prediction'].isin(valid_predictions)\n",
    "    invalid_indices = results_df[invalid_mask].index\n",
    "    \n",
    "    if len(invalid_indices) > 0:\n",
    "        print(f\"\\nFound {len(invalid_indices)} invalid predictions at row indices:\")\n",
    "        print(invalid_indices.tolist())\n",
    "        \n",
    "        print(\"\\nInvalid prediction rows:\")\n",
    "        print(dataset.loc[invalid_indices])\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "ee4008cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_experiment(lm, name, instance, dataset, examples, results=None, notes=None, save_dir='results_r1_explain', save_results=True,\n",
    "                        temperature=0.0, random_seed=42):\n",
    "    \"\"\"\n",
    "    Evaluate a model experiment and return detailed results and metrics\n",
    "    \n",
    "    Parameters:\n",
    "    lm (str): Language model identifier (e.g., 'gpt-4o-mini-2024-07-18')\n",
    "    name (str): Experiment name (e.g., 'e3_g4om_ebft')\n",
    "    instance (str): Model instance name (e.g., 'electra_base_gpt_sentiment')\n",
    "    dataset (pd.DataFrame): Test dataset\n",
    "    examples (list): Test dataset in form of list of DSPy examples\n",
    "    results(pd.DataFrame): Results DataFrame (default: None)\n",
    "    notes (str): Additional notes for the experiment (default: None)\n",
    "    save_dir (str): Directory to save results and metrics (default: 'results')\n",
    "    save_results (bool): Whether to save results to files (default: True)\n",
    "    \n",
    "    Returns:\n",
    "    tuple: (results_df, metrics_dict)\n",
    "    \"\"\"\n",
    "    start_time = datetime.now()\n",
    "    print('-' * 80)\n",
    "    print(f\"Experiment: {name.upper()}\")\n",
    "    print('-' * 80)\n",
    "    print(f\"Start time: {start_time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    print(f\"Notes: {notes}\") if notes is not None else None\n",
    "    print(f\"Model: {lm}\")\n",
    "    print(f\"Instance: {instance}\")\n",
    "    print(f\"Dataset shape: {list(dataset.shape)}\")\n",
    "    print(f\"Examples length: {len(examples)}\")\n",
    "    print(f\"Results shape: {list(results.shape)}\") if results is not None else None\n",
    "    print(f\"Save directory: {save_dir}\") if save_results else None\n",
    "    \n",
    "    if results is None:\n",
    "\n",
    "        print(f\"Temperature: {temperature}\")\n",
    "        print(f\"Random seed: {random_seed}\")\n",
    "\n",
    "        # Configure DSPy\n",
    "        lm = dspy.OpenAI(model=lm, api_key=openai_key, max_tokens=8192, temperature=temperature)\n",
    "        dspy.settings.configure(lm=lm, experimental=False, seed=random_seed)\n",
    "        dsp.settings.show_guidelines = True\n",
    "        \n",
    "        # Create evaluator\n",
    "        evaluator = Evaluate(\n",
    "            devset=examples,\n",
    "            num_threads=1,\n",
    "            display_progress=True,\n",
    "            display_table=False,\n",
    "            return_outputs=True\n",
    "        )\n",
    "    \n",
    "        # Run evaluation\n",
    "        print(f\"\\nRunning evaluation...\")\n",
    "        results = evaluator(eval(instance), metric=classification_match)\n",
    "        \n",
    "        # Convert results to DataFrame\n",
    "        results_df = convert_results_to_df(results)\n",
    "        return_results = True\n",
    "    else:\n",
    "        results_df = results.copy()\n",
    "        return_results = False\n",
    "    \n",
    "    # Add source information\n",
    "    if 'source' in dataset.columns:\n",
    "        results_df['source'] = dataset['source']\n",
    "\n",
    "    # Print the lengths of each subset of 'source' column\n",
    "    print(\"\\nSource value counts:\")\n",
    "    for source in results_df['source'].unique():\n",
    "        print(f\"{source:<20} {len(results_df[results_df['source'] == source]):>6}\")\n",
    "    \n",
    "    # Check for invalid predictions\n",
    "    has_invalid = check_invalid_predictions(results_df, dataset)\n",
    "    \n",
    "    if has_invalid:\n",
    "        print(\"\\nWARNING: Invalid predictions found. Please review the above details and re-run problematic cases.\")\n",
    "        return results_df, None\n",
    "\n",
    "    # Initialize metrics dictionary\n",
    "    metrics_dict = {\n",
    "        'experiment_name': name.upper(),\n",
    "        'start_time': start_time.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        'notes': notes,\n",
    "        'model': lm,\n",
    "        'instance': instance,\n",
    "        'dataset_shape': list(dataset.shape),\n",
    "        'examples_length': len(examples),\n",
    "        'results_shape': list(results_df.shape),\n",
    "        'save_directory': save_dir,\n",
    "        'temperature': temperature,\n",
    "        'random_seed': random_seed\n",
    "    }\n",
    "    \n",
    "    # Calculate and store overall metrics\n",
    "    overall_metrics = evaluate_model(results_df, model_name=name.upper())\n",
    "    metrics_dict['merged_local'] = extract_metrics_from_report(overall_metrics)\n",
    "    \n",
    "    # Calculate metrics for each source\n",
    "    sources = {\n",
    "        'dynasent_r1': 'DYN-R1',\n",
    "        'dynasent_r2': 'DYN-R2',\n",
    "        'sst_local': 'SST'\n",
    "    }\n",
    "\n",
    "    for source, id in sources.items():\n",
    "        source_df = results_df[results_df['source'] == source]\n",
    "        source_metrics = evaluate_model(source_df, model_name=f\"{name.upper()}-{id}\")\n",
    "        metrics_dict[source] = extract_metrics_from_report(source_metrics)\n",
    "    \n",
    "    # Save results if requested\n",
    "    if save_results:\n",
    "        print(f\"Saving results to '{save_dir}'...\")\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        results_df.to_csv(f\"{save_dir}/{name}_results.csv\", index=False)\n",
    "        \n",
    "        # Filter out any tqdm objects or other non-serializable items from metrics_dict\n",
    "        serializable_metrics = {}\n",
    "        for key, value in metrics_dict.items():\n",
    "            if isinstance(value, (dict, list, str, int, float, bool, type(None))):\n",
    "                serializable_metrics[key] = value\n",
    "                \n",
    "        with open(f\"{save_dir}/{name}_metrics.json\", 'w') as f:\n",
    "            json.dump(serializable_metrics, f, indent=2)\n",
    "    \n",
    "    # Print summary metrics\n",
    "    print(\"\\nSummary Metrics:\")\n",
    "    print(f\"{'Dataset':<12}\\tF1 (macro)\\tAccuracy\")\n",
    "    print(\"-\" * 45)\n",
    "    print(f\"{'Merged':<12}\\t{metrics_dict['merged_local']['macro avg']['f1-score']*100:>9.2f}\\t{metrics_dict['merged_local']['accuracy']*100:>8.2f}\")\n",
    "    print(f\"{'DynaSent R1':<12}\\t{metrics_dict['dynasent_r1']['macro avg']['f1-score']*100:>9.2f}\\t{metrics_dict['dynasent_r1']['accuracy']*100:>8.2f}\")\n",
    "    print(f\"{'DynaSent R2':<12}\\t{metrics_dict['dynasent_r2']['macro avg']['f1-score']*100:>9.2f}\\t{metrics_dict['dynasent_r2']['accuracy']*100:>8.2f}\")\n",
    "    print(f\"{'SST-3':<12}\\t{metrics_dict['sst_local']['macro avg']['f1-score']*100:>9.2f}\\t{metrics_dict['sst_local']['accuracy']*100:>8.2f}\")\n",
    "        \n",
    "    end_time = datetime.now()\n",
    "    duration = end_time - start_time\n",
    "    print(f\"\\nEvaluation completed\")\n",
    "    print(f\"End time: {end_time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    print(f\"Duration: {duration}\")\n",
    "    metrics_dict['end_time'] = end_time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    metrics_dict['duration'] = str(duration)\n",
    "    \n",
    "    # Return results if it was not provided, and metrics\n",
    "    if return_results:\n",
    "        return results_df, metrics_dict\n",
    "    else:\n",
    "        return metrics_dict\n",
    "\n",
    "def extract_metrics_from_report(report):\n",
    "    \"\"\"Helper function to extract metrics from classification report\"\"\"\n",
    "    return {\n",
    "        'negative': report['negative'],\n",
    "        'neutral': report['neutral'],\n",
    "        'positive': report['positive'],\n",
    "        'accuracy': report['accuracy'],\n",
    "        'macro avg': report['macro avg'],\n",
    "        'weighted avg': report['weighted avg']\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e179d1",
   "metadata": {},
   "source": [
    "## GPT Minimal Classifier that Mirrors Fine-Tuning Scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9f54a8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class to classify the sentiment of a review that aligns with the fine-tuning format\n",
    "class GPTMinSentiment:\n",
    "    def __init__(self, model=None):\n",
    "        \"\"\"\n",
    "        Initializes the sentiment model with the specified model name.\n",
    "        Args:\n",
    "            model (str): The model identifier for the OpenAI API.\n",
    "        \"\"\"\n",
    "        self.client = OpenAI()\n",
    "        self.history = []\n",
    "        self.model = model\n",
    "\n",
    "    def __call__(self, review):\n",
    "        messages = [\n",
    "            {'role': 'system', 'content': \"You are a model that classifies the sentiment of a review as either 'positive', 'neutral', or 'negative'.\"},\n",
    "            {'role': 'user', 'content': review}\n",
    "        ]\n",
    "        \n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=messages,\n",
    "            temperature=temperature\n",
    "        )\n",
    "        \n",
    "        # Store the full conversation\n",
    "        self.history = messages + [\n",
    "            {'role': 'assistant', 'content': response.choices[0].message.content}\n",
    "        ]\n",
    "        \n",
    "        sleep(0.5)\n",
    "        return {'classification': response.choices[0].message.content.strip().lower()}\n",
    "    \n",
    "    def get_last_conversation(self):\n",
    "        \"\"\"Returns the most recent conversation\"\"\"\n",
    "        return self.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0f706c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the GPT minimal sentiment module\n",
    "gpt_4o_mini_min_sentiment = GPTMinSentiment(model=\"ft:gpt-4o-mini-2024-07-18:personal::ALnBCKLv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d4f2d175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the GPT minimal sentiment module\n",
    "gpt_4o_min_sentiment = GPTMinSentiment(model=\"ft:gpt-4o-2024-08-06:personal::AM5cg622\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "da3a7fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class to classify the sentiment of a review that aligns with the fine-tuning format\n",
    "class GPTMinSentimentWithPred:\n",
    "    def __init__(self, model=None, model_type='base'):\n",
    "        \"\"\"\n",
    "        Initializes the sentiment model with the specified model name.\n",
    "        Args:\n",
    "            model (str): The model identifier for the OpenAI API.\n",
    "        \"\"\"\n",
    "        self.client = OpenAI()\n",
    "        self.history = []\n",
    "        self.model = model\n",
    "        self.numeric_dict = {0: 'negative', 1: 'neutral', 2: 'positive'}\n",
    "\n",
    "        # Determine which model and tokenizer to use\n",
    "        if model_type == 'base':\n",
    "            self.electra_model = electra_base_model\n",
    "            self.electra_model_name = 'google/electra-base-discriminator'\n",
    "        elif model_type == 'large':\n",
    "            self.electra_model = electra_large_model\n",
    "            self.electra_model_name = 'google/electra-large-discriminator'\n",
    "        else:\n",
    "            raise ValueError(\"Invalid model_type. Choose 'base' or 'large'.\")\n",
    "\n",
    "        # Load the ELECTRA tokenizer from Hugging Face\n",
    "        self.tokenizer = ElectraTokenizer.from_pretrained(self.electra_model_name)\n",
    "\n",
    "    def classify_with_electra(self, review):\n",
    "        _, predicted_label, probabilities = predict_sentence(self.electra_model, review, self.tokenizer, self.numeric_dict)\n",
    "        return predicted_label, probabilities\n",
    "\n",
    "    def model_summary(self):\n",
    "        # Display the model summary to confirm\n",
    "        print(f\"Model Summary for {self.electra_model_name}:\\n\")\n",
    "        \n",
    "        # Print the model architecture\n",
    "        print(self.electra_model)\n",
    "        #print(self.electra_model.model)  # Needed for DDP wrapped models\n",
    "\n",
    "    def __call__(self, review):\n",
    "        classifier_decision, probabilities = self.classify_with_electra(review)\n",
    "\n",
    "        messages = [\n",
    "            {'role': 'system', 'content': \"You are a model that classifies the sentiment of a review as either 'positive', 'neutral', or 'negative'. 'Classifier Decision' is the sentiment classification proposed by a model fine-tuned on sentiment.\"},\n",
    "            {'role': 'user', 'content': f'Classifier Decision: {classifier_decision}.\\nReview: {review}'}\n",
    "        ]\n",
    "        \n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=messages,\n",
    "            temperature=temperature\n",
    "        )\n",
    "        \n",
    "        # Store the full conversation\n",
    "        self.history = messages + [\n",
    "            {'role': 'assistant', 'content': response.choices[0].message.content}\n",
    "        ]\n",
    "        \n",
    "        sleep(0.5)\n",
    "        return {'classification': response.choices[0].message.content.strip().lower()}\n",
    "    \n",
    "    def get_last_conversation(self):\n",
    "        \"\"\"Returns the most recent conversation\"\"\"\n",
    "        return self.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a61200ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the GPT minimal sentiment module\n",
    "gpt_4o_mini_min_sentiment_with_pred = GPTMinSentimentWithPred(model=\"ft:gpt-4o-mini-2024-07-18:personal::ALnBCKLv\", model_type='large')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c322c45",
   "metadata": {},
   "source": [
    "### Evaluate GPT-4o-mini FT with prompt that matches fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bbcdc788",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batch(classifier, data, input_format='examples'):\n",
    "    \"\"\"\n",
    "    Process a batch of reviews through the sentiment classifier.\n",
    "    \n",
    "    Args:\n",
    "        classifier: Instance of GPTMinSentimentV1\n",
    "        data: Either list of Examples or DataFrame\n",
    "        input_format: 'examples' or 'dataframe'\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with columns: review, classification (ground truth), prediction, match\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    # Convert input to standard format\n",
    "    if input_format == 'examples':\n",
    "        reviews = [ex.review for ex in data]\n",
    "        labels = [ex.classification for ex in data]\n",
    "    else:  # dataframe\n",
    "        reviews = data['sentence'].tolist()\n",
    "        labels = data['label'].tolist()\n",
    "    \n",
    "    # Process each review\n",
    "    for review, true_label in tqdm(zip(reviews, labels), total=len(reviews)):\n",
    "        try:\n",
    "            result = classifier(review=review)\n",
    "            prediction = result['classification']\n",
    "            results.append({\n",
    "                'review': review,\n",
    "                'classification': true_label,\n",
    "                'prediction': prediction,\n",
    "                'match': true_label == prediction\n",
    "            })\n",
    "            sleep(0.25)  # Respect rate limits\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing review: {review[:50]}... Error: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d8c6c8",
   "metadata": {},
   "source": [
    "## Experiments\n",
    "\n",
    "Note: What follow are the original experiment IDs. The numbering was streamlined in the research paper and will vary in a few cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eaa585a",
   "metadata": {},
   "source": [
    "### B3-G4OM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c48ba00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch to the correct language model and disable experimental mode\n",
    "lm = dspy.OpenAI(model='gpt-4o-mini-2024-07-18', api_key=openai_key, max_tokens=8192, temperature=temperature)\n",
    "dspy.settings.configure(lm=lm, experimental=False, seed=random_seed)\n",
    "dsp.settings.show_guidelines = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d788f290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a test result for the GPT sentiment module\n",
    "b3_g4om_result = gpt_sentiment(review=test_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ac3fd1bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    classification='negative'\n",
       ")"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b3_g4om_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3f3e4d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Classify the sentiment of a review as either 'negative', 'neutral', or 'positive'.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Review: The review text to classify.\n",
      "Classification: One word representing the sentiment classification: 'negative', 'neutral', or 'positive' (do not repeat the field name, do not use 'mixed')\n",
      "\n",
      "---\n",
      "\n",
      "Review: Those 2 drinks are part of the HK culture and has years of history. It is so bad.\n",
      "Classification:\u001b[32m negative\u001b[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\n\\nClassify the sentiment of a review as either 'negative', 'neutral', or 'positive'.\\n\\n---\\n\\nFollow the following format.\\n\\nReview: The review text to classify.\\nClassification: One word representing the sentiment classification: 'negative', 'neutral', or 'positive' (do not repeat the field name, do not use 'mixed')\\n\\n---\\n\\nReview: Those 2 drinks are part of the HK culture and has years of history. It is so bad.\\nClassification:\\x1b[32m negative\\x1b[0m\\n\\n\\n\""
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "839b619e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the evaluater, setting threads to 1 to avoid rate limiting\n",
    "test_full_evaluater = Evaluate(\n",
    "    devset=test_ex,\n",
    "    num_threads=1,\n",
    "    display_progress=True,\n",
    "    display_table=False,\n",
    "    return_outputs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "30fdbcb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 5233 / 6530  (80.1): 100%|██████████| 6530/6530 [1:30:53<00:00,  1.20it/s]  \n"
     ]
    }
   ],
   "source": [
    "b3_g4om_results = test_full_evaluater(gpt_sentiment, metric=classification_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "dc1c7216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Columns in results DataFrame:\n",
      "review                 6530 values\n",
      "classification         6530 values\n",
      "prediction             6530 values\n",
      "match                  6530 values\n"
     ]
    }
   ],
   "source": [
    "b3_g4om_results_df = convert_results_to_df(b3_g4om_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "644af6ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prediction\n",
       "negative                                                                                                                                                                                                                                                                          2674\n",
       "positive                                                                                                                                                                                                                                                                          2087\n",
       "neutral                                                                                                                                                                                                                                                                           1767\n",
       "review: the review text to classify.\\nclassification: neutral                                                                                                                                                                                                                        1\n",
       "review: the product arrived late and was damaged. \\nclassification: negative\\n\\nreview: the service was okay, nothing special. \\nclassification: neutral\\n\\nreview: i absolutely love this new phone! it works perfectly and the camera is amazing. \\nclassification: positive       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display unique value counts for prediction column\n",
    "b3_g4om_results_df['prediction'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "617da026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find out the row IDs for the predictions that start with \"review\"\n",
    "review_indices = b3_g4om_results_df[b3_g4om_results_df['prediction'].str.startswith('review')].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c94f734e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([4512, 6426], dtype='int64')"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a472bb1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>source</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4512</th>\n",
       "      <td>https://www.yelp.com/biz/vegas-discount-nutrition-superstore-las-vegas-8?hrid=QQhKNmf3VF_6r_qAfE8jxg&amp;utm_campaign=www_review_share_popup&amp;utm_medium=copy_link&amp;utm_source=(direct)</td>\n",
       "      <td>neutral</td>\n",
       "      <td>dynasent_r1</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6426</th>\n",
       "      <td>HERE.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>dynasent_r1</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                               sentence  \\\n",
       "4512  https://www.yelp.com/biz/vegas-discount-nutrition-superstore-las-vegas-8?hrid=QQhKNmf3VF_6r_qAfE8jxg&utm_campaign=www_review_share_popup&utm_medium=copy_link&utm_source=(direct)   \n",
       "6426                                                                                                                                                                              HERE.   \n",
       "\n",
       "        label       source split  \n",
       "4512  neutral  dynasent_r1  test  \n",
       "6426  neutral  dynasent_r1  test  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.loc[review_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "89a219c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "b3_g4om_review_4512_retry = gpt_sentiment(review=test_df.loc[4512, 'sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c4967c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Classify the sentiment of a review as either 'negative', 'neutral', or 'positive'.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Review: The review text to classify.\n",
      "Classification: One word representing the sentiment classification: 'negative', 'neutral', or 'positive' (do not repeat the field name, do not use 'mixed')\n",
      "\n",
      "---\n",
      "\n",
      "Review: https://www.yelp.com/biz/vegas-discount-nutrition-superstore-las-vegas-8?hrid=QQhKNmf3VF_6r_qAfE8jxg&utm_campaign=www_review_share_popup&utm_medium=copy_link&utm_source=(direct)\n",
      "Classification:\u001b[32m Review: The review text to classify.\n",
      "Classification: neutral\u001b[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\n\\nClassify the sentiment of a review as either 'negative', 'neutral', or 'positive'.\\n\\n---\\n\\nFollow the following format.\\n\\nReview: The review text to classify.\\nClassification: One word representing the sentiment classification: 'negative', 'neutral', or 'positive' (do not repeat the field name, do not use 'mixed')\\n\\n---\\n\\nReview: https://www.yelp.com/biz/vegas-discount-nutrition-superstore-las-vegas-8?hrid=QQhKNmf3VF_6r_qAfE8jxg&utm_campaign=www_review_share_popup&utm_medium=copy_link&utm_source=(direct)\\nClassification:\\x1b[32m Review: The review text to classify.\\nClassification: neutral\\x1b[0m\\n\\n\\n\""
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7f8c9770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update b4_g4om_results_df with the retry result\n",
    "b3_g4om_results_df.at[4512, 'prediction'] = 'neutral'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "cbc7d567",
   "metadata": {},
   "outputs": [],
   "source": [
    "b3_g4om_review_6426_retry = gpt_sentiment(review=\"HERE. (This is the actual review, please just classify 'HERE.' Do not repeat 'Classification:')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7f116c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Classify the sentiment of a review as either 'negative', 'neutral', or 'positive'.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Review: The review text to classify.\n",
      "Classification: One word representing the sentiment classification: 'negative', 'neutral', or 'positive' (do not repeat the field name, do not use 'mixed')\n",
      "\n",
      "---\n",
      "\n",
      "Review: HERE. (This is the actual review, please just classify 'HERE.' Do not repeat 'Classification:')\n",
      "Classification:\u001b[32m neutral\u001b[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\n\\nClassify the sentiment of a review as either 'negative', 'neutral', or 'positive'.\\n\\n---\\n\\nFollow the following format.\\n\\nReview: The review text to classify.\\nClassification: One word representing the sentiment classification: 'negative', 'neutral', or 'positive' (do not repeat the field name, do not use 'mixed')\\n\\n---\\n\\nReview: HERE. (This is the actual review, please just classify 'HERE.' Do not repeat 'Classification:')\\nClassification:\\x1b[32m neutral\\x1b[0m\\n\\n\\n\""
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3e7e22bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update b4_g4om_results_df with the retry result\n",
    "b3_g4om_results_df.at[6426, 'prediction'] = b3_g4om_review_6426_retry.classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "92253f3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>classification</th>\n",
       "      <th>prediction</th>\n",
       "      <th>match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4512</th>\n",
       "      <td>https://www.yelp.com/biz/vegas-discount-nutrition-superstore-las-vegas-8?hrid=QQhKNmf3VF_6r_qAfE8jxg&amp;utm_campaign=www_review_share_popup&amp;utm_medium=copy_link&amp;utm_source=(direct)</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6426</th>\n",
       "      <td>HERE.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                 review  \\\n",
       "4512  https://www.yelp.com/biz/vegas-discount-nutrition-superstore-las-vegas-8?hrid=QQhKNmf3VF_6r_qAfE8jxg&utm_campaign=www_review_share_popup&utm_medium=copy_link&utm_source=(direct)   \n",
       "6426                                                                                                                                                                              HERE.   \n",
       "\n",
       "     classification prediction  match  \n",
       "4512        neutral    neutral   True  \n",
       "6426        neutral    neutral  False  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b3_g4om_results_df.loc[review_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9cfd8a96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prediction\n",
       "negative    2674\n",
       "positive    2087\n",
       "neutral     1769\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display unique value counts for prediction column\n",
    "b3_g4om_results_df['prediction'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "64cf9757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Experiment: B3-G4OM\n",
      "--------------------------------------------------------------------------------\n",
      "Start time: 2025-03-15 23:20:19\n",
      "Notes: Baseline 3: Establish GPT-4o-mini baseline with prompt\n",
      "Model: gpt-4o-mini-2024-07-18\n",
      "Instance: gpt_sentiment\n",
      "Dataset shape: [6530, 4]\n",
      "Examples length: 6530\n",
      "Results shape: [6530, 4]\n",
      "Save directory: results_round2\n",
      "\n",
      "Source value counts:\n",
      "dynasent_r1            3600\n",
      "sst_local              2210\n",
      "dynasent_r2             720\n",
      "\n",
      "Prediction value counts:\n",
      "negative               2674\n",
      "positive               2087\n",
      "neutral                1769\n",
      "\n",
      "B3-G4OM Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.7887    0.8967    0.8392      2352\n",
      "     neutral     0.7027    0.6796    0.6909      1829\n",
      "    positive     0.9018    0.8012    0.8485      2349\n",
      "\n",
      "    accuracy                         0.8015      6530\n",
      "   macro avg     0.7977    0.7925    0.7929      6530\n",
      "weighted avg     0.8053    0.8015    0.8010      6530\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative       2109      217        26\n",
      "neutral         407     1243       179\n",
      "positive        158      309      1882\n",
      "\n",
      "\n",
      "B3-G4OM-DYN-R1 Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.8293    0.8542    0.8415      1200\n",
      "     neutral     0.7240    0.8308    0.7738      1200\n",
      "    positive     0.9088    0.7475    0.8203      1200\n",
      "\n",
      "    accuracy                         0.8108      3600\n",
      "   macro avg     0.8207    0.8108    0.8119      3600\n",
      "weighted avg     0.8207    0.8108    0.8119      3600\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative       1025      160        15\n",
      "neutral         128      997        75\n",
      "positive         83      220       897\n",
      "\n",
      "\n",
      "B3-G4OM-DYN-R2 Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.7090    0.9542    0.8135       240\n",
      "     neutral     0.8079    0.5958    0.6859       240\n",
      "    positive     0.8409    0.7708    0.8043       240\n",
      "\n",
      "    accuracy                         0.7736       720\n",
      "   macro avg     0.7859    0.7736    0.7679       720\n",
      "weighted avg     0.7859    0.7736    0.7679       720\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative        229        8         3\n",
      "neutral          65      143        32\n",
      "positive         29       26       185\n",
      "\n",
      "\n",
      "B3-G4OM-SST Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.7668    0.9375    0.8436       912\n",
      "     neutral     0.4791    0.2648    0.3411       389\n",
      "    positive     0.9091    0.8801    0.8944       909\n",
      "\n",
      "    accuracy                         0.7955      2210\n",
      "   macro avg     0.7183    0.6941    0.6930      2210\n",
      "weighted avg     0.7747    0.7955    0.7760      2210\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative        855       49         8\n",
      "neutral         214      103        72\n",
      "positive         46       63       800\n",
      "\n",
      "Saving results to 'results_round2'...\n",
      "\n",
      "Summary Metrics:\n",
      "Dataset     \tF1 (macro)\tAccuracy\n",
      "---------------------------------------------\n",
      "Merged      \t    79.29\t   80.15\n",
      "DynaSent R1 \t    81.19\t   81.08\n",
      "DynaSent R2 \t    76.79\t   77.36\n",
      "SST-3       \t    69.30\t   79.55\n",
      "\n",
      "Evaluation completed\n",
      "End time: 2025-03-15 23:20:19\n",
      "Duration: 0:00:00.534177\n"
     ]
    }
   ],
   "source": [
    "b3_g4om_metrics = evaluate_experiment(\n",
    "    name='B3-G4OM',\n",
    "    notes='Baseline 3: Establish GPT-4o-mini baseline with prompt',\n",
    "    lm='gpt-4o-mini-2024-07-18',\n",
    "    instance='gpt_sentiment',\n",
    "    dataset=test_df,\n",
    "    examples=test_ex,\n",
    "    results=b3_g4om_results_df\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211f8389",
   "metadata": {},
   "source": [
    "### E3-G4OM-EBFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "14993521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch to the correct language model and disable experimental mode\n",
    "lm = dspy.OpenAI(model='gpt-4o-mini-2024-07-18', api_key=openai_key, max_tokens=8192, temperature=temperature)\n",
    "dspy.settings.configure(lm=lm, experimental=False, seed=random_seed)\n",
    "dsp.settings.show_guidelines = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "a1757cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a test result for the GPT sentiment module\n",
    "e3_g4om_ebft_result = electra_base_gpt_sentiment(review=test_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "1189c5a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    classification='negative',\n",
       "    classifier_decision='negative',\n",
       "    probabilities=[0.999830961227417, 0.00012046996562276036, 4.853002610616386e-05]\n",
       ")"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e3_g4om_ebft_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "715b0c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Classify the sentiment of a review as either 'negative', 'neutral', or 'positive'.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Review: The review text to classify.\n",
      "Classifier Decision: The sentiment classification proposed by a model fine-tuned on sentiment.\n",
      "Classification: One word representing the sentiment classification: 'negative', 'neutral', or 'positive' (do not repeat the field name, do not use 'mixed')\n",
      "\n",
      "---\n",
      "\n",
      "Review: Those 2 drinks are part of the HK culture and has years of history. It is so bad.\n",
      "Classifier Decision: negative\n",
      "Classification:\u001b[32m negative\u001b[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\n\\nClassify the sentiment of a review as either 'negative', 'neutral', or 'positive'.\\n\\n---\\n\\nFollow the following format.\\n\\nReview: The review text to classify.\\nClassifier Decision: The sentiment classification proposed by a model fine-tuned on sentiment.\\nClassification: One word representing the sentiment classification: 'negative', 'neutral', or 'positive' (do not repeat the field name, do not use 'mixed')\\n\\n---\\n\\nReview: Those 2 drinks are part of the HK culture and has years of history. It is so bad.\\nClassifier Decision: negative\\nClassification:\\x1b[32m negative\\x1b[0m\\n\\n\\n\""
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "3fa71270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the evaluater, setting threads to 1 to avoid rate limiting\n",
    "test_full_evaluater = Evaluate(\n",
    "    devset=test_ex,\n",
    "    num_threads=1,\n",
    "    display_progress=True,\n",
    "    display_table=False,\n",
    "    return_outputs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "9c91ffba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 5415 / 6530  (82.9): 100%|██████████| 6530/6530 [53:46<00:00,  2.02it/s]  \n"
     ]
    }
   ],
   "source": [
    "e3_g4om_ebft_results = test_full_evaluater(electra_base_gpt_sentiment, metric=classification_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "3a936719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Columns in results DataFrame:\n",
      "review                 6530 values\n",
      "classification         6530 values\n",
      "prediction             6530 values\n",
      "match                  6530 values\n",
      "classifier_decision    6530 values\n",
      "probabilities          6530 values\n"
     ]
    }
   ],
   "source": [
    "e3_g4om_ebft_results_df = convert_results_to_df(e3_g4om_ebft_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "2bc2899b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Experiment: E3-G4OM-EBFT\n",
      "--------------------------------------------------------------------------------\n",
      "Start time: 2025-03-27 22:30:57\n",
      "Notes: Experiment 3: Evaluate prompt-based model collaboration between GPT-4o-mini and Electra Base fine-tuned model\n",
      "Model: gpt-4o-mini-2024-07-18\n",
      "Instance: electra_base_gpt_sentiment\n",
      "Dataset shape: [6530, 4]\n",
      "Examples length: 6530\n",
      "Results shape: [6530, 6]\n",
      "Save directory: results_round2_take2\n",
      "\n",
      "Source value counts:\n",
      "dynasent_r1            3600\n",
      "sst_local              2210\n",
      "dynasent_r2             720\n",
      "\n",
      "Prediction value counts:\n",
      "negative               2575\n",
      "positive               2189\n",
      "neutral                1766\n",
      "\n",
      "E3-G4OM-EBFT Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.8190    0.8967    0.8561      2352\n",
      "     neutral     0.7576    0.7315    0.7444      1829\n",
      "    positive     0.8990    0.8378    0.8673      2349\n",
      "\n",
      "    accuracy                         0.8292      6530\n",
      "   macro avg     0.8252    0.8220    0.8226      6530\n",
      "weighted avg     0.8306    0.8292    0.8288      6530\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative       2109      197        46\n",
      "neutral         316     1338       175\n",
      "positive        150      231      1968\n",
      "\n",
      "\n",
      "E3-G4OM-EBFT-DYN-R1 Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.8919    0.8733    0.8825      1200\n",
      "     neutral     0.7947    0.9067    0.8470      1200\n",
      "    positive     0.9176    0.8075    0.8590      1200\n",
      "\n",
      "    accuracy                         0.8625      3600\n",
      "   macro avg     0.8681    0.8625    0.8629      3600\n",
      "weighted avg     0.8681    0.8625    0.8629      3600\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative       1048      122        30\n",
      "neutral          55     1088        57\n",
      "positive         72      159       969\n",
      "\n",
      "\n",
      "E3-G4OM-EBFT-DYN-R2 Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.6770    0.9083    0.7758       240\n",
      "     neutral     0.7857    0.5958    0.6777       240\n",
      "    positive     0.8241    0.7417    0.7807       240\n",
      "\n",
      "    accuracy                         0.7486       720\n",
      "   macro avg     0.7623    0.7486    0.7447       720\n",
      "weighted avg     0.7623    0.7486    0.7447       720\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative        218       19         3\n",
      "neutral          62      143        35\n",
      "positive         42       20       178\n",
      "\n",
      "\n",
      "E3-G4OM-EBFT-SST Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.7820    0.9243    0.8472       912\n",
      "     neutral     0.4977    0.2751    0.3543       389\n",
      "    positive     0.8953    0.9032    0.8992       909\n",
      "\n",
      "    accuracy                         0.8014      2210\n",
      "   macro avg     0.7250    0.7009    0.7003      2210\n",
      "weighted avg     0.7786    0.8014    0.7819      2210\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative        843       56        13\n",
      "neutral         199      107        83\n",
      "positive         36       52       821\n",
      "\n",
      "Saving results to 'results_round2_take2'...\n",
      "\n",
      "Summary Metrics:\n",
      "Dataset     \tF1 (macro)\tAccuracy\n",
      "---------------------------------------------\n",
      "Merged      \t    82.26\t   82.92\n",
      "DynaSent R1 \t    86.29\t   86.25\n",
      "DynaSent R2 \t    74.47\t   74.86\n",
      "SST-3       \t    70.03\t   80.14\n",
      "\n",
      "Evaluation completed\n",
      "End time: 2025-03-27 22:30:58\n",
      "Duration: 0:00:00.458862\n"
     ]
    }
   ],
   "source": [
    "e3_g4om_ebft_metrics = evaluate_experiment(\n",
    "    name='E3-G4OM-EBFT',\n",
    "    notes='Experiment 3: Evaluate prompt-based model collaboration between GPT-4o-mini and Electra Base fine-tuned model',\n",
    "    lm='gpt-4o-mini-2024-07-18',\n",
    "    instance='electra_base_gpt_sentiment',\n",
    "    dataset=test_df,\n",
    "    examples=test_ex,\n",
    "    results=e3_g4om_ebft_results_df\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b511c08",
   "metadata": {},
   "source": [
    "### E4-G4OMFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "353b4364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch to the correct language model and disable experimental mode\n",
    "lm = dspy.OpenAI(model='ft:gpt-4o-mini-2024-07-18:personal::AN2RNUvd', api_key=openai_key, max_tokens=8192, temperature=temperature)\n",
    "dspy.settings.configure(lm=lm, experimental=False, seed=random_seed)\n",
    "dsp.settings.show_guidelines = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "4f4d8b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a test result for the GPT sentiment module\n",
    "e4_g4omft_result = gpt_sentiment(review=test_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "7b901cf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    classification='negative'\n",
       ")"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e4_g4omft_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "9430de1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Classify the sentiment of a review as either 'negative', 'neutral', or 'positive'.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Review: The review text to classify.\n",
      "Classification: One word representing the sentiment classification: 'negative', 'neutral', or 'positive' (do not repeat the field name, do not use 'mixed')\n",
      "\n",
      "---\n",
      "\n",
      "Review: Those 2 drinks are part of the HK culture and has years of history. It is so bad.\n",
      "Classification:\u001b[32m negative\u001b[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\n\\nClassify the sentiment of a review as either 'negative', 'neutral', or 'positive'.\\n\\n---\\n\\nFollow the following format.\\n\\nReview: The review text to classify.\\nClassification: One word representing the sentiment classification: 'negative', 'neutral', or 'positive' (do not repeat the field name, do not use 'mixed')\\n\\n---\\n\\nReview: Those 2 drinks are part of the HK culture and has years of history. It is so bad.\\nClassification:\\x1b[32m negative\\x1b[0m\\n\\n\\n\""
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "bea7acb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Experiment: E4-G4OMFT\n",
      "--------------------------------------------------------------------------------\n",
      "Start time: 2025-03-16 03:09:18\n",
      "Notes: Experiment 4: Measure impact of fine-tuning on GPT-4o-mini\n",
      "Model: ft:gpt-4o-mini-2024-07-18:personal::AN2RNUvd\n",
      "Instance: gpt_sentiment\n",
      "Dataset shape: [6530, 4]\n",
      "Examples length: 6530\n",
      "Save directory: results_round2\n",
      "Temperature: 0.1\n",
      "Random seed: 123\n",
      "\n",
      "Running evaluation...\n",
      "Average Metric: 5687 / 6530  (87.1): 100%|██████████| 6530/6530 [1:33:08<00:00,  1.17it/s]  \n",
      "\n",
      "Columns in results DataFrame:\n",
      "review                 6530 values\n",
      "classification         6530 values\n",
      "prediction             6530 values\n",
      "match                  6530 values\n",
      "\n",
      "Source value counts:\n",
      "dynasent_r1            3600\n",
      "sst_local              2210\n",
      "dynasent_r2             720\n",
      "\n",
      "Prediction value counts:\n",
      "negative               2310\n",
      "positive               2279\n",
      "neutral                1941\n",
      "\n",
      "E4-G4OMFT Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.9052    0.8890    0.8970      2352\n",
      "     neutral     0.7723    0.8196    0.7952      1829\n",
      "    positive     0.9201    0.8927    0.9062      2349\n",
      "\n",
      "    accuracy                         0.8709      6530\n",
      "   macro avg     0.8659    0.8671    0.8662      6530\n",
      "weighted avg     0.8733    0.8709    0.8718      6530\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative       2091      225        36\n",
      "neutral         184     1499       146\n",
      "positive         35      217      2097\n",
      "\n",
      "\n",
      "E4-G4OMFT-DYN-R1 Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.9539    0.8800    0.9155      1200\n",
      "     neutral     0.7985    0.9575    0.8708      1200\n",
      "    positive     0.9592    0.8425    0.8971      1200\n",
      "\n",
      "    accuracy                         0.8933      3600\n",
      "   macro avg     0.9039    0.8933    0.8944      3600\n",
      "weighted avg     0.9039    0.8933    0.8944      3600\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative       1056      127        17\n",
      "neutral          25     1149        26\n",
      "positive         26      163      1011\n",
      "\n",
      "\n",
      "E4-G4OMFT-DYN-R2 Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.8831    0.9125    0.8975       240\n",
      "     neutral     0.8852    0.7708    0.8241       240\n",
      "    positive     0.8517    0.9333    0.8907       240\n",
      "\n",
      "    accuracy                         0.8722       720\n",
      "   macro avg     0.8733    0.8722    0.8708       720\n",
      "weighted avg     0.8733    0.8722    0.8708       720\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative        219       12         9\n",
      "neutral          25      185        30\n",
      "positive          4       12       224\n",
      "\n",
      "\n",
      "E4-G4OMFT-SST Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.8545    0.8947    0.8741       912\n",
      "     neutral     0.5631    0.4242    0.4839       389\n",
      "    positive     0.8960    0.9483    0.9214       909\n",
      "\n",
      "    accuracy                         0.8339      2210\n",
      "   macro avg     0.7712    0.7557    0.7598      2210\n",
      "weighted avg     0.8203    0.8339    0.8249      2210\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative        816       86        10\n",
      "neutral         134      165        90\n",
      "positive          5       42       862\n",
      "\n",
      "Saving results to 'results_round2'...\n",
      "\n",
      "Summary Metrics:\n",
      "Dataset     \tF1 (macro)\tAccuracy\n",
      "---------------------------------------------\n",
      "Merged      \t    86.62\t   87.09\n",
      "DynaSent R1 \t    89.44\t   89.33\n",
      "DynaSent R2 \t    87.08\t   87.22\n",
      "SST-3       \t    75.98\t   83.39\n",
      "\n",
      "Evaluation completed\n",
      "End time: 2025-03-16 04:42:27\n",
      "Duration: 1:33:09.368488\n"
     ]
    }
   ],
   "source": [
    "e4_g4omft_results_df, e4_g4omft_metrics = evaluate_experiment(\n",
    "    name='E4-G4OMFT',\n",
    "    notes='Experiment 4: Measure impact of fine-tuning on GPT-4o-mini',\n",
    "    lm='ft:gpt-4o-mini-2024-07-18:personal::AN2RNUvd',\n",
    "    instance='gpt_sentiment',\n",
    "    dataset=test_df,\n",
    "    examples=test_ex,\n",
    "    temperature=temperature,\n",
    "    random_seed=random_seed\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acea418c",
   "metadata": {},
   "source": [
    "### E5-G4OMFT-EBFT-P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "d256f577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch to the correct language model and disable experimental mode\n",
    "lm = dspy.OpenAI(model='ft:gpt-4o-mini-2024-07-18:personal::AN2RNUvd', api_key=openai_key, max_tokens=8192, temperature=temperature)\n",
    "dspy.settings.configure(lm=lm, experimental=False, seed=random_seed)\n",
    "dsp.settings.show_guidelines = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "d155dcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a test result for the ELECTRA Base GPT sentiment module\n",
    "e5_g4omft_ebft_p_result = electra_base_gpt_sentiment(review=test_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "91b406e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    classification='negative',\n",
       "    classifier_decision='negative',\n",
       "    probabilities=[0.999830961227417, 0.00012046996562276036, 4.853002610616386e-05]\n",
       ")"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e5_g4omft_ebft_p_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "175e1372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Classify the sentiment of a review as either 'negative', 'neutral', or 'positive'.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Review: The review text to classify.\n",
      "Classifier Decision: The sentiment classification proposed by a model fine-tuned on sentiment.\n",
      "Classification: One word representing the sentiment classification: 'negative', 'neutral', or 'positive' (do not repeat the field name, do not use 'mixed')\n",
      "\n",
      "---\n",
      "\n",
      "Review: Those 2 drinks are part of the HK culture and has years of history. It is so bad.\n",
      "Classifier Decision: negative\n",
      "Classification:\u001b[32m negative\u001b[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\n\\nClassify the sentiment of a review as either 'negative', 'neutral', or 'positive'.\\n\\n---\\n\\nFollow the following format.\\n\\nReview: The review text to classify.\\nClassifier Decision: The sentiment classification proposed by a model fine-tuned on sentiment.\\nClassification: One word representing the sentiment classification: 'negative', 'neutral', or 'positive' (do not repeat the field name, do not use 'mixed')\\n\\n---\\n\\nReview: Those 2 drinks are part of the HK culture and has years of history. It is so bad.\\nClassifier Decision: negative\\nClassification:\\x1b[32m negative\\x1b[0m\\n\\n\\n\""
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "408aab2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Experiment: E5-G4OMFT-EBFT-P\n",
      "--------------------------------------------------------------------------------\n",
      "Start time: 2025-03-27 22:41:41\n",
      "Notes: Experiment 5: Evaluate combined impact of fine-tuning and prompt collaboration between GPT-4o-mini and Electra Base fine-tuned model\n",
      "Model: ft:gpt-4o-mini-2024-07-18:personal::AN2RNUvd\n",
      "Instance: electra_base_gpt_sentiment\n",
      "Dataset shape: [6530, 4]\n",
      "Examples length: 6530\n",
      "Save directory: results_round2_take2\n",
      "Temperature: 0.1\n",
      "Random seed: 123\n",
      "\n",
      "Running evaluation...\n",
      "Average Metric: 5305 / 6530  (81.2): 100%|██████████| 6530/6530 [55:09<00:00,  1.97it/s]  \n",
      "\n",
      "Columns in results DataFrame:\n",
      "review                 6530 values\n",
      "classification         6530 values\n",
      "prediction             6530 values\n",
      "match                  6530 values\n",
      "classifier_decision    6530 values\n",
      "probabilities          6530 values\n",
      "\n",
      "Source value counts:\n",
      "dynasent_r1            3600\n",
      "sst_local              2210\n",
      "dynasent_r2             720\n",
      "\n",
      "Prediction value counts:\n",
      "positive               2429\n",
      "negative               2336\n",
      "neutral                1765\n",
      "\n",
      "E5-G4OMFT-EBFT-P Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.8365    0.8308    0.8336      2352\n",
      "     neutral     0.7575    0.7310    0.7440      1829\n",
      "    positive     0.8291    0.8574    0.8430      2349\n",
      "\n",
      "    accuracy                         0.8124      6530\n",
      "   macro avg     0.8077    0.8064    0.8069      6530\n",
      "weighted avg     0.8117    0.8124    0.8119      6530\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative       1954      221       177\n",
      "neutral         254     1337       238\n",
      "positive        128      207      2014\n",
      "\n",
      "\n",
      "E5-G4OMFT-EBFT-P-DYN-R1 Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.8964    0.7933    0.8417      1200\n",
      "     neutral     0.7928    0.9150    0.8495      1200\n",
      "    positive     0.8630    0.8292    0.8457      1200\n",
      "\n",
      "    accuracy                         0.8458      3600\n",
      "   macro avg     0.8507    0.8458    0.8457      3600\n",
      "weighted avg     0.8507    0.8458    0.8457      3600\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative        952      145       103\n",
      "neutral          47     1098        55\n",
      "positive         63      142       995\n",
      "\n",
      "\n",
      "E5-G4OMFT-EBFT-P-DYN-R2 Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.6890    0.8125    0.7457       240\n",
      "     neutral     0.7898    0.5792    0.6683       240\n",
      "    positive     0.7050    0.7667    0.7345       240\n",
      "\n",
      "    accuracy                         0.7194       720\n",
      "   macro avg     0.7279    0.7194    0.7162       720\n",
      "weighted avg     0.7279    0.7194    0.7162       720\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative        195       19        26\n",
      "neutral          50      139        51\n",
      "positive         38       18       184\n",
      "\n",
      "\n",
      "E5-G4OMFT-EBFT-P-SST Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.8143    0.8849    0.8481       912\n",
      "     neutral     0.4902    0.2571    0.3373       389\n",
      "    positive     0.8227    0.9186    0.8680       909\n",
      "\n",
      "    accuracy                         0.7882      2210\n",
      "   macro avg     0.7091    0.6868    0.6845      2210\n",
      "weighted avg     0.7607    0.7882    0.7664      2210\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative        807       57        48\n",
      "neutral         157      100       132\n",
      "positive         27       47       835\n",
      "\n",
      "Saving results to 'results_round2_take2'...\n",
      "\n",
      "Summary Metrics:\n",
      "Dataset     \tF1 (macro)\tAccuracy\n",
      "---------------------------------------------\n",
      "Merged      \t    80.69\t   81.24\n",
      "DynaSent R1 \t    84.57\t   84.58\n",
      "DynaSent R2 \t    71.62\t   71.94\n",
      "SST-3       \t    68.45\t   78.82\n",
      "\n",
      "Evaluation completed\n",
      "End time: 2025-03-27 23:36:51\n",
      "Duration: 0:55:09.986066\n"
     ]
    }
   ],
   "source": [
    "e5_g4omft_ebft_p_results_df, e5_g4omft_ebft_p_metrics = evaluate_experiment(\n",
    "    name='E5-G4OMFT-EBFT-P',\n",
    "    notes='Experiment 5: Evaluate combined impact of fine-tuning and prompt collaboration between GPT-4o-mini and Electra Base fine-tuned model',\n",
    "    lm='ft:gpt-4o-mini-2024-07-18:personal::AN2RNUvd',\n",
    "    instance='electra_base_gpt_sentiment',\n",
    "    dataset=test_df,\n",
    "    examples=test_ex,\n",
    "    temperature=temperature,\n",
    "    random_seed=random_seed\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d033d67",
   "metadata": {},
   "source": [
    "### E6-G4OMFT-EBFT-FT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "ae239139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch to the correct language model and disable experimental mode\n",
    "lm = dspy.OpenAI(model='ft:gpt-4o-mini-2024-07-18:personal::ANVDva8W', api_key=openai_key, max_tokens=8192, temperature=temperature)\n",
    "dspy.settings.configure(lm=lm, experimental=False, seed=random_seed)\n",
    "dsp.settings.show_guidelines = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "f8ebc426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a test result for the ELECTRA Base GPT sentiment module\n",
    "e6_g4omft_ebft_ft_result = electra_base_gpt_sentiment(review=test_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "487d3d6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    classification='negative',\n",
       "    classifier_decision='negative',\n",
       "    probabilities=[0.999830961227417, 0.00012046996562276036, 4.853002610616386e-05]\n",
       ")"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e6_g4omft_ebft_ft_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "ffba4059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Classify the sentiment of a review as either 'negative', 'neutral', or 'positive'.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Review: The review text to classify.\n",
      "Classifier Decision: The sentiment classification proposed by a model fine-tuned on sentiment.\n",
      "Classification: One word representing the sentiment classification: 'negative', 'neutral', or 'positive' (do not repeat the field name, do not use 'mixed')\n",
      "\n",
      "---\n",
      "\n",
      "Review: Those 2 drinks are part of the HK culture and has years of history. It is so bad.\n",
      "Classifier Decision: negative\n",
      "Classification:\u001b[32m negative\u001b[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\n\\nClassify the sentiment of a review as either 'negative', 'neutral', or 'positive'.\\n\\n---\\n\\nFollow the following format.\\n\\nReview: The review text to classify.\\nClassifier Decision: The sentiment classification proposed by a model fine-tuned on sentiment.\\nClassification: One word representing the sentiment classification: 'negative', 'neutral', or 'positive' (do not repeat the field name, do not use 'mixed')\\n\\n---\\n\\nReview: Those 2 drinks are part of the HK culture and has years of history. It is so bad.\\nClassifier Decision: negative\\nClassification:\\x1b[32m negative\\x1b[0m\\n\\n\\n\""
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "24a4cc37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Experiment: E6-G4OMFT-EBFT-FT\n",
      "--------------------------------------------------------------------------------\n",
      "Start time: 2025-03-27 23:42:58\n",
      "Notes: Experiment 6: Evaluate deep model collaboration through fine-tuning GPT-4o-mini and Electra Base fine-tuned model\n",
      "Model: ft:gpt-4o-mini-2024-07-18:personal::ANVDva8W\n",
      "Instance: electra_base_gpt_sentiment\n",
      "Dataset shape: [6530, 4]\n",
      "Examples length: 6530\n",
      "Save directory: results_round2_take2\n",
      "Temperature: 0.1\n",
      "Random seed: 123\n",
      "\n",
      "Running evaluation...\n",
      "Average Metric: 5371 / 6530  (82.3): 100%|██████████| 6530/6530 [1:03:52<00:00,  1.70it/s]  \n",
      "\n",
      "Columns in results DataFrame:\n",
      "review                 6530 values\n",
      "classification         6530 values\n",
      "prediction             6530 values\n",
      "match                  6530 values\n",
      "classifier_decision    6530 values\n",
      "probabilities          6530 values\n",
      "\n",
      "Source value counts:\n",
      "dynasent_r1            3600\n",
      "sst_local              2210\n",
      "dynasent_r2             720\n",
      "\n",
      "Prediction value counts:\n",
      "positive               2326\n",
      "negative               2296\n",
      "neutral                1908\n",
      "\n",
      "E6-G4OMFT-EBFT-FT Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.8593    0.8389    0.8490      2352\n",
      "     neutral     0.7165    0.7474    0.7316      1829\n",
      "    positive     0.8732    0.8646    0.8689      2349\n",
      "\n",
      "    accuracy                         0.8225      6530\n",
      "   macro avg     0.8163    0.8170    0.8165      6530\n",
      "weighted avg     0.8243    0.8225    0.8233      6530\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative       1973      295        84\n",
      "neutral         251     1367       211\n",
      "positive         72      246      2031\n",
      "\n",
      "\n",
      "E6-G4OMFT-EBFT-FT-DYN-R1 Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.9223    0.8017    0.8578      1200\n",
      "     neutral     0.7544    0.9217    0.8297      1200\n",
      "    positive     0.9102    0.8275    0.8669      1200\n",
      "\n",
      "    accuracy                         0.8503      3600\n",
      "   macro avg     0.8623    0.8503    0.8515      3600\n",
      "weighted avg     0.8623    0.8503    0.8515      3600\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative        962      191        47\n",
      "neutral          43     1106        51\n",
      "positive         38      169       993\n",
      "\n",
      "\n",
      "E6-G4OMFT-EBFT-FT-DYN-R2 Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.7625    0.8292    0.7944       240\n",
      "     neutral     0.7602    0.6208    0.6835       240\n",
      "    positive     0.7795    0.8542    0.8151       240\n",
      "\n",
      "    accuracy                         0.7681       720\n",
      "   macro avg     0.7674    0.7681    0.7643       720\n",
      "weighted avg     0.7674    0.7681    0.7643       720\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative        199       28        13\n",
      "neutral          46      149        45\n",
      "positive         16       19       205\n",
      "\n",
      "\n",
      "E6-G4OMFT-EBFT-FT-SST Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.8185    0.8904    0.8529       912\n",
      "     neutral     0.4553    0.2879    0.3528       389\n",
      "    positive     0.8570    0.9164    0.8857       909\n",
      "\n",
      "    accuracy                         0.7950      2210\n",
      "   macro avg     0.7103    0.6982    0.6971      2210\n",
      "weighted avg     0.7704    0.7950    0.7784      2210\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative        812       76        24\n",
      "neutral         162      112       115\n",
      "positive         18       58       833\n",
      "\n",
      "Saving results to 'results_round2_take2'...\n",
      "\n",
      "Summary Metrics:\n",
      "Dataset     \tF1 (macro)\tAccuracy\n",
      "---------------------------------------------\n",
      "Merged      \t    81.65\t   82.25\n",
      "DynaSent R1 \t    85.15\t   85.03\n",
      "DynaSent R2 \t    76.43\t   76.81\n",
      "SST-3       \t    69.71\t   79.50\n",
      "\n",
      "Evaluation completed\n",
      "End time: 2025-03-28 00:46:52\n",
      "Duration: 1:03:53.297022\n"
     ]
    }
   ],
   "source": [
    "e6_g4omft_ebft_ft_results_df, e6_g4omft_ebft_ft_metrics = evaluate_experiment(\n",
    "    name='E6-G4OMFT-EBFT-FT',\n",
    "    notes='Experiment 6: Evaluate deep model collaboration through fine-tuning GPT-4o-mini and Electra Base fine-tuned model',\n",
    "    lm='ft:gpt-4o-mini-2024-07-18:personal::ANVDva8W',\n",
    "    instance='electra_base_gpt_sentiment',\n",
    "    dataset=test_df,\n",
    "    examples=test_ex,\n",
    "    temperature=temperature,\n",
    "    random_seed=random_seed\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4314346f",
   "metadata": {},
   "source": [
    "### E25-G4OMFT-EBFT-FT5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "0f2edf08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch to the correct language model and disable experimental mode\n",
    "lm = dspy.OpenAI(model='ft:gpt-4o-mini-2024-07-18:personal::BBcWZNa3', api_key=openai_key, max_tokens=8192, temperature=temperature)\n",
    "dspy.settings.configure(lm=lm, experimental=False, seed=random_seed)\n",
    "dsp.settings.show_guidelines = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "dcbdb877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a test result for the ELECTRA Base GPT sentiment module\n",
    "e25_g4omft_ebft_ft5_result = electra_base_gpt_sentiment(review=test_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "c01ac999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    classification='negative',\n",
       "    classifier_decision='negative',\n",
       "    probabilities=[0.999830961227417, 0.00012046996562276036, 4.853002610616386e-05]\n",
       ")"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e25_g4omft_ebft_ft5_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "ca5a5866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Classify the sentiment of a review as either 'negative', 'neutral', or 'positive'.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Review: The review text to classify.\n",
      "Classifier Decision: The sentiment classification proposed by a model fine-tuned on sentiment.\n",
      "Classification: One word representing the sentiment classification: 'negative', 'neutral', or 'positive' (do not repeat the field name, do not use 'mixed')\n",
      "\n",
      "---\n",
      "\n",
      "Review: Those 2 drinks are part of the HK culture and has years of history. It is so bad.\n",
      "Classifier Decision: negative\n",
      "Classification:\u001b[32m negative\u001b[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\n\\nClassify the sentiment of a review as either 'negative', 'neutral', or 'positive'.\\n\\n---\\n\\nFollow the following format.\\n\\nReview: The review text to classify.\\nClassifier Decision: The sentiment classification proposed by a model fine-tuned on sentiment.\\nClassification: One word representing the sentiment classification: 'negative', 'neutral', or 'positive' (do not repeat the field name, do not use 'mixed')\\n\\n---\\n\\nReview: Those 2 drinks are part of the HK culture and has years of history. It is so bad.\\nClassifier Decision: negative\\nClassification:\\x1b[32m negative\\x1b[0m\\n\\n\\n\""
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "bf0edc4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Experiment: E25-G4OMFT-EBFT-FT5\n",
      "--------------------------------------------------------------------------------\n",
      "Start time: 2025-03-28 00:46:52\n",
      "Notes: Experiment 25: Evaluate deep model collaboration through fine-tuning GPT-4o-mini and Electra Base fine-tuned model, fine-tuned on 5 epochs\n",
      "Model: ft:gpt-4o-mini-2024-07-18:personal::BBcWZNa3\n",
      "Instance: electra_base_gpt_sentiment\n",
      "Dataset shape: [6530, 4]\n",
      "Examples length: 6530\n",
      "Save directory: results_round2_take2\n",
      "Temperature: 0.1\n",
      "Random seed: 123\n",
      "\n",
      "Running evaluation...\n",
      "Average Metric: 5478 / 6530  (83.9): 100%|██████████| 6530/6530 [57:50<00:00,  1.88it/s]   \n",
      "\n",
      "Columns in results DataFrame:\n",
      "review                 6530 values\n",
      "classification         6530 values\n",
      "prediction             6530 values\n",
      "match                  6530 values\n",
      "classifier_decision    6530 values\n",
      "probabilities          6530 values\n",
      "\n",
      "Source value counts:\n",
      "dynasent_r1            3600\n",
      "sst_local              2210\n",
      "dynasent_r2             720\n",
      "\n",
      "Prediction value counts:\n",
      "positive               2289\n",
      "negative               2205\n",
      "neutral                2036\n",
      "\n",
      "E25-G4OMFT-EBFT-FT5 Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.8921    0.8363    0.8633      2352\n",
      "     neutral     0.7200    0.8015    0.7586      1829\n",
      "    positive     0.8934    0.8706    0.8818      2349\n",
      "\n",
      "    accuracy                         0.8389      6530\n",
      "   macro avg     0.8352    0.8361    0.8346      6530\n",
      "weighted avg     0.8444    0.8389    0.8406      6530\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative       1967      323        62\n",
      "neutral         181     1466       182\n",
      "positive         57      247      2045\n",
      "\n",
      "\n",
      "E25-G4OMFT-EBFT-FT5-DYN-R1 Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.9428    0.8108    0.8719      1200\n",
      "     neutral     0.7592    0.9325    0.8369      1200\n",
      "    positive     0.9141    0.8333    0.8718      1200\n",
      "\n",
      "    accuracy                         0.8589      3600\n",
      "   macro avg     0.8720    0.8589    0.8602      3600\n",
      "weighted avg     0.8720    0.8589    0.8602      3600\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative        973      184        43\n",
      "neutral          30     1119        51\n",
      "positive         29      171      1000\n",
      "\n",
      "\n",
      "E25-G4OMFT-EBFT-FT5-DYN-R2 Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.8125    0.8667    0.8387       240\n",
      "     neutral     0.8019    0.6917    0.7427       240\n",
      "    positive     0.8132    0.8708    0.8410       240\n",
      "\n",
      "    accuracy                         0.8097       720\n",
      "   macro avg     0.8092    0.8097    0.8075       720\n",
      "weighted avg     0.8092    0.8097    0.8075       720\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative        208       25         7\n",
      "neutral          33      166        41\n",
      "positive         15       16       209\n",
      "\n",
      "\n",
      "E25-G4OMFT-EBFT-FT5-SST Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.8571    0.8618    0.8595       912\n",
      "     neutral     0.5099    0.4653    0.4866       389\n",
      "    positive     0.8913    0.9197    0.9053       909\n",
      "\n",
      "    accuracy                         0.8158      2210\n",
      "   macro avg     0.7528    0.7489    0.7504      2210\n",
      "weighted avg     0.8100    0.8158    0.8127      2210\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative        786      114        12\n",
      "neutral         118      181        90\n",
      "positive         13       60       836\n",
      "\n",
      "Saving results to 'results_round2_take2'...\n",
      "\n",
      "Summary Metrics:\n",
      "Dataset     \tF1 (macro)\tAccuracy\n",
      "---------------------------------------------\n",
      "Merged      \t    83.46\t   83.89\n",
      "DynaSent R1 \t    86.02\t   85.89\n",
      "DynaSent R2 \t    80.75\t   80.97\n",
      "SST-3       \t    75.04\t   81.58\n",
      "\n",
      "Evaluation completed\n",
      "End time: 2025-03-28 01:44:44\n",
      "Duration: 0:57:51.270583\n"
     ]
    }
   ],
   "source": [
    "e25_g4omft_ebft_ft5_results_df, e25_g4omft_ebft_ft5_metrics = evaluate_experiment(\n",
    "    name='E25-G4OMFT-EBFT-FT5',\n",
    "    notes='Experiment 25: Evaluate deep model collaboration through fine-tuning GPT-4o-mini and Electra Base fine-tuned model, fine-tuned on 5 epochs',\n",
    "    lm='ft:gpt-4o-mini-2024-07-18:personal::BBcWZNa3',\n",
    "    instance='electra_base_gpt_sentiment',\n",
    "    dataset=test_df,\n",
    "    examples=test_ex,\n",
    "    temperature=temperature,\n",
    "    random_seed=random_seed\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45a1fad",
   "metadata": {},
   "source": [
    "### E26-G4OMFT-ELFT-FT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7d2bdf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch to the correct language model and disable experimental mode\n",
    "lm = dspy.OpenAI(model='ft:gpt-4o-mini-2024-07-18:personal::BBq9HSob', api_key=openai_key, max_tokens=8192, temperature=temperature)\n",
    "dspy.settings.configure(lm=lm, experimental=False, seed=random_seed)\n",
    "dsp.settings.show_guidelines = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b5fcfd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a test result for the ELECTRA Base GPT sentiment module\n",
    "e26_g4omft_elft_ft_result = electra_large_gpt_sentiment(review=test_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "74f2be3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    classification='negative',\n",
       "    classifier_decision='negative',\n",
       "    probabilities=[0.9990077614784241, 0.0005539217963814735, 0.000438391842180863]\n",
       ")"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e26_g4omft_elft_ft_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a8ea44ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Classify the sentiment of a review as either 'negative', 'neutral', or 'positive'.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Review: The review text to classify.\n",
      "Classifier Decision: The sentiment classification proposed by a model fine-tuned on sentiment.\n",
      "Classification: One word representing the sentiment classification: 'negative', 'neutral', or 'positive' (do not repeat the field name, do not use 'mixed')\n",
      "\n",
      "---\n",
      "\n",
      "Review: Those 2 drinks are part of the HK culture and has years of history. It is so bad.\n",
      "Classifier Decision: negative\n",
      "Classification:\u001b[32m negative\u001b[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\n\\nClassify the sentiment of a review as either 'negative', 'neutral', or 'positive'.\\n\\n---\\n\\nFollow the following format.\\n\\nReview: The review text to classify.\\nClassifier Decision: The sentiment classification proposed by a model fine-tuned on sentiment.\\nClassification: One word representing the sentiment classification: 'negative', 'neutral', or 'positive' (do not repeat the field name, do not use 'mixed')\\n\\n---\\n\\nReview: Those 2 drinks are part of the HK culture and has years of history. It is so bad.\\nClassifier Decision: negative\\nClassification:\\x1b[32m negative\\x1b[0m\\n\\n\\n\""
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e647ded9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Experiment: E26-G4OMFT-ELFT-FT\n",
      "--------------------------------------------------------------------------------\n",
      "Start time: 2025-03-26 03:22:38\n",
      "Notes: Experiment 26: Evaluate deep model collaboration through fine-tuning GPT-4o-mini and Electra Large fine-tuned model, including Large predictions in FT prompt\n",
      "Model: ft:gpt-4o-mini-2024-07-18:personal::BBq9HSob\n",
      "Instance: electra_large_gpt_sentiment\n",
      "Dataset shape: [6530, 4]\n",
      "Examples length: 6530\n",
      "Save directory: results_round2_take2\n",
      "Temperature: 0.1\n",
      "Random seed: 123\n",
      "\n",
      "Running evaluation...\n",
      "Average Metric: 5524 / 6530  (84.6): 100%|██████████| 6530/6530 [1:01:44<00:00,  1.76it/s]\n",
      "\n",
      "Columns in results DataFrame:\n",
      "review                 6530 values\n",
      "classification         6530 values\n",
      "prediction             6530 values\n",
      "match                  6530 values\n",
      "classifier_decision    6530 values\n",
      "probabilities          6530 values\n",
      "\n",
      "Source value counts:\n",
      "dynasent_r1            3600\n",
      "sst_local              2210\n",
      "dynasent_r2             720\n",
      "\n",
      "Prediction value counts:\n",
      "positive               2329\n",
      "negative               2281\n",
      "neutral                1920\n",
      "\n",
      "E26-G4OMFT-ELFT-FT Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.8865    0.8597    0.8729      2352\n",
      "     neutral     0.7469    0.7840    0.7650      1829\n",
      "    positive     0.8879    0.8804    0.8841      2349\n",
      "\n",
      "    accuracy                         0.8459      6530\n",
      "   macro avg     0.8404    0.8414    0.8407      6530\n",
      "weighted avg     0.8479    0.8459    0.8467      6530\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative       2022      257        73\n",
      "neutral         207     1434       188\n",
      "positive         52      229      2068\n",
      "\n",
      "\n",
      "E26-G4OMFT-ELFT-FT-DYN-R1 Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.9364    0.8467    0.8893      1200\n",
      "     neutral     0.7900    0.9308    0.8546      1200\n",
      "    positive     0.9210    0.8450    0.8814      1200\n",
      "\n",
      "    accuracy                         0.8742      3600\n",
      "   macro avg     0.8824    0.8742    0.8751      3600\n",
      "weighted avg     0.8824    0.8742    0.8751      3600\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative       1016      146        38\n",
      "neutral          34     1117        49\n",
      "positive         35      151      1014\n",
      "\n",
      "\n",
      "E26-G4OMFT-ELFT-FT-DYN-R2 Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.8157    0.8667    0.8404       240\n",
      "     neutral     0.8291    0.6875    0.7517       240\n",
      "    positive     0.7857    0.8708    0.8261       240\n",
      "\n",
      "    accuracy                         0.8083       720\n",
      "   macro avg     0.8102    0.8083    0.8061       720\n",
      "weighted avg     0.8102    0.8083    0.8061       720\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative        208       13        19\n",
      "neutral          37      165        38\n",
      "positive         10       21       209\n",
      "\n",
      "\n",
      "E26-G4OMFT-ELFT-FT-SST Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.8480    0.8750    0.8613       912\n",
      "     neutral     0.4951    0.3907    0.4368       389\n",
      "    positive     0.8784    0.9296    0.9033       909\n",
      "\n",
      "    accuracy                         0.8122      2210\n",
      "   macro avg     0.7405    0.7318    0.7338      2210\n",
      "weighted avg     0.7984    0.8122    0.8038      2210\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative        798       98        16\n",
      "neutral         136      152       101\n",
      "positive          7       57       845\n",
      "\n",
      "Saving results to 'results_round2_take2'...\n",
      "\n",
      "Summary Metrics:\n",
      "Dataset     \tF1 (macro)\tAccuracy\n",
      "---------------------------------------------\n",
      "Merged      \t    84.07\t   84.59\n",
      "DynaSent R1 \t    87.51\t   87.42\n",
      "DynaSent R2 \t    80.61\t   80.83\n",
      "SST-3       \t    73.38\t   81.22\n",
      "\n",
      "Evaluation completed\n",
      "End time: 2025-03-26 04:24:23\n",
      "Duration: 1:01:44.826318\n"
     ]
    }
   ],
   "source": [
    "e26_g4omft_elft_ft_results_df, e26_g4omft_elft_ft_metrics = evaluate_experiment(\n",
    "    name='E26-G4OMFT-ELFT-FT',\n",
    "    notes='Experiment 26: Evaluate deep model collaboration through fine-tuning GPT-4o-mini and Electra Large fine-tuned model, including Large predictions in FT prompt',\n",
    "    lm='ft:gpt-4o-mini-2024-07-18:personal::BBq9HSob',\n",
    "    instance='electra_large_gpt_sentiment',\n",
    "    dataset=test_df,\n",
    "    examples=test_ex,\n",
    "    temperature=temperature,\n",
    "    random_seed=random_seed\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcef122b",
   "metadata": {},
   "source": [
    "### E27-G4OMFT-ELFT-FT5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e96f8ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch to the correct language model and disable experimental mode\n",
    "lm = dspy.OpenAI(model='ft:gpt-4o-mini-2024-07-18:personal:5-epochs:BBxo6eOL', api_key=openai_key, max_tokens=8192, temperature=temperature)\n",
    "dspy.settings.configure(lm=lm, experimental=False, seed=random_seed)\n",
    "dsp.settings.show_guidelines = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b3f950ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a test result for the ELECTRA Base GPT sentiment module\n",
    "e27_g4omft_elft_ft5_result = electra_large_gpt_sentiment(review=test_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "95b33a98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    classification='negative',\n",
       "    classifier_decision='negative',\n",
       "    probabilities=[0.9990077614784241, 0.0005539217963814735, 0.000438391842180863]\n",
       ")"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e27_g4omft_elft_ft5_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9621633f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Classify the sentiment of a review as either 'negative', 'neutral', or 'positive'.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Review: The review text to classify.\n",
      "Classifier Decision: The sentiment classification proposed by a model fine-tuned on sentiment.\n",
      "Classification: One word representing the sentiment classification: 'negative', 'neutral', or 'positive' (do not repeat the field name, do not use 'mixed')\n",
      "\n",
      "---\n",
      "\n",
      "Review: Those 2 drinks are part of the HK culture and has years of history. It is so bad.\n",
      "Classifier Decision: negative\n",
      "Classification:\u001b[32m negative\u001b[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\n\\nClassify the sentiment of a review as either 'negative', 'neutral', or 'positive'.\\n\\n---\\n\\nFollow the following format.\\n\\nReview: The review text to classify.\\nClassifier Decision: The sentiment classification proposed by a model fine-tuned on sentiment.\\nClassification: One word representing the sentiment classification: 'negative', 'neutral', or 'positive' (do not repeat the field name, do not use 'mixed')\\n\\n---\\n\\nReview: Those 2 drinks are part of the HK culture and has years of history. It is so bad.\\nClassifier Decision: negative\\nClassification:\\x1b[32m negative\\x1b[0m\\n\\n\\n\""
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4812e663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Experiment: E27-G4OMFT-ELFT-FT5\n",
      "--------------------------------------------------------------------------------\n",
      "Start time: 2025-03-26 04:27:51\n",
      "Notes: Experiment 27: Evaluate deep model collaboration through fine-tuning GPT-4o-mini and Electra Large fine-tuned model, including Large predictions in FT prompt, 5 epochs\n",
      "Model: ft:gpt-4o-mini-2024-07-18:personal:5-epochs:BBxo6eOL\n",
      "Instance: electra_large_gpt_sentiment\n",
      "Dataset shape: [6530, 4]\n",
      "Examples length: 6530\n",
      "Save directory: results_round2_take2\n",
      "Temperature: 0.1\n",
      "Random seed: 123\n",
      "\n",
      "Running evaluation...\n",
      "Average Metric: 5560 / 6530  (85.1): 100%|██████████| 6530/6530 [1:03:27<00:00,  1.72it/s]\n",
      "\n",
      "Columns in results DataFrame:\n",
      "review                 6530 values\n",
      "classification         6530 values\n",
      "prediction             6530 values\n",
      "match                  6530 values\n",
      "classifier_decision    6530 values\n",
      "probabilities          6530 values\n",
      "\n",
      "Source value counts:\n",
      "dynasent_r1            3600\n",
      "sst_local              2210\n",
      "dynasent_r2             720\n",
      "\n",
      "Prediction value counts:\n",
      "negative               2224\n",
      "positive               2219\n",
      "neutral                2087\n",
      "\n",
      "E27-G4OMFT-ELFT-FT5 Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.9033    0.8542    0.8781      2352\n",
      "     neutral     0.7288    0.8316    0.7768      1829\n",
      "    positive     0.9148    0.8642    0.8888      2349\n",
      "\n",
      "    accuracy                         0.8515      6530\n",
      "   macro avg     0.8490    0.8500    0.8479      6530\n",
      "weighted avg     0.8586    0.8515    0.8536      6530\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative       2009      296        47\n",
      "neutral         166     1521       142\n",
      "positive         49      270      2030\n",
      "\n",
      "\n",
      "E27-G4OMFT-ELFT-FT5-DYN-R1 Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.9432    0.8433    0.8905      1200\n",
      "     neutral     0.7769    0.9433    0.8521      1200\n",
      "    positive     0.9402    0.8383    0.8863      1200\n",
      "\n",
      "    accuracy                         0.8750      3600\n",
      "   macro avg     0.8868    0.8750    0.8763      3600\n",
      "weighted avg     0.8868    0.8750    0.8763      3600\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative       1012      163        25\n",
      "neutral          29     1132        39\n",
      "positive         32      162      1006\n",
      "\n",
      "\n",
      "E27-G4OMFT-ELFT-FT5-DYN-R2 Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.8623    0.8875    0.8747       240\n",
      "     neutral     0.8468    0.7833    0.8139       240\n",
      "    positive     0.8406    0.8792    0.8595       240\n",
      "\n",
      "    accuracy                         0.8500       720\n",
      "   macro avg     0.8499    0.8500    0.8494       720\n",
      "weighted avg     0.8499    0.8500    0.8494       720\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative        213       16        11\n",
      "neutral          23      188        29\n",
      "positive         11       18       211\n",
      "\n",
      "\n",
      "E27-G4OMFT-ELFT-FT5-SST Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.8673    0.8596    0.8634       912\n",
      "     neutral     0.4926    0.5167    0.5044       389\n",
      "    positive     0.9053    0.8944    0.8998       909\n",
      "\n",
      "    accuracy                         0.8136      2210\n",
      "   macro avg     0.7551    0.7569    0.7559      2210\n",
      "weighted avg     0.8170    0.8136    0.8152      2210\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative        784      117        11\n",
      "neutral         114      201        74\n",
      "positive          6       90       813\n",
      "\n",
      "Saving results to 'results_round2_take2'...\n",
      "\n",
      "Summary Metrics:\n",
      "Dataset     \tF1 (macro)\tAccuracy\n",
      "---------------------------------------------\n",
      "Merged      \t    84.79\t   85.15\n",
      "DynaSent R1 \t    87.63\t   87.50\n",
      "DynaSent R2 \t    84.94\t   85.00\n",
      "SST-3       \t    75.59\t   81.36\n",
      "\n",
      "Evaluation completed\n",
      "End time: 2025-03-26 05:31:19\n",
      "Duration: 1:03:28.067702\n"
     ]
    }
   ],
   "source": [
    "e27_g4omft_elft_ft5_results_df, e27_g4omft_elft_ft5_metrics = evaluate_experiment(\n",
    "    name='E27-G4OMFT-ELFT-FT5',\n",
    "    notes='Experiment 27: Evaluate deep model collaboration through fine-tuning GPT-4o-mini and Electra Large fine-tuned model, including Large predictions in FT prompt, 5 epochs',\n",
    "    lm='ft:gpt-4o-mini-2024-07-18:personal:5-epochs:BBxo6eOL',\n",
    "    instance='electra_large_gpt_sentiment',\n",
    "    dataset=test_df,\n",
    "    examples=test_ex,\n",
    "    temperature=temperature,\n",
    "    random_seed=random_seed\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25abce24",
   "metadata": {},
   "source": [
    "### E28-G4OMFT-ELFT-P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "16b3c951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch to the correct language model and disable experimental mode\n",
    "lm = dspy.OpenAI(model='ft:gpt-4o-mini-2024-07-18:personal::AN2RNUvd', api_key=openai_key, max_tokens=8192, temperature=temperature)\n",
    "dspy.settings.configure(lm=lm, experimental=False, seed=random_seed)\n",
    "dsp.settings.show_guidelines = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8b095d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a test result for the ELECTRA Base GPT sentiment module\n",
    "e28_g4omft_elft_p_result = electra_large_gpt_sentiment(review=test_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b581388f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    classification='negative',\n",
       "    classifier_decision='negative',\n",
       "    probabilities=[0.9990077614784241, 0.0005539217963814735, 0.000438391842180863]\n",
       ")"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e28_g4omft_elft_p_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6d3108cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Classify the sentiment of a review as either 'negative', 'neutral', or 'positive'.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Review: The review text to classify.\n",
      "Classifier Decision: The sentiment classification proposed by a model fine-tuned on sentiment.\n",
      "Classification: One word representing the sentiment classification: 'negative', 'neutral', or 'positive' (do not repeat the field name, do not use 'mixed')\n",
      "\n",
      "---\n",
      "\n",
      "Review: Those 2 drinks are part of the HK culture and has years of history. It is so bad.\n",
      "Classifier Decision: negative\n",
      "Classification:\u001b[32m negative\u001b[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\n\\nClassify the sentiment of a review as either 'negative', 'neutral', or 'positive'.\\n\\n---\\n\\nFollow the following format.\\n\\nReview: The review text to classify.\\nClassifier Decision: The sentiment classification proposed by a model fine-tuned on sentiment.\\nClassification: One word representing the sentiment classification: 'negative', 'neutral', or 'positive' (do not repeat the field name, do not use 'mixed')\\n\\n---\\n\\nReview: Those 2 drinks are part of the HK culture and has years of history. It is so bad.\\nClassifier Decision: negative\\nClassification:\\x1b[32m negative\\x1b[0m\\n\\n\\n\""
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a362784e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Experiment: E28-G4OMFT-ELFT-P\n",
      "--------------------------------------------------------------------------------\n",
      "Start time: 2025-03-26 05:44:21\n",
      "Notes: Experiment 28: Evaluate combined impact of fine-tuning and prompt collaboration between GPT-4o-mini and Electra Large fine-tuned model\n",
      "Model: ft:gpt-4o-mini-2024-07-18:personal::AN2RNUvd\n",
      "Instance: electra_large_gpt_sentiment\n",
      "Dataset shape: [6530, 4]\n",
      "Examples length: 6530\n",
      "Save directory: results_round2_take2\n",
      "Temperature: 0.1\n",
      "Random seed: 123\n",
      "\n",
      "Running evaluation...\n",
      "Average Metric: 2208 / 2618  (84.3):  40%|████      | 2618/6530 [25:18<1:19:12,  1.21s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:opentelemetry.exporter.otlp.proto.http.trace_exporter:Transient error Service Unavailable encountered while exporting span batch, retrying in 1s.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2208 / 2618  (84.3):  40%|████      | 2618/6530 [25:19<1:19:12,  1.21s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:opentelemetry.exporter.otlp.proto.http.trace_exporter:Transient error Service Unavailable encountered while exporting span batch, retrying in 2s.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2208 / 2618  (84.3):  40%|████      | 2618/6530 [25:26<1:19:12,  1.21s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:opentelemetry.exporter.otlp.proto.http.trace_exporter:Transient error Service Unavailable encountered while exporting span batch, retrying in 4s.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2208 / 2618  (84.3):  40%|████      | 2618/6530 [25:30<1:19:12,  1.21s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:opentelemetry.exporter.otlp.proto.http.trace_exporter:Transient error Service Unavailable encountered while exporting span batch, retrying in 8s.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2208 / 2618  (84.3):  40%|████      | 2618/6530 [25:48<1:19:12,  1.21s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2208 / 2618  (84.3):  40%|████      | 2618/6530 [25:59<1:19:12,  1.21s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2209 / 2619  (84.3):  40%|████      | 2619/6530 [26:09<14:20:21, 13.20s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2209 / 2619  (84.3):  40%|████      | 2619/6530 [26:19<14:20:21, 13.20s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2209 / 2619  (84.3):  40%|████      | 2619/6530 [26:29<14:20:21, 13.20s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2210 / 2620  (84.4):  40%|████      | 2620/6530 [26:39<19:57:54, 18.38s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2210 / 2620  (84.4):  40%|████      | 2620/6530 [26:49<19:57:54, 18.38s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2210 / 2620  (84.4):  40%|████      | 2620/6530 [27:00<19:57:54, 18.38s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2211 / 2621  (84.4):  40%|████      | 2621/6530 [27:10<23:54:25, 22.02s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2211 / 2621  (84.4):  40%|████      | 2621/6530 [27:20<23:54:25, 22.02s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2211 / 2621  (84.4):  40%|████      | 2621/6530 [27:30<23:54:25, 22.02s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2212 / 2622  (84.4):  40%|████      | 2622/6530 [27:40<26:39:14, 24.55s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2212 / 2622  (84.4):  40%|████      | 2622/6530 [27:50<26:39:14, 24.55s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2212 / 2622  (84.4):  40%|████      | 2622/6530 [28:01<26:39:14, 24.55s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2213 / 2623  (84.4):  40%|████      | 2623/6530 [28:11<28:34:49, 26.33s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2213 / 2623  (84.4):  40%|████      | 2623/6530 [28:21<28:34:49, 26.33s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2213 / 2623  (84.4):  40%|████      | 2623/6530 [28:31<28:34:49, 26.33s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2213 / 2624  (84.3):  40%|████      | 2624/6530 [28:41<29:55:25, 27.58s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2213 / 2624  (84.3):  40%|████      | 2624/6530 [28:51<29:55:25, 27.58s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2213 / 2624  (84.3):  40%|████      | 2624/6530 [29:02<29:55:25, 27.58s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2213 / 2625  (84.3):  40%|████      | 2625/6530 [29:12<30:51:43, 28.45s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2213 / 2625  (84.3):  40%|████      | 2625/6530 [29:22<30:51:43, 28.45s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2213 / 2625  (84.3):  40%|████      | 2625/6530 [29:32<30:51:43, 28.45s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2213 / 2626  (84.3):  40%|████      | 2626/6530 [29:42<31:30:44, 29.06s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2213 / 2626  (84.3):  40%|████      | 2626/6530 [29:52<31:30:44, 29.06s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2213 / 2626  (84.3):  40%|████      | 2626/6530 [30:03<31:30:44, 29.06s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2214 / 2627  (84.3):  40%|████      | 2627/6530 [30:13<31:58:15, 29.49s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2214 / 2627  (84.3):  40%|████      | 2627/6530 [30:23<31:58:15, 29.49s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2214 / 2627  (84.3):  40%|████      | 2627/6530 [30:33<31:58:15, 29.49s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2215 / 2628  (84.3):  40%|████      | 2628/6530 [30:43<32:17:21, 29.79s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2215 / 2628  (84.3):  40%|████      | 2628/6530 [30:53<32:17:21, 29.79s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2215 / 2628  (84.3):  40%|████      | 2628/6530 [31:04<32:17:21, 29.79s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2215 / 2629  (84.3):  40%|████      | 2629/6530 [31:14<32:31:27, 30.01s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2215 / 2629  (84.3):  40%|████      | 2629/6530 [31:24<32:31:27, 30.01s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2215 / 2629  (84.3):  40%|████      | 2629/6530 [31:34<32:31:27, 30.01s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2216 / 2630  (84.3):  40%|████      | 2630/6530 [31:45<32:40:25, 30.16s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2216 / 2630  (84.3):  40%|████      | 2630/6530 [31:55<32:40:25, 30.16s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2216 / 2630  (84.3):  40%|████      | 2630/6530 [32:06<32:40:25, 30.16s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2217 / 2631  (84.3):  40%|████      | 2631/6530 [32:16<33:02:51, 30.51s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2217 / 2631  (84.3):  40%|████      | 2631/6530 [32:26<33:02:51, 30.51s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2217 / 2631  (84.3):  40%|████      | 2631/6530 [32:36<33:02:51, 30.51s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2218 / 2632  (84.3):  40%|████      | 2632/6530 [32:46<33:01:49, 30.51s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2218 / 2632  (84.3):  40%|████      | 2632/6530 [32:56<33:01:49, 30.51s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2218 / 2632  (84.3):  40%|████      | 2632/6530 [33:06<33:01:49, 30.51s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2219 / 2633  (84.3):  40%|████      | 2633/6530 [33:17<33:01:24, 30.51s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2219 / 2633  (84.3):  40%|████      | 2633/6530 [33:27<33:01:24, 30.51s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2219 / 2633  (84.3):  40%|████      | 2633/6530 [33:37<33:01:24, 30.51s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2220 / 2634  (84.3):  40%|████      | 2634/6530 [33:47<32:59:51, 30.49s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2220 / 2634  (84.3):  40%|████      | 2634/6530 [33:57<32:59:51, 30.49s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2220 / 2634  (84.3):  40%|████      | 2634/6530 [34:07<32:59:51, 30.49s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2221 / 2635  (84.3):  40%|████      | 2635/6530 [34:18<32:59:17, 30.49s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2221 / 2635  (84.3):  40%|████      | 2635/6530 [34:28<32:59:17, 30.49s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2221 / 2635  (84.3):  40%|████      | 2635/6530 [34:38<32:59:17, 30.49s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2222 / 2636  (84.3):  40%|████      | 2636/6530 [34:48<32:58:31, 30.49s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2222 / 2636  (84.3):  40%|████      | 2636/6530 [34:58<32:58:31, 30.49s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2222 / 2636  (84.3):  40%|████      | 2636/6530 [35:08<32:58:31, 30.49s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2223 / 2637  (84.3):  40%|████      | 2637/6530 [35:19<32:58:26, 30.49s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2223 / 2637  (84.3):  40%|████      | 2637/6530 [35:29<32:58:26, 30.49s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2223 / 2637  (84.3):  40%|████      | 2637/6530 [35:39<32:58:26, 30.49s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2224 / 2638  (84.3):  40%|████      | 2638/6530 [35:49<32:57:29, 30.49s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2224 / 2638  (84.3):  40%|████      | 2638/6530 [35:59<32:57:29, 30.49s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2224 / 2638  (84.3):  40%|████      | 2638/6530 [36:09<32:57:29, 30.49s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2225 / 2639  (84.3):  40%|████      | 2639/6530 [36:20<32:58:15, 30.51s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2225 / 2639  (84.3):  40%|████      | 2639/6530 [36:30<32:58:15, 30.51s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2225 / 2639  (84.3):  40%|████      | 2639/6530 [36:40<32:58:15, 30.51s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2226 / 2640  (84.3):  40%|████      | 2640/6530 [36:50<32:57:17, 30.50s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2226 / 2640  (84.3):  40%|████      | 2640/6530 [37:00<32:57:17, 30.50s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2226 / 2640  (84.3):  40%|████      | 2640/6530 [37:10<32:57:17, 30.50s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2226 / 2641  (84.3):  40%|████      | 2641/6530 [37:21<32:56:09, 30.49s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2226 / 2641  (84.3):  40%|████      | 2641/6530 [37:31<32:56:09, 30.49s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2226 / 2641  (84.3):  40%|████      | 2641/6530 [37:41<32:56:09, 30.49s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2227 / 2642  (84.3):  40%|████      | 2642/6530 [37:51<32:55:43, 30.49s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2227 / 2642  (84.3):  40%|████      | 2642/6530 [38:01<32:55:43, 30.49s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2227 / 2642  (84.3):  40%|████      | 2642/6530 [38:11<32:55:43, 30.49s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2228 / 2643  (84.3):  40%|████      | 2643/6530 [38:22<32:55:08, 30.49s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2228 / 2643  (84.3):  40%|████      | 2643/6530 [38:32<32:55:08, 30.49s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2228 / 2643  (84.3):  40%|████      | 2643/6530 [38:42<32:55:08, 30.49s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2229 / 2644  (84.3):  40%|████      | 2644/6530 [38:52<32:54:55, 30.49s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2229 / 2644  (84.3):  40%|████      | 2644/6530 [39:02<32:54:55, 30.49s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2229 / 2644  (84.3):  40%|████      | 2644/6530 [39:12<32:54:55, 30.49s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2229 / 2645  (84.3):  41%|████      | 2645/6530 [39:22<32:53:45, 30.48s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2229 / 2645  (84.3):  41%|████      | 2645/6530 [39:33<32:53:45, 30.48s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2229 / 2645  (84.3):  41%|████      | 2645/6530 [39:43<32:53:45, 30.48s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2230 / 2646  (84.3):  41%|████      | 2646/6530 [39:53<32:53:08, 30.48s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2230 / 2646  (84.3):  41%|████      | 2646/6530 [40:03<32:53:08, 30.48s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2230 / 2646  (84.3):  41%|████      | 2646/6530 [40:13<32:53:08, 30.48s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2231 / 2647  (84.3):  41%|████      | 2647/6530 [40:23<32:52:19, 30.48s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2231 / 2647  (84.3):  41%|████      | 2647/6530 [40:33<32:52:19, 30.48s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2231 / 2647  (84.3):  41%|████      | 2647/6530 [40:44<32:52:19, 30.48s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2232 / 2648  (84.3):  41%|████      | 2648/6530 [40:54<32:51:48, 30.48s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2232 / 2648  (84.3):  41%|████      | 2648/6530 [41:04<32:51:48, 30.48s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2232 / 2648  (84.3):  41%|████      | 2648/6530 [41:14<32:51:48, 30.48s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2233 / 2649  (84.3):  41%|████      | 2649/6530 [41:24<32:52:26, 30.49s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2233 / 2649  (84.3):  41%|████      | 2649/6530 [41:34<32:52:26, 30.49s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2233 / 2649  (84.3):  41%|████      | 2649/6530 [41:45<32:52:26, 30.49s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2234 / 2650  (84.3):  41%|████      | 2650/6530 [41:55<32:52:02, 30.50s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2234 / 2650  (84.3):  41%|████      | 2650/6530 [42:05<32:52:02, 30.50s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2234 / 2650  (84.3):  41%|████      | 2650/6530 [42:15<32:52:02, 30.50s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2235 / 2651  (84.3):  41%|████      | 2651/6530 [42:25<32:51:17, 30.49s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2235 / 2651  (84.3):  41%|████      | 2651/6530 [42:35<32:51:17, 30.49s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 3364 / 3990  (84.3):  61%|██████    | 3990/6530 [55:33<23:18,  1.82it/s]   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:opentelemetry.exporter.otlp.proto.http.trace_exporter:Transient error Bad Gateway encountered while exporting span batch, retrying in 1s.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 3364 / 3991  (84.3):  61%|██████    | 3991/6530 [55:44<38:17,  1.10it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:opentelemetry.exporter.otlp.proto.http.trace_exporter:Transient error Bad Gateway encountered while exporting span batch, retrying in 1s.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 5514 / 6530  (84.4): 100%|██████████| 6530/6530 [1:20:20<00:00,  1.35it/s]  \n",
      "\n",
      "Columns in results DataFrame:\n",
      "review                 6530 values\n",
      "classification         6530 values\n",
      "prediction             6530 values\n",
      "match                  6530 values\n",
      "classifier_decision    6530 values\n",
      "probabilities          6530 values\n",
      "\n",
      "Source value counts:\n",
      "dynasent_r1            3600\n",
      "sst_local              2210\n",
      "dynasent_r2             720\n",
      "\n",
      "Prediction value counts:\n",
      "positive               2353\n",
      "negative               2324\n",
      "neutral                1853\n",
      "\n",
      "E28-G4OMFT-ELFT-P Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.8752    0.8648    0.8700      2352\n",
      "     neutral     0.7593    0.7693    0.7643      1829\n",
      "    positive     0.8810    0.8825    0.8818      2349\n",
      "\n",
      "    accuracy                         0.8444      6530\n",
      "   macro avg     0.8385    0.8389    0.8387      6530\n",
      "weighted avg     0.8448    0.8444    0.8446      6530\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative       2034      234        84\n",
      "neutral         226     1407       196\n",
      "positive         64      212      2073\n",
      "\n",
      "\n",
      "E28-G4OMFT-ELFT-P-DYN-R1 Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.9282    0.8508    0.8878      1200\n",
      "     neutral     0.7986    0.9250    0.8571      1200\n",
      "    positive     0.9153    0.8467    0.8797      1200\n",
      "\n",
      "    accuracy                         0.8742      3600\n",
      "   macro avg     0.8807    0.8742    0.8749      3600\n",
      "weighted avg     0.8807    0.8742    0.8749      3600\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative       1021      136        43\n",
      "neutral          39     1110        51\n",
      "positive         40      144      1016\n",
      "\n",
      "\n",
      "E28-G4OMFT-ELFT-P-DYN-R2 Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.7985    0.8750    0.8350       240\n",
      "     neutral     0.8413    0.6625    0.7413       240\n",
      "    positive     0.7799    0.8708    0.8228       240\n",
      "\n",
      "    accuracy                         0.8028       720\n",
      "   macro avg     0.8065    0.8028    0.7997       720\n",
      "weighted avg     0.8065    0.8028    0.7997       720\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative        210       12        18\n",
      "neutral          40      159        41\n",
      "positive         13       18       209\n",
      "\n",
      "\n",
      "E28-G4OMFT-ELFT-P-SST Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.8356    0.8805    0.8574       912\n",
      "     neutral     0.5036    0.3548    0.4163       389\n",
      "    positive     0.8697    0.9329    0.9002       909\n",
      "\n",
      "    accuracy                         0.8095      2210\n",
      "   macro avg     0.7363    0.7227    0.7246      2210\n",
      "weighted avg     0.7912    0.8095    0.7974      2210\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative        803       86        23\n",
      "neutral         147      138       104\n",
      "positive         11       50       848\n",
      "\n",
      "Saving results to 'results_round2_take2'...\n",
      "\n",
      "Summary Metrics:\n",
      "Dataset     \tF1 (macro)\tAccuracy\n",
      "---------------------------------------------\n",
      "Merged      \t    83.87\t   84.44\n",
      "DynaSent R1 \t    87.49\t   87.42\n",
      "DynaSent R2 \t    79.97\t   80.28\n",
      "SST-3       \t    72.46\t   80.95\n",
      "\n",
      "Evaluation completed\n",
      "End time: 2025-03-26 07:04:42\n",
      "Duration: 1:20:20.657885\n"
     ]
    }
   ],
   "source": [
    "e28_g4omft_elft_p_results_df, e28_g4omft_elft_p_metrics = evaluate_experiment(\n",
    "    name='E28-G4OMFT-ELFT-P',\n",
    "    notes='Experiment 28: Evaluate combined impact of fine-tuning and prompt collaboration between GPT-4o-mini and Electra Large fine-tuned model',\n",
    "    lm='ft:gpt-4o-mini-2024-07-18:personal::AN2RNUvd',\n",
    "    instance='electra_large_gpt_sentiment',\n",
    "    dataset=test_df,\n",
    "    examples=test_ex,\n",
    "    temperature=temperature,\n",
    "    random_seed=random_seed\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2138a1e3",
   "metadata": {},
   "source": [
    "### E29-G4OMFT5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "63871296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch to the correct language model and disable experimental mode\n",
    "lm = dspy.OpenAI(model='ft:gpt-4o-mini-2024-07-18:personal:5-epochs:BCEIp15y', api_key=openai_key, max_tokens=8192, temperature=temperature)\n",
    "dspy.settings.configure(lm=lm, experimental=False, seed=random_seed)\n",
    "dsp.settings.show_guidelines = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "e35153ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a test result for the GPT sentiment module\n",
    "e29_g4omft5_result = gpt_sentiment(review=test_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "2d704247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    classification='negative'\n",
       ")"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e29_g4omft5_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "4f621dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Classify the sentiment of a review as either 'negative', 'neutral', or 'positive'.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Review: The review text to classify.\n",
      "Classification: One word representing the sentiment classification: 'negative', 'neutral', or 'positive' (do not repeat the field name, do not use 'mixed')\n",
      "\n",
      "---\n",
      "\n",
      "Review: Those 2 drinks are part of the HK culture and has years of history. It is so bad.\n",
      "Classification:\u001b[32m negative\u001b[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\n\\nClassify the sentiment of a review as either 'negative', 'neutral', or 'positive'.\\n\\n---\\n\\nFollow the following format.\\n\\nReview: The review text to classify.\\nClassification: One word representing the sentiment classification: 'negative', 'neutral', or 'positive' (do not repeat the field name, do not use 'mixed')\\n\\n---\\n\\nReview: Those 2 drinks are part of the HK culture and has years of history. It is so bad.\\nClassification:\\x1b[32m negative\\x1b[0m\\n\\n\\n\""
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "c4580403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Experiment: E29-G4OMFT5\n",
      "--------------------------------------------------------------------------------\n",
      "Start time: 2025-03-18 00:33:43\n",
      "Notes: Experiment 29: Measure impact of fine-tuning on GPT-4o-mini, 5 epochs\n",
      "Model: ft:gpt-4o-mini-2024-07-18:personal:5-epochs:BCEIp15y\n",
      "Instance: gpt_sentiment\n",
      "Dataset shape: [6530, 4]\n",
      "Examples length: 6530\n",
      "Save directory: results_round2\n",
      "Temperature: 0.1\n",
      "Random seed: 123\n",
      "\n",
      "Running evaluation...\n",
      "Average Metric: 5555 / 6530  (85.1): 100%|██████████| 6530/6530 [1:52:00<00:00,  1.03s/it]  \n",
      "\n",
      "Columns in results DataFrame:\n",
      "review                 6530 values\n",
      "classification         6530 values\n",
      "prediction             6530 values\n",
      "match                  6530 values\n",
      "\n",
      "Source value counts:\n",
      "dynasent_r1            3600\n",
      "sst_local              2210\n",
      "dynasent_r2             720\n",
      "\n",
      "Prediction value counts:\n",
      "positive               2200\n",
      "neutral                2170\n",
      "negative               2160\n",
      "\n",
      "E29-G4OMFT5 Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.9162    0.8414    0.8772      2352\n",
      "     neutral     0.7120    0.8447    0.7727      1829\n",
      "    positive     0.9232    0.8646    0.8929      2349\n",
      "\n",
      "    accuracy                         0.8507      6530\n",
      "   macro avg     0.8505    0.8503    0.8476      6530\n",
      "weighted avg     0.8615    0.8507    0.8536      6530\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative       1979      341        32\n",
      "neutral         147     1545       137\n",
      "positive         34      284      2031\n",
      "\n",
      "\n",
      "E29-G4OMFT5-DYN-R1 Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.9524    0.8342    0.8894      1200\n",
      "     neutral     0.7651    0.9525    0.8486      1200\n",
      "    positive     0.9526    0.8375    0.8914      1200\n",
      "\n",
      "    accuracy                         0.8747      3600\n",
      "   macro avg     0.8900    0.8747    0.8764      3600\n",
      "weighted avg     0.8900    0.8747    0.8764      3600\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative       1001      182        17\n",
      "neutral          24     1143        33\n",
      "positive         26      169      1005\n",
      "\n",
      "\n",
      "E29-G4OMFT5-DYN-R2 Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.9083    0.8667    0.8870       240\n",
      "     neutral     0.8333    0.8125    0.8228       240\n",
      "    positive     0.8560    0.9167    0.8853       240\n",
      "\n",
      "    accuracy                         0.8653       720\n",
      "   macro avg     0.8659    0.8653    0.8650       720\n",
      "weighted avg     0.8659    0.8653    0.8650       720\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative        208       23         9\n",
      "neutral          17      195        28\n",
      "positive          4       16       220\n",
      "\n",
      "\n",
      "E29-G4OMFT5-SST Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.8750    0.8443    0.8594       912\n",
      "     neutral     0.4683    0.5321    0.4982       389\n",
      "    positive     0.9077    0.8867    0.8971       909\n",
      "\n",
      "    accuracy                         0.8068      2210\n",
      "   macro avg     0.7503    0.7544    0.7515      2210\n",
      "weighted avg     0.8169    0.8068    0.8113      2210\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative        770      136         6\n",
      "neutral         106      207        76\n",
      "positive          4       99       806\n",
      "\n",
      "Saving results to 'results_round2'...\n",
      "\n",
      "Summary Metrics:\n",
      "Dataset     \tF1 (macro)\tAccuracy\n",
      "---------------------------------------------\n",
      "Merged      \t    84.76\t   85.07\n",
      "DynaSent R1 \t    87.64\t   87.47\n",
      "DynaSent R2 \t    86.50\t   86.53\n",
      "SST-3       \t    75.15\t   80.68\n",
      "\n",
      "Evaluation completed\n",
      "End time: 2025-03-18 02:25:44\n",
      "Duration: 1:52:00.802887\n"
     ]
    }
   ],
   "source": [
    "e29_g4omft5_results_df, e29_g4omft5_metrics = evaluate_experiment(\n",
    "    name='E29-G4OMFT5',\n",
    "    notes='Experiment 29: Measure impact of fine-tuning on GPT-4o-mini, 5 epochs',\n",
    "    lm='ft:gpt-4o-mini-2024-07-18:personal:5-epochs:BCEIp15y',\n",
    "    instance='gpt_sentiment',\n",
    "    dataset=test_df,\n",
    "    examples=test_ex,\n",
    "    temperature=temperature,\n",
    "    random_seed=random_seed\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efcad82",
   "metadata": {},
   "source": [
    "#### E11-G4OMFT-M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "fc263a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a test result for the GPT sentiment module\n",
    "e11_g4omft_m_result = gpt_4o_mini_min_sentiment(review=test_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "13c30d5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classification': 'negative'}"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e11_g4omft_m_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "5eb2abca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': \"You are a model that classifies the sentiment of a review as either 'positive', 'neutral', or 'negative'.\"},\n",
       " {'role': 'user',\n",
       "  'content': 'Those 2 drinks are part of the HK culture and has years of history. It is so bad.'},\n",
       " {'role': 'assistant', 'content': 'negative'}]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_4o_mini_min_sentiment.get_last_conversation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "8d970a88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92ff5a87628a41359eb43717e08f9f77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6530 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "e11_g4omft_m_results_df = process_batch(gpt_4o_mini_min_sentiment, test_df, input_format='dataframe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "4acc5fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Experiment: E11-G4OMFT-M\n",
      "--------------------------------------------------------------------------------\n",
      "Start time: 2025-03-16 12:20:40\n",
      "Notes: Experiment 11: Measure impact of fine-tuning on GPT-4o-mini using a minimal format\n",
      "Model: ft:gpt-4o-mini-2024-07-18:personal::ALnBCKLv\n",
      "Instance: gpt_min_sentiment\n",
      "Dataset shape: [6530, 4]\n",
      "Examples length: 6530\n",
      "Results shape: [6530, 4]\n",
      "Save directory: results_round2\n",
      "\n",
      "Source value counts:\n",
      "dynasent_r1            3600\n",
      "sst_local              2210\n",
      "dynasent_r2             720\n",
      "\n",
      "Prediction value counts:\n",
      "positive               2278\n",
      "negative               2240\n",
      "neutral                2012\n",
      "\n",
      "E11-G4OMFT-M Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.9121    0.8686    0.8898      2352\n",
      "     neutral     0.7580    0.8338    0.7941      1829\n",
      "    positive     0.9245    0.8966    0.9103      2349\n",
      "\n",
      "    accuracy                         0.8689      6530\n",
      "   macro avg     0.8648    0.8663    0.8647      6530\n",
      "weighted avg     0.8734    0.8689    0.8704      6530\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative       2043      279        30\n",
      "neutral         162     1525       142\n",
      "positive         35      208      2106\n",
      "\n",
      "\n",
      "E11-G4OMFT-M-DYN-R1 Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.9634    0.8567    0.9069      1200\n",
      "     neutral     0.7917    0.9658    0.8701      1200\n",
      "    positive     0.9616    0.8567    0.9061      1200\n",
      "\n",
      "    accuracy                         0.8931      3600\n",
      "   macro avg     0.9056    0.8931    0.8944      3600\n",
      "weighted avg     0.9056    0.8931    0.8944      3600\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative       1028      157        15\n",
      "neutral          15     1159        26\n",
      "positive         24      148      1028\n",
      "\n",
      "\n",
      "E11-G4OMFT-M-DYN-R2 Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.8930    0.9042    0.8986       240\n",
      "     neutral     0.8643    0.7958    0.8286       240\n",
      "    positive     0.8633    0.9208    0.8911       240\n",
      "\n",
      "    accuracy                         0.8736       720\n",
      "   macro avg     0.8735    0.8736    0.8728       720\n",
      "weighted avg     0.8735    0.8736    0.8728       720\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative        217       15         8\n",
      "neutral          22      191        27\n",
      "positive          4       15       221\n",
      "\n",
      "\n",
      "E11-G4OMFT-M-SST Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.8581    0.8750    0.8664       912\n",
      "     neutral     0.5352    0.4499    0.4888       389\n",
      "    positive     0.8993    0.9428    0.9205       909\n",
      "\n",
      "    accuracy                         0.8281      2210\n",
      "   macro avg     0.7642    0.7559    0.7586      2210\n",
      "weighted avg     0.8182    0.8281    0.8222      2210\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative        798      107         7\n",
      "neutral         125      175        89\n",
      "positive          7       45       857\n",
      "\n",
      "Saving results to 'results_round2'...\n",
      "\n",
      "Summary Metrics:\n",
      "Dataset     \tF1 (macro)\tAccuracy\n",
      "---------------------------------------------\n",
      "Merged      \t    86.47\t   86.89\n",
      "DynaSent R1 \t    89.44\t   89.31\n",
      "DynaSent R2 \t    87.28\t   87.36\n",
      "SST-3       \t    75.86\t   82.81\n",
      "\n",
      "Evaluation completed\n",
      "End time: 2025-03-16 12:20:40\n",
      "Duration: 0:00:00.435095\n"
     ]
    }
   ],
   "source": [
    "e11_g4omft_m_metrics = evaluate_experiment(\n",
    "    name='E11-G4OMFT-M',\n",
    "    notes='Experiment 11: Measure impact of fine-tuning on GPT-4o-mini using a minimal format',\n",
    "    lm='ft:gpt-4o-mini-2024-07-18:personal::ALnBCKLv',\n",
    "    instance='gpt_min_sentiment',\n",
    "    dataset=test_df,\n",
    "    examples=test_ex,\n",
    "    results=e11_g4omft_m_results_df,\n",
    "    temperature=temperature,\n",
    "    random_seed=random_seed\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141a38fe",
   "metadata": {},
   "source": [
    "### B4-G4O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "86b98b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch to the correct language model and disable experimental mode\n",
    "lm = dspy.OpenAI(model='gpt-4o-2024-08-06', api_key=openai_key, max_tokens=8192, temperature=temperature)\n",
    "dspy.settings.configure(lm=lm, experimental=False, seed=random_seed)\n",
    "dsp.settings.show_guidelines = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "4d3a7b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a test result for the ELECTRA Base GPT sentiment module\n",
    "b4_g4o_result = gpt_sentiment(review=test_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "c11cca74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    classification='negative'\n",
       ")"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b4_g4o_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "c3dd1ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Classify the sentiment of a review as either 'negative', 'neutral', or 'positive'.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Review: The review text to classify.\n",
      "Classification: One word representing the sentiment classification: 'negative', 'neutral', or 'positive' (do not repeat the field name, do not use 'mixed')\n",
      "\n",
      "---\n",
      "\n",
      "Review: Those 2 drinks are part of the HK culture and has years of history. It is so bad.\n",
      "Classification:\u001b[32m negative\u001b[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\n\\nClassify the sentiment of a review as either 'negative', 'neutral', or 'positive'.\\n\\n---\\n\\nFollow the following format.\\n\\nReview: The review text to classify.\\nClassification: One word representing the sentiment classification: 'negative', 'neutral', or 'positive' (do not repeat the field name, do not use 'mixed')\\n\\n---\\n\\nReview: Those 2 drinks are part of the HK culture and has years of history. It is so bad.\\nClassification:\\x1b[32m negative\\x1b[0m\\n\\n\\n\""
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "30ad4ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Experiment: B4-G4O\n",
      "--------------------------------------------------------------------------------\n",
      "Start time: 2025-03-16 12:25:40\n",
      "Notes: Baseline 4: Establish GPT-4o baseline with prompt\n",
      "Model: gpt-4o-2024-08-06\n",
      "Instance: gpt_sentiment\n",
      "Dataset shape: [6530, 4]\n",
      "Examples length: 6530\n",
      "Save directory: results_round2\n",
      "Temperature: 0.1\n",
      "Random seed: 123\n",
      "\n",
      "Running evaluation...\n",
      "Average Metric: 5254 / 6530  (80.5): 100%|██████████| 6530/6530 [1:28:49<00:00,  1.23it/s]  \n",
      "\n",
      "Columns in results DataFrame:\n",
      "review                 6530 values\n",
      "classification         6530 values\n",
      "prediction             6530 values\n",
      "match                  6530 values\n",
      "\n",
      "Source value counts:\n",
      "dynasent_r1            3600\n",
      "sst_local              2210\n",
      "dynasent_r2             720\n",
      "\n",
      "Prediction value counts:\n",
      "negative               2556\n",
      "positive               2008\n",
      "neutral                1965\n",
      "i'm sorry, but i can't access external links or content from them. if you provide the text of the review, i'd be happy to help classify its sentiment.      1\n",
      "\n",
      "Found 1 invalid predictions at row indices:\n",
      "[4512]\n",
      "\n",
      "Invalid prediction rows:\n",
      "                                                                                                                                                                               sentence  \\\n",
      "4512  https://www.yelp.com/biz/vegas-discount-nutrition-superstore-las-vegas-8?hrid=QQhKNmf3VF_6r_qAfE8jxg&utm_campaign=www_review_share_popup&utm_medium=copy_link&utm_source=(direct)   \n",
      "\n",
      "        label       source split  \n",
      "4512  neutral  dynasent_r1  test  \n",
      "\n",
      "WARNING: Invalid predictions found. Please review the above details and re-run problematic cases.\n"
     ]
    }
   ],
   "source": [
    "b4_g4o_results_df, b4_g4o_metrics = evaluate_experiment(\n",
    "    name='B4-G4O',\n",
    "    notes='Baseline 4: Establish GPT-4o baseline with prompt',\n",
    "    lm='gpt-4o-2024-08-06',\n",
    "    instance='gpt_sentiment',\n",
    "    dataset=test_df,\n",
    "    examples=test_ex,\n",
    "    temperature=temperature,\n",
    "    random_seed=random_seed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "4faaa847",
   "metadata": {},
   "outputs": [],
   "source": [
    "b4_g4o_review_4512_retry = gpt_sentiment(review='https://www.yelp.com/biz/vegas-discount-nutrition-superstore-las-vegas-8?hrid=QQhKNmf3VF_6r_qAfE8jxg&utm_campaign=www_review_share_popup&utm_medium=copy_link&utm_source=(direct) (Do not access the URL. Just make the classification decision as if the URL itself was the content of the review)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "ae5ab6e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    classification='neutral'\n",
       ")"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b4_g4o_review_4512_retry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "b4b8f5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update b4_g4o_results_df with the retry result\n",
    "b4_g4o_results_df.at[4512, 'prediction'] = 'neutral'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "cf6dda21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Experiment: B4-G4O\n",
      "--------------------------------------------------------------------------------\n",
      "Start time: 2025-03-16 17:19:19\n",
      "Notes: Baseline 4: Establish GPT-4o baseline with prompt\n",
      "Model: gpt-4o-2024-08-06\n",
      "Instance: gpt_sentiment\n",
      "Dataset shape: [6530, 4]\n",
      "Examples length: 6530\n",
      "Results shape: [6530, 5]\n",
      "Save directory: results_round2\n",
      "\n",
      "Source value counts:\n",
      "dynasent_r1            3600\n",
      "sst_local              2210\n",
      "dynasent_r2             720\n",
      "\n",
      "Prediction value counts:\n",
      "negative               2556\n",
      "positive               2008\n",
      "neutral                1966\n",
      "\n",
      "B4-G4O Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.8196    0.8907    0.8537      2352\n",
      "     neutral     0.6724    0.7228    0.6967      1829\n",
      "    positive     0.9153    0.7825    0.8437      2349\n",
      "\n",
      "    accuracy                         0.8047      6530\n",
      "   macro avg     0.8025    0.7987    0.7980      6530\n",
      "weighted avg     0.8128    0.8047    0.8061      6530\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative       2095      243        14\n",
      "neutral         351     1322       156\n",
      "positive        110      401      1838\n",
      "\n",
      "\n",
      "B4-G4O-DYN-R1 Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.8537    0.8508    0.8523      1200\n",
      "     neutral     0.6936    0.8525    0.7649      1200\n",
      "    positive     0.9236    0.7150    0.8060      1200\n",
      "\n",
      "    accuracy                         0.8061      3600\n",
      "   macro avg     0.8236    0.8061    0.8077      3600\n",
      "weighted avg     0.8236    0.8061    0.8077      3600\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative       1021      172         7\n",
      "neutral         113     1023        64\n",
      "positive         62      280       858\n",
      "\n",
      "\n",
      "B4-G4O-DYN-R2 Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.7744    0.9583    0.8566       240\n",
      "     neutral     0.7778    0.6708    0.7204       240\n",
      "    positive     0.8704    0.7833    0.8246       240\n",
      "\n",
      "    accuracy                         0.8042       720\n",
      "   macro avg     0.8075    0.8042    0.8005       720\n",
      "weighted avg     0.8075    0.8042    0.8005       720\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative        230        7         3\n",
      "neutral          54      161        25\n",
      "positive         13       39       188\n",
      "\n",
      "\n",
      "B4-G4O-SST Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.7940    0.9254    0.8547       912\n",
      "     neutral     0.4859    0.3548    0.4101       389\n",
      "    positive     0.9177    0.8713    0.8939       909\n",
      "\n",
      "    accuracy                         0.8027      2210\n",
      "   macro avg     0.7325    0.7172    0.7196      2210\n",
      "weighted avg     0.7907    0.8027    0.7926      2210\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative        844       64         4\n",
      "neutral         184      138        67\n",
      "positive         35       82       792\n",
      "\n",
      "Saving results to 'results_round2'...\n",
      "\n",
      "Summary Metrics:\n",
      "Dataset     \tF1 (macro)\tAccuracy\n",
      "---------------------------------------------\n",
      "Merged      \t    79.80\t   80.47\n",
      "DynaSent R1 \t    80.77\t   80.61\n",
      "DynaSent R2 \t    80.05\t   80.42\n",
      "SST-3       \t    71.96\t   80.27\n",
      "\n",
      "Evaluation completed\n",
      "End time: 2025-03-16 17:19:19\n",
      "Duration: 0:00:00.441839\n"
     ]
    }
   ],
   "source": [
    "b4_g4o_metrics = evaluate_experiment(\n",
    "    name='B4-G4O',\n",
    "    notes='Baseline 4: Establish GPT-4o baseline with prompt',\n",
    "    lm='gpt-4o-2024-08-06',\n",
    "    instance='gpt_sentiment',\n",
    "    dataset=test_df,\n",
    "    examples=test_ex,\n",
    "    results=b4_g4o_results_df\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ab1b5b",
   "metadata": {},
   "source": [
    "### E7-G4O-ELFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "99acd5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch to the correct language model and disable experimental mode\n",
    "lm = dspy.OpenAI(model='gpt-4o-2024-08-06', api_key=openai_key, max_tokens=8192, temperature=temperature)\n",
    "dspy.settings.configure(lm=lm, experimental=False, seed=random_seed)\n",
    "dsp.settings.show_guidelines = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "c3f7fd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a test result for the ELECTRA Base GPT sentiment module\n",
    "e7_g4o_elft_result = electra_large_gpt_sentiment(review=test_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "1f591984",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    classification='negative',\n",
       "    classifier_decision='negative',\n",
       "    probabilities=[0.9990077614784241, 0.0005539217963814735, 0.000438391842180863]\n",
       ")"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e7_g4o_elft_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "ed456a36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Classify the sentiment of a review as either 'negative', 'neutral', or 'positive'.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Review: The review text to classify.\n",
      "Classifier Decision: The sentiment classification proposed by a model fine-tuned on sentiment.\n",
      "Classification: One word representing the sentiment classification: 'negative', 'neutral', or 'positive' (do not repeat the field name, do not use 'mixed')\n",
      "\n",
      "---\n",
      "\n",
      "Review: Those 2 drinks are part of the HK culture and has years of history. It is so bad.\n",
      "Classifier Decision: negative\n",
      "Classification:\u001b[32m negative\u001b[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\n\\nClassify the sentiment of a review as either 'negative', 'neutral', or 'positive'.\\n\\n---\\n\\nFollow the following format.\\n\\nReview: The review text to classify.\\nClassifier Decision: The sentiment classification proposed by a model fine-tuned on sentiment.\\nClassification: One word representing the sentiment classification: 'negative', 'neutral', or 'positive' (do not repeat the field name, do not use 'mixed')\\n\\n---\\n\\nReview: Those 2 drinks are part of the HK culture and has years of history. It is so bad.\\nClassifier Decision: negative\\nClassification:\\x1b[32m negative\\x1b[0m\\n\\n\\n\""
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "1fd31e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Experiment: E7-G4O-ELFT\n",
      "--------------------------------------------------------------------------------\n",
      "Start time: 2025-03-27 07:30:38\n",
      "Notes: Experiment 7: Evaluate prompt-based collaboration with larger models\n",
      "Model: gpt-4o-2024-08-06\n",
      "Instance: electra_large_gpt_sentiment\n",
      "Dataset shape: [6530, 4]\n",
      "Examples length: 6530\n",
      "Save directory: results_round2_take2\n",
      "Temperature: 0.1\n",
      "Random seed: 123\n",
      "\n",
      "Running evaluation...\n",
      "Average Metric: 5465 / 6530  (83.7): 100%|██████████| 6530/6530 [1:05:23<00:00,  1.66it/s]\n",
      "\n",
      "Columns in results DataFrame:\n",
      "review                 6530 values\n",
      "classification         6530 values\n",
      "prediction             6530 values\n",
      "match                  6530 values\n",
      "classifier_decision    6530 values\n",
      "probabilities          6530 values\n",
      "\n",
      "Source value counts:\n",
      "dynasent_r1            3600\n",
      "sst_local              2210\n",
      "dynasent_r2             720\n",
      "\n",
      "Prediction value counts:\n",
      "negative               2357\n",
      "positive               2156\n",
      "neutral                2017\n",
      "\n",
      "E7-G4O-ELFT Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.8727    0.8746    0.8736      2352\n",
      "     neutral     0.7119    0.7851    0.7467      1829\n",
      "    positive     0.9147    0.8395    0.8755      2349\n",
      "\n",
      "    accuracy                         0.8369      6530\n",
      "   macro avg     0.8331    0.8331    0.8320      6530\n",
      "weighted avg     0.8428    0.8369    0.8388      6530\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative       2057      276        19\n",
      "neutral         228     1436       165\n",
      "positive         72      305      1972\n",
      "\n",
      "\n",
      "E7-G4O-ELFT-DYN-R1 Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.9203    0.8567    0.8874      1200\n",
      "     neutral     0.7473    0.9242    0.8264      1200\n",
      "    positive     0.9439    0.7858    0.8577      1200\n",
      "\n",
      "    accuracy                         0.8556      3600\n",
      "   macro avg     0.8705    0.8556    0.8571      3600\n",
      "weighted avg     0.8705    0.8556    0.8571      3600\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative       1028      165         7\n",
      "neutral          42     1109        49\n",
      "positive         47      210       943\n",
      "\n",
      "\n",
      "E7-G4O-ELFT-DYN-R2 Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.8246    0.9208    0.8701       240\n",
      "     neutral     0.8057    0.7083    0.7539       240\n",
      "    positive     0.8382    0.8417    0.8399       240\n",
      "\n",
      "    accuracy                         0.8236       720\n",
      "   macro avg     0.8228    0.8236    0.8213       720\n",
      "weighted avg     0.8228    0.8236    0.8213       720\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative        221       13         6\n",
      "neutral          37      170        33\n",
      "positive         10       28       202\n",
      "\n",
      "\n",
      "E7-G4O-ELFT-SST Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.8313    0.8860    0.8577       912\n",
      "     neutral     0.4876    0.4036    0.4416       389\n",
      "    positive     0.9028    0.9098    0.9063       909\n",
      "\n",
      "    accuracy                         0.8109      2210\n",
      "   macro avg     0.7406    0.7331    0.7352      2210\n",
      "weighted avg     0.8002    0.8109    0.8045      2210\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative        808       98         6\n",
      "neutral         149      157        83\n",
      "positive         15       67       827\n",
      "\n",
      "Saving results to 'results_round2_take2'...\n",
      "\n",
      "Summary Metrics:\n",
      "Dataset     \tF1 (macro)\tAccuracy\n",
      "---------------------------------------------\n",
      "Merged      \t    83.20\t   83.69\n",
      "DynaSent R1 \t    85.71\t   85.56\n",
      "DynaSent R2 \t    82.13\t   82.36\n",
      "SST-3       \t    73.52\t   81.09\n",
      "\n",
      "Evaluation completed\n",
      "End time: 2025-03-27 08:36:02\n",
      "Duration: 1:05:24.100413\n"
     ]
    }
   ],
   "source": [
    "e7_g4o_elft_results_df, e7_g4o_elft_metrics = evaluate_experiment(\n",
    "    name='E7-G4O-ELFT',\n",
    "    notes='Experiment 7: Evaluate prompt-based collaboration with larger models',\n",
    "    lm='gpt-4o-2024-08-06',\n",
    "    instance='electra_large_gpt_sentiment',\n",
    "    dataset=test_df,\n",
    "    examples=test_ex,\n",
    "    temperature=temperature,\n",
    "    random_seed=random_seed\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9002e396",
   "metadata": {},
   "source": [
    "### E8-G4OFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "87d18416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch to the correct language model and disable experimental mode\n",
    "lm = dspy.OpenAI(model='ft:gpt-4o-2024-08-06:personal::AN55MS6K', api_key=openai_key, max_tokens=8192, temperature=temperature)\n",
    "dspy.settings.configure(lm=lm, experimental=False, seed=random_seed)\n",
    "dsp.settings.show_guidelines = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "281f3ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a test result for the ELECTRA Base GPT sentiment module\n",
    "e8_g4oft_result = gpt_sentiment(review=test_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "ce45759b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    classification='negative'\n",
       ")"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e8_g4oft_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "c6adf3a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Classify the sentiment of a review as either 'negative', 'neutral', or 'positive'.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Review: The review text to classify.\n",
      "Classification: One word representing the sentiment classification: 'negative', 'neutral', or 'positive' (do not repeat the field name, do not use 'mixed')\n",
      "\n",
      "---\n",
      "\n",
      "Review: Those 2 drinks are part of the HK culture and has years of history. It is so bad.\n",
      "Classification:\u001b[32m negative\u001b[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\n\\nClassify the sentiment of a review as either 'negative', 'neutral', or 'positive'.\\n\\n---\\n\\nFollow the following format.\\n\\nReview: The review text to classify.\\nClassification: One word representing the sentiment classification: 'negative', 'neutral', or 'positive' (do not repeat the field name, do not use 'mixed')\\n\\n---\\n\\nReview: Those 2 drinks are part of the HK culture and has years of history. It is so bad.\\nClassification:\\x1b[32m negative\\x1b[0m\\n\\n\\n\""
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "af5f1272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Experiment: E8-G4OFT\n",
      "--------------------------------------------------------------------------------\n",
      "Start time: 2025-03-16 21:45:49\n",
      "Notes: Experiment 8: Measure impact of fine-tuning on GPT-4o\n",
      "Model: ft:gpt-4o-2024-08-06:personal::AN55MS6K\n",
      "Instance: gpt_sentiment\n",
      "Dataset shape: [6530, 4]\n",
      "Examples length: 6530\n",
      "Save directory: results_round2\n",
      "Temperature: 0.1\n",
      "Random seed: 123\n",
      "\n",
      "Running evaluation...\n",
      "Average Metric: 5702 / 6530  (87.3): 100%|██████████| 6530/6530 [2:10:47<00:00,  1.20s/it]  \n",
      "\n",
      "Columns in results DataFrame:\n",
      "review                 6530 values\n",
      "classification         6530 values\n",
      "prediction             6530 values\n",
      "match                  6530 values\n",
      "\n",
      "Source value counts:\n",
      "dynasent_r1            3600\n",
      "sst_local              2210\n",
      "dynasent_r2             720\n",
      "\n",
      "Prediction value counts:\n",
      "negative               2361\n",
      "positive               2347\n",
      "neutral                1822\n",
      "\n",
      "E8-G4OFT Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.8971    0.9005    0.8988      2352\n",
      "     neutral     0.7975    0.7944    0.7959      1829\n",
      "    positive     0.9080    0.9072    0.9076      2349\n",
      "\n",
      "    accuracy                         0.8732      6530\n",
      "   macro avg     0.8675    0.8674    0.8674      6530\n",
      "weighted avg     0.8731    0.8732    0.8731      6530\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative       2118      199        35\n",
      "neutral         195     1453       181\n",
      "positive         48      170      2131\n",
      "\n",
      "\n",
      "E8-G4OFT-DYN-R1 Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.9488    0.8958    0.9216      1200\n",
      "     neutral     0.8328    0.9425    0.8843      1200\n",
      "    positive     0.9459    0.8742    0.9086      1200\n",
      "\n",
      "    accuracy                         0.9042      3600\n",
      "   macro avg     0.9092    0.9042    0.9048      3600\n",
      "weighted avg     0.9092    0.9042    0.9048      3600\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative       1075      108        17\n",
      "neutral          26     1131        43\n",
      "positive         32      119      1049\n",
      "\n",
      "\n",
      "E8-G4OFT-DYN-R2 Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.8840    0.9208    0.9020       240\n",
      "     neutral     0.9043    0.7875    0.8419       240\n",
      "    positive     0.8582    0.9333    0.8942       240\n",
      "\n",
      "    accuracy                         0.8806       720\n",
      "   macro avg     0.8822    0.8806    0.8794       720\n",
      "weighted avg     0.8822    0.8806    0.8794       720\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative        221        9        10\n",
      "neutral          24      189        27\n",
      "positive          5       11       224\n",
      "\n",
      "\n",
      "E8-G4OFT-SST Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.8405    0.9013    0.8698       912\n",
      "     neutral     0.5216    0.3419    0.4130       389\n",
      "    positive     0.8782    0.9439    0.9099       909\n",
      "\n",
      "    accuracy                         0.8204      2210\n",
      "   macro avg     0.7468    0.7290    0.7309      2210\n",
      "weighted avg     0.7999    0.8204    0.8059      2210\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative        822       82         8\n",
      "neutral         145      133       111\n",
      "positive         11       40       858\n",
      "\n",
      "Saving results to 'results_round2'...\n",
      "\n",
      "Summary Metrics:\n",
      "Dataset     \tF1 (macro)\tAccuracy\n",
      "---------------------------------------------\n",
      "Merged      \t    86.74\t   87.32\n",
      "DynaSent R1 \t    90.48\t   90.42\n",
      "DynaSent R2 \t    87.94\t   88.06\n",
      "SST-3       \t    73.09\t   82.04\n",
      "\n",
      "Evaluation completed\n",
      "End time: 2025-03-16 23:56:36\n",
      "Duration: 2:10:47.607301\n"
     ]
    }
   ],
   "source": [
    "e8_g4oft_results_df, e8_g4oft_metrics = evaluate_experiment(\n",
    "    name='E8-G4OFT',\n",
    "    notes='Experiment 8: Measure impact of fine-tuning on GPT-4o',\n",
    "    lm='ft:gpt-4o-2024-08-06:personal::AN55MS6K',\n",
    "    instance='gpt_sentiment',\n",
    "    dataset=test_df,\n",
    "    examples=test_ex,\n",
    "    temperature=temperature,\n",
    "    random_seed=random_seed\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f328a23",
   "metadata": {},
   "source": [
    "### E9-G4OFT-ELFT-P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e853dbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch to the correct language model and disable experimental mode\n",
    "lm = dspy.OpenAI(model='ft:gpt-4o-2024-08-06:personal::AN55MS6K', api_key=openai_key, max_tokens=8192, temperature=temperature)\n",
    "dspy.settings.configure(lm=lm, experimental=False, seed=random_seed)\n",
    "dsp.settings.show_guidelines = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7230b71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a test result for the ELECTRA Base GPT sentiment module\n",
    "e9_g4oft_elft_p_result = electra_large_gpt_sentiment(review=test_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "80f1f203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    classification='negative',\n",
       "    classifier_decision='negative',\n",
       "    probabilities=[0.9990077614784241, 0.0005539217963814735, 0.000438391842180863]\n",
       ")"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e9_g4oft_elft_p_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "fdb85e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Classify the sentiment of a review as either 'negative', 'neutral', or 'positive'.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Review: The review text to classify.\n",
      "Classifier Decision: The sentiment classification proposed by a model fine-tuned on sentiment.\n",
      "Classification: One word representing the sentiment classification: 'negative', 'neutral', or 'positive' (do not repeat the field name, do not use 'mixed')\n",
      "\n",
      "---\n",
      "\n",
      "Review: Those 2 drinks are part of the HK culture and has years of history. It is so bad.\n",
      "Classifier Decision: negative\n",
      "Classification:\u001b[32m negative\u001b[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\n\\nClassify the sentiment of a review as either 'negative', 'neutral', or 'positive'.\\n\\n---\\n\\nFollow the following format.\\n\\nReview: The review text to classify.\\nClassifier Decision: The sentiment classification proposed by a model fine-tuned on sentiment.\\nClassification: One word representing the sentiment classification: 'negative', 'neutral', or 'positive' (do not repeat the field name, do not use 'mixed')\\n\\n---\\n\\nReview: Those 2 drinks are part of the HK culture and has years of history. It is so bad.\\nClassifier Decision: negative\\nClassification:\\x1b[32m negative\\x1b[0m\\n\\n\\n\""
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "24ce2a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Experiment: E9-G4OFT-ELFT-P\n",
      "--------------------------------------------------------------------------------\n",
      "Start time: 2025-03-26 08:46:48\n",
      "Notes: Experiment 9: Evaluate combined impact of fine-tuning and prompt collaboration with larger models\n",
      "Model: ft:gpt-4o-2024-08-06:personal::AN55MS6K\n",
      "Instance: electra_large_gpt_sentiment\n",
      "Dataset shape: [6530, 4]\n",
      "Examples length: 6530\n",
      "Save directory: results_round2_take2\n",
      "Temperature: 0.1\n",
      "Random seed: 123\n",
      "\n",
      "Running evaluation...\n",
      "Average Metric: 5540 / 6530  (84.8): 100%|██████████| 6530/6530 [1:06:18<00:00,  1.64it/s] \n",
      "\n",
      "Columns in results DataFrame:\n",
      "review                 6530 values\n",
      "classification         6530 values\n",
      "prediction             6530 values\n",
      "match                  6530 values\n",
      "classifier_decision    6530 values\n",
      "probabilities          6530 values\n",
      "\n",
      "Source value counts:\n",
      "dynasent_r1            3600\n",
      "sst_local              2210\n",
      "dynasent_r2             720\n",
      "\n",
      "Prediction value counts:\n",
      "positive               2339\n",
      "negative               2327\n",
      "neutral                1864\n",
      "\n",
      "E9-G4OFT-ELFT-P Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.8805    0.8712    0.8758      2352\n",
      "     neutral     0.7570    0.7715    0.7641      1829\n",
      "    positive     0.8893    0.8855    0.8874      2349\n",
      "\n",
      "    accuracy                         0.8484      6530\n",
      "   macro avg     0.8423    0.8427    0.8424      6530\n",
      "weighted avg     0.8491    0.8484    0.8487      6530\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative       2049      239        64\n",
      "neutral         223     1411       195\n",
      "positive         55      214      2080\n",
      "\n",
      "\n",
      "E9-G4OFT-ELFT-P-DYN-R1 Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.9357    0.8608    0.8967      1200\n",
      "     neutral     0.7957    0.9250    0.8555      1200\n",
      "    positive     0.9273    0.8508    0.8874      1200\n",
      "\n",
      "    accuracy                         0.8789      3600\n",
      "   macro avg     0.8862    0.8789    0.8799      3600\n",
      "weighted avg     0.8862    0.8789    0.8799      3600\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative       1033      138        29\n",
      "neutral          39     1110        51\n",
      "positive         32      147      1021\n",
      "\n",
      "\n",
      "E9-G4OFT-ELFT-P-DYN-R2 Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.8023    0.8792    0.8390       240\n",
      "     neutral     0.8466    0.6667    0.7459       240\n",
      "    positive     0.7873    0.8792    0.8307       240\n",
      "\n",
      "    accuracy                         0.8083       720\n",
      "   macro avg     0.8121    0.8083    0.8052       720\n",
      "weighted avg     0.8121    0.8083    0.8052       720\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative        211       12        17\n",
      "neutral          40      160        40\n",
      "positive         12       17       211\n",
      "\n",
      "\n",
      "E9-G4OFT-ELFT-P-SST Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.8385    0.8827    0.8600       912\n",
      "     neutral     0.5036    0.3625    0.4215       389\n",
      "    positive     0.8742    0.9329    0.9026       909\n",
      "\n",
      "    accuracy                         0.8118      2210\n",
      "   macro avg     0.7388    0.7260    0.7281      2210\n",
      "weighted avg     0.7943    0.8118    0.8004      2210\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative        805       89        18\n",
      "neutral         144      141       104\n",
      "positive         11       50       848\n",
      "\n",
      "Saving results to 'results_round2_take2'...\n",
      "\n",
      "Summary Metrics:\n",
      "Dataset     \tF1 (macro)\tAccuracy\n",
      "---------------------------------------------\n",
      "Merged      \t    84.24\t   84.84\n",
      "DynaSent R1 \t    87.99\t   87.89\n",
      "DynaSent R2 \t    80.52\t   80.83\n",
      "SST-3       \t    72.81\t   81.18\n",
      "\n",
      "Evaluation completed\n",
      "End time: 2025-03-26 09:53:07\n",
      "Duration: 1:06:18.604017\n"
     ]
    }
   ],
   "source": [
    "e9_g4oft_elft_p_results_df, e9_g4oft_elft_p_metrics = evaluate_experiment(\n",
    "    name='E9-G4OFT-ELFT-P',\n",
    "    notes='Experiment 9: Evaluate combined impact of fine-tuning and prompt collaboration with larger models',\n",
    "    lm='ft:gpt-4o-2024-08-06:personal::AN55MS6K',\n",
    "    instance='electra_large_gpt_sentiment',\n",
    "    dataset=test_df,\n",
    "    examples=test_ex,\n",
    "    temperature=temperature,\n",
    "    random_seed=random_seed\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c143fb5b",
   "metadata": {},
   "source": [
    "### E10-G4OFT-ELFT-FT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "8a499709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch to the correct language model and disable experimental mode\n",
    "lm = dspy.OpenAI(model='ft:gpt-4o-2024-08-06:personal::ANcREuvn', api_key=openai_key, max_tokens=8192, temperature=temperature)\n",
    "dspy.settings.configure(lm=lm, experimental=False, seed=random_seed)\n",
    "dsp.settings.show_guidelines = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "969c8c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a test result for the ELECTRA Base GPT sentiment module\n",
    "e10_g4oft_elft_ft_result = electra_large_gpt_sentiment(review=test_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "31b835ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    classification='negative',\n",
       "    classifier_decision='negative',\n",
       "    probabilities=[0.9990077614784241, 0.0005539217963814735, 0.000438391842180863]\n",
       ")"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e10_g4oft_elft_ft_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "eba5d279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Classify the sentiment of a review as either 'negative', 'neutral', or 'positive'.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Review: The review text to classify.\n",
      "Classifier Decision: The sentiment classification proposed by a model fine-tuned on sentiment.\n",
      "Classification: One word representing the sentiment classification: 'negative', 'neutral', or 'positive' (do not repeat the field name, do not use 'mixed')\n",
      "\n",
      "---\n",
      "\n",
      "Review: Those 2 drinks are part of the HK culture and has years of history. It is so bad.\n",
      "Classifier Decision: negative\n",
      "Classification:\u001b[32m negative\u001b[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\n\\nClassify the sentiment of a review as either 'negative', 'neutral', or 'positive'.\\n\\n---\\n\\nFollow the following format.\\n\\nReview: The review text to classify.\\nClassifier Decision: The sentiment classification proposed by a model fine-tuned on sentiment.\\nClassification: One word representing the sentiment classification: 'negative', 'neutral', or 'positive' (do not repeat the field name, do not use 'mixed')\\n\\n---\\n\\nReview: Those 2 drinks are part of the HK culture and has years of history. It is so bad.\\nClassifier Decision: negative\\nClassification:\\x1b[32m negative\\x1b[0m\\n\\n\\n\""
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "dff9db4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Experiment: E10-G4OFT-ELFT-FT\n",
      "--------------------------------------------------------------------------------\n",
      "Start time: 2025-03-26 09:57:45\n",
      "Notes: Experiment 10: Measure impact of fine-tuning on GPT-4o using a minimal format\n",
      "Model: ft:gpt-4o-2024-08-06:personal::ANcREuvn\n",
      "Instance: electra_large_gpt_sentiment\n",
      "Dataset shape: [6530, 4]\n",
      "Examples length: 6530\n",
      "Save directory: results_round2_take2\n",
      "Temperature: 0.1\n",
      "Random seed: 123\n",
      "\n",
      "Running evaluation...\n",
      "Average Metric: 3130 / 3674  (85.2):  56%|█████▋    | 3674/6530 [38:36<26:10,  1.82it/s]   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:opentelemetry.exporter.otlp.proto.http.trace_exporter:Transient error Service Unavailable encountered while exporting span batch, retrying in 1s.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 5553 / 6530  (85.0): 100%|██████████| 6530/6530 [1:06:26<00:00,  1.64it/s]\n",
      "\n",
      "Columns in results DataFrame:\n",
      "review                 6530 values\n",
      "classification         6530 values\n",
      "prediction             6530 values\n",
      "match                  6530 values\n",
      "classifier_decision    6530 values\n",
      "probabilities          6530 values\n",
      "\n",
      "Source value counts:\n",
      "dynasent_r1            3600\n",
      "sst_local              2210\n",
      "dynasent_r2             720\n",
      "\n",
      "Prediction value counts:\n",
      "positive               2302\n",
      "negative               2299\n",
      "neutral                1929\n",
      "\n",
      "E10-G4OFT-ELFT-FT Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.8886    0.8686    0.8785      2352\n",
      "     neutral     0.7470    0.7879    0.7669      1829\n",
      "    positive     0.8988    0.8808    0.8897      2349\n",
      "\n",
      "    accuracy                         0.8504      6530\n",
      "   macro avg     0.8448    0.8458    0.8450      6530\n",
      "weighted avg     0.8526    0.8504    0.8513      6530\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative       2043      259        50\n",
      "neutral         205     1441       183\n",
      "positive         51      229      2069\n",
      "\n",
      "\n",
      "E10-G4OFT-ELFT-FT-DYN-R1 Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.9396    0.8550    0.8953      1200\n",
      "     neutral     0.7857    0.9350    0.8539      1200\n",
      "    positive     0.9361    0.8425    0.8868      1200\n",
      "\n",
      "    accuracy                         0.8775      3600\n",
      "   macro avg     0.8871    0.8775    0.8787      3600\n",
      "weighted avg     0.8871    0.8775    0.8787      3600\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative       1026      152        22\n",
      "neutral          31     1122        47\n",
      "positive         35      154      1011\n",
      "\n",
      "\n",
      "E10-G4OFT-ELFT-FT-DYN-R2 Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.8320    0.8875    0.8589       240\n",
      "     neutral     0.8325    0.7042    0.7630       240\n",
      "    positive     0.8046    0.8750    0.8383       240\n",
      "\n",
      "    accuracy                         0.8222       720\n",
      "   macro avg     0.8230    0.8222    0.8201       720\n",
      "weighted avg     0.8230    0.8222    0.8201       720\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative        213       13        14\n",
      "neutral          34      169        37\n",
      "positive          9       21       210\n",
      "\n",
      "\n",
      "E10-G4OFT-ELFT-FT-SST Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.8454    0.8816    0.8631       912\n",
      "     neutral     0.5034    0.3856    0.4367       389\n",
      "    positive     0.8824    0.9329    0.9070       909\n",
      "\n",
      "    accuracy                         0.8154      2210\n",
      "   macro avg     0.7437    0.7334    0.7356      2210\n",
      "weighted avg     0.8004    0.8154    0.8061      2210\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative        804       94        14\n",
      "neutral         140      150        99\n",
      "positive          7       54       848\n",
      "\n",
      "Saving results to 'results_round2_take2'...\n",
      "\n",
      "Summary Metrics:\n",
      "Dataset     \tF1 (macro)\tAccuracy\n",
      "---------------------------------------------\n",
      "Merged      \t    84.50\t   85.04\n",
      "DynaSent R1 \t    87.87\t   87.75\n",
      "DynaSent R2 \t    82.01\t   82.22\n",
      "SST-3       \t    73.56\t   81.54\n",
      "\n",
      "Evaluation completed\n",
      "End time: 2025-03-26 11:04:12\n",
      "Duration: 1:06:27.007732\n"
     ]
    }
   ],
   "source": [
    "e10_g4oft_elft_ft_results_df, e10_g4oft_elft_ft_metrics = evaluate_experiment(\n",
    "    name='E10-G4OFT-ELFT-FT',\n",
    "    notes='Experiment 10: Measure impact of fine-tuning on GPT-4o using a minimal format',\n",
    "    lm='ft:gpt-4o-2024-08-06:personal::ANcREuvn',\n",
    "    instance='electra_large_gpt_sentiment',\n",
    "    dataset=test_df,\n",
    "    examples=test_ex,\n",
    "    temperature=temperature,\n",
    "    random_seed=random_seed\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdc46e2",
   "metadata": {},
   "source": [
    "#### E12-G4OFT-M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "7433edc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a test result for the GPT sentiment module\n",
    "e12_g4oft_m_result = gpt_4o_min_sentiment(review=test_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "9f4a0f40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classification': 'negative'}"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e12_g4oft_m_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "9cd1ec2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': \"You are a model that classifies the sentiment of a review as either 'positive', 'neutral', or 'negative'.\"},\n",
       " {'role': 'user',\n",
       "  'content': 'Those 2 drinks are part of the HK culture and has years of history. It is so bad.'},\n",
       " {'role': 'assistant', 'content': 'negative'}]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_4o_min_sentiment.get_last_conversation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "9d6d373a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23d0533271424d2a99acceca8a389447",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6530 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "e12_g4oft_m_results_df = process_batch(gpt_4o_min_sentiment, test_df, input_format='dataframe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523b9510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Experiment: E12-G4OFT-M\n",
      "--------------------------------------------------------------------------------\n",
      "Start time: 2024-10-31 00:49:33\n",
      "Notes: Experiment 12: Measure impact of fine-tuning on GPT-4o using a minimal format\n",
      "Model: ft:gpt-4o-2024-08-06:personal::AM5cg622\n",
      "Instance: gpt_4o_min_sentiment\n",
      "Dataset shape: [6530, 4]\n",
      "Examples length: 6530\n",
      "Results shape: [6530, 4]\n",
      "Save directory: research\n",
      "\n",
      "Source value counts:\n",
      "dynasent_r1            3600\n",
      "sst_local              2210\n",
      "dynasent_r2             720\n",
      "\n",
      "Prediction value counts:\n",
      "negative               2379\n",
      "positive               2308\n",
      "neutral                1843\n",
      "\n",
      "E12-G4OFT-M Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.8983    0.9086    0.9034      2352\n",
      "     neutral     0.7933    0.7993    0.7963      1829\n",
      "    positive     0.9181    0.9021    0.9100      2349\n",
      "\n",
      "    accuracy                         0.8757      6530\n",
      "   macro avg     0.8699    0.8700    0.8699      6530\n",
      "weighted avg     0.8760    0.8757    0.8758      6530\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative       2137      195        20\n",
      "neutral         198     1462       169\n",
      "positive         44      186      2119\n",
      "\n",
      "\n",
      "E12-G4OFT-M-DYN-R1 Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.9468    0.9050    0.9254      1200\n",
      "     neutral     0.8306    0.9400    0.8819      1200\n",
      "    positive     0.9534    0.8700    0.9098      1200\n",
      "\n",
      "    accuracy                         0.9050      3600\n",
      "   macro avg     0.9103    0.9050    0.9057      3600\n",
      "weighted avg     0.9103    0.9050    0.9057      3600\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative       1086      104        10\n",
      "neutral          31     1128        41\n",
      "positive         30      126      1044\n",
      "\n",
      "\n",
      "E12-G4OFT-M-DYN-R2 Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.8851    0.9625    0.9222       240\n",
      "     neutral     0.9126    0.7833    0.8430       240\n",
      "    positive     0.8814    0.9292    0.9047       240\n",
      "\n",
      "    accuracy                         0.8917       720\n",
      "   macro avg     0.8930    0.8917    0.8900       720\n",
      "weighted avg     0.8930    0.8917    0.8900       720\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative        231        6         3\n",
      "neutral          25      188        27\n",
      "positive          5       12       223\n",
      "\n",
      "\n",
      "E12-G4OFT-M-SST Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.8445    0.8991    0.8710       912\n",
      "     neutral     0.5233    0.3753    0.4371       389\n",
      "    positive     0.8875    0.9373    0.9117       909\n",
      "\n",
      "    accuracy                         0.8226      2210\n",
      "   macro avg     0.7518    0.7372    0.7399      2210\n",
      "weighted avg     0.8056    0.8226    0.8114      2210\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative        820       85         7\n",
      "neutral         142      146       101\n",
      "positive          9       48       852\n",
      "\n",
      "Saving results to 'research'...\n",
      "\n",
      "Summary Metrics:\n",
      "Dataset     \tF1 (macro)\tAccuracy\n",
      "---------------------------------------------\n",
      "Merged      \t    86.99\t   87.57\n",
      "DynaSent R1 \t    90.57\t   90.50\n",
      "DynaSent R2 \t    89.00\t   89.17\n",
      "SST-3       \t    73.99\t   82.26\n",
      "\n",
      "Evaluation completed\n",
      "End time: 2024-10-31 00:49:34\n",
      "Duration: 0:00:00.444904\n"
     ]
    }
   ],
   "source": [
    "e12_g4oft_m_metrics = evaluate_experiment(\n",
    "    name='E12-G4OFT-M',\n",
    "    notes='Experiment 12: Measure impact of fine-tuning on GPT-4o using a minimal format',\n",
    "    lm='ft:gpt-4o-2024-08-06:personal::AM5cg622',\n",
    "    instance='gpt_4o_min_sentiment',\n",
    "    dataset=test_df,\n",
    "    examples=test_ex,\n",
    "    results=e12_g4oft_m_results_df,\n",
    "    temperature=temperature,\n",
    "    random_seed=random_seed\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cac6611",
   "metadata": {},
   "source": [
    "### E13-G4OM-ELFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c24eda38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch to the correct language model and disable experimental mode\n",
    "lm = dspy.OpenAI(model='gpt-4o-mini-2024-07-18', api_key=openai_key, max_tokens=8192, temperature=temperature)\n",
    "dspy.settings.configure(lm=lm, experimental=False, seed=random_seed)\n",
    "dsp.settings.show_guidelines = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "3aa1e887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a test result for the GPT sentiment module\n",
    "e13_g4om_elft_result = electra_large_gpt_sentiment(review=test_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e54f8147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    classification='negative',\n",
       "    classifier_decision='negative',\n",
       "    probabilities=[0.9990077614784241, 0.0005539217963814735, 0.000438391842180863]\n",
       ")"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e13_g4om_elft_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "8867ddce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Classify the sentiment of a review as either 'negative', 'neutral', or 'positive'.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Review: The review text to classify.\n",
      "Classifier Decision: The sentiment classification proposed by a model fine-tuned on sentiment.\n",
      "Classification: One word representing the sentiment classification: 'negative', 'neutral', or 'positive' (do not repeat the field name, do not use 'mixed')\n",
      "\n",
      "---\n",
      "\n",
      "Review: Those 2 drinks are part of the HK culture and has years of history. It is so bad.\n",
      "Classifier Decision: negative\n",
      "Classification:\u001b[32m negative\u001b[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\n\\nClassify the sentiment of a review as either 'negative', 'neutral', or 'positive'.\\n\\n---\\n\\nFollow the following format.\\n\\nReview: The review text to classify.\\nClassifier Decision: The sentiment classification proposed by a model fine-tuned on sentiment.\\nClassification: One word representing the sentiment classification: 'negative', 'neutral', or 'positive' (do not repeat the field name, do not use 'mixed')\\n\\n---\\n\\nReview: Those 2 drinks are part of the HK culture and has years of history. It is so bad.\\nClassifier Decision: negative\\nClassification:\\x1b[32m negative\\x1b[0m\\n\\n\\n\""
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "b13fd9ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Experiment: E13-G4OM-ELFT\n",
      "--------------------------------------------------------------------------------\n",
      "Start time: 2025-03-26 11:08:45\n",
      "Notes: Experiment 13: Evaluate prompt-based model collaboration between GPT-4o-mini and Electra Large fine-tuned model\n",
      "Model: gpt-4o-mini-2024-07-18\n",
      "Instance: electra_large_gpt_sentiment\n",
      "Dataset shape: [6530, 4]\n",
      "Examples length: 6530\n",
      "Save directory: results_round2_take2\n",
      "Temperature: 0.1\n",
      "Random seed: 123\n",
      "\n",
      "Running evaluation...\n",
      "Average Metric: 5533 / 6530  (84.7): 100%|██████████| 6530/6530 [1:01:31<00:00,  1.77it/s]\n",
      "\n",
      "Columns in results DataFrame:\n",
      "review                 6530 values\n",
      "classification         6530 values\n",
      "prediction             6530 values\n",
      "match                  6530 values\n",
      "classifier_decision    6530 values\n",
      "probabilities          6530 values\n",
      "\n",
      "Source value counts:\n",
      "dynasent_r1            3600\n",
      "sst_local              2210\n",
      "dynasent_r2             720\n",
      "\n",
      "Prediction value counts:\n",
      "negative               2497\n",
      "positive               2228\n",
      "neutral                1805\n",
      "\n",
      "E13-G4OM-ELFT Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.8494    0.9018    0.8748      2352\n",
      "     neutral     0.7684    0.7583    0.7633      1829\n",
      "    positive     0.9089    0.8621    0.8849      2349\n",
      "\n",
      "    accuracy                         0.8473      6530\n",
      "   macro avg     0.8422    0.8407    0.8410      6530\n",
      "weighted avg     0.8481    0.8473    0.8472      6530\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative       2121      200        31\n",
      "neutral         270     1387       172\n",
      "positive        106      218      2025\n",
      "\n",
      "\n",
      "E13-G4OM-ELFT-DYN-R1 Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.9112    0.8892    0.9000      1200\n",
      "     neutral     0.8050    0.9117    0.8550      1200\n",
      "    positive     0.9355    0.8342    0.8819      1200\n",
      "\n",
      "    accuracy                         0.8783      3600\n",
      "   macro avg     0.8839    0.8783    0.8790      3600\n",
      "weighted avg     0.8839    0.8783    0.8790      3600\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative       1067      116        17\n",
      "neutral          54     1094        52\n",
      "positive         50      149      1001\n",
      "\n",
      "\n",
      "E13-G4OM-ELFT-DYN-R2 Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.7508    0.9417    0.8355       240\n",
      "     neutral     0.8377    0.6667    0.7425       240\n",
      "    positive     0.8289    0.7875    0.8077       240\n",
      "\n",
      "    accuracy                         0.7986       720\n",
      "   macro avg     0.8058    0.7986    0.7952       720\n",
      "weighted avg     0.8058    0.7986    0.7952       720\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative        226        9         5\n",
      "neutral          46      160        34\n",
      "positive         29       22       189\n",
      "\n",
      "\n",
      "E13-G4OM-ELFT-SST Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.8078    0.9079    0.8549       912\n",
      "     neutral     0.5216    0.3419    0.4130       389\n",
      "    positive     0.8978    0.9186    0.9081       909\n",
      "\n",
      "    accuracy                         0.8127      2210\n",
      "   macro avg     0.7424    0.7228    0.7254      2210\n",
      "weighted avg     0.7945    0.8127    0.7990      2210\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative        828       75         9\n",
      "neutral         170      133        86\n",
      "positive         27       47       835\n",
      "\n",
      "Saving results to 'results_round2_take2'...\n",
      "\n",
      "Summary Metrics:\n",
      "Dataset     \tF1 (macro)\tAccuracy\n",
      "---------------------------------------------\n",
      "Merged      \t    84.10\t   84.73\n",
      "DynaSent R1 \t    87.90\t   87.83\n",
      "DynaSent R2 \t    79.52\t   79.86\n",
      "SST-3       \t    72.54\t   81.27\n",
      "\n",
      "Evaluation completed\n",
      "End time: 2025-03-26 12:10:17\n",
      "Duration: 1:01:32.320269\n"
     ]
    }
   ],
   "source": [
    "e13_g4om_elft_metrics = evaluate_experiment(\n",
    "    name='E13-G4OM-ELFT',\n",
    "    notes='Experiment 13: Evaluate prompt-based model collaboration between GPT-4o-mini and Electra Large fine-tuned model',\n",
    "    lm='gpt-4o-mini-2024-07-18',\n",
    "    instance='electra_large_gpt_sentiment',\n",
    "    dataset=test_df,\n",
    "    examples=test_ex,\n",
    "    temperature=temperature,\n",
    "    random_seed=random_seed\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2a2a10",
   "metadata": {},
   "source": [
    "#### E14-G4OMFT-ELFT-P-M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "cc5cb091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a test result for the GPT sentiment module\n",
    "e14_g4omft_elft_p_m_result = gpt_4o_mini_min_sentiment_with_pred(review=test_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "bfade659",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classification': 'negative'}"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e14_g4omft_elft_p_m_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "f987f39d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': \"You are a model that classifies the sentiment of a review as either 'positive', 'neutral', or 'negative'. 'Classifier Decision' is the sentiment classification proposed by a model fine-tuned on sentiment.\"},\n",
       " {'role': 'user',\n",
       "  'content': 'Classifier Decision: negative.\\nReview: Those 2 drinks are part of the HK culture and has years of history. It is so bad.'},\n",
       " {'role': 'assistant', 'content': 'negative'}]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_4o_mini_min_sentiment_with_pred.get_last_conversation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "decf680b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "209337a5f8b246f9a786e45187e62a3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6530 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "e14_g4omft_elft_p_m_results_df = process_batch(gpt_4o_mini_min_sentiment_with_pred, test_df, input_format='dataframe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "411869d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Experiment: E14-G4OMFT-ELFT-P-M\n",
      "--------------------------------------------------------------------------------\n",
      "Start time: 2025-03-18 09:14:46\n",
      "Notes: Experiment 14: Evaluate prompt-based model collaboration using a minimal format\n",
      "Model: ft:gpt-4o-mini-2024-07-18:personal::ALnBCKLv\n",
      "Instance: gpt_4o_mini_min_sentiment_with_pred\n",
      "Dataset shape: [6530, 4]\n",
      "Examples length: 6530\n",
      "Results shape: [6530, 4]\n",
      "Save directory: results_round2\n",
      "\n",
      "Source value counts:\n",
      "dynasent_r1            3600\n",
      "sst_local              2210\n",
      "dynasent_r2             720\n",
      "\n",
      "Prediction value counts:\n",
      "neutral                2912\n",
      "positive               2249\n",
      "negative               1369\n",
      "\n",
      "E14-G4OMFT-ELFT-P-M Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.9072    0.5281    0.6676      2352\n",
      "     neutral     0.5440    0.8660    0.6682      1829\n",
      "    positive     0.9160    0.8770    0.8960      2349\n",
      "\n",
      "    accuracy                         0.7482      6530\n",
      "   macro avg     0.7891    0.7570    0.7439      6530\n",
      "weighted avg     0.8086    0.7482    0.7499      6530\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative       1242     1073        37\n",
      "neutral          93     1584       152\n",
      "positive         34      255      2060\n",
      "\n",
      "\n",
      "E14-G4OMFT-ELFT-P-M-DYN-R1 Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.9574    0.4875    0.6461      1200\n",
      "     neutral     0.5992    0.9717    0.7413      1200\n",
      "    positive     0.9569    0.8317    0.8899      1200\n",
      "\n",
      "    accuracy                         0.7636      3600\n",
      "   macro avg     0.8378    0.7636    0.7591      3600\n",
      "weighted avg     0.8378    0.7636    0.7591      3600\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative        585      599        16\n",
      "neutral           5     1166        29\n",
      "positive         21      181       998\n",
      "\n",
      "\n",
      "E14-G4OMFT-ELFT-P-M-DYN-R2 Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.9521    0.6625    0.7813       240\n",
      "     neutral     0.6776    0.8583    0.7574       240\n",
      "    positive     0.8434    0.8750    0.8589       240\n",
      "\n",
      "    accuracy                         0.7986       720\n",
      "   macro avg     0.8244    0.7986    0.7992       720\n",
      "weighted avg     0.8244    0.7986    0.7992       720\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative        159       72         9\n",
      "neutral           4      206        30\n",
      "positive          4       26       210\n",
      "\n",
      "\n",
      "E14-G4OMFT-ELFT-P-M-SST Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.8426    0.5461    0.6627       912\n",
      "     neutral     0.3202    0.5450    0.4034       389\n",
      "    positive     0.8903    0.9373    0.9132       909\n",
      "\n",
      "    accuracy                         0.7068      2210\n",
      "   macro avg     0.6844    0.6761    0.6598      2210\n",
      "weighted avg     0.7703    0.7068    0.7201      2210\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative        498      402        12\n",
      "neutral          84      212        93\n",
      "positive          9       48       852\n",
      "\n",
      "Saving results to 'results_round2'...\n",
      "\n",
      "Summary Metrics:\n",
      "Dataset     \tF1 (macro)\tAccuracy\n",
      "---------------------------------------------\n",
      "Merged      \t    74.39\t   74.82\n",
      "DynaSent R1 \t    75.91\t   76.36\n",
      "DynaSent R2 \t    79.92\t   79.86\n",
      "SST-3       \t    65.98\t   70.68\n",
      "\n",
      "Evaluation completed\n",
      "End time: 2025-03-18 09:14:47\n",
      "Duration: 0:00:00.454745\n"
     ]
    }
   ],
   "source": [
    "e14_g4omft_elft_p_m_metrics = evaluate_experiment(\n",
    "    name='E14-G4OMFT-ELFT-P-M',\n",
    "    notes='Experiment 14: Evaluate prompt-based model collaboration using a minimal format',\n",
    "    lm='ft:gpt-4o-mini-2024-07-18:personal::ALnBCKLv',\n",
    "    instance='gpt_4o_mini_min_sentiment_with_pred',\n",
    "    dataset=test_df,\n",
    "    examples=test_ex,\n",
    "    results=e14_g4omft_elft_p_m_results_df,\n",
    "    temperature=temperature,\n",
    "    random_seed=random_seed\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803bcb9e",
   "metadata": {},
   "source": [
    "### E15-G4OM-ELFT-EX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f6a3bb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch to the correct language model and disable experimental mode\n",
    "lm = dspy.OpenAI(model='gpt-4o-mini-2024-07-18', api_key=openai_key, max_tokens=8192, temperature=temperature)\n",
    "dspy.settings.configure(lm=lm, experimental=False, seed=random_seed)\n",
    "dsp.settings.show_guidelines = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "ec54b824",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:opentelemetry.sdk.trace.export:Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 801, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/util/retry.py\", line 552, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/packages/six.py\", line 769, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 191, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 161, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 135, in _export\n",
      "    return self._session.post(\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/jim/miniconda3/envs/nlu/lib/python3.9/site-packages/requests/adapters.py\", line 682, in send\n",
      "    raise ConnectionError(err, request=request)\n",
      "requests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))\n"
     ]
    }
   ],
   "source": [
    "# Create a test result for the GPT sentiment module\n",
    "e15_g4om_elft_ex_result = electra_large_gpt_sentiment_examples(review=test_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "0c4d600a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    examples=[{'index': 1385, 'similarity_score': 0.9959219694137573, 'review': 'I remembered this place from a few years ago. It was really bad.', 'classification': 'negative'}, {'index': 1770, 'similarity_score': 0.9956880211830139, 'review': \"But I've been probably 6 times and have never left impressed. It sucks.\", 'classification': 'negative'}, {'index': 1948, 'similarity_score': 0.9954952597618103, 'review': 'So got beans, rice and tacos, no flavour.', 'classification': 'negative'}, {'index': 3282, 'similarity_score': 0.995331346988678, 'review': 'Anyhoos, we waited FOREVER (more like an hour plus) for our food.', 'classification': 'negative'}, {'index': 1391, 'similarity_score': 0.9952993392944336, 'review': 'The loyalty card is not worth it.', 'classification': 'negative'}],\n",
       "    classification='negative',\n",
       "    classifier_decision='negative',\n",
       "    probabilities=[0.9990077614784241, 0.0005539217963814735, 0.000438391842180863]\n",
       ")"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e15_g4om_elft_ex_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "e7fc3e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Classify the sentiment of a review as either 'negative', 'neutral', or 'positive'.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Examples: A list of examples that demonstrate different sentiment classes.\n",
      "\n",
      "Review: The review text to classify.\n",
      "\n",
      "Classifier Decision: The sentiment classification proposed by a model fine-tuned on sentiment.\n",
      "\n",
      "Classification: One word representing the sentiment classification: 'negative', 'neutral', or 'positive' (do not repeat the field name, do not use 'mixed')\n",
      "\n",
      "---\n",
      "\n",
      "Examples:\n",
      "- negative: I remembered this place from a few years ago. It was really bad.\n",
      "- negative: But I've been probably 6 times and have never left impressed. It sucks.\n",
      "- negative: So got beans, rice and tacos, no flavour.\n",
      "- negative: Anyhoos, we waited FOREVER (more like an hour plus) for our food.\n",
      "- negative: The loyalty card is not worth it.\n",
      "\n",
      "Review: Those 2 drinks are part of the HK culture and has years of history. It is so bad.\n",
      "\n",
      "Classifier Decision: negative\n",
      "\n",
      "Classification:\u001b[32m negative\u001b[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\n\\nClassify the sentiment of a review as either 'negative', 'neutral', or 'positive'.\\n\\n---\\n\\nFollow the following format.\\n\\nExamples: A list of examples that demonstrate different sentiment classes.\\n\\nReview: The review text to classify.\\n\\nClassifier Decision: The sentiment classification proposed by a model fine-tuned on sentiment.\\n\\nClassification: One word representing the sentiment classification: 'negative', 'neutral', or 'positive' (do not repeat the field name, do not use 'mixed')\\n\\n---\\n\\nExamples:\\n- negative: I remembered this place from a few years ago. It was really bad.\\n- negative: But I've been probably 6 times and have never left impressed. It sucks.\\n- negative: So got beans, rice and tacos, no flavour.\\n- negative: Anyhoos, we waited FOREVER (more like an hour plus) for our food.\\n- negative: The loyalty card is not worth it.\\n\\nReview: Those 2 drinks are part of the HK culture and has years of history. It is so bad.\\n\\nClassifier Decision: negative\\n\\nClassification:\\x1b[32m negative\\x1b[0m\\n\\n\\n\""
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "cb683c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Experiment: E15-G4OM-ELFT-EX\n",
      "--------------------------------------------------------------------------------\n",
      "Start time: 2025-03-26 12:14:45\n",
      "Notes: Experiment 15: Evaluate prompt-based model collaboration that includes similar examples\n",
      "Model: gpt-4o-mini-2024-07-18\n",
      "Instance: electra_large_gpt_sentiment_examples\n",
      "Dataset shape: [6530, 4]\n",
      "Examples length: 6530\n",
      "Save directory: results_round2_take2\n",
      "Temperature: 0.1\n",
      "Random seed: 123\n",
      "\n",
      "Running evaluation...\n",
      "Average Metric: 5497 / 6530  (84.2): 100%|██████████| 6530/6530 [1:26:30<00:00,  1.26it/s]  \n",
      "\n",
      "Columns in results DataFrame:\n",
      "review                 6530 values\n",
      "classification         6530 values\n",
      "prediction             6530 values\n",
      "match                  6530 values\n",
      "classifier_decision    6530 values\n",
      "probabilities          6530 values\n",
      "\n",
      "Source value counts:\n",
      "dynasent_r1            3600\n",
      "sst_local              2210\n",
      "dynasent_r2             720\n",
      "\n",
      "Prediction value counts:\n",
      "negative               2438\n",
      "positive               2188\n",
      "neutral                1904\n",
      "\n",
      "E15-G4OM-ELFT-EX Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.8527    0.8839    0.8681      2352\n",
      "     neutral     0.7426    0.7731    0.7576      1829\n",
      "    positive     0.9159    0.8531    0.8834      2349\n",
      "\n",
      "    accuracy                         0.8418      6530\n",
      "   macro avg     0.8371    0.8367    0.8363      6530\n",
      "weighted avg     0.8446    0.8418    0.8426      6530\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative       2079      247        26\n",
      "neutral         257     1414       158\n",
      "positive        102      243      2004\n",
      "\n",
      "\n",
      "E15-G4OM-ELFT-EX-DYN-R1 Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.9100    0.8683    0.8887      1200\n",
      "     neutral     0.7839    0.9192    0.8462      1200\n",
      "    positive     0.9427    0.8233    0.8790      1200\n",
      "\n",
      "    accuracy                         0.8703      3600\n",
      "   macro avg     0.8789    0.8703    0.8713      3600\n",
      "weighted avg     0.8789    0.8703    0.8713      3600\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative       1042      144        14\n",
      "neutral          51     1103        46\n",
      "positive         52      160       988\n",
      "\n",
      "\n",
      "E15-G4OM-ELFT-EX-DYN-R2 Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.7743    0.9292    0.8447       240\n",
      "     neutral     0.8218    0.6917    0.7511       240\n",
      "    positive     0.8304    0.7958    0.8128       240\n",
      "\n",
      "    accuracy                         0.8056       720\n",
      "   macro avg     0.8088    0.8056    0.8029       720\n",
      "weighted avg     0.8088    0.8056    0.8029       720\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative        223       11         6\n",
      "neutral          41      166        33\n",
      "positive         24       25       191\n",
      "\n",
      "\n",
      "E15-G4OM-ELFT-EX-SST Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.8100    0.8925    0.8492       912\n",
      "     neutral     0.4915    0.3728    0.4240       389\n",
      "    positive     0.9066    0.9076    0.9071       909\n",
      "\n",
      "    accuracy                         0.8072      2210\n",
      "   macro avg     0.7360    0.7243    0.7268      2210\n",
      "weighted avg     0.7937    0.8072    0.7982      2210\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative        814       92         6\n",
      "neutral         165      145        79\n",
      "positive         26       58       825\n",
      "\n",
      "Saving results to 'results_round2_take2'...\n",
      "\n",
      "Summary Metrics:\n",
      "Dataset     \tF1 (macro)\tAccuracy\n",
      "---------------------------------------------\n",
      "Merged      \t    83.63\t   84.18\n",
      "DynaSent R1 \t    87.13\t   87.03\n",
      "DynaSent R2 \t    80.29\t   80.56\n",
      "SST-3       \t    72.68\t   80.72\n",
      "\n",
      "Evaluation completed\n",
      "End time: 2025-03-26 13:41:17\n",
      "Duration: 1:26:31.823081\n"
     ]
    }
   ],
   "source": [
    "e15_g4om_elft_ex_metrics = evaluate_experiment(\n",
    "    name='E15-G4OM-ELFT-EX',\n",
    "    notes='Experiment 15: Evaluate prompt-based model collaboration that includes similar examples',\n",
    "    lm='gpt-4o-mini-2024-07-18',\n",
    "    instance='electra_large_gpt_sentiment_examples',\n",
    "    dataset=test_df,\n",
    "    examples=test_ex,\n",
    "    temperature=temperature,\n",
    "    random_seed=random_seed\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0cb3fe",
   "metadata": {},
   "source": [
    "### E16-G4OM-ELFT-PR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d7b32d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch to the correct language model and disable experimental mode\n",
    "lm = dspy.OpenAI(model='gpt-4o-mini-2024-07-18', api_key=openai_key, max_tokens=8192, temperature=temperature)\n",
    "dspy.settings.configure(lm=lm, experimental=False, seed=random_seed)\n",
    "dsp.settings.show_guidelines = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "53b8d467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a test result for the GPT sentiment module\n",
    "e16_g4om_elft_pr_result = electra_large_gpt_sentiment_probs(review=test_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "d3b761d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    classification='negative',\n",
       "    negative_probability='99.90%',\n",
       "    neutral_probability='0.06%',\n",
       "    positive_probability='0.04%'\n",
       ")"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e16_g4om_elft_pr_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "b5d896a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Classify the sentiment of a review as either 'negative', 'neutral', or 'positive'.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Review: The review text to classify.\n",
      "\n",
      "Negative Probability: Probability the review is negative from a model fine-tuned on sentiment\n",
      "\n",
      "Neutral Probability: Probability the review is neutral from a model fine-tuned on sentiment\n",
      "\n",
      "Positive Probability: Probability the review is positive from a model fine-tuned on sentiment\n",
      "\n",
      "Classification: One word representing the sentiment classification: 'negative', 'neutral', or 'positive' (do not repeat the field name, do not use 'mixed')\n",
      "\n",
      "---\n",
      "\n",
      "Review: Those 2 drinks are part of the HK culture and has years of history. It is so bad.\n",
      "\n",
      "Negative Probability: 99.90%\n",
      "\n",
      "Neutral Probability: 0.06%\n",
      "\n",
      "Positive Probability: 0.04%\n",
      "\n",
      "Classification:\u001b[32m negative\u001b[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\n\\nClassify the sentiment of a review as either 'negative', 'neutral', or 'positive'.\\n\\n---\\n\\nFollow the following format.\\n\\nReview: The review text to classify.\\n\\nNegative Probability: Probability the review is negative from a model fine-tuned on sentiment\\n\\nNeutral Probability: Probability the review is neutral from a model fine-tuned on sentiment\\n\\nPositive Probability: Probability the review is positive from a model fine-tuned on sentiment\\n\\nClassification: One word representing the sentiment classification: 'negative', 'neutral', or 'positive' (do not repeat the field name, do not use 'mixed')\\n\\n---\\n\\nReview: Those 2 drinks are part of the HK culture and has years of history. It is so bad.\\n\\nNegative Probability: 99.90%\\n\\nNeutral Probability: 0.06%\\n\\nPositive Probability: 0.04%\\n\\nClassification:\\x1b[32m negative\\x1b[0m\\n\\n\\n\""
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "960405f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Experiment: E16-G4OM-ELFT-PR\n",
      "--------------------------------------------------------------------------------\n",
      "Start time: 2025-03-26 13:45:45\n",
      "Notes: Experiment 16: Evaluate prompt-based model collaboration with probabilities\n",
      "Model: gpt-4o-mini-2024-07-18\n",
      "Instance: electra_large_gpt_sentiment_probs\n",
      "Dataset shape: [6530, 4]\n",
      "Examples length: 6530\n",
      "Save directory: results_round2_take2\n",
      "Temperature: 0.1\n",
      "Random seed: 123\n",
      "\n",
      "Running evaluation...\n",
      "Average Metric: 5490 / 6530  (84.1): 100%|██████████| 6530/6530 [1:50:26<00:00,  1.01s/it]  \n",
      "\n",
      "Columns in results DataFrame:\n",
      "review                 6530 values\n",
      "classification         6530 values\n",
      "prediction             6530 values\n",
      "match                  6530 values\n",
      "\n",
      "Source value counts:\n",
      "dynasent_r1            3600\n",
      "sst_local              2210\n",
      "dynasent_r2             720\n",
      "\n",
      "Prediction value counts:\n",
      "positive               2353\n",
      "negative               2271\n",
      "neutral                1903\n",
      "review: if you don't have a groupon and are planning to eat at this place, you are out of your mind.\n",
      "\n",
      "negative probability: 85.12%\n",
      "\n",
      "neutral probability: 10.34%\n",
      "\n",
      "positive probability: 4.54%\n",
      "\n",
      "classification: negative      1\n",
      "review: found the place to be in this local restaurant wasteland.\n",
      "\n",
      "negative probability: 99.85%\n",
      "\n",
      "neutral probability: 0.10%\n",
      "\n",
      "positive probability: 0.05%\n",
      "\n",
      "classification: negative      1\n",
      "review: loyal customers, good customers, are treated with abandon here!\n",
      "\n",
      "negative probability: 99.85%\n",
      "\n",
      "neutral probability: 0.10%\n",
      "\n",
      "positive probability: 0.05%\n",
      "\n",
      "classification: negative      1\n",
      "\n",
      "Found 3 invalid predictions at row indices:\n",
      "[1201, 4058, 4436]\n",
      "\n",
      "Invalid prediction rows:\n",
      "                                                                                          sentence  \\\n",
      "1201  If you don't have a groupon and are planning to eat at this place, you are out of your mind.   \n",
      "4058                                     Found the place to be in this local restaurant wasteland.   \n",
      "4436                               Loyal customers, good customers, are treated with abandon here!   \n",
      "\n",
      "         label       source split  \n",
      "1201  negative  dynasent_r1  test  \n",
      "4058  negative  dynasent_r2  test  \n",
      "4436  negative  dynasent_r2  test  \n",
      "\n",
      "WARNING: Invalid predictions found. Please review the above details and re-run problematic cases.\n"
     ]
    }
   ],
   "source": [
    "e16_g4om_elft_pr_metrics = evaluate_experiment(\n",
    "    name='E16-G4OM-ELFT-PR',\n",
    "    notes='Experiment 16: Evaluate prompt-based model collaboration with probabilities',\n",
    "    lm='gpt-4o-mini-2024-07-18',\n",
    "    instance='electra_large_gpt_sentiment_probs',\n",
    "    dataset=test_df,\n",
    "    examples=test_ex,\n",
    "    temperature=temperature,\n",
    "    random_seed=random_seed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c14b6f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "e16_g4om_elft_pr_results_df = e16_g4om_elft_pr_metrics[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "29fd6ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_indices = [1201, 4058, 4436]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "4805a9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "e16_g4om_elft_pr_results_df.loc[invalid_indices, 'prediction'] = e16_g4om_elft_pr_results_df.loc[invalid_indices, 'classification']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "d2d6d9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "e16_g4om_elft_pr_results_df_orig = pd.DataFrame.copy(e16_g4om_elft_pr_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "34b6bbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Define the regular expression pattern to extract the classification label\n",
    "pattern = r\"classification:\\s*(\\w+)\"\n",
    "\n",
    "# Function to extract classification from the prediction text and update the prediction column\n",
    "def update_prediction(row):\n",
    "    match = re.search(pattern, row['prediction'])\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    return row['prediction']  # Keep the original if no match found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "18549e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to the invalid rows\n",
    "e16_g4om_elft_pr_results_df.loc[invalid_indices, 'prediction'] = e16_g4om_elft_pr_results_df.loc[invalid_indices].apply(update_prediction, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "57307ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated rows:\n",
      "                                                                                            review  \\\n",
      "1201  If you don't have a groupon and are planning to eat at this place, you are out of your mind.   \n",
      "4058                                     Found the place to be in this local restaurant wasteland.   \n",
      "4436                               Loyal customers, good customers, are treated with abandon here!   \n",
      "\n",
      "     classification prediction  \n",
      "1201       negative   negative  \n",
      "4058       negative   negative  \n",
      "4436       negative   negative  \n"
     ]
    }
   ],
   "source": [
    "# Verify the changes\n",
    "print(\"Updated rows:\")\n",
    "print(e16_g4om_elft_pr_results_df.loc[invalid_indices, ['review', 'classification', 'prediction']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "b6bc2abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Experiment: E16-G4OM-ELFT-PR\n",
      "--------------------------------------------------------------------------------\n",
      "Start time: 2025-03-26 16:10:02\n",
      "Notes: Experiment 16: Evaluate prompt-based model collaboration with probabilities\n",
      "Model: gpt-4o-mini-2024-07-18\n",
      "Instance: electra_large_gpt_sentiment_probs\n",
      "Dataset shape: [6530, 4]\n",
      "Examples length: 6530\n",
      "Results shape: [6530, 5]\n",
      "Save directory: results_round2_take2\n",
      "\n",
      "Source value counts:\n",
      "dynasent_r1            3600\n",
      "sst_local              2210\n",
      "dynasent_r2             720\n",
      "\n",
      "Prediction value counts:\n",
      "positive               2353\n",
      "negative               2274\n",
      "neutral                1903\n",
      "\n",
      "E16-G4OM-ELFT-PR Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.8813    0.8520    0.8664      2352\n",
      "     neutral     0.7446    0.7747    0.7594      1829\n",
      "    positive     0.8793    0.8808    0.8801      2349\n",
      "\n",
      "    accuracy                         0.8407      6530\n",
      "   macro avg     0.8351    0.8359    0.8353      6530\n",
      "weighted avg     0.8423    0.8407    0.8413      6530\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative       2004      262        86\n",
      "neutral         214     1417       198\n",
      "positive         56      224      2069\n",
      "\n",
      "\n",
      "E16-G4OM-ELFT-PR-DYN-R1 Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.9317    0.8300    0.8779      1200\n",
      "     neutral     0.7817    0.9250    0.8473      1200\n",
      "    positive     0.9127    0.8450    0.8775      1200\n",
      "\n",
      "    accuracy                         0.8667      3600\n",
      "   macro avg     0.8754    0.8667    0.8676      3600\n",
      "weighted avg     0.8754    0.8667    0.8676      3600\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative        996      159        45\n",
      "neutral          38     1110        52\n",
      "positive         35      151      1014\n",
      "\n",
      "\n",
      "E16-G4OM-ELFT-PR-DYN-R2 Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.8086    0.8625    0.8347       240\n",
      "     neutral     0.8265    0.6750    0.7431       240\n",
      "    positive     0.7761    0.8667    0.8189       240\n",
      "\n",
      "    accuracy                         0.8014       720\n",
      "   macro avg     0.8037    0.8014    0.7989       720\n",
      "weighted avg     0.8037    0.8014    0.7989       720\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative        207       14        19\n",
      "neutral          37      162        41\n",
      "positive         12       20       208\n",
      "\n",
      "\n",
      "E16-G4OM-ELFT-PR-SST Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.8440    0.8783    0.8608       912\n",
      "     neutral     0.5052    0.3728    0.4290       389\n",
      "    positive     0.8696    0.9318    0.8996       909\n",
      "\n",
      "    accuracy                         0.8113      2210\n",
      "   macro avg     0.7396    0.7276    0.7298      2210\n",
      "weighted avg     0.7949    0.8113    0.8008      2210\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative        801       89        22\n",
      "neutral         139      145       105\n",
      "positive          9       53       847\n",
      "\n",
      "Saving results to 'results_round2_take2'...\n",
      "\n",
      "Summary Metrics:\n",
      "Dataset     \tF1 (macro)\tAccuracy\n",
      "---------------------------------------------\n",
      "Merged      \t    83.53\t   84.07\n",
      "DynaSent R1 \t    86.76\t   86.67\n",
      "DynaSent R2 \t    79.89\t   80.14\n",
      "SST-3       \t    72.98\t   81.13\n",
      "\n",
      "Evaluation completed\n",
      "End time: 2025-03-26 16:10:02\n",
      "Duration: 0:00:00.435981\n"
     ]
    }
   ],
   "source": [
    "e16_g4om_elft_pr_metrics = evaluate_experiment(\n",
    "    name='E16-G4OM-ELFT-PR',\n",
    "    notes='Experiment 16: Evaluate prompt-based model collaboration with probabilities',\n",
    "    lm='gpt-4o-mini-2024-07-18',\n",
    "    instance='electra_large_gpt_sentiment_probs',\n",
    "    dataset=test_df,\n",
    "    examples=test_ex,\n",
    "    results=e16_g4om_elft_pr_results_df,\n",
    "    temperature=temperature,\n",
    "    random_seed=random_seed\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ec8cf7",
   "metadata": {},
   "source": [
    "### E17-G4OM-ELFT-PR2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "48c74e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch to the correct language model and disable experimental mode\n",
    "lm = dspy.OpenAI(model='gpt-4o-mini-2024-07-18', api_key=openai_key, max_tokens=8192, temperature=temperature)\n",
    "dspy.settings.configure(lm=lm, experimental=False, seed=random_seed)\n",
    "dsp.settings.show_guidelines = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "ac9fae3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a test result for the GPT sentiment module\n",
    "e17_g4om_elft_pr2_result = electra_large_gpt_sentiment_pred_probs(review=test_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "992cf1f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    classification='negative',\n",
       "    classifier_decision='negative',\n",
       "    negative_probability='99.90%',\n",
       "    neutral_probability='0.06%',\n",
       "    positive_probability='0.04%'\n",
       ")"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e17_g4om_elft_pr2_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "04f91186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Classify the sentiment of a review as either 'negative', 'neutral', or 'positive'.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Review: The review text to classify.\n",
      "\n",
      "Classifier Decision: The sentiment classification proposed by a model fine-tuned on sentiment.\n",
      "\n",
      "Negative Probability: Probability the review is negative\n",
      "\n",
      "Neutral Probability: Probability the review is neutral\n",
      "\n",
      "Positive Probability: Probability the review is positive\n",
      "\n",
      "Classification: One word representing the sentiment classification: 'negative', 'neutral', or 'positive' (do not repeat the field name, do not use 'mixed')\n",
      "\n",
      "---\n",
      "\n",
      "Review: Those 2 drinks are part of the HK culture and has years of history. It is so bad.\n",
      "\n",
      "Classifier Decision: negative\n",
      "\n",
      "Negative Probability: 99.90%\n",
      "\n",
      "Neutral Probability: 0.06%\n",
      "\n",
      "Positive Probability: 0.04%\n",
      "\n",
      "Classification:\u001b[32m negative\u001b[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\n\\nClassify the sentiment of a review as either 'negative', 'neutral', or 'positive'.\\n\\n---\\n\\nFollow the following format.\\n\\nReview: The review text to classify.\\n\\nClassifier Decision: The sentiment classification proposed by a model fine-tuned on sentiment.\\n\\nNegative Probability: Probability the review is negative\\n\\nNeutral Probability: Probability the review is neutral\\n\\nPositive Probability: Probability the review is positive\\n\\nClassification: One word representing the sentiment classification: 'negative', 'neutral', or 'positive' (do not repeat the field name, do not use 'mixed')\\n\\n---\\n\\nReview: Those 2 drinks are part of the HK culture and has years of history. It is so bad.\\n\\nClassifier Decision: negative\\n\\nNegative Probability: 99.90%\\n\\nNeutral Probability: 0.06%\\n\\nPositive Probability: 0.04%\\n\\nClassification:\\x1b[32m negative\\x1b[0m\\n\\n\\n\""
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "8ee1be78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Experiment: E17-G4OM-ELFT-PR2\n",
      "--------------------------------------------------------------------------------\n",
      "Start time: 2025-03-26 16:10:24\n",
      "Notes: Experiment 17: Evaluate prompt-based model collaboration with prediction and probabilities\n",
      "Model: gpt-4o-mini-2024-07-18\n",
      "Instance: electra_large_gpt_sentiment_pred_probs\n",
      "Dataset shape: [6530, 4]\n",
      "Examples length: 6530\n",
      "Save directory: results_round2_take2\n",
      "Temperature: 0.1\n",
      "Random seed: 123\n",
      "\n",
      "Running evaluation...\n",
      "Average Metric: 5516 / 6530  (84.5): 100%|██████████| 6530/6530 [1:55:53<00:00,  1.06s/it]  \n",
      "\n",
      "Columns in results DataFrame:\n",
      "review                 6530 values\n",
      "classification         6530 values\n",
      "prediction             6530 values\n",
      "match                  6530 values\n",
      "classifier_decision    6530 values\n",
      "\n",
      "Source value counts:\n",
      "dynasent_r1            3600\n",
      "sst_local              2210\n",
      "dynasent_r2             720\n",
      "\n",
      "Prediction value counts:\n",
      "negative               2363\n",
      "positive               2311\n",
      "neutral                1850\n",
      "review: they gratefully charge 5% more and do an amazing nothing extra.\n",
      "\n",
      "classifier decision: negative\n",
      "\n",
      "negative probability: 85.12%\n",
      "\n",
      "neutral probability: 10.45%\n",
      "\n",
      "positive probability: 4.43%\n",
      "\n",
      "classification: negative      1\n",
      "review: i cannot believe this place is so helpful.\n",
      "\n",
      "classifier decision: positive\n",
      "\n",
      "negative probability: 5.12%\n",
      "\n",
      "neutral probability: 3.45%\n",
      "\n",
      "positive probability: 91.43%\n",
      "\n",
      "classification: positive      1\n",
      "review: it is , by conventional standards , a fairly terrible movie ... but it is also weirdly fascinating , a ready-made eurotrash cult object .\n",
      "\n",
      "classifier decision: positive\n",
      "\n",
      "negative probability: 4.11%\n",
      "\n",
      "neutral probability: 48.59%\n",
      "\n",
      "positive probability: 47.30%\n",
      "\n",
      "classification: positive      1\n",
      "review: frozen meat patties are disgusting except for this brand.\n",
      "\n",
      "classifier decision: positive\n",
      "\n",
      "negative probability: 0.38%\n",
      "\n",
      "neutral probability: 0.07%\n",
      "\n",
      "positive probability: 99.56%\n",
      "\n",
      "classification: positive      1\n",
      "review: ringo sounded great at the concert if you had earplugs in and couldn't hear him sing over the recording\n",
      "\n",
      "classifier decision: negative\n",
      "\n",
      "negative probability: 85.67%\n",
      "\n",
      "neutral probability: 10.12%\n",
      "\n",
      "positive probability: 4.21%\n",
      "\n",
      "classification: negative      1\n",
      "review: we thought the price ($18) was too good to be true--and it was.\n",
      "\n",
      "classifier decision: negative\n",
      "\n",
      "negative probability: 89.75%\n",
      "\n",
      "neutral probability: 5.12%\n",
      "\n",
      "positive probability: 5.13%\n",
      "\n",
      "classification: negative      1\n",
      "\n",
      "Found 6 invalid predictions at row indices:\n",
      "[1076, 2209, 2312, 4234, 4815, 5873]\n",
      "\n",
      "Invalid prediction rows:\n",
      "                                                                                                                                       sentence  \\\n",
      "1076                                                                            They gratefully charge 5% more and do an amazing NOTHING extra.   \n",
      "2209                                                                                                 I cannot believe this place is so helpful.   \n",
      "2312  It is , by conventional standards , a fairly terrible movie ... but it is also weirdly fascinating , a ready-made Eurotrash cult object .   \n",
      "4234                                                                                  Frozen meat patties are disgusting except for this brand.   \n",
      "4815                                    Ringo sounded great at the concert if you had earplugs in and couldn't hear him sing over the recording   \n",
      "5873                                                                            We thought the price ($18) was too good to be true--and it was.   \n",
      "\n",
      "         label       source split  \n",
      "1076  negative  dynasent_r2  test  \n",
      "2209  positive  dynasent_r2  test  \n",
      "2312   neutral    sst_local  test  \n",
      "4234  positive  dynasent_r2  test  \n",
      "4815  negative  dynasent_r2  test  \n",
      "5873  negative  dynasent_r1  test  \n",
      "\n",
      "WARNING: Invalid predictions found. Please review the above details and re-run problematic cases.\n"
     ]
    }
   ],
   "source": [
    "e17_g4om_elft_pr2_df, e17_g4om_elft_pr2_metrics = evaluate_experiment(\n",
    "    name='E17-G4OM-ELFT-PR2',\n",
    "    notes='Experiment 17: Evaluate prompt-based model collaboration with prediction and probabilities',\n",
    "    lm='gpt-4o-mini-2024-07-18',\n",
    "    instance='electra_large_gpt_sentiment_pred_probs',\n",
    "    dataset=test_df,\n",
    "    examples=test_ex,\n",
    "    temperature=temperature,\n",
    "    random_seed=random_seed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "644fdd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_indices = [1076, 2209, 2312, 4234, 4815, 5873]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "39141246",
   "metadata": {},
   "outputs": [],
   "source": [
    "e17_g4om_elft_pr2_df_orig = pd.DataFrame.copy(e17_g4om_elft_pr2_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "100c46b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to the invalid rows\n",
    "e17_g4om_elft_pr2_df.loc[invalid_indices, 'prediction'] = e17_g4om_elft_pr2_df.loc[invalid_indices].apply(update_prediction, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "79341b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated rows:\n",
      "                                                                                                                                         review  \\\n",
      "1076                                                                            They gratefully charge 5% more and do an amazing NOTHING extra.   \n",
      "2209                                                                                                 I cannot believe this place is so helpful.   \n",
      "2312  It is , by conventional standards , a fairly terrible movie ... but it is also weirdly fascinating , a ready-made Eurotrash cult object .   \n",
      "4234                                                                                  Frozen meat patties are disgusting except for this brand.   \n",
      "4815                                    Ringo sounded great at the concert if you had earplugs in and couldn't hear him sing over the recording   \n",
      "5873                                                                            We thought the price ($18) was too good to be true--and it was.   \n",
      "\n",
      "     classification prediction  \n",
      "1076       negative   negative  \n",
      "2209       positive   positive  \n",
      "2312        neutral   positive  \n",
      "4234       positive   positive  \n",
      "4815       negative   negative  \n",
      "5873       negative   negative  \n"
     ]
    }
   ],
   "source": [
    "# Verify the changes\n",
    "print(\"Updated rows:\")\n",
    "print(e17_g4om_elft_pr2_df.loc[invalid_indices, ['review', 'classification', 'prediction']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "902836e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Experiment: E17-G4OM-ELFT-PR2\n",
      "--------------------------------------------------------------------------------\n",
      "Start time: 2025-03-27 05:36:55\n",
      "Notes: Experiment 17: Evaluate prompt-based model collaboration with prediction and probabilities\n",
      "Model: gpt-4o-mini-2024-07-18\n",
      "Instance: electra_large_gpt_sentiment_pred_probs\n",
      "Dataset shape: [6530, 4]\n",
      "Examples length: 6530\n",
      "Results shape: [6530, 6]\n",
      "Save directory: results_round2_take2\n",
      "\n",
      "Source value counts:\n",
      "dynasent_r1            3600\n",
      "sst_local              2210\n",
      "dynasent_r2             720\n",
      "\n",
      "Prediction value counts:\n",
      "negative               2366\n",
      "positive               2314\n",
      "neutral                1850\n",
      "\n",
      "E17-G4OM-ELFT-PR2 Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.8677    0.8729    0.8703      2352\n",
      "     neutral     0.7573    0.7660    0.7616      1829\n",
      "    positive     0.8911    0.8778    0.8844      2349\n",
      "\n",
      "    accuracy                         0.8447      6530\n",
      "   macro avg     0.8387    0.8389    0.8388      6530\n",
      "weighted avg     0.8452    0.8447    0.8449      6530\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative       2053      241        58\n",
      "neutral         234     1401       194\n",
      "positive         79      208      2062\n",
      "\n",
      "\n",
      "E17-G4OM-ELFT-PR2-DYN-R1 Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.9235    0.8550    0.8879      1200\n",
      "     neutral     0.7960    0.9200    0.8535      1200\n",
      "    positive     0.9201    0.8450    0.8810      1200\n",
      "\n",
      "    accuracy                         0.8733      3600\n",
      "   macro avg     0.8799    0.8733    0.8741      3600\n",
      "weighted avg     0.8799    0.8733    0.8741      3600\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative       1026      140        34\n",
      "neutral          42     1104        54\n",
      "positive         43      143      1014\n",
      "\n",
      "\n",
      "E17-G4OM-ELFT-PR2-DYN-R2 Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.7849    0.9125    0.8439       240\n",
      "     neutral     0.8377    0.6667    0.7425       240\n",
      "    positive     0.8040    0.8375    0.8204       240\n",
      "\n",
      "    accuracy                         0.8056       720\n",
      "   macro avg     0.8089    0.8056    0.8023       720\n",
      "weighted avg     0.8089    0.8056    0.8023       720\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative        219       12         9\n",
      "neutral          40      160        40\n",
      "positive         20       19       201\n",
      "\n",
      "\n",
      "E17-G4OM-ELFT-PR2-SST Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.8279    0.8860    0.8559       912\n",
      "     neutral     0.5037    0.3522    0.4145       389\n",
      "    positive     0.8805    0.9318    0.9054       909\n",
      "\n",
      "    accuracy                         0.8109      2210\n",
      "   macro avg     0.7373    0.7233    0.7253      2210\n",
      "weighted avg     0.7924    0.8109    0.7986      2210\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative        808       89        15\n",
      "neutral         152      137       100\n",
      "positive         16       46       847\n",
      "\n",
      "Saving results to 'results_round2_take2'...\n",
      "\n",
      "Summary Metrics:\n",
      "Dataset     \tF1 (macro)\tAccuracy\n",
      "---------------------------------------------\n",
      "Merged      \t    83.88\t   84.47\n",
      "DynaSent R1 \t    87.41\t   87.33\n",
      "DynaSent R2 \t    80.23\t   80.56\n",
      "SST-3       \t    72.53\t   81.09\n",
      "\n",
      "Evaluation completed\n",
      "End time: 2025-03-27 05:36:56\n",
      "Duration: 0:00:00.441209\n"
     ]
    }
   ],
   "source": [
    "e17_g4om_elft_pr2_metrics = evaluate_experiment(\n",
    "    name='E17-G4OM-ELFT-PR2',\n",
    "    notes='Experiment 17: Evaluate prompt-based model collaboration with prediction and probabilities',\n",
    "    lm='gpt-4o-mini-2024-07-18',\n",
    "    instance='electra_large_gpt_sentiment_pred_probs',\n",
    "    dataset=test_df,\n",
    "    examples=test_ex,\n",
    "    results=e17_g4om_elft_pr2_df,\n",
    "    temperature=temperature,\n",
    "    random_seed=random_seed\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6af2c5",
   "metadata": {},
   "source": [
    "### E18-G4OM-ELFT-EX-PR2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "9a83cdbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch to the correct language model and disable experimental mode\n",
    "lm = dspy.OpenAI(model='gpt-4o-mini-2024-07-18', api_key=openai_key, max_tokens=8192, temperature=temperature)\n",
    "dspy.settings.configure(lm=lm, experimental=False, seed=random_seed)\n",
    "dsp.settings.show_guidelines = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "6c5fcf02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    examples=[{'index': 1128, 'similarity_score': 1.0000001192092896, 'review': 'After some haggling, they offered $200 off.', 'classification': 'neutral'}, {'index': 155, 'similarity_score': 0.9981587529182434, 'review': 'So I mailed my check to HMFC and saved $499.', 'classification': 'positive'}, {'index': 3861, 'similarity_score': 0.9978066086769104, 'review': 'We were looking forward to that this year.', 'classification': 'positive'}, {'index': 3647, 'similarity_score': 0.9976930618286133, 'review': 'I was really looking forward to dining here.', 'classification': 'positive'}, {'index': 437, 'similarity_score': 0.9976181387901306, 'review': 'They had happy hour specials on food and drinks that just ended.', 'classification': 'neutral'}],\n",
       "    classification='positive',\n",
       "    classifier_decision='positive',\n",
       "    negative_probability='0.25%',\n",
       "    neutral_probability='46.41%',\n",
       "    positive_probability='53.33%'\n",
       ")"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "electra_large_gpt_sentiment_pred_probs_examples(review='After some haggling, they offered $200 off.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "0f606394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Classify the sentiment of a review as either 'negative', 'neutral', or 'positive'.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Examples: A list of examples that demonstrate different sentiment classes.\n",
      "\n",
      "Review: The review text to classify.\n",
      "\n",
      "Classifier Decision: The sentiment classification proposed by a model fine-tuned on sentiment.\n",
      "\n",
      "Negative Probability: Probability the review is negative\n",
      "\n",
      "Neutral Probability: Probability the review is neutral\n",
      "\n",
      "Positive Probability: Probability the review is positive\n",
      "\n",
      "Classification: One word representing the sentiment classification: 'negative', 'neutral', or 'positive' (do not repeat the field name, do not use 'mixed')\n",
      "\n",
      "---\n",
      "\n",
      "Examples:\n",
      "- neutral: After some haggling, they offered $200 off.\n",
      "- positive: So I mailed my check to HMFC and saved $499.\n",
      "- positive: We were looking forward to that this year.\n",
      "- positive: I was really looking forward to dining here.\n",
      "- neutral: They had happy hour specials on food and drinks that just ended.\n",
      "\n",
      "Review: After some haggling, they offered $200 off.\n",
      "\n",
      "Classifier Decision: positive\n",
      "\n",
      "Negative Probability: 0.25%\n",
      "\n",
      "Neutral Probability: 46.41%\n",
      "\n",
      "Positive Probability: 53.33%\n",
      "\n",
      "Classification:\u001b[32m positive\u001b[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\n\\nClassify the sentiment of a review as either 'negative', 'neutral', or 'positive'.\\n\\n---\\n\\nFollow the following format.\\n\\nExamples: A list of examples that demonstrate different sentiment classes.\\n\\nReview: The review text to classify.\\n\\nClassifier Decision: The sentiment classification proposed by a model fine-tuned on sentiment.\\n\\nNegative Probability: Probability the review is negative\\n\\nNeutral Probability: Probability the review is neutral\\n\\nPositive Probability: Probability the review is positive\\n\\nClassification: One word representing the sentiment classification: 'negative', 'neutral', or 'positive' (do not repeat the field name, do not use 'mixed')\\n\\n---\\n\\nExamples:\\n- neutral: After some haggling, they offered $200 off.\\n- positive: So I mailed my check to HMFC and saved $499.\\n- positive: We were looking forward to that this year.\\n- positive: I was really looking forward to dining here.\\n- neutral: They had happy hour specials on food and drinks that just ended.\\n\\nReview: After some haggling, they offered $200 off.\\n\\nClassifier Decision: positive\\n\\nNegative Probability: 0.25%\\n\\nNeutral Probability: 46.41%\\n\\nPositive Probability: 53.33%\\n\\nClassification:\\x1b[32m positive\\x1b[0m\\n\\n\\n\""
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "0fb9ac1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a test result for the GPT sentiment module\n",
    "e18_g4om_elft_ex_pr2_result = electra_large_gpt_sentiment_pred_probs_examples(review=test_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "444467a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    examples=[{'index': 1385, 'similarity_score': 0.9959219694137573, 'review': 'I remembered this place from a few years ago. It was really bad.', 'classification': 'negative'}, {'index': 1770, 'similarity_score': 0.9956880211830139, 'review': \"But I've been probably 6 times and have never left impressed. It sucks.\", 'classification': 'negative'}, {'index': 1948, 'similarity_score': 0.9954952597618103, 'review': 'So got beans, rice and tacos, no flavour.', 'classification': 'negative'}, {'index': 3282, 'similarity_score': 0.995331346988678, 'review': 'Anyhoos, we waited FOREVER (more like an hour plus) for our food.', 'classification': 'negative'}, {'index': 1391, 'similarity_score': 0.9952993392944336, 'review': 'The loyalty card is not worth it.', 'classification': 'negative'}],\n",
       "    classification='negative',\n",
       "    classifier_decision='negative',\n",
       "    negative_probability='99.90%',\n",
       "    neutral_probability='0.06%',\n",
       "    positive_probability='0.04%'\n",
       ")"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e18_g4om_elft_ex_pr2_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "a3c463df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Classify the sentiment of a review as either 'negative', 'neutral', or 'positive'.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Examples: A list of examples that demonstrate different sentiment classes.\n",
      "\n",
      "Review: The review text to classify.\n",
      "\n",
      "Classifier Decision: The sentiment classification proposed by a model fine-tuned on sentiment.\n",
      "\n",
      "Negative Probability: Probability the review is negative\n",
      "\n",
      "Neutral Probability: Probability the review is neutral\n",
      "\n",
      "Positive Probability: Probability the review is positive\n",
      "\n",
      "Classification: One word representing the sentiment classification: 'negative', 'neutral', or 'positive' (do not repeat the field name, do not use 'mixed')\n",
      "\n",
      "---\n",
      "\n",
      "Examples:\n",
      "- negative: I remembered this place from a few years ago. It was really bad.\n",
      "- negative: But I've been probably 6 times and have never left impressed. It sucks.\n",
      "- negative: So got beans, rice and tacos, no flavour.\n",
      "- negative: Anyhoos, we waited FOREVER (more like an hour plus) for our food.\n",
      "- negative: The loyalty card is not worth it.\n",
      "\n",
      "Review: Those 2 drinks are part of the HK culture and has years of history. It is so bad.\n",
      "\n",
      "Classifier Decision: negative\n",
      "\n",
      "Negative Probability: 99.90%\n",
      "\n",
      "Neutral Probability: 0.06%\n",
      "\n",
      "Positive Probability: 0.04%\n",
      "\n",
      "Classification:\u001b[32m negative\u001b[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\n\\nClassify the sentiment of a review as either 'negative', 'neutral', or 'positive'.\\n\\n---\\n\\nFollow the following format.\\n\\nExamples: A list of examples that demonstrate different sentiment classes.\\n\\nReview: The review text to classify.\\n\\nClassifier Decision: The sentiment classification proposed by a model fine-tuned on sentiment.\\n\\nNegative Probability: Probability the review is negative\\n\\nNeutral Probability: Probability the review is neutral\\n\\nPositive Probability: Probability the review is positive\\n\\nClassification: One word representing the sentiment classification: 'negative', 'neutral', or 'positive' (do not repeat the field name, do not use 'mixed')\\n\\n---\\n\\nExamples:\\n- negative: I remembered this place from a few years ago. It was really bad.\\n- negative: But I've been probably 6 times and have never left impressed. It sucks.\\n- negative: So got beans, rice and tacos, no flavour.\\n- negative: Anyhoos, we waited FOREVER (more like an hour plus) for our food.\\n- negative: The loyalty card is not worth it.\\n\\nReview: Those 2 drinks are part of the HK culture and has years of history. It is so bad.\\n\\nClassifier Decision: negative\\n\\nNegative Probability: 99.90%\\n\\nNeutral Probability: 0.06%\\n\\nPositive Probability: 0.04%\\n\\nClassification:\\x1b[32m negative\\x1b[0m\\n\\n\\n\""
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "b8a47353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Experiment: E18-G4OM-ELFT-EX-PR2\n",
      "--------------------------------------------------------------------------------\n",
      "Start time: 2025-03-26 18:12:45\n",
      "Notes: Experiment 18: Evaluate prompt-based model collaboration with prediction, probabilities, and similar examples\n",
      "Model: gpt-4o-mini-2024-07-18\n",
      "Instance: electra_large_gpt_sentiment_pred_probs_examples\n",
      "Dataset shape: [6530, 4]\n",
      "Examples length: 6530\n",
      "Save directory: results_round2_take2\n",
      "Temperature: 0.1\n",
      "Random seed: 123\n",
      "\n",
      "Running evaluation...\n",
      "Average Metric: 5487 / 6530  (84.0): 100%|██████████| 6530/6530 [1:39:57<00:00,  1.09it/s]  \n",
      "\n",
      "Columns in results DataFrame:\n",
      "review                 6530 values\n",
      "classification         6530 values\n",
      "prediction             6530 values\n",
      "match                  6530 values\n",
      "classifier_decision    6530 values\n",
      "\n",
      "Source value counts:\n",
      "dynasent_r1            3600\n",
      "sst_local              2210\n",
      "dynasent_r2             720\n",
      "\n",
      "Prediction value counts:\n",
      "negative               2364\n",
      "positive               2252\n",
      "neutral                1882\n",
      "examples:\n",
      "- positive: i bought an ice cream sandwich. the man who sold it was super nice and prices were great!\n",
      "- positive: it was fine. i also had some facial waxing and tinting done and it was great as well.\n",
      "- positive: the sides of veggies were good, as were the apps.\n",
      "- positive: great salads, soups, meat, felafel, everything you ordered was delicious.\n",
      "- positive: i ordered the amok fish, which was one of the best things i ate while in cambodia.\n",
      "\n",
      "review: the service was slow and the food was cold.\n",
      "\n",
      "classifier decision: negative\n",
      "\n",
      "negative probability: 95.00%\n",
      "\n",
      "neutral probability: 3.00%\n",
      "\n",
      "positive probability: 2.00%\n",
      "\n",
      "classification: negative      1\n",
      "negative: the service was slow and the staff seemed disinterested in helping us.\n",
      "\n",
      "classifier decision: negative\n",
      "\n",
      "negative probability: 85.67%\n",
      "\n",
      "neutral probability: 10.12%\n",
      "\n",
      "positive probability: 4.21%\n",
      "\n",
      "classification: negative      1\n",
      "- positive: despite sitting outside, we were promptly served and tended to throughout our meal.\n",
      "- positive: we opted for an eight course meal and every dish that was presented was far beyond what we had expected.\n",
      "- positive: we were on the hunt in minneapolis for the best biscuits & gravy and this place would have won that competition. we were glad to come close.\n",
      "- positive: this is probably our favorite sushi restaurant in town...date night or with the kids.\n",
      "- positive: he helped me out by getting them back quickly and refused to take the extra money i offered.\n",
      "\n",
      "review: (eventually a delicious red sangria was selected, which went down entirely too fast.)\n",
      "\n",
      "classifier decision: positive\n",
      "\n",
      "negative probability: 0.01%\n",
      "\n",
      "neutral probability: 0.01%\n",
      "\n",
      "positive probability: 99.98%\n",
      "\n",
      "classification: positive      1\n",
      "- positive: the movie was absolutely fantastic and kept me on the edge of my seat!\n",
      "- negative: i was really disappointed with the service; it took forever to get our food.\n",
      "- neutral: the restaurant has a nice ambiance, but i didn't try the food.\n",
      "- positive: the staff was friendly and the atmosphere was great, making for a wonderful evening.\n",
      "- negative: i would not recommend this place; the food was bland and overpriced.\n",
      "\n",
      "review: and if the hours wins ` best picture ' i just might .\n",
      "\n",
      "classifier decision: positive\n",
      "\n",
      "negative probability: 0.84%\n",
      "\n",
      "neutral probability: 31.50%\n",
      "\n",
      "positive probability: 67.67%\n",
      "\n",
      "classification: positive      1\n",
      "negative: the food was cold and the service was incredibly slow, making for a disappointing experience. \n",
      "\n",
      "review: the food was cold and the service was incredibly slow, making for a disappointing experience.\n",
      "\n",
      "classifier decision: negative\n",
      "\n",
      "negative probability: 78.45%\n",
      "\n",
      "neutral probability: 15.32%\n",
      "\n",
      "positive probability: 6.23%\n",
      "\n",
      "classification: negative      1\n",
      "negative: the service was slow and the food was cold when it arrived.  \n",
      "positive: the ambiance was lovely and the staff were friendly.  \n",
      "neutral: the restaurant was okay, nothing special but not terrible either.  \n",
      "positive: i absolutely loved the dessert; it was the highlight of my meal.  \n",
      "negative: i was disappointed with the portion sizes; they were way too small for the price.  \n",
      "\n",
      "review: the meat was cut well but that's pretty much impossible to mess up.\n",
      "\n",
      "classifier decision: positive\n",
      "\n",
      "negative probability: 1.59%\n",
      "\n",
      "neutral probability: 0.35%\n",
      "\n",
      "positive probability: 98.06%\n",
      "\n",
      "classification: positive      1\n",
      "- positive: the staff was incredibly helpful and made our experience enjoyable.\n",
      "- negative: i was disappointed with the service; it took too long to get our food.\n",
      "- neutral: the restaurant was average, nothing stood out but nothing was terrible either.\n",
      "- positive: the movie was fantastic and kept me on the edge of my seat the entire time.\n",
      "- negative: i would not recommend this product; it broke after just one use.\n",
      "\n",
      "review: we drove back home to atlanta and pulled into children's scottish rite and were immediately met with competency, that we had become accustomed to over the last 3 years.\n",
      "\n",
      "classifier decision: positive\n",
      "\n",
      "negative probability: 0.01%\n",
      "\n",
      "neutral probability: 0.08%\n",
      "\n",
      "positive probability: 99.91%\n",
      "\n",
      "classification: positive      1\n",
      "- neutral: whoever answered said they could take a look.\n",
      "- positive: we went there the last time and thought we would try it again.\n",
      "- neutral: she said she would check on it.\n",
      "- neutral: so, that's exactly how much i'll spend at jared.\n",
      "- neutral: my husband wanted his favorite beer, and i felt like drinking some cool iced tea.\n",
      "\n",
      "review: he said they would begin preparing our order again now if that was ok.\n",
      "\n",
      "classifier decision: neutral\n",
      "\n",
      "negative probability: 0.05%\n",
      "\n",
      "neutral probability: 94.99%\n",
      "\n",
      "positive probability: 4.96%\n",
      "\n",
      "classification: neutral      1\n",
      "- positive: the service was exceptional and the atmosphere was delightful.\n",
      "- negative: i was disappointed with the food; it was cold and tasteless.\n",
      "- neutral: the restaurant was okay, nothing special but not terrible either.\n",
      "- positive: the dessert was heavenly and the presentation was beautiful.\n",
      "- negative: i waited for over an hour and my order was wrong.\n",
      "\n",
      "review: the ambiance was nice, but the food was just average.\n",
      "\n",
      "classifier decision: neutral\n",
      "\n",
      "negative probability: 15.20%\n",
      "\n",
      "neutral probability: 70.50%\n",
      "\n",
      "positive probability: 14.30%\n",
      "\n",
      "classification: neutral      1\n",
      "examples:\n",
      "- neutral: the meeting was scheduled for 10 am and started on time.\n",
      "- positive: i absolutely loved the new restaurant; the food was fantastic!\n",
      "- negative: i was really disappointed with the service; it took forever to get our order.\n",
      "- positive: the movie was an incredible experience; i can't wait to see it again!\n",
      "- neutral: the book was okay, but it didn't really stand out to me.\n",
      "\n",
      "review: the product arrived late and was not what i expected.\n",
      "\n",
      "classifier decision: negative\n",
      "\n",
      "negative probability: 85.12%\n",
      "\n",
      "neutral probability: 10.45%\n",
      "\n",
      "positive probability: 4.43%\n",
      "\n",
      "classification: negative      1\n",
      "- positive: the service was excellent and the staff were very friendly.\n",
      "- neutral: the restaurant has a variety of options on the menu.\n",
      "- negative: i was disappointed with the quality of the food and the long wait time.\n",
      "- neutral: the location is convenient for my needs.\n",
      "- positive: i absolutely loved the ambiance and the live music was a great touch.\n",
      "\n",
      "review: the food was decent, but the service was slow and the atmosphere was nothing special.\n",
      "\n",
      "classifier decision: neutral\n",
      "\n",
      "negative probability: 25.45%\n",
      "\n",
      "neutral probability: 50.12%\n",
      "\n",
      "positive probability: 24.43%\n",
      "\n",
      "classification: neutral      1\n",
      "- negative: the service was terrible and the food was cold when it arrived.\n",
      "- neutral: the restaurant was okay, nothing special but not bad either.\n",
      "- positive: i absolutely loved the ambiance and the staff were very friendly!\n",
      "\n",
      "review: i just can't get over their prices -- i mean, 5 bucks for 5 blouses is unbelievable.\n",
      "\n",
      "classifier decision: positive\n",
      "\n",
      "negative probability: 0.25%\n",
      "\n",
      "neutral probability: 0.04%\n",
      "\n",
      "positive probability: 99.71%\n",
      "\n",
      "classification: positive      1\n",
      "- positive: i was craving a an eclair and when i walked past this place, they had a beautiful assortment of pastries that looked amazing so i got my eclair.\n",
      "- positive: the salsa was more than just a chunky tomato sauce, it had a few sparse spices to give it that zing.\n",
      "- positive: if you dig on david mamet 's mind tricks ... rent this movie and enjoy !\n",
      "- positive: the pool area is definitely the highlight of the resort.\n",
      "- positive: the place overall has a good interior and has a modern design, so that will attract anyone that focuses on the atmosphere when visiting restaurants.\n",
      "\n",
      "review: of the fries, the eggplant were better to my taste although the zucchini were good, too.\n",
      "\n",
      "classifier decision: positive\n",
      "\n",
      "negative probability: 0.01%\n",
      "\n",
      "neutral probability: 0.02%\n",
      "\n",
      "positive probability: 99.97%\n",
      "\n",
      "classification: positive      1\n",
      "- positive: the older gentleman who helped me was pleasant and tried to help me find what i was after.\n",
      "- positive: the place overall has a good interior and has a modern design, so that will attract anyone that focuses on the atmosphere when visiting restaurants.\n",
      "- positive: i move over to get my manicure and the girl was very sweet.\n",
      "- positive: i've just seen one young man working there, who is plenty nice.\n",
      "- positive: important points:\n",
      "\n",
      "1) they have two locations which are spacious, well-lit and family friendly.\n",
      "\n",
      "review: on the upside there was a play area so the kids were happy in the end.\n",
      "\n",
      "classifier decision: positive\n",
      "\n",
      "negative probability: 0.00%\n",
      "\n",
      "neutral probability: 0.02%\n",
      "\n",
      "positive probability: 99.98%\n",
      "\n",
      "classification: positive      1\n",
      "- positive: the ambiance was delightful, and the service was impeccable. i can't wait to return!\n",
      "- negative: i was really disappointed with the food; it was cold and tasteless.\n",
      "- neutral: the restaurant was okay, nothing special but not bad either.\n",
      "- positive: the staff was friendly and the coffee was excellent, i highly recommend this place!\n",
      "- negative: i had to wait for over an hour for my order, which was frustrating.\n",
      "\n",
      "review: the service was slow, and the food was mediocre at best. i expected more from this place.\n",
      "\n",
      "classifier decision: negative\n",
      "\n",
      "negative probability: 95.00%\n",
      "\n",
      "neutral probability: 4.00%\n",
      "\n",
      "positive probability: 1.00%\n",
      "\n",
      "classification: negative      1\n",
      "examples:\n",
      "- positive: the service was exceptional and the food was delicious.\n",
      "- negative: i was very disappointed with the quality of the product.\n",
      "- neutral: the experience was okay, nothing special.\n",
      "- positive: i absolutely loved the atmosphere and the staff were very friendly.\n",
      "- negative: the wait time was too long and the staff seemed uninterested.\n",
      "\n",
      "review: the food was decent, but the service was lacking and the ambiance was nothing to write home about.\n",
      "\n",
      "classifier decision: neutral\n",
      "\n",
      "negative probability: 25.34%\n",
      "\n",
      "neutral probability: 50.12%\n",
      "\n",
      "positive probability: 24.54%\n",
      "\n",
      "classification: neutral      1\n",
      "examples:\n",
      "- negative: the food was cold and the service was terrible.\n",
      "- neutral: the movie was about a young girl and her adventures.\n",
      "- positive: i absolutely loved the concert; it was amazing!\n",
      "\n",
      "review: the hotel was okay, but nothing special.\n",
      "\n",
      "classifier decision: neutral\n",
      "\n",
      "negative probability: 12.34%\n",
      "\n",
      "neutral probability: 75.67%\n",
      "\n",
      "positive probability: 12.99%\n",
      "\n",
      "classification: neutral      1\n",
      "negative: i was really disappointed with the service and will not be returning.  \n",
      "neutral: the food was okay, nothing special.  \n",
      "positive: i absolutely loved the atmosphere and the staff were incredibly friendly!  \n",
      "positive: this is the best movie i've seen in a long time!  \n",
      "neutral: the product works as expected, but i didn't find it particularly impressive.  \n",
      "\n",
      "review: i booked the appointment for 12 sharp and she arrived at 1:15.  \n",
      "classifier decision: neutral  \n",
      "negative probability: 3.12%  \n",
      "neutral probability: 71.63%  \n",
      "positive probability: 25.26%  \n",
      "classification: neutral      1\n",
      "- negative: the service was terrible and the food was cold.\n",
      "- negative: i will never come back to this restaurant again.\n",
      "- negative: this product broke after one use, very disappointing.\n",
      "- neutral: the meal was okay, nothing special.\n",
      "- neutral: i had a regular experience, neither good nor bad.\n",
      "- neutral: the movie was just average, not worth the hype.\n",
      "- positive: the staff was friendly and the ambiance was lovely.\n",
      "- positive: i absolutely loved the dessert, it was amazing!\n",
      "- positive: this is the best coffee i've ever had, highly recommend!\n",
      "\n",
      "review: the food was bland and the service was slow.\n",
      "\n",
      "classifier decision: negative\n",
      "\n",
      "negative probability: 87.45%\n",
      "\n",
      "neutral probability: 8.32%\n",
      "\n",
      "positive probability: 4.23%\n",
      "\n",
      "classification: negative      1\n",
      "negative\n",
      "\n",
      "---\n",
      "\n",
      "examples:\n",
      "- positive: absolutely loved it!\n",
      "- positive: this is the best experience i've ever had.\n",
      "- neutral: it was okay, nothing special.\n",
      "- neutral: i don't have strong feelings about it.\n",
      "- negative: i hated the service.\n",
      "\n",
      "review: it was okay, nothing special.\n",
      "\n",
      "classifier decision: neutral\n",
      "\n",
      "negative probability: 12.45%\n",
      "\n",
      "neutral probability: 75.32%\n",
      "\n",
      "positive probability: 12.23%\n",
      "\n",
      "classification: neutral      1\n",
      "- negative: the service was terrible and the food was cold.\n",
      "- negative: i will never come back to this place again.\n",
      "- negative: the atmosphere was dull and uninviting.\n",
      "- neutral: the restaurant was okay, nothing special.\n",
      "- neutral: i had a meal here, and it was just average.\n",
      "- neutral: the experience was neither good nor bad.\n",
      "- positive: the food was amazing and the staff were friendly.\n",
      "- positive: i loved the ambiance and the service was top-notch.\n",
      "- positive: this is my favorite restaurant in town!\n",
      "\n",
      "review: the food was bland and the service was slow.\n",
      "\n",
      "classifier decision: negative\n",
      "\n",
      "negative probability: 85.3%\n",
      "\n",
      "neutral probability: 10.5%\n",
      "\n",
      "positive probability: 4.2%\n",
      "\n",
      "classification: negative      1\n",
      "- positive: the service was exceptional and the food was delicious!\n",
      "- negative: i was really disappointed with the quality of the meal; it was overcooked and bland.\n",
      "- neutral: the restaurant has a variety of options on the menu, but i didn't try anything new this time.\n",
      "- positive: i absolutely loved the ambiance and the staff were very friendly.\n",
      "- negative: the wait time was far too long, and i won't be coming back again.\n",
      "\n",
      "review: the food was decent, but the service was lacking and the atmosphere was nothing special.\n",
      "\n",
      "classifier decision: neutral\n",
      "\n",
      "negative probability: 15.32%\n",
      "\n",
      "neutral probability: 54.67%\n",
      "\n",
      "positive probability: 30.01%\n",
      "\n",
      "classification: neutral      1\n",
      "negative: the service was terrible and the food was cold when it arrived.  \n",
      "negative: i was really disappointed with my experience; the staff was rude and unhelpful.  \n",
      "neutral: the restaurant was okay, nothing special but not bad either.  \n",
      "neutral: i had a meal there, and it was just average.  \n",
      "positive: the dessert was absolutely delicious and the staff was very friendly!  \n",
      "\n",
      "review: the appetizers looked great but we never would have been able eat it all!  \n",
      "\n",
      "classifier decision: positive  \n",
      "\n",
      "negative probability: 0.01%  \n",
      "\n",
      "neutral probability: 0.01%  \n",
      "\n",
      "positive probability: 99.98%  \n",
      "\n",
      "classification: positive      1\n",
      "examples:\n",
      "- positive: my neice and i went because we saw the amazing pictures online.\n",
      "- positive: we ate alone for happy hour. they were known for the best beer in town.\n",
      "- positive: because there are way too many things on the menu that you will want to try.\n",
      "- positive: next time we want to try the conveyor belt system, which looked like fun.\n",
      "- positive: if you are an actor who can relate to the search for inner peace by dramatically depicting the lives of others onstage, then esther's story is a compelling quest for truth.\n",
      "\n",
      "review: the service was slow and the food was cold when it arrived.\n",
      "\n",
      "classifier decision: negative\n",
      "\n",
      "negative probability: 85.34%\n",
      "\n",
      "neutral probability: 10.12%\n",
      "\n",
      "positive probability: 4.54%\n",
      "\n",
      "classification: negative      1\n",
      "examples:\n",
      "- negative: the food was cold and the service was terrible.\n",
      "- neutral: the restaurant is located downtown and has a nice ambiance.\n",
      "- positive: i absolutely loved the dessert; it was the best i've ever had!\n",
      "\n",
      "review: the atmosphere was nice, but the food was just average.\n",
      "\n",
      "classifier decision: neutral\n",
      "\n",
      "negative probability: 0.10%\n",
      "\n",
      "neutral probability: 89.90%\n",
      "\n",
      "positive probability: 10.00%\n",
      "\n",
      "classification: neutral      1\n",
      "examples:\n",
      "- positive: the fries were very thin but tasted good. i really recommend.\n",
      "- positive: we ended up sitting at the bar at mesa grill, which i like because sometimes you can meet interesting people at the bar. it was awesome.\n",
      "- positive: the next night we went to bali foot spa and it was wonderful and cost only $20.\n",
      "- positive: tony was lovely, and took care of an ingrown toenail, and my nails looked lovely when i left.\n",
      "- positive: we tried a new place. we enjoyed our stay and at the rate we paid, we would gladly return.\n",
      "\n",
      "review: the food prices are what you would expect from a place like this. very nice\n",
      "\n",
      "classifier decision: positive\n",
      "\n",
      "negative probability: 0.02%\n",
      "\n",
      "neutral probability: 0.01%\n",
      "\n",
      "positive probability: 99.97%\n",
      "\n",
      "classification: positive      1\n",
      "- positive: the building is very chic and the place looked exactly like a place i wanted to visit later.\n",
      "- positive: the characters are interesting and often very creatively constructed from figure to backstory.\n",
      "- positive: awesome creatures, breathtaking scenery, and epic battle scenes add up to another spectacular spectacle.\n",
      "- positive: however, we made the right choice and went to a sam fox restaurant where we were taken care of.\n",
      "- positive: important points: 1) they have two locations which are spacious, well-lit and family friendly.\n",
      "\n",
      "review: well i was very excited and thought how cute/charming on the outside the restaurant looked.\n",
      "\n",
      "classifier decision: positive\n",
      "\n",
      "negative probability: 0.00%\n",
      "\n",
      "neutral probability: 0.04%\n",
      "\n",
      "positive probability: 99.96%\n",
      "\n",
      "classification: positive      1\n",
      "negative: c'est finalement du riz blanc et de la mauvaise friture.\n",
      "\n",
      "classifier decision: negative\n",
      "\n",
      "negative probability: 85.32%\n",
      "\n",
      "neutral probability: 10.45%\n",
      "\n",
      "positive probability: 4.23%\n",
      "\n",
      "classification: negative      1\n",
      "negative: je n'aime pas du tout ce produit.      1\n",
      "examples:\n",
      "- negative: the service was terrible and the food was cold.\n",
      "- neutral: the restaurant was okay, nothing special.\n",
      "- positive: the ambiance was lovely and the staff were friendly.\n",
      "\n",
      "review: the food was decent, but the service could have been better.\n",
      "\n",
      "classifier decision: neutral\n",
      "\n",
      "negative probability: 15.20%\n",
      "\n",
      "neutral probability: 70.50%\n",
      "\n",
      "positive probability: 14.30%\n",
      "\n",
      "classification: neutral      1\n",
      "- positive: a lot less from what i was expected to pay (hey i'm not complaining) but regardless of it being a mistake or not, i'll happily return.\n",
      "- positive: you get what you pay for and she is very fair especially with the product she produce!\n",
      "- positive: mac and cheese was good, portion was average and came with garlic bread.\n",
      "- positive: my mom spilled her beer on her entire pizza and despite insisting she didn't want another pie, he put in an order and didn't charge us.\n",
      "- positive: sadly, i only tried the awesome bubble tea.\n",
      "\n",
      "review: the place didn't have that hipster downtown vibe, bonus!\n",
      "\n",
      "classifier decision: positive\n",
      "\n",
      "negative probability: 0.08%\n",
      "\n",
      "neutral probability: 0.03%\n",
      "\n",
      "positive probability: 99.90%\n",
      "\n",
      "classification: positive      1\n",
      "- negative: the service was terrible and the food was cold.\n",
      "- neutral: the restaurant was okay, nothing special.\n",
      "- positive: i absolutely loved the dessert; it was the best i've ever had!\n",
      "\n",
      "review: the atmosphere was nice, but the food was just average.\n",
      "\n",
      "classifier decision: neutral\n",
      "\n",
      "negative probability: 10.5%\n",
      "\n",
      "neutral probability: 78.3%\n",
      "\n",
      "positive probability: 11.2%\n",
      "\n",
      "classification: neutral      1\n",
      "\n",
      "Found 32 invalid predictions at row indices:\n",
      "[573, 623, 734, 1753, 2361, 2392, 2397, 3353, 3907, 4050, 4058, 4668, 4686, 4887, 4966, 4976, 5059, 5246, 5302, 5333, 5354, 5385, 5390, 5516, 5656, 5728, 5730, 5998, 6233, 6277, 6338, 6484]\n",
      "\n",
      "Invalid prediction rows:\n",
      "                                                                                                                                                                      sentence  \\\n",
      "573                                                                                                                   The place didn't have that hipster downtown vibe, bonus!   \n",
      "623                                                                                                            It looked like a good place for lunch, pretty quiet for dinner.   \n",
      "734                                                                                                                                                   C'est un incontournable!   \n",
      "1753                                                                                                                  C'est finalement du riz blanc et de la mauvaise friture.   \n",
      "2361                                                                               Well I was very excited and thought how cute/charming on the outside the restaurant looked.   \n",
      "2392                                                                                               The food prices are what you would expect from a place like this. very nice   \n",
      "2397                                                                                      Cashier was knowledgeable and was able to tell me everything that came on the salad.   \n",
      "3353                                                                                                             Somehow I can really end up nerding out at a place like this.   \n",
      "3907                                                                                                 The appetizers looked great but we never would have been able eat it all!   \n",
      "4050                                                                                       And I'm sure if I wanted to add something to my order, that would be justtttt fine.   \n",
      "4058                                                                                                                 Found the place to be in this local restaurant wasteland.   \n",
      "4668                                                                                                                                                              Ridiculous .   \n",
      "4686                                                                                                                                        My favorite place for a good dump.   \n",
      "4887                                                                                                            I booked the appointment for 12 sharp and she arrived at 1:15.   \n",
      "4966  [we tipped very well that night] The guy making our food brought us our food and engaged us in a friendly chat for about 15 minutes [much needed to restore his nerves].   \n",
      "4976                                                                                              I told him that I had already bought a ring but that I would need a diamond.   \n",
      "5059  We drove back home to Atlanta and pulled into Children's Scottish Rite and were immediately met with competency, that we had become accustomed to over the last 3 years.   \n",
      "5246                                                                                                    On the upside there was a play area so the kids were happy in the end.   \n",
      "5302                                                                                  Of the fries, the eggplant were better to my taste although the zucchini were good, too.   \n",
      "5333                                                                                      I just can't get over their prices -- I mean, 5 bucks for 5 blouses is unbelievable.   \n",
      "5354                                                                               My drop off was around 11am and by 3pm they called letting me know that they were finished.   \n",
      "5385                                                                                         After opening the presents I asked him if I had to sign anything, and he said no.   \n",
      "5390                                                                                                    Steaks melted in your mouth and I could almost cut it without a knife.   \n",
      "5516                                                                                                    He said they would begin preparing our order again now if that was ok.   \n",
      "5656                                        I personally think they have some of the best fish tacos in the area, though they don't push them so much. They rock my socks off.   \n",
      "5728                                                                                                       The meat was cut well but that's pretty much impossible to mess up.   \n",
      "5730                                                                     Immediately I wonder why this place isn't busy being in the heart of W25 during a weekday lunch hour?   \n",
      "5998                                                                                                                     And if The Hours wins ` Best Picture ' I just might .   \n",
      "6233                                                                                     (Eventually a delicious red sangria was selected, which went down entirely too fast.)   \n",
      "6277                                              The person taking your order rapidly goes through several lists of ingredients that are somewhat logically grouped together.   \n",
      "6338                                                                                                                  (It had a pleasant kick) The bar-b-que sauce was superb.   \n",
      "6484                                                                                                                  :( \\nI was not disappointed in getting ice cream though!   \n",
      "\n",
      "         label       source split  \n",
      "573   positive  dynasent_r1  test  \n",
      "623   positive  dynasent_r1  test  \n",
      "734    neutral  dynasent_r1  test  \n",
      "1753   neutral  dynasent_r1  test  \n",
      "2361  positive  dynasent_r1  test  \n",
      "2392  positive  dynasent_r2  test  \n",
      "2397  positive  dynasent_r1  test  \n",
      "3353  positive  dynasent_r2  test  \n",
      "3907  positive  dynasent_r1  test  \n",
      "4050  positive  dynasent_r1  test  \n",
      "4058  negative  dynasent_r2  test  \n",
      "4668  negative    sst_local  test  \n",
      "4686  positive  dynasent_r1  test  \n",
      "4887  negative  dynasent_r1  test  \n",
      "4966  positive  dynasent_r1  test  \n",
      "4976   neutral  dynasent_r1  test  \n",
      "5059  positive  dynasent_r1  test  \n",
      "5246  positive  dynasent_r1  test  \n",
      "5302  positive  dynasent_r1  test  \n",
      "5333  positive  dynasent_r2  test  \n",
      "5354  positive  dynasent_r1  test  \n",
      "5385   neutral  dynasent_r2  test  \n",
      "5390  positive  dynasent_r1  test  \n",
      "5516   neutral  dynasent_r1  test  \n",
      "5656  positive  dynasent_r2  test  \n",
      "5728  positive  dynasent_r1  test  \n",
      "5730  negative  dynasent_r1  test  \n",
      "5998  positive    sst_local  test  \n",
      "6233  positive  dynasent_r1  test  \n",
      "6277   neutral  dynasent_r1  test  \n",
      "6338  positive  dynasent_r2  test  \n",
      "6484  positive  dynasent_r1  test  \n",
      "\n",
      "WARNING: Invalid predictions found. Please review the above details and re-run problematic cases.\n"
     ]
    }
   ],
   "source": [
    "e18_g4om_elft_ex_pr2_df, e18_g4om_elft_ex_pr2_metrics = evaluate_experiment(\n",
    "    name='E18-G4OM-ELFT-EX-PR2',\n",
    "    notes='Experiment 18: Evaluate prompt-based model collaboration with prediction, probabilities, and similar examples',\n",
    "    lm='gpt-4o-mini-2024-07-18',\n",
    "    instance='electra_large_gpt_sentiment_pred_probs_examples',\n",
    "    dataset=test_df,\n",
    "    examples=test_ex,\n",
    "    temperature=temperature,\n",
    "    random_seed=random_seed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "cfbba151",
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_indices = [573, 623, 734, 1753, 2361, 2392, 2397, 3353, 3907, 4050, 4058, 4668, 4686, 4887, 4966, 4976, 5059, 5246, 5302, 5333, 5354, 5385, 5390, 5516, 5656, 5728, 5730, 5998, 6233, 6277, 6338, 6484]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "e0a8c04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "e18_g4om_elft_ex_pr2_df_orig = pd.DataFrame.copy(e18_g4om_elft_ex_pr2_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "e15e2006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to the invalid rows\n",
    "e18_g4om_elft_ex_pr2_df.loc[invalid_indices, 'prediction'] = e18_g4om_elft_ex_pr2_df.loc[invalid_indices].apply(update_prediction, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "4b9705c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prediction\n",
       "negative                                       2373\n",
       "positive                                       2263\n",
       "neutral                                        1893\n",
       "negative: je n'aime pas du tout ce produit.       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check unique values for prediction\n",
    "e18_g4om_elft_ex_pr2_df['prediction'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "ba0d788a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find rows that start with 'negative:' in the 'prediction' column\n",
    "negative_indices = e18_g4om_elft_ex_pr2_df[e18_g4om_elft_ex_pr2_df['prediction'].str.startswith('negative:')].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "ea3b909f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([734], dtype='int64')"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "fa552ea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>classification</th>\n",
       "      <th>prediction</th>\n",
       "      <th>match</th>\n",
       "      <th>classifier_decision</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>C'est un incontournable!</td>\n",
       "      <td>neutral</td>\n",
       "      <td>negative: je n'aime pas du tout ce produit.</td>\n",
       "      <td>False</td>\n",
       "      <td>neutral</td>\n",
       "      <td>dynasent_r1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       review classification  \\\n",
       "734  C'est un incontournable!        neutral   \n",
       "\n",
       "                                      prediction  match classifier_decision  \\\n",
       "734  negative: je n'aime pas du tout ce produit.  False             neutral   \n",
       "\n",
       "          source  \n",
       "734  dynasent_r1  "
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display the rows with negative indices\n",
    "e18_g4om_elft_ex_pr2_df.loc[negative_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "0c0fe4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "e18_734_redo = electra_large_gpt_sentiment_pred_probs_examples(review=\"C'est un incontournable!\t(Please only respond with one word for the classification)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "ec901f44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    examples=[{'index': 1856, 'similarity_score': 0.9976580142974854, 'review': \"He sez 'go there now'.\", 'classification': 'neutral'}, {'index': 5203, 'similarity_score': 0.9974283576011658, 'review': \"I'm sure the other waitresses too.\", 'classification': 'positive'}, {'index': 1373, 'similarity_score': 0.9973297119140625, 'review': 'We applied for a townhouse and we made well over the amount required to rent.', 'classification': 'neutral'}, {'index': 2574, 'similarity_score': 0.9972288012504578, 'review': '*Use the nurses line for simple questions.', 'classification': 'neutral'}, {'index': 5096, 'similarity_score': 0.9971334338188171, 'review': 'Went through the drive thu and ordered 1 hamburger!!!!', 'classification': 'neutral'}],\n",
       "    classification='positive',\n",
       "    classifier_decision='neutral',\n",
       "    negative_probability='0.42%',\n",
       "    neutral_probability='97.66%',\n",
       "    positive_probability='1.93%'\n",
       ")"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e18_734_redo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "a1dd75ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the prediction for the review\n",
    "e18_g4om_elft_ex_pr2_df.at[734, 'prediction'] = e18_734_redo.classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "c65cff85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prediction\n",
       "negative    2373\n",
       "positive    2264\n",
       "neutral     1893\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check unique values for prediction\n",
    "e18_g4om_elft_ex_pr2_df['prediction'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "5175c1e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Experiment: E18-G4OM-ELFT-EX-PR2\n",
      "--------------------------------------------------------------------------------\n",
      "Start time: 2025-03-27 05:42:54\n",
      "Notes: Experiment 18: Evaluate prompt-based model collaboration with prediction, probabilities, and similar examples\n",
      "Model: gpt-4o-mini-2024-07-18\n",
      "Instance: electra_large_gpt_sentiment_pred_probs_examples\n",
      "Dataset shape: [6530, 4]\n",
      "Examples length: 6530\n",
      "Results shape: [6530, 6]\n",
      "Save directory: results_round2_take2\n",
      "\n",
      "Source value counts:\n",
      "dynasent_r1            3600\n",
      "sst_local              2210\n",
      "dynasent_r2             720\n",
      "\n",
      "Prediction value counts:\n",
      "negative               2373\n",
      "positive               2264\n",
      "neutral                1893\n",
      "\n",
      "E18-G4OM-ELFT-EX-PR2 Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.8639    0.8716    0.8677      2352\n",
      "     neutral     0.7422    0.7682    0.7550      1829\n",
      "    positive     0.8975    0.8650    0.8810      2349\n",
      "\n",
      "    accuracy                         0.8403      6530\n",
      "   macro avg     0.8345    0.8349    0.8346      6530\n",
      "weighted avg     0.8419    0.8403    0.8409      6530\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative       2050      258        44\n",
      "neutral         236     1405       188\n",
      "positive         87      230      2032\n",
      "\n",
      "\n",
      "E18-G4OM-ELFT-EX-PR2-DYN-R1 Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.9218    0.8550    0.8872      1200\n",
      "     neutral     0.7811    0.9217    0.8456      1200\n",
      "    positive     0.9300    0.8300    0.8771      1200\n",
      "\n",
      "    accuracy                         0.8689      3600\n",
      "   macro avg     0.8776    0.8689    0.8700      3600\n",
      "weighted avg     0.8776    0.8689    0.8700      3600\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative       1026      152        22\n",
      "neutral          41     1106        53\n",
      "positive         46      158       996\n",
      "\n",
      "\n",
      "E18-G4OM-ELFT-EX-PR2-DYN-R2 Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.7676    0.9083    0.8321       240\n",
      "     neutral     0.8247    0.6667    0.7373       240\n",
      "    positive     0.8058    0.8125    0.8091       240\n",
      "\n",
      "    accuracy                         0.7958       720\n",
      "   macro avg     0.7994    0.7958    0.7928       720\n",
      "weighted avg     0.7994    0.7958    0.7928       720\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative        218       13         9\n",
      "neutral          42      160        38\n",
      "positive         24       21       195\n",
      "\n",
      "\n",
      "E18-G4OM-ELFT-EX-PR2-SST Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.8258    0.8838    0.8538       912\n",
      "     neutral     0.4912    0.3573    0.4137       389\n",
      "    positive     0.8843    0.9252    0.9043       909\n",
      "\n",
      "    accuracy                         0.8081      2210\n",
      "   macro avg     0.7338    0.7221    0.7239      2210\n",
      "weighted avg     0.7910    0.8081    0.7971      2210\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative        806       93        13\n",
      "neutral         153      139        97\n",
      "positive         17       51       841\n",
      "\n",
      "Saving results to 'results_round2_take2'...\n",
      "\n",
      "Summary Metrics:\n",
      "Dataset     \tF1 (macro)\tAccuracy\n",
      "---------------------------------------------\n",
      "Merged      \t    83.46\t   84.03\n",
      "DynaSent R1 \t    87.00\t   86.89\n",
      "DynaSent R2 \t    79.28\t   79.58\n",
      "SST-3       \t    72.39\t   80.81\n",
      "\n",
      "Evaluation completed\n",
      "End time: 2025-03-27 05:42:55\n",
      "Duration: 0:00:00.445306\n"
     ]
    }
   ],
   "source": [
    "e18_g4om_elft_ex_pr2_metrics = evaluate_experiment(\n",
    "    name='E18-G4OM-ELFT-EX-PR2',\n",
    "    notes='Experiment 18: Evaluate prompt-based model collaboration with prediction, probabilities, and similar examples',\n",
    "    lm='gpt-4o-mini-2024-07-18',\n",
    "    instance='electra_large_gpt_sentiment_pred_probs_examples',\n",
    "    dataset=test_df,\n",
    "    examples=test_ex,\n",
    "    results=e18_g4om_elft_ex_pr2_df,\n",
    "    temperature=temperature,\n",
    "    random_seed=random_seed\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590e77bb",
   "metadata": {},
   "source": [
    "### E19-G4OM-ELFT-BEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "7224a239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch to the correct language model and disable experimental mode\n",
    "lm = dspy.OpenAI(model='gpt-4o-mini-2024-07-18', api_key=openai_key, max_tokens=8192, temperature=temperature)\n",
    "dspy.settings.configure(lm=lm, experimental=False, seed=random_seed)\n",
    "dsp.settings.show_guidelines = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "ce8f269c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a test result for the GPT sentiment module\n",
    "e19_g4om_elft_bex_result = electra_large_gpt_sentiment_examples_balanced(review=test_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "43bf2b40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    examples=[{'index': 1385, 'similarity_score': 0.9959219694137573, 'review': 'I remembered this place from a few years ago. It was really bad.', 'classification': 'negative'}, {'index': 1770, 'similarity_score': 0.9956880211830139, 'review': \"But I've been probably 6 times and have never left impressed. It sucks.\", 'classification': 'negative'}, {'index': 3642, 'similarity_score': 0.9821950197219849, 'review': 'My husband got the prime rib special and it came out with the salad and cold.', 'classification': 'neutral'}, {'index': 4792, 'similarity_score': 0.9807704091072083, 'review': 'This is brand spankin new so a longer soft opening is definitely necessary especially when dealing with us downtown folks during the lunch rush and after work dinner pickup, they need work.', 'classification': 'neutral'}, {'index': 474, 'similarity_score': 0.9905312061309814, 'review': 'The colors and tech were something to be desired.', 'classification': 'positive'}, {'index': 3014, 'similarity_score': 0.9897524118423462, 'review': \"The food here isn't the greatest in the neighborhood but on the entire east coast.\", 'classification': 'positive'}],\n",
       "    classification='negative',\n",
       "    classifier_decision='negative',\n",
       "    probabilities=[0.9990077614784241, 0.0005539217963814735, 0.000438391842180863]\n",
       ")"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e19_g4om_elft_bex_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "a6398505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Classify the sentiment of a review as either 'negative', 'neutral', or 'positive'.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Examples: A list of examples that demonstrate different sentiment classes.\n",
      "\n",
      "Review: The review text to classify.\n",
      "\n",
      "Classifier Decision: The sentiment classification proposed by a model fine-tuned on sentiment.\n",
      "\n",
      "Classification: One word representing the sentiment classification: 'negative', 'neutral', or 'positive' (do not repeat the field name, do not use 'mixed')\n",
      "\n",
      "---\n",
      "\n",
      "Examples:\n",
      "- negative: I remembered this place from a few years ago. It was really bad.\n",
      "- negative: But I've been probably 6 times and have never left impressed. It sucks.\n",
      "- neutral: My husband got the prime rib special and it came out with the salad and cold.\n",
      "- neutral: This is brand spankin new so a longer soft opening is definitely necessary especially when dealing with us downtown folks during the lunch rush and after work dinner pickup, they need work.\n",
      "- positive: The colors and tech were something to be desired.\n",
      "- positive: The food here isn't the greatest in the neighborhood but on the entire east coast.\n",
      "\n",
      "Review: Those 2 drinks are part of the HK culture and has years of history. It is so bad.\n",
      "\n",
      "Classifier Decision: negative\n",
      "\n",
      "Classification:\u001b[32m negative\u001b[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\n\\nClassify the sentiment of a review as either 'negative', 'neutral', or 'positive'.\\n\\n---\\n\\nFollow the following format.\\n\\nExamples: A list of examples that demonstrate different sentiment classes.\\n\\nReview: The review text to classify.\\n\\nClassifier Decision: The sentiment classification proposed by a model fine-tuned on sentiment.\\n\\nClassification: One word representing the sentiment classification: 'negative', 'neutral', or 'positive' (do not repeat the field name, do not use 'mixed')\\n\\n---\\n\\nExamples:\\n- negative: I remembered this place from a few years ago. It was really bad.\\n- negative: But I've been probably 6 times and have never left impressed. It sucks.\\n- neutral: My husband got the prime rib special and it came out with the salad and cold.\\n- neutral: This is brand spankin new so a longer soft opening is definitely necessary especially when dealing with us downtown folks during the lunch rush and after work dinner pickup, they need work.\\n- positive: The colors and tech were something to be desired.\\n- positive: The food here isn't the greatest in the neighborhood but on the entire east coast.\\n\\nReview: Those 2 drinks are part of the HK culture and has years of history. It is so bad.\\n\\nClassifier Decision: negative\\n\\nClassification:\\x1b[32m negative\\x1b[0m\\n\\n\\n\""
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "5d4137e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Experiment: E19-G4OM-ELFT-BEX\n",
      "--------------------------------------------------------------------------------\n",
      "Start time: 2025-03-26 19:56:45\n",
      "Notes: Experiment 19: Evaluate prompt-based model collaboration that includes similar, balanced examples\n",
      "Model: gpt-4o-mini-2024-07-18\n",
      "Instance: electra_large_gpt_sentiment_examples_balanced\n",
      "Dataset shape: [6530, 4]\n",
      "Examples length: 6530\n",
      "Save directory: results_round2_take2\n",
      "Temperature: 0.1\n",
      "Random seed: 123\n",
      "\n",
      "Running evaluation...\n",
      "Average Metric: 5473 / 6530  (83.8): 100%|██████████| 6530/6530 [1:35:50<00:00,  1.14it/s]  \n",
      "\n",
      "Columns in results DataFrame:\n",
      "review                 6530 values\n",
      "classification         6530 values\n",
      "prediction             6530 values\n",
      "match                  6530 values\n",
      "classifier_decision    6530 values\n",
      "probabilities          6530 values\n",
      "\n",
      "Source value counts:\n",
      "dynasent_r1            3600\n",
      "sst_local              2210\n",
      "dynasent_r2             720\n",
      "\n",
      "Prediction value counts:\n",
      "negative               2417\n",
      "positive               2177\n",
      "neutral                1936\n",
      "\n",
      "E19-G4OM-ELFT-BEX Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.8552    0.8788    0.8668      2352\n",
      "     neutral     0.7309    0.7736    0.7517      1829\n",
      "    positive     0.9146    0.8476    0.8798      2349\n",
      "\n",
      "    accuracy                         0.8381      6530\n",
      "   macro avg     0.8335    0.8334    0.8328      6530\n",
      "weighted avg     0.8417    0.8381    0.8392      6530\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative       2067      259        26\n",
      "neutral         254     1415       160\n",
      "positive         96      262      1991\n",
      "\n",
      "\n",
      "E19-G4OM-ELFT-BEX-DYN-R1 Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.9127    0.8625    0.8869      1200\n",
      "     neutral     0.7720    0.9200    0.8395      1200\n",
      "    positive     0.9440    0.8150    0.8748      1200\n",
      "\n",
      "    accuracy                         0.8658      3600\n",
      "   macro avg     0.8762    0.8658    0.8671      3600\n",
      "weighted avg     0.8762    0.8658    0.8671      3600\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative       1035      153        12\n",
      "neutral          50     1104        46\n",
      "positive         49      173       978\n",
      "\n",
      "\n",
      "E19-G4OM-ELFT-BEX-DYN-R2 Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.7845    0.9250    0.8489       240\n",
      "     neutral     0.8079    0.6833    0.7404       240\n",
      "    positive     0.8248    0.8042    0.8143       240\n",
      "\n",
      "    accuracy                         0.8042       720\n",
      "   macro avg     0.8057    0.8042    0.8012       720\n",
      "weighted avg     0.8057    0.8042    0.8012       720\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative        222       11         7\n",
      "neutral          42      164        34\n",
      "positive         19       28       193\n",
      "\n",
      "\n",
      "E19-G4OM-ELFT-BEX-SST Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.8100    0.8882    0.8473       912\n",
      "     neutral     0.4851    0.3779    0.4249       389\n",
      "    positive     0.9041    0.9021    0.9031       909\n",
      "\n",
      "    accuracy                         0.8041      2210\n",
      "   macro avg     0.7331    0.7227    0.7251      2210\n",
      "weighted avg     0.7915    0.8041    0.7959      2210\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative        810       95         7\n",
      "neutral         162      147        80\n",
      "positive         28       61       820\n",
      "\n",
      "Saving results to 'results_round2_take2'...\n",
      "\n",
      "Summary Metrics:\n",
      "Dataset     \tF1 (macro)\tAccuracy\n",
      "---------------------------------------------\n",
      "Merged      \t    83.28\t   83.81\n",
      "DynaSent R1 \t    86.71\t   86.58\n",
      "DynaSent R2 \t    80.12\t   80.42\n",
      "SST-3       \t    72.51\t   80.41\n",
      "\n",
      "Evaluation completed\n",
      "End time: 2025-03-26 21:32:37\n",
      "Duration: 1:35:51.528021\n"
     ]
    }
   ],
   "source": [
    "e19_g4om_elft_bex_df, e19_g4om_elft_bex_metrics = evaluate_experiment(\n",
    "    name='E19-G4OM-ELFT-BEX',\n",
    "    notes='Experiment 19: Evaluate prompt-based model collaboration that includes similar, balanced examples',\n",
    "    lm='gpt-4o-mini-2024-07-18',\n",
    "    instance='electra_large_gpt_sentiment_examples_balanced',\n",
    "    dataset=test_df,\n",
    "    examples=test_ex,\n",
    "    temperature=temperature,\n",
    "    random_seed=random_seed\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d412811d",
   "metadata": {},
   "source": [
    "### E20-G4O-ELFT-EX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "f2b7137e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch to the correct language model and disable experimental mode\n",
    "lm = dspy.OpenAI(model='gpt-4o-2024-08-06', api_key=openai_key, max_tokens=8192, temperature=temperature)\n",
    "dspy.settings.configure(lm=lm, experimental=False, seed=random_seed)\n",
    "dsp.settings.show_guidelines = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "78742792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a test result for the GPT sentiment module\n",
    "e20_g4o_elft_ex_result = electra_large_gpt_sentiment_examples(review=test_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "6fa413ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    examples=[{'index': 1385, 'similarity_score': 0.9959219694137573, 'review': 'I remembered this place from a few years ago. It was really bad.', 'classification': 'negative'}, {'index': 1770, 'similarity_score': 0.9956880211830139, 'review': \"But I've been probably 6 times and have never left impressed. It sucks.\", 'classification': 'negative'}, {'index': 1948, 'similarity_score': 0.9954952597618103, 'review': 'So got beans, rice and tacos, no flavour.', 'classification': 'negative'}, {'index': 3282, 'similarity_score': 0.995331346988678, 'review': 'Anyhoos, we waited FOREVER (more like an hour plus) for our food.', 'classification': 'negative'}, {'index': 1391, 'similarity_score': 0.9952993392944336, 'review': 'The loyalty card is not worth it.', 'classification': 'negative'}],\n",
       "    classification='negative',\n",
       "    classifier_decision='negative',\n",
       "    probabilities=[0.9990077614784241, 0.0005539217963814735, 0.000438391842180863]\n",
       ")"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e20_g4o_elft_ex_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "d29f2748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Classify the sentiment of a review as either 'negative', 'neutral', or 'positive'.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Examples: A list of examples that demonstrate different sentiment classes.\n",
      "\n",
      "Review: The review text to classify.\n",
      "\n",
      "Classifier Decision: The sentiment classification proposed by a model fine-tuned on sentiment.\n",
      "\n",
      "Classification: One word representing the sentiment classification: 'negative', 'neutral', or 'positive' (do not repeat the field name, do not use 'mixed')\n",
      "\n",
      "---\n",
      "\n",
      "Examples:\n",
      "- negative: I remembered this place from a few years ago. It was really bad.\n",
      "- negative: But I've been probably 6 times and have never left impressed. It sucks.\n",
      "- negative: So got beans, rice and tacos, no flavour.\n",
      "- negative: Anyhoos, we waited FOREVER (more like an hour plus) for our food.\n",
      "- negative: The loyalty card is not worth it.\n",
      "\n",
      "Review: Those 2 drinks are part of the HK culture and has years of history. It is so bad.\n",
      "\n",
      "Classifier Decision: negative\n",
      "\n",
      "Classification:\u001b[32m negative\u001b[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\n\\nClassify the sentiment of a review as either 'negative', 'neutral', or 'positive'.\\n\\n---\\n\\nFollow the following format.\\n\\nExamples: A list of examples that demonstrate different sentiment classes.\\n\\nReview: The review text to classify.\\n\\nClassifier Decision: The sentiment classification proposed by a model fine-tuned on sentiment.\\n\\nClassification: One word representing the sentiment classification: 'negative', 'neutral', or 'positive' (do not repeat the field name, do not use 'mixed')\\n\\n---\\n\\nExamples:\\n- negative: I remembered this place from a few years ago. It was really bad.\\n- negative: But I've been probably 6 times and have never left impressed. It sucks.\\n- negative: So got beans, rice and tacos, no flavour.\\n- negative: Anyhoos, we waited FOREVER (more like an hour plus) for our food.\\n- negative: The loyalty card is not worth it.\\n\\nReview: Those 2 drinks are part of the HK culture and has years of history. It is so bad.\\n\\nClassifier Decision: negative\\n\\nClassification:\\x1b[32m negative\\x1b[0m\\n\\n\\n\""
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "da3ed3e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Experiment: E20-G4O-ELFT-EX\n",
      "--------------------------------------------------------------------------------\n",
      "Start time: 2025-03-26 21:36:45\n",
      "Notes: Experiment 20: Evaluate prompt-based model collaboration that includes similar examples\n",
      "Model: gpt-4o-2024-08-06\n",
      "Instance: electra_large_gpt_sentiment_examples\n",
      "Dataset shape: [6530, 4]\n",
      "Examples length: 6530\n",
      "Save directory: results_round2_take2\n",
      "Temperature: 0.1\n",
      "Random seed: 123\n",
      "\n",
      "Running evaluation...\n",
      "Average Metric: 2636 / 3150  (83.7):  48%|████▊     | 3150/6530 [40:08<1:28:48,  1.58s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:opentelemetry.exporter.otlp.proto.http.trace_exporter:Transient error Service Unavailable encountered while exporting span batch, retrying in 1s.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 5485 / 6530  (84.0): 100%|██████████| 6530/6530 [1:30:12<00:00,  1.21it/s]  \n",
      "\n",
      "Columns in results DataFrame:\n",
      "review                 6530 values\n",
      "classification         6530 values\n",
      "prediction             6530 values\n",
      "match                  6530 values\n",
      "classifier_decision    6530 values\n",
      "probabilities          6530 values\n",
      "\n",
      "Source value counts:\n",
      "dynasent_r1            3600\n",
      "sst_local              2210\n",
      "dynasent_r2             720\n",
      "\n",
      "Prediction value counts:\n",
      "negative               2311\n",
      "positive               2234\n",
      "neutral                1985\n",
      "\n",
      "E20-G4O-ELFT-EX Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.8793    0.8639    0.8715      2352\n",
      "     neutral     0.7219    0.7835    0.7514      1829\n",
      "    positive     0.9042    0.8599    0.8815      2349\n",
      "\n",
      "    accuracy                         0.8400      6530\n",
      "   macro avg     0.8351    0.8358    0.8348      6530\n",
      "weighted avg     0.8442    0.8400    0.8415      6530\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative       2032      280        40\n",
      "neutral         222     1433       174\n",
      "positive         57      272      2020\n",
      "\n",
      "\n",
      "E20-G4O-ELFT-EX-DYN-R1 Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.9289    0.8492    0.8872      1200\n",
      "     neutral     0.7568    0.9233    0.8318      1200\n",
      "    positive     0.9346    0.8092    0.8674      1200\n",
      "\n",
      "    accuracy                         0.8606      3600\n",
      "   macro avg     0.8734    0.8606    0.8621      3600\n",
      "weighted avg     0.8734    0.8606    0.8621      3600\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative       1019      164        17\n",
      "neutral          41     1108        51\n",
      "positive         37      192       971\n",
      "\n",
      "\n",
      "E20-G4O-ELFT-EX-DYN-R2 Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.8106    0.8917    0.8492       240\n",
      "     neutral     0.8107    0.6958    0.7489       240\n",
      "    positive     0.8280    0.8625    0.8449       240\n",
      "\n",
      "    accuracy                         0.8167       720\n",
      "   macro avg     0.8164    0.8167    0.8143       720\n",
      "weighted avg     0.8164    0.8167    0.8143       720\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative        214       15        11\n",
      "neutral          41      167        32\n",
      "positive          9       24       207\n",
      "\n",
      "\n",
      "E20-G4O-ELFT-EX-SST Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.8411    0.8761    0.8582       912\n",
      "     neutral     0.5016    0.4062    0.4489       389\n",
      "    positive     0.8910    0.9263    0.9083       909\n",
      "\n",
      "    accuracy                         0.8140      2210\n",
      "   macro avg     0.7445    0.7362    0.7385      2210\n",
      "weighted avg     0.8018    0.8140    0.8068      2210\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative        799      101        12\n",
      "neutral         140      158        91\n",
      "positive         11       56       842\n",
      "\n",
      "Saving results to 'results_round2_take2'...\n",
      "\n",
      "Summary Metrics:\n",
      "Dataset     \tF1 (macro)\tAccuracy\n",
      "---------------------------------------------\n",
      "Merged      \t    83.48\t   84.00\n",
      "DynaSent R1 \t    86.21\t   86.06\n",
      "DynaSent R2 \t    81.43\t   81.67\n",
      "SST-3       \t    73.85\t   81.40\n",
      "\n",
      "Evaluation completed\n",
      "End time: 2025-03-26 23:06:58\n",
      "Duration: 1:30:13.082174\n"
     ]
    }
   ],
   "source": [
    "e20_g4o_elft_ex_results_df, e20_g4o_elft_ex_metrics = evaluate_experiment(\n",
    "    name='E20-G4O-ELFT-EX',\n",
    "    notes='Experiment 20: Evaluate prompt-based model collaboration that includes similar examples',\n",
    "    lm='gpt-4o-2024-08-06',\n",
    "    instance='electra_large_gpt_sentiment_examples',\n",
    "    dataset=test_df,\n",
    "    examples=test_ex,\n",
    "    temperature=temperature,\n",
    "    random_seed=random_seed\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae731205",
   "metadata": {},
   "source": [
    "### E21-G4O-ELFT-BEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "e0233627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch to the correct language model and disable experimental mode\n",
    "lm = dspy.OpenAI(model='gpt-4o-2024-08-06', api_key=openai_key, max_tokens=8192, temperature=temperature)\n",
    "dspy.settings.configure(lm=lm, experimental=False, seed=random_seed)\n",
    "dsp.settings.show_guidelines = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "b029ba7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a test result for the GPT sentiment module\n",
    "e21_g4o_elft_bex_result = electra_large_gpt_sentiment_examples_balanced(review=test_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "9027c83d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    examples=[{'index': 1385, 'similarity_score': 0.9959219694137573, 'review': 'I remembered this place from a few years ago. It was really bad.', 'classification': 'negative'}, {'index': 1770, 'similarity_score': 0.9956880211830139, 'review': \"But I've been probably 6 times and have never left impressed. It sucks.\", 'classification': 'negative'}, {'index': 3642, 'similarity_score': 0.9821950197219849, 'review': 'My husband got the prime rib special and it came out with the salad and cold.', 'classification': 'neutral'}, {'index': 4792, 'similarity_score': 0.9807704091072083, 'review': 'This is brand spankin new so a longer soft opening is definitely necessary especially when dealing with us downtown folks during the lunch rush and after work dinner pickup, they need work.', 'classification': 'neutral'}, {'index': 474, 'similarity_score': 0.9905312061309814, 'review': 'The colors and tech were something to be desired.', 'classification': 'positive'}, {'index': 3014, 'similarity_score': 0.9897524118423462, 'review': \"The food here isn't the greatest in the neighborhood but on the entire east coast.\", 'classification': 'positive'}],\n",
       "    classification='negative',\n",
       "    classifier_decision='negative',\n",
       "    probabilities=[0.9990077614784241, 0.0005539217963814735, 0.000438391842180863]\n",
       ")"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e21_g4o_elft_bex_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "baec1ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Classify the sentiment of a review as either 'negative', 'neutral', or 'positive'.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Examples: A list of examples that demonstrate different sentiment classes.\n",
      "\n",
      "Review: The review text to classify.\n",
      "\n",
      "Classifier Decision: The sentiment classification proposed by a model fine-tuned on sentiment.\n",
      "\n",
      "Classification: One word representing the sentiment classification: 'negative', 'neutral', or 'positive' (do not repeat the field name, do not use 'mixed')\n",
      "\n",
      "---\n",
      "\n",
      "Examples:\n",
      "- negative: I remembered this place from a few years ago. It was really bad.\n",
      "- negative: But I've been probably 6 times and have never left impressed. It sucks.\n",
      "- neutral: My husband got the prime rib special and it came out with the salad and cold.\n",
      "- neutral: This is brand spankin new so a longer soft opening is definitely necessary especially when dealing with us downtown folks during the lunch rush and after work dinner pickup, they need work.\n",
      "- positive: The colors and tech were something to be desired.\n",
      "- positive: The food here isn't the greatest in the neighborhood but on the entire east coast.\n",
      "\n",
      "Review: Those 2 drinks are part of the HK culture and has years of history. It is so bad.\n",
      "\n",
      "Classifier Decision: negative\n",
      "\n",
      "Classification:\u001b[32m negative\u001b[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\n\\nClassify the sentiment of a review as either 'negative', 'neutral', or 'positive'.\\n\\n---\\n\\nFollow the following format.\\n\\nExamples: A list of examples that demonstrate different sentiment classes.\\n\\nReview: The review text to classify.\\n\\nClassifier Decision: The sentiment classification proposed by a model fine-tuned on sentiment.\\n\\nClassification: One word representing the sentiment classification: 'negative', 'neutral', or 'positive' (do not repeat the field name, do not use 'mixed')\\n\\n---\\n\\nExamples:\\n- negative: I remembered this place from a few years ago. It was really bad.\\n- negative: But I've been probably 6 times and have never left impressed. It sucks.\\n- neutral: My husband got the prime rib special and it came out with the salad and cold.\\n- neutral: This is brand spankin new so a longer soft opening is definitely necessary especially when dealing with us downtown folks during the lunch rush and after work dinner pickup, they need work.\\n- positive: The colors and tech were something to be desired.\\n- positive: The food here isn't the greatest in the neighborhood but on the entire east coast.\\n\\nReview: Those 2 drinks are part of the HK culture and has years of history. It is so bad.\\n\\nClassifier Decision: negative\\n\\nClassification:\\x1b[32m negative\\x1b[0m\\n\\n\\n\""
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "06f3108e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Experiment: E21-G4O-ELFT-BEX\n",
      "--------------------------------------------------------------------------------\n",
      "Start time: 2025-03-26 23:11:45\n",
      "Notes: Experiment 21: Evaluate prompt-based model collaboration that includes similar, balanced examples\n",
      "Model: gpt-4o-2024-08-06\n",
      "Instance: electra_large_gpt_sentiment_examples_balanced\n",
      "Dataset shape: [6530, 4]\n",
      "Examples length: 6530\n",
      "Save directory: results_round2_take2\n",
      "Temperature: 0.1\n",
      "Random seed: 123\n",
      "\n",
      "Running evaluation...\n",
      "Average Metric: 5478 / 6530  (83.9): 100%|██████████| 6530/6530 [1:17:57<00:00,  1.40it/s]  \n",
      "\n",
      "Columns in results DataFrame:\n",
      "review                 6530 values\n",
      "classification         6530 values\n",
      "prediction             6530 values\n",
      "match                  6530 values\n",
      "classifier_decision    6530 values\n",
      "probabilities          6530 values\n",
      "\n",
      "Source value counts:\n",
      "dynasent_r1            3600\n",
      "sst_local              2210\n",
      "dynasent_r2             720\n",
      "\n",
      "Prediction value counts:\n",
      "negative               2313\n",
      "positive               2226\n",
      "neutral                1991\n",
      "\n",
      "E21-G4O-ELFT-BEX Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.8768    0.8622    0.8695      2352\n",
      "     neutral     0.7187    0.7824    0.7492      1829\n",
      "    positive     0.9070    0.8595    0.8826      2349\n",
      "\n",
      "    accuracy                         0.8389      6530\n",
      "   macro avg     0.8342    0.8347    0.8338      6530\n",
      "weighted avg     0.8434    0.8389    0.8405      6530\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative       2028      291        33\n",
      "neutral         224     1431       174\n",
      "positive         61      269      2019\n",
      "\n",
      "\n",
      "E21-G4O-ELFT-BEX-DYN-R1 Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.9267    0.8425    0.8826      1200\n",
      "     neutral     0.7543    0.9233    0.8303      1200\n",
      "    positive     0.9385    0.8133    0.8714      1200\n",
      "\n",
      "    accuracy                         0.8597      3600\n",
      "   macro avg     0.8731    0.8597    0.8614      3600\n",
      "weighted avg     0.8731    0.8597    0.8614      3600\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative       1011      176        13\n",
      "neutral          41     1108        51\n",
      "positive         39      185       976\n",
      "\n",
      "\n",
      "E21-G4O-ELFT-BEX-DYN-R2 Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.8106    0.8917    0.8492       240\n",
      "     neutral     0.8038    0.7000    0.7483       240\n",
      "    positive     0.8259    0.8500    0.8378       240\n",
      "\n",
      "    accuracy                         0.8139       720\n",
      "   macro avg     0.8134    0.8139    0.8118       720\n",
      "weighted avg     0.8134    0.8139    0.8118       720\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative        214       17         9\n",
      "neutral          38      168        34\n",
      "positive         12       24       204\n",
      "\n",
      "\n",
      "E21-G4O-ELFT-BEX-SST Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.8382    0.8805    0.8588       912\n",
      "     neutral     0.4952    0.3985    0.4416       389\n",
      "    positive     0.8935    0.9230    0.9080       909\n",
      "\n",
      "    accuracy                         0.8131      2210\n",
      "   macro avg     0.7423    0.7340    0.7361      2210\n",
      "weighted avg     0.8006    0.8131    0.8056      2210\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative        803       98        11\n",
      "neutral         145      155        89\n",
      "positive         10       60       839\n",
      "\n",
      "Saving results to 'results_round2_take2'...\n",
      "\n",
      "Summary Metrics:\n",
      "Dataset     \tF1 (macro)\tAccuracy\n",
      "---------------------------------------------\n",
      "Merged      \t    83.38\t   83.89\n",
      "DynaSent R1 \t    86.14\t   85.97\n",
      "DynaSent R2 \t    81.18\t   81.39\n",
      "SST-3       \t    73.61\t   81.31\n",
      "\n",
      "Evaluation completed\n",
      "End time: 2025-03-27 00:29:44\n",
      "Duration: 1:17:58.219067\n"
     ]
    }
   ],
   "source": [
    "e21_g4o_elft_bex_df, e21_g4o_elft_bex_metrics = evaluate_experiment(\n",
    "    name='E21-G4O-ELFT-BEX',\n",
    "    notes='Experiment 21: Evaluate prompt-based model collaboration that includes similar, balanced examples',\n",
    "    lm='gpt-4o-2024-08-06',\n",
    "    instance='electra_large_gpt_sentiment_examples_balanced',\n",
    "    dataset=test_df,\n",
    "    examples=test_ex,\n",
    "    temperature=temperature,\n",
    "    random_seed=random_seed\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f882630",
   "metadata": {},
   "source": [
    "### E22-G4O-ELFT-PR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "59eb87f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch to the correct language model and disable experimental mode\n",
    "lm = dspy.OpenAI(model='gpt-4o-2024-08-06', api_key=openai_key, max_tokens=8192, temperature=temperature)\n",
    "dspy.settings.configure(lm=lm, experimental=False, seed=random_seed)\n",
    "dsp.settings.show_guidelines = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "94f42f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a test result for the GPT sentiment module\n",
    "e22_g4o_elft_pr_result = electra_large_gpt_sentiment_probs(review=test_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "8f7bf04b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    classification='negative',\n",
       "    negative_probability='99.90%',\n",
       "    neutral_probability='0.06%',\n",
       "    positive_probability='0.04%'\n",
       ")"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e22_g4o_elft_pr_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "2b3715ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Classify the sentiment of a review as either 'negative', 'neutral', or 'positive'.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Review: The review text to classify.\n",
      "\n",
      "Negative Probability: Probability the review is negative from a model fine-tuned on sentiment\n",
      "\n",
      "Neutral Probability: Probability the review is neutral from a model fine-tuned on sentiment\n",
      "\n",
      "Positive Probability: Probability the review is positive from a model fine-tuned on sentiment\n",
      "\n",
      "Classification: One word representing the sentiment classification: 'negative', 'neutral', or 'positive' (do not repeat the field name, do not use 'mixed')\n",
      "\n",
      "---\n",
      "\n",
      "Review: Those 2 drinks are part of the HK culture and has years of history. It is so bad.\n",
      "\n",
      "Negative Probability: 99.90%\n",
      "\n",
      "Neutral Probability: 0.06%\n",
      "\n",
      "Positive Probability: 0.04%\n",
      "\n",
      "Classification:\u001b[32m negative\u001b[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\n\\nClassify the sentiment of a review as either 'negative', 'neutral', or 'positive'.\\n\\n---\\n\\nFollow the following format.\\n\\nReview: The review text to classify.\\n\\nNegative Probability: Probability the review is negative from a model fine-tuned on sentiment\\n\\nNeutral Probability: Probability the review is neutral from a model fine-tuned on sentiment\\n\\nPositive Probability: Probability the review is positive from a model fine-tuned on sentiment\\n\\nClassification: One word representing the sentiment classification: 'negative', 'neutral', or 'positive' (do not repeat the field name, do not use 'mixed')\\n\\n---\\n\\nReview: Those 2 drinks are part of the HK culture and has years of history. It is so bad.\\n\\nNegative Probability: 99.90%\\n\\nNeutral Probability: 0.06%\\n\\nPositive Probability: 0.04%\\n\\nClassification:\\x1b[32m negative\\x1b[0m\\n\\n\\n\""
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "2fdecb20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Experiment: E22-G4O-ELFT-PR\n",
      "--------------------------------------------------------------------------------\n",
      "Start time: 2025-03-27 00:29:45\n",
      "Notes: Experiment 22: Evaluate prompt-based model collaboration with probabilities\n",
      "Model: gpt-4o-2024-08-06\n",
      "Instance: electra_large_gpt_sentiment_probs\n",
      "Dataset shape: [6530, 4]\n",
      "Examples length: 6530\n",
      "Save directory: results_round2_take2\n",
      "Temperature: 0.1\n",
      "Random seed: 123\n",
      "\n",
      "Running evaluation...\n",
      "Average Metric: 5477 / 6530  (83.9): 100%|██████████| 6530/6530 [1:38:22<00:00,  1.11it/s]  \n",
      "\n",
      "Columns in results DataFrame:\n",
      "review                 6530 values\n",
      "classification         6530 values\n",
      "prediction             6530 values\n",
      "match                  6530 values\n",
      "\n",
      "Source value counts:\n",
      "dynasent_r1            3600\n",
      "sst_local              2210\n",
      "dynasent_r2             720\n",
      "\n",
      "Prediction value counts:\n",
      "positive               2328\n",
      "negative               2294\n",
      "neutral                1908\n",
      "\n",
      "E22-G4O-ELFT-PR Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.8749    0.8533    0.8640      2352\n",
      "     neutral     0.7390    0.7709    0.7546      1829\n",
      "    positive     0.8849    0.8770    0.8809      2349\n",
      "\n",
      "    accuracy                         0.8387      6530\n",
      "   macro avg     0.8329    0.8337    0.8332      6530\n",
      "weighted avg     0.8404    0.8387    0.8394      6530\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative       2007      273        72\n",
      "neutral         223     1410       196\n",
      "positive         64      225      2060\n",
      "\n",
      "\n",
      "E22-G4O-ELFT-PR-DYN-R1 Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.9260    0.8342    0.8777      1200\n",
      "     neutral     0.7788    0.9242    0.8453      1200\n",
      "    positive     0.9196    0.8392    0.8776      1200\n",
      "\n",
      "    accuracy                         0.8658      3600\n",
      "   macro avg     0.8748    0.8658    0.8668      3600\n",
      "weighted avg     0.8748    0.8658    0.8668      3600\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative       1001      162        37\n",
      "neutral          40     1109        51\n",
      "positive         40      153      1007\n",
      "\n",
      "\n",
      "E22-G4O-ELFT-PR-DYN-R2 Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.7962    0.8625    0.8280       240\n",
      "     neutral     0.7990    0.6625    0.7244       240\n",
      "    positive     0.7893    0.8583    0.8224       240\n",
      "\n",
      "    accuracy                         0.7944       720\n",
      "   macro avg     0.7948    0.7944    0.7916       720\n",
      "weighted avg     0.7948    0.7944    0.7916       720\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative        207       19        14\n",
      "neutral          40      159        41\n",
      "positive         13       21       206\n",
      "\n",
      "\n",
      "E22-G4O-ELFT-PR-SST Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.8384    0.8761    0.8568       912\n",
      "     neutral     0.4982    0.3650    0.4214       389\n",
      "    positive     0.8714    0.9318    0.9006       909\n",
      "\n",
      "    accuracy                         0.8090      2210\n",
      "   macro avg     0.7360    0.7243    0.7263      2210\n",
      "weighted avg     0.7921    0.8090    0.7982      2210\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative        799       92        21\n",
      "neutral         143      142       104\n",
      "positive         11       51       847\n",
      "\n",
      "Saving results to 'results_round2_take2'...\n",
      "\n",
      "Summary Metrics:\n",
      "Dataset     \tF1 (macro)\tAccuracy\n",
      "---------------------------------------------\n",
      "Merged      \t    83.32\t   83.87\n",
      "DynaSent R1 \t    86.68\t   86.58\n",
      "DynaSent R2 \t    79.16\t   79.44\n",
      "SST-3       \t    72.63\t   80.90\n",
      "\n",
      "Evaluation completed\n",
      "End time: 2025-03-27 02:08:08\n",
      "Duration: 1:38:22.558328\n"
     ]
    }
   ],
   "source": [
    "e22_g4o_elft_pr_results_df, e22_g4o_elft_pr_metrics = evaluate_experiment(\n",
    "    name='E22-G4O-ELFT-PR',\n",
    "    notes='Experiment 22: Evaluate prompt-based model collaboration with probabilities',\n",
    "    lm='gpt-4o-2024-08-06',\n",
    "    instance='electra_large_gpt_sentiment_probs',\n",
    "    dataset=test_df,\n",
    "    examples=test_ex,\n",
    "    temperature=temperature,\n",
    "    random_seed=random_seed\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80d39fb",
   "metadata": {},
   "source": [
    "### E23-G4O-ELFT-PR2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "dde8c794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch to the correct language model and disable experimental mode\n",
    "lm = dspy.OpenAI(model='gpt-4o-2024-08-06', api_key=openai_key, max_tokens=8192, temperature=temperature)\n",
    "dspy.settings.configure(lm=lm, experimental=False, seed=random_seed)\n",
    "dsp.settings.show_guidelines = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "264137ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a test result for the GPT sentiment module\n",
    "e23_g4o_elft_pr2_result = electra_large_gpt_sentiment_pred_probs(review=test_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "06b38a7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    classification='negative',\n",
       "    classifier_decision='negative',\n",
       "    negative_probability='99.90%',\n",
       "    neutral_probability='0.06%',\n",
       "    positive_probability='0.04%'\n",
       ")"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e23_g4o_elft_pr2_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "2580cc6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Classify the sentiment of a review as either 'negative', 'neutral', or 'positive'.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Review: The review text to classify.\n",
      "\n",
      "Classifier Decision: The sentiment classification proposed by a model fine-tuned on sentiment.\n",
      "\n",
      "Negative Probability: Probability the review is negative\n",
      "\n",
      "Neutral Probability: Probability the review is neutral\n",
      "\n",
      "Positive Probability: Probability the review is positive\n",
      "\n",
      "Classification: One word representing the sentiment classification: 'negative', 'neutral', or 'positive' (do not repeat the field name, do not use 'mixed')\n",
      "\n",
      "---\n",
      "\n",
      "Review: Those 2 drinks are part of the HK culture and has years of history. It is so bad.\n",
      "\n",
      "Classifier Decision: negative\n",
      "\n",
      "Negative Probability: 99.90%\n",
      "\n",
      "Neutral Probability: 0.06%\n",
      "\n",
      "Positive Probability: 0.04%\n",
      "\n",
      "Classification:\u001b[32m negative\u001b[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\n\\nClassify the sentiment of a review as either 'negative', 'neutral', or 'positive'.\\n\\n---\\n\\nFollow the following format.\\n\\nReview: The review text to classify.\\n\\nClassifier Decision: The sentiment classification proposed by a model fine-tuned on sentiment.\\n\\nNegative Probability: Probability the review is negative\\n\\nNeutral Probability: Probability the review is neutral\\n\\nPositive Probability: Probability the review is positive\\n\\nClassification: One word representing the sentiment classification: 'negative', 'neutral', or 'positive' (do not repeat the field name, do not use 'mixed')\\n\\n---\\n\\nReview: Those 2 drinks are part of the HK culture and has years of history. It is so bad.\\n\\nClassifier Decision: negative\\n\\nNegative Probability: 99.90%\\n\\nNeutral Probability: 0.06%\\n\\nPositive Probability: 0.04%\\n\\nClassification:\\x1b[32m negative\\x1b[0m\\n\\n\\n\""
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "7a2487a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Experiment: E23-G4O-ELFT-PR2\n",
      "--------------------------------------------------------------------------------\n",
      "Start time: 2025-03-27 02:12:46\n",
      "Notes: Experiment 23: Evaluate prompt-based model collaboration with prediction and probabilities\n",
      "Model: gpt-4o-2024-08-06\n",
      "Instance: electra_large_gpt_sentiment_pred_probs\n",
      "Dataset shape: [6530, 4]\n",
      "Examples length: 6530\n",
      "Save directory: results_round2_take2\n",
      "Temperature: 0.1\n",
      "Random seed: 123\n",
      "\n",
      "Running evaluation...\n",
      "Average Metric: 5492 / 6530  (84.1): 100%|██████████| 6530/6530 [1:37:38<00:00,  1.11it/s]  \n",
      "\n",
      "Columns in results DataFrame:\n",
      "review                 6530 values\n",
      "classification         6530 values\n",
      "prediction             6530 values\n",
      "match                  6530 values\n",
      "classifier_decision    6530 values\n",
      "\n",
      "Source value counts:\n",
      "dynasent_r1            3600\n",
      "sst_local              2210\n",
      "dynasent_r2             720\n",
      "\n",
      "Prediction value counts:\n",
      "negative               2309\n",
      "positive               2305\n",
      "neutral                1916\n",
      "\n",
      "E23-G4O-ELFT-PR2 Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.8761    0.8601    0.8681      2352\n",
      "     neutral     0.7375    0.7726    0.7546      1829\n",
      "    positive     0.8920    0.8753    0.8835      2349\n",
      "\n",
      "    accuracy                         0.8410      6530\n",
      "   macro avg     0.8352    0.8360    0.8354      6530\n",
      "weighted avg     0.8430    0.8410    0.8418      6530\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative       2023      273        56\n",
      "neutral         223     1413       193\n",
      "positive         63      230      2056\n",
      "\n",
      "\n",
      "E23-G4O-ELFT-PR2-DYN-R1 Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.9275    0.8425    0.8830      1200\n",
      "     neutral     0.7757    0.9250    0.8438      1200\n",
      "    positive     0.9305    0.8367    0.8811      1200\n",
      "\n",
      "    accuracy                         0.8681      3600\n",
      "   macro avg     0.8779    0.8681    0.8693      3600\n",
      "weighted avg     0.8779    0.8681    0.8693      3600\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative       1011      164        25\n",
      "neutral          40     1110        50\n",
      "positive         39      157      1004\n",
      "\n",
      "\n",
      "E23-G4O-ELFT-PR2-DYN-R2 Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.7992    0.8792    0.8373       240\n",
      "     neutral     0.8030    0.6625    0.7260       240\n",
      "    positive     0.7984    0.8583    0.8273       240\n",
      "\n",
      "    accuracy                         0.8000       720\n",
      "   macro avg     0.8002    0.8000    0.7969       720\n",
      "weighted avg     0.8002    0.8000    0.7969       720\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative        211       18        11\n",
      "neutral          40      159        41\n",
      "positive         13       21       206\n",
      "\n",
      "\n",
      "E23-G4O-ELFT-PR2-SST Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.8387    0.8783    0.8581       912\n",
      "     neutral     0.5017    0.3702    0.4260       389\n",
      "    positive     0.8740    0.9307    0.9014       909\n",
      "\n",
      "    accuracy                         0.8104      2210\n",
      "   macro avg     0.7382    0.7264    0.7285      2210\n",
      "weighted avg     0.7939    0.8104    0.7999      2210\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative        801       91        20\n",
      "neutral         143      144       102\n",
      "positive         11       52       846\n",
      "\n",
      "Saving results to 'results_round2_take2'...\n",
      "\n",
      "Summary Metrics:\n",
      "Dataset     \tF1 (macro)\tAccuracy\n",
      "---------------------------------------------\n",
      "Merged      \t    83.54\t   84.10\n",
      "DynaSent R1 \t    86.93\t   86.81\n",
      "DynaSent R2 \t    79.69\t   80.00\n",
      "SST-3       \t    72.85\t   81.04\n",
      "\n",
      "Evaluation completed\n",
      "End time: 2025-03-27 03:50:25\n",
      "Duration: 1:37:39.351041\n"
     ]
    }
   ],
   "source": [
    "e23_g4o_elft_pr2_df, e23_g4o_elft_pr2_metrics = evaluate_experiment(\n",
    "    name='E23-G4O-ELFT-PR2',\n",
    "    notes='Experiment 23: Evaluate prompt-based model collaboration with prediction and probabilities',\n",
    "    lm='gpt-4o-2024-08-06',\n",
    "    instance='electra_large_gpt_sentiment_pred_probs',\n",
    "    dataset=test_df,\n",
    "    examples=test_ex,\n",
    "    temperature=temperature,\n",
    "    random_seed=random_seed\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd855f2",
   "metadata": {},
   "source": [
    "### E24-G4O-ELFT-EX-PR2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "ff6cd9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch to the correct language model and disable experimental mode\n",
    "lm = dspy.OpenAI(model='gpt-4o-2024-08-06', api_key=openai_key, max_tokens=8192, temperature=temperature)\n",
    "dspy.settings.configure(lm=lm, experimental=False, seed=random_seed)\n",
    "dsp.settings.show_guidelines = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "ec2d099e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a test result for the GPT sentiment module\n",
    "e24_g4o_elft_ex_pr2_result = electra_large_gpt_sentiment_pred_probs_examples(review=test_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "87a86afc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    examples=[{'index': 1385, 'similarity_score': 0.9959219694137573, 'review': 'I remembered this place from a few years ago. It was really bad.', 'classification': 'negative'}, {'index': 1770, 'similarity_score': 0.9956880211830139, 'review': \"But I've been probably 6 times and have never left impressed. It sucks.\", 'classification': 'negative'}, {'index': 1948, 'similarity_score': 0.9954952597618103, 'review': 'So got beans, rice and tacos, no flavour.', 'classification': 'negative'}, {'index': 3282, 'similarity_score': 0.995331346988678, 'review': 'Anyhoos, we waited FOREVER (more like an hour plus) for our food.', 'classification': 'negative'}, {'index': 1391, 'similarity_score': 0.9952993392944336, 'review': 'The loyalty card is not worth it.', 'classification': 'negative'}],\n",
       "    classification='negative',\n",
       "    classifier_decision='negative',\n",
       "    negative_probability='99.90%',\n",
       "    neutral_probability='0.06%',\n",
       "    positive_probability='0.04%'\n",
       ")"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e24_g4o_elft_ex_pr2_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "d1ad7072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Classify the sentiment of a review as either 'negative', 'neutral', or 'positive'.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Examples: A list of examples that demonstrate different sentiment classes.\n",
      "\n",
      "Review: The review text to classify.\n",
      "\n",
      "Classifier Decision: The sentiment classification proposed by a model fine-tuned on sentiment.\n",
      "\n",
      "Negative Probability: Probability the review is negative\n",
      "\n",
      "Neutral Probability: Probability the review is neutral\n",
      "\n",
      "Positive Probability: Probability the review is positive\n",
      "\n",
      "Classification: One word representing the sentiment classification: 'negative', 'neutral', or 'positive' (do not repeat the field name, do not use 'mixed')\n",
      "\n",
      "---\n",
      "\n",
      "Examples:\n",
      "- negative: I remembered this place from a few years ago. It was really bad.\n",
      "- negative: But I've been probably 6 times and have never left impressed. It sucks.\n",
      "- negative: So got beans, rice and tacos, no flavour.\n",
      "- negative: Anyhoos, we waited FOREVER (more like an hour plus) for our food.\n",
      "- negative: The loyalty card is not worth it.\n",
      "\n",
      "Review: Those 2 drinks are part of the HK culture and has years of history. It is so bad.\n",
      "\n",
      "Classifier Decision: negative\n",
      "\n",
      "Negative Probability: 99.90%\n",
      "\n",
      "Neutral Probability: 0.06%\n",
      "\n",
      "Positive Probability: 0.04%\n",
      "\n",
      "Classification:\u001b[32m negative\u001b[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\n\\nClassify the sentiment of a review as either 'negative', 'neutral', or 'positive'.\\n\\n---\\n\\nFollow the following format.\\n\\nExamples: A list of examples that demonstrate different sentiment classes.\\n\\nReview: The review text to classify.\\n\\nClassifier Decision: The sentiment classification proposed by a model fine-tuned on sentiment.\\n\\nNegative Probability: Probability the review is negative\\n\\nNeutral Probability: Probability the review is neutral\\n\\nPositive Probability: Probability the review is positive\\n\\nClassification: One word representing the sentiment classification: 'negative', 'neutral', or 'positive' (do not repeat the field name, do not use 'mixed')\\n\\n---\\n\\nExamples:\\n- negative: I remembered this place from a few years ago. It was really bad.\\n- negative: But I've been probably 6 times and have never left impressed. It sucks.\\n- negative: So got beans, rice and tacos, no flavour.\\n- negative: Anyhoos, we waited FOREVER (more like an hour plus) for our food.\\n- negative: The loyalty card is not worth it.\\n\\nReview: Those 2 drinks are part of the HK culture and has years of history. It is so bad.\\n\\nClassifier Decision: negative\\n\\nNegative Probability: 99.90%\\n\\nNeutral Probability: 0.06%\\n\\nPositive Probability: 0.04%\\n\\nClassification:\\x1b[32m negative\\x1b[0m\\n\\n\\n\""
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "b21cc22e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Experiment: E24-G4O-ELFT-EX-PR2\n",
      "--------------------------------------------------------------------------------\n",
      "Start time: 2025-03-27 03:54:46\n",
      "Notes: Experiment 24: Evaluate prompt-based model collaboration with prediction, probabilities, and similar examples\n",
      "Model: gpt-4o-2024-08-06\n",
      "Instance: electra_large_gpt_sentiment_pred_probs_examples\n",
      "Dataset shape: [6530, 4]\n",
      "Examples length: 6530\n",
      "Save directory: results_round2_take2\n",
      "Temperature: 0.1\n",
      "Random seed: 123\n",
      "\n",
      "Running evaluation...\n",
      "Average Metric: 2154 / 2574  (83.7):  39%|███▉      | 2574/6530 [30:48<48:14,  1.37it/s]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:opentelemetry.exporter.otlp.proto.http.trace_exporter:Transient error Service Unavailable encountered while exporting span batch, retrying in 1s.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 5478 / 6530  (83.9): 100%|██████████| 6530/6530 [1:17:25<00:00,  1.41it/s]\n",
      "\n",
      "Columns in results DataFrame:\n",
      "review                 6530 values\n",
      "classification         6530 values\n",
      "prediction             6530 values\n",
      "match                  6530 values\n",
      "classifier_decision    6530 values\n",
      "\n",
      "Source value counts:\n",
      "dynasent_r1            3600\n",
      "sst_local              2210\n",
      "dynasent_r2             720\n",
      "\n",
      "Prediction value counts:\n",
      "positive               2319\n",
      "negative               2295\n",
      "neutral                1916\n",
      "\n",
      "E24-G4O-ELFT-EX-PR2 Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.8749    0.8537    0.8642      2352\n",
      "     neutral     0.7375    0.7726    0.7546      1829\n",
      "    positive     0.8870    0.8757    0.8813      2349\n",
      "\n",
      "    accuracy                         0.8389      6530\n",
      "   macro avg     0.8331    0.8340    0.8334      6530\n",
      "weighted avg     0.8408    0.8389    0.8397      6530\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative       2008      275        69\n",
      "neutral         223     1413       193\n",
      "positive         64      228      2057\n",
      "\n",
      "\n",
      "E24-G4O-ELFT-EX-PR2-DYN-R1 Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.9261    0.8358    0.8787      1200\n",
      "     neutral     0.7751    0.9250    0.8435      1200\n",
      "    positive     0.9263    0.8375    0.8796      1200\n",
      "\n",
      "    accuracy                         0.8661      3600\n",
      "   macro avg     0.8758    0.8661    0.8673      3600\n",
      "weighted avg     0.8758    0.8661    0.8673      3600\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative       1003      167        30\n",
      "neutral          40     1110        50\n",
      "positive         40      155      1005\n",
      "\n",
      "\n",
      "E24-G4O-ELFT-EX-PR2-DYN-R2 Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.7954    0.8583    0.8257       240\n",
      "     neutral     0.8081    0.6667    0.7306       240\n",
      "    positive     0.7833    0.8583    0.8191       240\n",
      "\n",
      "    accuracy                         0.7944       720\n",
      "   macro avg     0.7956    0.7944    0.7918       720\n",
      "weighted avg     0.7956    0.7944    0.7918       720\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative        206       17        17\n",
      "neutral          40      160        40\n",
      "positive         13       21       206\n",
      "\n",
      "\n",
      "E24-G4O-ELFT-EX-PR2-SST Multi-Class Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.8384    0.8761    0.8568       912\n",
      "     neutral     0.5000    0.3676    0.4237       389\n",
      "    positive     0.8713    0.9307    0.9000       909\n",
      "\n",
      "    accuracy                         0.8090      2210\n",
      "   macro avg     0.7366    0.7248    0.7268      2210\n",
      "weighted avg     0.7924    0.8090    0.7984      2210\n",
      "\n",
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative        799       91        22\n",
      "neutral         143      143       103\n",
      "positive         11       52       846\n",
      "\n",
      "Saving results to 'results_round2_take2'...\n",
      "\n",
      "Summary Metrics:\n",
      "Dataset     \tF1 (macro)\tAccuracy\n",
      "---------------------------------------------\n",
      "Merged      \t    83.34\t   83.89\n",
      "DynaSent R1 \t    86.73\t   86.61\n",
      "DynaSent R2 \t    79.18\t   79.44\n",
      "SST-3       \t    72.68\t   80.90\n",
      "\n",
      "Evaluation completed\n",
      "End time: 2025-03-27 05:12:12\n",
      "Duration: 1:17:26.071622\n"
     ]
    }
   ],
   "source": [
    "e24_g4o_elft_ex_pr2_df, e24_g4o_elft_ex_pr2_metrics = evaluate_experiment(\n",
    "    name='E24-G4O-ELFT-EX-PR2',\n",
    "    notes='Experiment 24: Evaluate prompt-based model collaboration with prediction, probabilities, and similar examples',\n",
    "    lm='gpt-4o-2024-08-06',\n",
    "    instance='electra_large_gpt_sentiment_pred_probs_examples',\n",
    "    dataset=test_df,\n",
    "    examples=test_ex,\n",
    "    temperature=temperature,\n",
    "    random_seed=random_seed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6289da7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlu",
   "language": "python",
   "name": "nlu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
